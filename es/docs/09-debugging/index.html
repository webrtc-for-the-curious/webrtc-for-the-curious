<!doctype html><html lang=es dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Debugging # Debugging WebRTC can be a daunting task. There are a lot of moving parts, and they all can break independently. If you aren&rsquo;t careful, you can lose weeks of time looking at the wrong things. When you do finally find the part that is broken, you will need to learn a bit to understand why.
This chapter will get you in the mindset to debug WebRTC. It will show you how to break down the problem."><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://webrtcforthecurious.com/es/docs/09-debugging/"><meta property="og:site_name" content="WebRTC para los curiosos"><meta property="og:title" content="Debugging"><meta property="og:description" content="Debugging # Debugging WebRTC can be a daunting task. There are a lot of moving parts, and they all can break independently. If you aren’t careful, you can lose weeks of time looking at the wrong things. When you do finally find the part that is broken, you will need to learn a bit to understand why.
This chapter will get you in the mindset to debug WebRTC. It will show you how to break down the problem."><meta property="og:locale" content="es"><meta property="og:type" content="article"><meta property="article:section" content="docs"><meta property="article:modified_time" content="2022-10-13T16:52:43-05:00"><title>Debugging | WebRTC para los curiosos</title>
<link rel=manifest href=/manifest.json><link rel=icon href=/favicon.png><link rel=canonical href=https://webrtcforthecurious.com/es/docs/09-debugging/><link rel=alternate hreflang=en href=https://webrtcforthecurious.com/docs/09-debugging/ title=Debugging><link rel=alternate hreflang=ru href=https://webrtcforthecurious.com/ru/docs/09-debugging/ title=Debugging><link rel=alternate hreflang=sv href=https://webrtcforthecurious.com/sv/docs/09-debugging/ title=Felsökning><link rel=alternate hreflang=zh href=https://webrtcforthecurious.com/zh/docs/09-debugging/ title=调试><link rel=alternate hreflang=ja href=https://webrtcforthecurious.com/ja/docs/09-debugging/ title=デバッグ><link rel=alternate hreflang=fa href=https://webrtcforthecurious.com/fa/docs/09-debugging/ title="اشکال زدایی"><link rel=alternate hreflang=fr href=https://webrtcforthecurious.com/fr/docs/09-debugging/ title=Debugging><link rel=alternate hreflang=id href=https://webrtcforthecurious.com/id/docs/09-debugging/ title=Debugging><link rel=alternate hreflang=tr href=https://webrtcforthecurious.com/tr/docs/09-debugging/ title="Hata Ayıklama"><link rel=alternate hreflang=ko href=https://webrtcforthecurious.com/ko/docs/09-debugging/ title=디버깅><link rel=stylesheet href=/book.min.309b7ed028807cdb68d8d61e26d609f48369c098dbf5e4d8c0dcf4cdf49feafc.css integrity="sha256-MJt+0CiAfNto2NYeJtYJ9INpwJjb9eTYwNz0zfSf6vw=" crossorigin=anonymous><script defer src=/fuse.min.js></script><script defer src=/es.search.min.2d38175f41c1ca411f8cd73a75ec2ba9298a483c0946aaeb5fa89734ec217c31.js integrity="sha256-LTgXX0HBykEfjNc6dewrqSmKSDwJRqrrX6iXNOwhfDE=" crossorigin=anonymous></script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/es/><span>WebRTC para los curiosos</span></a></h2><div class="book-search hidden"><input type=text id=book-search-input placeholder=Buscar aria-label=Buscar maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script><ul class=book-languages><li><input type=checkbox id=languages class=toggle>
<label for=languages class="flex justify-between"><a role=button class="flex align-center"><img src=/svg/translate.svg class=book-icon alt=Languages>
Español</a></label><ul><li><a href=https://webrtcforthecurious.com/docs/09-debugging/>English</a></li><li><a href=https://webrtcforthecurious.com/ru/docs/09-debugging/>Русский</a></li><li><a href=https://webrtcforthecurious.com/sv/docs/09-debugging/>Svenska</a></li><li><a href=https://webrtcforthecurious.com/zh/docs/09-debugging/>简体中文</a></li><li><a href=https://webrtcforthecurious.com/ja/docs/09-debugging/>日本語</a></li><li><a href=https://webrtcforthecurious.com/fa/docs/09-debugging/>Persian</a></li><li><a href=https://webrtcforthecurious.com/fr/docs/09-debugging/>Français</a></li><li><a href=https://webrtcforthecurious.com/id/docs/09-debugging/>Bahasa Indonesia</a></li><li><a href=https://webrtcforthecurious.com/tr/docs/09-debugging/>Türkçe</a></li><li><a href=https://webrtcforthecurious.com/ko/docs/09-debugging/>한국어</a></li></ul></li></ul><ul><li><a href=/es/docs/01-what-why-and-how/>¿Qué, Por qué y Cómo?</a></li><li><a href=/es/docs/02-signaling/>Signaling</a></li><li><a href=/es/docs/03-connecting/>Connecting</a></li><li><a href=/es/docs/04-securing/>Securing</a></li><li><a href=/es/docs/05-real-time-networking/>Real-time Networking</a></li><li><a href=/es/docs/06-media-communication/>Media Communication</a></li><li><a href=/es/docs/07-data-communication/>Data Communication</a></li><li><a href=/es/docs/08-applied-webrtc/>Applied WebRTC</a></li><li><a href=/es/docs/09-debugging/ class=active>Debugging</a></li><li><a href=/es/docs/10-history-of-webrtc/>History</a></li><li><a href=/es/docs/11-faq/>FAQ</a></li><li><a href=/es/docs/12-glossary/>Glossary</a></li><li><a href=/es/docs/13-reference/>Reference</a></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu>
</label><strong>Debugging</strong>
<label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#isolate-the-problem>Isolate The Problem</a><ul><li><a href=#signaling-failure>Signaling Failure</a></li><li><a href=#networking-failure>Networking Failure</a></li><li><a href=#security-failure>Security Failure</a></li><li><a href=#media-failure>Media Failure</a></li><li><a href=#data-failure>Data Failure</a></li></ul></li><li><a href=#tools-of-the-trade>Tools of the trade</a><ul><li><a href=#netcat-nc>netcat (nc)</a></li><li><a href=#tcpdump>tcpdump</a></li><li><a href=#wireshark>Wireshark</a></li><li><a href=#webrtc-internals>webrtc-internals</a></li></ul></li><li><a href=#latency>Latency</a><ul><li><a href=#manual-end-to-end-latency-measurement>Manual end-to-end latency measurement</a></li><li><a href=#automatic-end-to-end-latency-measurement>Automatic end-to-end latency measurement</a></li><li><a href=#latency-debugging-tips>Latency Debugging Tips</a></li></ul></li></ul></nav></aside></header><article class="markdown book-article"><h1 id=debugging>Debugging
<a class=anchor href=#debugging>#</a></h1><p>Debugging WebRTC can be a daunting task. There are a lot of moving parts, and they all can break independently. If you aren&rsquo;t careful, you can lose weeks of time looking at the wrong things. When you do finally find the part that is broken, you will need to learn a bit to understand why.</p><p>This chapter will get you in the mindset to debug WebRTC. It will show you how to break down the problem. After we know the problem, we will give a quick tour of the popular debugging tools.</p><h2 id=isolate-the-problem>Isolate The Problem
<a class=anchor href=#isolate-the-problem>#</a></h2><p>When debugging, you need to isolate where the issue is coming from. Start from the beginning of the&mldr;</p><h3 id=signaling-failure>Signaling Failure
<a class=anchor href=#signaling-failure>#</a></h3><h3 id=networking-failure>Networking Failure
<a class=anchor href=#networking-failure>#</a></h3><p>Test your STUN server using netcat:</p><ol><li><p>Prepare the <strong>20-byte</strong> binding request packet:</p><pre tabindex=0><code>echo -ne &#34;\x00\x01\x00\x00\x21\x12\xA4\x42TESTTESTTEST&#34; | hexdump -C
00000000  00 01 00 00 21 12 a4 42  54 45 53 54 54 45 53 54  |....!..BTESTTEST|
00000010  54 45 53 54                                       |TEST|
00000014
</code></pre><p>Interpretation:</p><ul><li><code>00 01</code> is the message type.</li><li><code>00 00</code> is the length of the data section.</li><li><code>21 12 a4 42</code> is the magic cookie.</li><li>and <code>54 45 53 54 54 45 53 54 54 45 53 54</code> (Decodes to ASCII: <code>TESTTESTTEST</code>) is the 12-byte transaction ID.</li></ul></li><li><p>Send the request and wait for the <strong>32 byte</strong> response:</p><pre tabindex=0><code>stunserver=stun1.l.google.com;stunport=19302;listenport=20000;echo -ne &#34;\x00\x01\x00\x00\x21\x12\xA4\x42TESTTESTTEST&#34; | nc -u -p $listenport $stunserver $stunport -w 1 | hexdump -C
00000000  01 01 00 0c 21 12 a4 42  54 45 53 54 54 45 53 54  |....!..BTESTTEST|
00000010  54 45 53 54 00 20 00 08  00 01 6f 32 7f 36 de 89  |TEST. ....o2.6..|
00000020
</code></pre><p>Interpretation:</p><ul><li><code>01 01</code> is the message type</li><li><code>00 0c</code> is the length of the data section which decodes to 12 in decimal</li><li><code>21 12 a4 42</code> is the magic cookie</li><li>and <code>54 45 53 54 54 45 53 54 54 45 53 54</code> (Decodes to ASCII: <code>TESTTESTTEST</code>) is the 12-byte transaction ID.</li><li><code>00 20 00 08 00 01 6f 32 7f 36 de 89</code> is the 12-byte data, interpretation:<ul><li><code>00 20</code> is the type: <code>XOR-MAPPED-ADDRESS</code></li><li><code>00 08</code> is the length of the value section which decodes to 8 in decimal</li><li><code>00 01 6f 32 7f 36 de 89</code> is the data value, interpretation:<ul><li><code>00 01</code> is the address type (IPv4)</li><li><code>6f 32</code> is the XOR-mapped port</li><li><code>7f 36 de 89</code> is the XOR-mapped IP address</li></ul></li></ul></li></ul></li></ol><p>Decoding the XOR-mapped section is cumbersome, but we can trick the stun server to perform a dummy XOR-mapping, by supplying an (invalid) dummy magic cookie set to <code>00 00 00 00</code>:</p><pre tabindex=0><code>stunserver=stun1.l.google.com;stunport=19302;listenport=20000;echo -ne &#34;\x00\x01\x00\x00\x00\x00\x00\x00TESTTESTTEST&#34; | nc -u -p $listenport $stunserver $stunport -w 1 | hexdump -C
00000000  01 01 00 0c 00 00 00 00  54 45 53 54 54 45 53 54  |........TESTTEST|
00000010  54 45 53 54 00 01 00 08  00 01 4e 20 5e 24 7a cb  |TEST......N ^$z.|
00000020
</code></pre><p>XOR-ing against the dummy magic cookie is idempotent, so the port and address will be in clear in the response. This will not work in all situations, because some routers manipulate the passing packets, cheating on the IP address. If we look at the returned data value (last eight bytes):</p><ul><li><code>00 01 4e 20 5e 24 7a cb</code> is the data value, interpretation:<ul><li><code>00 01</code> is the address type (IPv4)</li><li><code>4e 20</code> is the mapped port, which decodes to 20000 in decimal</li><li><code>5e 24 7a cb</code> is the IP address, which decodes to <code>94.36.122.203</code> in dotted-decimal notation.</li></ul></li></ul><h3 id=security-failure>Security Failure
<a class=anchor href=#security-failure>#</a></h3><h3 id=media-failure>Media Failure
<a class=anchor href=#media-failure>#</a></h3><h3 id=data-failure>Data Failure
<a class=anchor href=#data-failure>#</a></h3><h2 id=tools-of-the-trade>Tools of the trade
<a class=anchor href=#tools-of-the-trade>#</a></h2><h3 id=netcat-nc>netcat (nc)
<a class=anchor href=#netcat-nc>#</a></h3><p><a href=https://en.wikipedia.org/wiki/Netcat>netcat</a> is command-line networking utility for reading from and writing to network connections using TCP or UDP. It is typically available as the <code>nc</code> command.</p><h3 id=tcpdump>tcpdump
<a class=anchor href=#tcpdump>#</a></h3><p><a href=https://en.wikipedia.org/wiki/Tcpdump>tcpdump</a> is a command-line data-network packet analyzer.</p><p>Common commands:</p><ul><li><p>Capture UDP packets to and from port 19302, print a hexdump of the packet content:</p><p><code>sudo tcpdump 'udp port 19302' -xx</code></p></li><li><p>Same, but save packets in a PCAP (packet capture) file for later inspection:</p><p><code>sudo tcpdump 'udp port 19302' -w stun.pcap</code></p><p>The PCAP file can be opened with the Wireshark application: <code>wireshark stun.pcap</code></p></li></ul><h3 id=wireshark>Wireshark
<a class=anchor href=#wireshark>#</a></h3><p><a href=https://www.wireshark.org>Wireshark</a> is a widely-used network protocol analyzer.</p><h3 id=webrtc-internals>webrtc-internals
<a class=anchor href=#webrtc-internals>#</a></h3><p>Chrome comes with a built-in WebRTC statistics page available at <a href=chrome://webrtc-internals>chrome://webrtc-internals</a>.</p><h2 id=latency>Latency
<a class=anchor href=#latency>#</a></h2><p>How do you know you have high latency? You may have noticed that your video is lagging, but do you know precisely how much it is lagging?
To be able to reduce this latency, you have to start by measuring it first.</p><p>True latency is supposed to be measured end-to-end. That means not just the latency of the network path between the sender and the receiver, but the combined latency of camera capture, frame encoding, transmission, receiving, decoding and displaying, as well as possible queueing between any of these steps.</p><p>End-to-end latency is not a simple sum of latencies of each component.</p><p>While you could theoretically measure the latency of the components of a live video transmission pipeline separately and then add them together, in practice, at least some components will be either inaccessible for instrumentation, or produce significantly different results when measured outside the pipeline.
Variable queue depths between pipeline stages, network topology and camera exposure changes are just a few examples of components affecting end-to-end latency.</p><p>The intrinsic latency of each component in your live-streaming system can change and affect downstream components.
Even the content of captured video affects latency.
For example, many more bits are required for high frequency features such as tree branches, compared to a low frequency clear blue sky.
A camera with auto exposure turned on may take <em>much</em> longer than the expected 33 milliseconds to capture a frame, even if when the capture rate is set to 30 frames per second.
Transmission over the network, especially so cellular, is also very dynamic due to changing demand.
More users introduce more chatter on the air.
Your physical location (notorious low signal zones) and multiple other factors increase packet loss and latency.
What happens when you send a packet to a network interface, say WiFi adapter or an LTE modem for delivery?
If it can not be immediately delivered it is queued on the interface, the larger the queue the more latency such network interface introduces.</p><h3 id=manual-end-to-end-latency-measurement>Manual end-to-end latency measurement
<a class=anchor href=#manual-end-to-end-latency-measurement>#</a></h3><p>When we talk about end-to-end latency, we mean the time between an event happening and it being observed, meaning video frames appearing on the screen.</p><pre tabindex=0><code>EndToEndLatency = T(observe) - T(happen)
</code></pre><p>A naive approach is to record the time when an event happens and subtract it from the time at observation.
However, as precision goes down to milliseconds time synchronization becomes an issue.
Trying to synchronize clocks across distributed systems is mostly futile, even a small error in time sync produces unreliable latency measurement.</p><p>A simple workaround for clock sync issues is to use the same clock.
Put sender and receiver in the same frame of reference.</p><p>Imagine you have a ticking millisecond clock or any other event source really.
You want to measure latency in a system that live streams the clock to a remote screen by pointing a camera at it.
An obvious way to measure time between the millisecond timer ticking (T<sub><code>happen</code></sub>) and video frames of the clock appear on screen (T<sub><code>observe</code></sub>) is the following:</p><ul><li>Point your camera at the millisecond clock.</li><li>Send video frames to a receiver that is in the same physical location.</li><li>Take a picture (use your phone) of the millisecond timer and the received video on screen.</li><li>Subtract two times.</li></ul><p>That is the most true-to-yourself end-to-end latency measurement.
It accounts for all components latencies (camera, encoder, network, decoder) and does not rely on any clock synchronization.</p><p><img src=../images/09-diy-latency.png alt="DIY Latency" title="DIY Latency Measurement">.
<img src=../images/09-diy-latency-happen-observe.png alt="DIY Latency Example" title="DIY Latency Measurement Example">
In the photo above measured end-to-end latency is 101 msec. Event happening right now is 10:16:02.862, but the live-streaming system observer sees 10:16:02.761.</p><h3 id=automatic-end-to-end-latency-measurement>Automatic end-to-end latency measurement
<a class=anchor href=#automatic-end-to-end-latency-measurement>#</a></h3><p>As of the time of writing (May 2021) the WebRTC standard for end-to-end delay is being actively <a href=https://github.com/w3c/webrtc-stats/issues/537>discussed</a>.
Firefox implemented a set of APIs to let users create automatic latency measurement on top of standard WebRTC APIs.
However in this paragraph, we discuss the most compatible way to automatically measure latency.</p><p><img src=../images/09-ntp-latency.png alt="NTP Style Latency Measurement" title="NTP Style Latency Measurement"></p><p>Roundtrip time in a nutshell: I send you my time <code>tR1</code>, when I receive back my <code>tR1</code> at time <code>tR2</code>, I know round trip time is <code>tR2 - tR1</code>.</p><p>Given a communication channel between sender and receiver (e.g. <a href=https://webrtc.org/getting-started/data-channels>DataChannel</a>), the receiver may model the sender&rsquo;s monotonic clock by following the steps below:</p><ol><li>At time <code>tR1</code>, the receiver sends a message with its local monotonic clock timestamp.</li><li>When it is received at the sender with local time <code>tS1</code>, the sender responds with a copy of <code>tR1</code> as well as the sender’s <code>tS1</code> and the sender&rsquo;s video track time <code>tSV1</code>.</li><li>At time <code>tR2</code> on the receiving end, round trip time is calculated by subtracting the message&rsquo;s send and receive times: <code>RTT = tR2 - tR1</code>.</li><li>Round trip time <code>RTT</code> together with sender local timestamp <code>tS1</code> is enough to create an estimation of the sender&rsquo;s monotonic clock. Current time on the sender at time <code>tR2</code> would be equal to <code>tS1</code> plus half of round trip time.</li><li>Sender&rsquo;s local clock timestamp <code>tS1</code> paired with video track timestamp <code>tSV1</code> together with round trip time <code>RTT</code> is therefore enough to sync receiver video track time to the sender video track.</li></ol><p>Now that we know how much time has passed since the last known sender video frame time <code>tSV1</code>, we can approximate the latency by subtracting the currently displayed video frame&rsquo;s time (<code>actual_video_time</code>) from the expected time:</p><pre tabindex=0><code>expected_video_time = tSV1 + time_since(tSV1)
latency = expected_video_time - actual_video_time
</code></pre><p>This method&rsquo;s drawback is that it does not include the camera&rsquo;s intrinsic latency.
Most video systems consider the frame capture timestamp to be the time when the frame from the camera is delivered to the main memory, which will be a few moments after the event being recorded actually happened.</p><h4 id=example-latency-estimation>Example latency estimation
<a class=anchor href=#example-latency-estimation>#</a></h4><p>A sample implementation opens a <code>latency</code> data channel on the receiver and periodically sends the receiver&rsquo;s monotonic timer timestamps to the sender. The sender responds back with a JSON message and the receiver calculates the latency based the message.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span>{
</span></span><span style=display:flex><span>    <span style=color:#f92672>&#34;received_time&#34;</span>: <span style=color:#ae81ff>64714</span>,       <span style=color:#75715e>// Timestamp sent by receiver, sender reflects the timestamp. 
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#f92672>&#34;delay_since_received&#34;</span>: <span style=color:#ae81ff>46</span>,   <span style=color:#75715e>// Time elapsed since last `received_time` received on sender.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#f92672>&#34;local_clock&#34;</span>: <span style=color:#ae81ff>1597366470336</span>, <span style=color:#75715e>// The sender&#39;s current monotonic clock time.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#f92672>&#34;track_times_msec&#34;</span>: {
</span></span><span style=display:flex><span>        <span style=color:#f92672>&#34;myvideo_track1&#34;</span>: [
</span></span><span style=display:flex><span>            <span style=color:#ae81ff>13100</span>,        <span style=color:#75715e>// Video frame RTP timestamp (in milliseconds).
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>            <span style=color:#ae81ff>1597366470289</span> <span style=color:#75715e>// Video frame monotonic clock timestamp.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>        ]
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Open the data channel on the receiver:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-javascript data-lang=javascript><span style=display:flex><span><span style=color:#a6e22e>dataChannel</span> <span style=color:#f92672>=</span> <span style=color:#a6e22e>peerConnection</span>.<span style=color:#a6e22e>createDataChannel</span>(<span style=color:#e6db74>&#39;latency&#39;</span>);
</span></span></code></pre></div><p>Send the receiver&rsquo;s time <code>tR1</code> periodically. This example uses 2 seconds for no particular reason:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-javascript data-lang=javascript><span style=display:flex><span><span style=color:#a6e22e>setInterval</span>(() =&gt; {
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>let</span> <span style=color:#a6e22e>tR1</span> <span style=color:#f92672>=</span> Math.<span style=color:#a6e22e>trunc</span>(<span style=color:#a6e22e>performance</span>.<span style=color:#a6e22e>now</span>());
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>dataChannel</span>.<span style=color:#a6e22e>send</span>(<span style=color:#e6db74>&#34;&#34;</span> <span style=color:#f92672>+</span> <span style=color:#a6e22e>tR1</span>);
</span></span><span style=display:flex><span>}, <span style=color:#ae81ff>2000</span>);
</span></span></code></pre></div><p>Handle incoming message from receiver on sender:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-javascript data-lang=javascript><span style=display:flex><span><span style=color:#75715e>// Assuming event.data is a string like &#34;1234567&#34;.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#a6e22e>tR1</span> <span style=color:#f92672>=</span> <span style=color:#a6e22e>event</span>.<span style=color:#a6e22e>data</span>
</span></span><span style=display:flex><span><span style=color:#a6e22e>now</span> <span style=color:#f92672>=</span> Math.<span style=color:#a6e22e>trunc</span>(<span style=color:#a6e22e>performance</span>.<span style=color:#a6e22e>now</span>());
</span></span><span style=display:flex><span><span style=color:#a6e22e>tSV1</span> <span style=color:#f92672>=</span> <span style=color:#ae81ff>42000</span>; <span style=color:#75715e>// Current frame RTP timestamp converted to millisecond timescale.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#a6e22e>tS1</span> <span style=color:#f92672>=</span> <span style=color:#ae81ff>1597366470289</span>; <span style=color:#75715e>// Current frame monotonic clock timestamp.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#a6e22e>msg</span> <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;received_time&#34;</span><span style=color:#f92672>:</span> <span style=color:#a6e22e>tR1</span>,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;delay_since_received&#34;</span><span style=color:#f92672>:</span> <span style=color:#ae81ff>0</span>,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;local_clock&#34;</span><span style=color:#f92672>:</span> <span style=color:#a6e22e>now</span>,
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;track_times_msec&#34;</span><span style=color:#f92672>:</span> {
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;myvideo_track1&#34;</span><span style=color:#f92672>:</span> [<span style=color:#a6e22e>tSV1</span>, <span style=color:#a6e22e>tS1</span>]
</span></span><span style=display:flex><span>  }
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span><span style=color:#a6e22e>dataChannel</span>.<span style=color:#a6e22e>send</span>(<span style=color:#a6e22e>JSON</span>.<span style=color:#a6e22e>stringify</span>(<span style=color:#a6e22e>msg</span>));
</span></span></code></pre></div><p>Handle incoming message from the sender and print the estimated latency to the <code>console</code>:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-javascript data-lang=javascript><span style=display:flex><span><span style=color:#66d9ef>let</span> <span style=color:#a6e22e>tR2</span> <span style=color:#f92672>=</span> <span style=color:#a6e22e>performance</span>.<span style=color:#a6e22e>now</span>();
</span></span><span style=display:flex><span><span style=color:#66d9ef>let</span> <span style=color:#a6e22e>fromSender</span> <span style=color:#f92672>=</span> <span style=color:#a6e22e>JSON</span>.<span style=color:#a6e22e>parse</span>(<span style=color:#a6e22e>event</span>.<span style=color:#a6e22e>data</span>);
</span></span><span style=display:flex><span><span style=color:#66d9ef>let</span> <span style=color:#a6e22e>tR1</span> <span style=color:#f92672>=</span> <span style=color:#a6e22e>fromSender</span>[<span style=color:#e6db74>&#39;received_time&#39;</span>];
</span></span><span style=display:flex><span><span style=color:#66d9ef>let</span> <span style=color:#a6e22e>delay</span> <span style=color:#f92672>=</span> <span style=color:#a6e22e>fromSender</span>[<span style=color:#e6db74>&#39;delay_since_received&#39;</span>]; <span style=color:#75715e>// How much time that has passed between the sender receiving and sending the response.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>let</span> <span style=color:#a6e22e>senderTimeFromResponse</span> <span style=color:#f92672>=</span> <span style=color:#a6e22e>fromSender</span>[<span style=color:#e6db74>&#39;local_clock&#39;</span>];
</span></span><span style=display:flex><span><span style=color:#66d9ef>let</span> <span style=color:#a6e22e>rtt</span> <span style=color:#f92672>=</span> <span style=color:#a6e22e>tR2</span> <span style=color:#f92672>-</span> <span style=color:#a6e22e>delay</span> <span style=color:#f92672>-</span> <span style=color:#a6e22e>tR1</span>;
</span></span><span style=display:flex><span><span style=color:#66d9ef>let</span> <span style=color:#a6e22e>networkLatency</span> <span style=color:#f92672>=</span> <span style=color:#a6e22e>rtt</span> <span style=color:#f92672>/</span> <span style=color:#ae81ff>2</span>;
</span></span><span style=display:flex><span><span style=color:#66d9ef>let</span> <span style=color:#a6e22e>senderTime</span> <span style=color:#f92672>=</span> (<span style=color:#a6e22e>senderTimeFromResponse</span> <span style=color:#f92672>+</span> <span style=color:#a6e22e>delay</span> <span style=color:#f92672>+</span> <span style=color:#a6e22e>networkLatency</span>);
</span></span><span style=display:flex><span><span style=color:#a6e22e>VIDEO</span>.<span style=color:#a6e22e>requestVideoFrameCallback</span>((<span style=color:#a6e22e>now</span>, <span style=color:#a6e22e>framemeta</span>) =&gt; {
</span></span><span style=display:flex><span>    <span style=color:#75715e>// Estimate current time of the sender.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#66d9ef>let</span> <span style=color:#a6e22e>delaySinceVideoCallbackRequested</span> <span style=color:#f92672>=</span> <span style=color:#a6e22e>now</span> <span style=color:#f92672>-</span> <span style=color:#a6e22e>tR2</span>;
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>senderTime</span> <span style=color:#f92672>+=</span> <span style=color:#a6e22e>delaySinceVideoCallbackRequested</span>;
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>let</span> [<span style=color:#a6e22e>tSV1</span>, <span style=color:#a6e22e>tS1</span>] <span style=color:#f92672>=</span> Object.<span style=color:#a6e22e>entries</span>(<span style=color:#a6e22e>fromSender</span>[<span style=color:#e6db74>&#39;track_times_msec&#39;</span>])[<span style=color:#ae81ff>0</span>][<span style=color:#ae81ff>1</span>]
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>let</span> <span style=color:#a6e22e>timeSinceLastKnownFrame</span> <span style=color:#f92672>=</span> <span style=color:#a6e22e>senderTime</span> <span style=color:#f92672>-</span> <span style=color:#a6e22e>tS1</span>;
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>let</span> <span style=color:#a6e22e>expectedVideoTimeMsec</span> <span style=color:#f92672>=</span> <span style=color:#a6e22e>tSV1</span> <span style=color:#f92672>+</span> <span style=color:#a6e22e>timeSinceLastKnownFrame</span>;
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>let</span> <span style=color:#a6e22e>actualVideoTimeMsec</span> <span style=color:#f92672>=</span> Math.<span style=color:#a6e22e>trunc</span>(<span style=color:#a6e22e>framemeta</span>.<span style=color:#a6e22e>rtpTimestamp</span> <span style=color:#f92672>/</span> <span style=color:#ae81ff>90</span>); <span style=color:#75715e>// Convert RTP timebase (90000) to millisecond timebase.
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#66d9ef>let</span> <span style=color:#a6e22e>latency</span> <span style=color:#f92672>=</span> <span style=color:#a6e22e>expectedVideoTimeMsec</span> <span style=color:#f92672>-</span> <span style=color:#a6e22e>actualVideoTimeMsec</span>;
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>console</span>.<span style=color:#a6e22e>log</span>(<span style=color:#e6db74>&#39;latency&#39;</span>, <span style=color:#a6e22e>latency</span>, <span style=color:#e6db74>&#39;msec&#39;</span>);
</span></span><span style=display:flex><span>});
</span></span></code></pre></div><h4 id=actual-video-time-in-browser>Actual video time in browser
<a class=anchor href=#actual-video-time-in-browser>#</a></h4><blockquote><p><code>&lt;video>.requestVideoFrameCallback()</code> allows web authors to be notified when a frame has been presented for composition.</p></blockquote><p>Until very recently (May 2020), it was next to impossible to reliably get a timestamp of the currently displayed video frame in browsers. Workaround methods based on <code>video.currentTime</code> existed, but were not particularly precise.
Both the Chrome and Mozilla browser developers <a href=https://github.com/mozilla/standards-positions/issues/250>supported</a> the introduction of a new W3C standard, <a href=https://wicg.github.io/video-rvfc/><code>HTMLVideoElement.requestVideoFrameCallback()</code></a>, that adds an API callback to access the current video frame time.
While the addition sounds trivial, it has enabled multiple advanced media applications on the web that require audio and video synchronization.
Specifically for WebRTC, the callback will include the <code>rtpTimestamp</code> field, the RTP timestamp associated with the current video frame.
This should be present for WebRTC applications, but absent otherwise.</p><h3 id=latency-debugging-tips>Latency Debugging Tips
<a class=anchor href=#latency-debugging-tips>#</a></h3><p>Since debugging is likely to affect the measured latency, the general rule is to simplify your setup to the smallest possible one that can still reproduce the issue.
The more components you can remove, the easier it will be to figure out which component is causing the latency problem.</p><h4 id=camera-latency>Camera latency
<a class=anchor href=#camera-latency>#</a></h4><p>Depending on camera settings camera latency may vary.
Check auto exposure, auto focus and auto white balance settings.
All the &ldquo;auto&rdquo; features of web cameras take some extra time to analyse the captured image before making it available to the WebRTC stack.</p><p>If you are on Linux, you can use the <code>v4l2-ctl</code> command line tool to control camera settings:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># Disable autofocus:</span>
</span></span><span style=display:flex><span>v4l2-ctl -d /dev/video0 -c focus_auto<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Set focus to infinity:</span>
</span></span><span style=display:flex><span>v4l2-ctl -d /dev/video0 -c focus_absolute<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>
</span></span></code></pre></div><p>You can also use the graphical UI tool <code>guvcview</code> to quickly check and tweak camera settings.</p><h4 id=encoder-latency>Encoder latency
<a class=anchor href=#encoder-latency>#</a></h4><p>Most modern encoders will buffer some frames before outputting an encoded one.
Their first priority is a balance between the quality of the produced picture and bitrate.
Multipass encoding is an extreme example of an encoder&rsquo;s disregard for output latency.
During the first pass encoder ingests the entire video and only after that starts outputting frames.</p><p>However, with proper tuning people have achieved sub-frame latencies.
Make sure your encoder does not use excessive reference frames or rely on B-frames.
Every codec&rsquo;s latency tuning settings are different, but for x264 we recommend using <code>tune=zerolatency</code> and <code>profile=baseline</code> for the lowest frame output latency.</p><h4 id=network-latency>Network latency
<a class=anchor href=#network-latency>#</a></h4><p>Network latency is the one you can arguably do least about, other than upgrading to a better network connection.
Network latency is very much like the weather - you can&rsquo;t stop the rain, but you can check the forecast and take an umbrella.
WebRTC is measuring network conditions with millisecond precision.
Important metrics are:</p><ul><li>Round-trip time.</li><li>Packet loss and packet retransmissions.</li></ul><p><strong>Round-Trip Time</strong></p><p>The WebRTC stack has a built-in network round trip time (RTT) measurement <a href=https://www.w3.org/TR/webrtc-stats/#dom-rtcremoteinboundrtpstreamstats-roundtriptime>mechanism</a>.
A good-enough approximation of latency is half of the RTT. It assumes that it takes the same time to send and receive a packet, which is not always the case.
RTT sets the lower bound on the end-to-end latency.
Your video frames can not reach the receiver faster than <code>RTT/2</code>, no matter how optimized your camera to encoder pipeline is.</p><p>The built-in RTT mechanism is based on special RTCP packets called sender/receiver reports.
Sender sends its time reading to receiver, the receiver in turn reflects the same timestamp to the sender.
Thereby the sender knows how much time it took for the packet to travel to the receiver and return back.
Refer to <a href=../06-media-communication/#senderreceiver-reports>Sender/Receiver Reports</a> chapter for more details of RTT measurement.</p><p><strong>Packet loss and packet retransmissions</strong></p><p>Both RTP and RTCP are protocols based on UDP, which does not have any guarantee of ordering, successful delivery, or non-duplication.
All of the above can and does happen in real world WebRTC applications.
An unsophisticated decoder implementation expects all packets of a frame to be delivered for the decoder to successfully reassemble the image.
In presence of packet loss decoding artifacts may appear if packets of a <a href=../06-media-communication/#inter-frame-types>P-frame</a> are lost.
If I-frame packets are lost then all of its dependent frames will either get heavy artifacts or won&rsquo;t be decoded at all.
Most likely this will make the video &ldquo;freeze&rdquo; for a moment.</p><p>To avoid (well, at least to try to avoid) video freezing or decoding artifacts, WebRTC uses negative acknowledgement messages (<a href=../06-media-communication/#negative-acknowledgment>NACK</a>).
When the receiver does not get an expected RTP packet, it returns a NACK message to tell the sender to send the missing packet again.
The receiver <em>waits</em> for the retransmission of the packet.
Such retransmissions cause increased latency.
The number of NACK packets sent and received is recorded in WebRTC&rsquo;s built-in stats fields <a href=https://www.w3.org/TR/webrtc-stats/#dom-rtcoutboundrtpstreamstats-nackcount>outbound stream nackCount</a> and <a href=https://www.w3.org/TR/webrtc-stats/#dom-rtcinboundrtpstreamstats-nackcount>inbound stream nackCount</a>.</p><p>You can see nice graphs of inbound and outbound <code>nackCount</code> on the <a href=#webrtc-internals>webrtc internals page</a>.
If you see the <code>nackCount</code> increasing, it means the network is experiencing high packet loss, and the WebRTC stack is doing its best to create a smooth video/audio experience despite that.</p><p>When packet loss is so high that the decoder is unable to produce an image, or subsequent dependent images like in the case of a fully lost I-frame, all future P-frames will not be decoded.
The receiver will try to mitigate that by sending a special Picture Loss Indication message (<a href=../06-media-communication/#full-intra-frame-request-fir-and-picture-loss-indication-pli>PLI</a>).
Once the sender receives a <code>PLI</code>, it will produce a new I-frame to help the receiver&rsquo;s decoder.
I-frames are normally larger in size than P-frames. This increases the number of packets that need to be transmitted.
Like with NACK messages, the receiver will need to wait for the new I-frame, introducing additional latency.</p><p>Watch for <code>pliCount</code> on the <a href=#webrtc-internals>webrtc internals page</a>. If it increases, tweak your encoder to produce less packets or enable a more error resilient mode.</p><h4 id=receiver-side-latency>Receiver side latency
<a class=anchor href=#receiver-side-latency>#</a></h4><p>Latency will be affected by packets arriving out of order.
If the bottom half of the image packet comes before the top you would have to wait for the top before decoding.
This is explained in the <a href=05-real-time-networking/#solving-jitter>Solving Jitter</a> chapter in great detail.</p><p>You can also refer to the built-in <a href=https://www.w3.org/TR/webrtc-stats/#dom-rtcinboundrtpstreamstats-jitterbufferdelay>jitterBufferDelay</a> metric to see how long a frame was held in the receive buffer, waiting for all of its packets until it was released to the decoder.</p></article><footer class=book-footer><div class="flex flex-wrap justify-between"><div><a class="flex align-center" href=https://github.com/webrtc-for-the-curious/webrtc-for-the-curious/commit/d229c648fe5ab89cddd7a7b46a96de7db6f1d815 title='Última modificación por zackfall | octubre 13, 2022' target=_blank rel=noopener><img src=/svg/calendar.svg class=book-icon alt>
<span>octubre 13, 2022</span></a></div><div><a class="flex align-center" href=https://github.com/webrtc-for-the-curious/webrtc-for-the-curious/edit/master/content/docs/09-debugging.md target=_blank rel=noopener><img src=/svg/edit.svg class=book-icon alt>
<span>Editar esta página</span></a></div></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#isolate-the-problem>Isolate The Problem</a><ul><li><a href=#signaling-failure>Signaling Failure</a></li><li><a href=#networking-failure>Networking Failure</a></li><li><a href=#security-failure>Security Failure</a></li><li><a href=#media-failure>Media Failure</a></li><li><a href=#data-failure>Data Failure</a></li></ul></li><li><a href=#tools-of-the-trade>Tools of the trade</a><ul><li><a href=#netcat-nc>netcat (nc)</a></li><li><a href=#tcpdump>tcpdump</a></li><li><a href=#wireshark>Wireshark</a></li><li><a href=#webrtc-internals>webrtc-internals</a></li></ul></li><li><a href=#latency>Latency</a><ul><li><a href=#manual-end-to-end-latency-measurement>Manual end-to-end latency measurement</a></li><li><a href=#automatic-end-to-end-latency-measurement>Automatic end-to-end latency measurement</a></li><li><a href=#latency-debugging-tips>Latency Debugging Tips</a></li></ul></li></ul></nav></div></aside></main></body></html>