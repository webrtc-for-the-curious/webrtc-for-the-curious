<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="What do I get from WebRTC&rsquo;s media communication? #  WebRTC allows you to send and receive an unlimited amount of audio and video streams. You can add and remove these streams at anytime during a call. These streams could all be independent, or they could be bundled together! You could send a video feed of your desktop, and then include audio/video from your webcam.
The WebRTC protocol is codec agnostic."><meta name=theme-color content="#FFFFFF"><meta property="og:title" content="Media Communication"><meta property="og:description" content="What do I get from WebRTC&rsquo;s media communication? #  WebRTC allows you to send and receive an unlimited amount of audio and video streams. You can add and remove these streams at anytime during a call. These streams could all be independent, or they could be bundled together! You could send a video feed of your desktop, and then include audio/video from your webcam.
The WebRTC protocol is codec agnostic."><meta property="og:type" content="article"><meta property="og:url" content="https://webrtcforthecurious.com/docs/05-media-communication/"><meta property="article:modified_time" content="2020-08-28T21:17:40-07:00"><title>Media Communication | WebRTC for the Curious</title><link rel=manifest href=/manifest.json><link rel=icon href=/favicon.png type=image/x-icon><link rel=stylesheet href=/book.min.6cd8553a6854f4812343f0f0c8baca31271e686434f381fbe3c7226f66639176.css integrity="sha256-bNhVOmhU9IEjQ/DwyLrKMSceaGQ084H748cib2ZjkXY="><script defer src=/en.search.min.4a3a5362aa9621936ead9d443af9058edc4d770480be15dab1cdfd6926caa414.js integrity="sha256-SjpTYqqWIZNurZ1EOvkFjtxNdwSAvhXasc39aSbKpBQ="></script></head><body><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><nav><h2 class=book-brand><a href=/><span>WebRTC for the Curious</span></a></h2><div class=book-search><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><ul><li><a href=/docs/01-what-why-and-how/>What, Why and How</a></li><li><a href=/docs/02-signaling/>Signaling</a></li><li><a href=/docs/03-connecting/>Connecting</a></li><li><a href=/docs/04-securing/>Securing</a></li><li><a href=/docs/05-media-communication/ class=active>Media Communication</a></li><li><a href=/docs/06-data-communication/>Data Communication</a></li><li><a href=/docs/08-applied-webrtc/>Applied WebRTC</a></li><li><a href=/docs/09-debugging/>Debugging</a></li><li><a href=/docs/10-history-of-webrtc/>History</a></li><li><a href=/docs/11-faq/>FAQ</a></li></ul></nav><script>(function(){var menu=document.querySelector("aside.book-menu nav");addEventListener("beforeunload",function(event){localStorage.setItem("menu.scrollTop",menu.scrollTop);});menu.scrollTop=localStorage.getItem("menu.scrollTop");})();</script></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu></label>
<strong>Media Communication</strong>
<label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#what-do-i-get-from-webrtcs-media-communication>What do I get from WebRTC&rsquo;s media communication?</a></li><li><a href=#how-does-it-work>How does it work?</a></li><li><a href=#latency-vs-quality>Latency vs Quality</a><ul><li><a href=#real-world-limitations>Real World Limitations</a></li></ul></li><li><a href=#media-101>Media 101</a><ul><li><a href=#codec>Codec</a></li><li><a href=#frame-types>Frame Types</a></li></ul></li><li><a href=#rtp>RTP</a><ul><li><a href=#packet-format>Packet Format</a></li><li><a href=#extensions>Extensions</a></li><li><a href=#mapping-payload-types-to-codecs>Mapping Payload Types to Codecs</a></li></ul></li><li><a href=#rtcp>RTCP</a><ul><li><a href=#packet-format-1>Packet Format</a></li></ul></li><li><a href=#rtprtcp-working-together>RTP/RTCP working together</a><ul><li><a href=#nack>NACK</a></li><li><a href=#fec>FEC</a></li><li><a href=#jitterbuffer>JitterBuffer</a></li><li><a href=#post-decode-audiovideo-improvements>Post-Decode Audio/Video Improvements</a></li></ul></li></ul></nav></aside></header><article class=markdown><h2 id=what-do-i-get-from-webrtcs-media-communication>What do I get from WebRTC&rsquo;s media communication?
<a class=anchor href=#what-do-i-get-from-webrtcs-media-communication>#</a></h2><p>WebRTC allows you to send and receive an unlimited amount of audio and video streams. You can add and remove these streams at anytime during a call. These streams could all be independent, or they could be bundled together! You could send a video feed of your desktop, and then include audio/video from your webcam.</p><p>The WebRTC protocol is codec agnostic. The underlying transport supports everything, even things that don&rsquo;t exist yet! However, the WebRTC Agent you are communicating with may not have the necessary tools to accept it.</p><p>WebRTC is also designed to handle dynamic network conditions. During a call your bandwidth might increase, or decrease. Maybe you all the sudden experience lots of packet loss. The protocol is designed to handle all of this. WebRTC responds to network conditions and tries to give you the best experience possible with the resources available.</p><h2 id=how-does-it-work>How does it work?
<a class=anchor href=#how-does-it-work>#</a></h2><p>WebRTC uses two pre-existing protocols RTP and RTCP, both defined in <a href=https://tools.ietf.org/html/rfc1889>RFC 1889</a></p><p>RTP is the protocol that carries the media. It was designed to allow real-time delivery of video. It doesn&rsquo;t stipulate any rules around latency or reliability, but gives you the tools to implement them. RTP gives you streams, so you can run multiple media feeds over one connection. It also gives you the timing and ordering information you need to feed a media pipeline.</p><p>RTCP is the protocol that communicates metadata about the call. The format is flexible enough so you can add whatever you want. This is used to communicate statistics about the call. It is also necessary to handle packet loss and to implement congestion control. It gives you the bi-directional communication necessary to respond to network conditions changing.</p><h2 id=latency-vs-quality>Latency vs Quality
<a class=anchor href=#latency-vs-quality>#</a></h2><p>Real-time media is about making trade-offs between latency and quality. The more latency you are willing to tolerate, the higher quality video you can expect.</p><h3 id=real-world-limitations>Real World Limitations
<a class=anchor href=#real-world-limitations>#</a></h3><p>These constraints are all caused by the limitations off the real world. These are all characteristics of your network that you will need to overcome.</p><h4 id=bandwidth>Bandwidth
<a class=anchor href=#bandwidth>#</a></h4><p>Bandwidth is the maximum rate of data that can be transferred across a given path. It is important to remember this isn&rsquo;t a static number either. The bandwidth will change along the route as more (or less) people use it.</p><p>When you attempt to send more data then available bandwidth you will experience network congestion.</p><h4 id=transmission-time>Transmission Time
<a class=anchor href=#transmission-time>#</a></h4><p>Transmission Time is how long it takes for a packet to arrive. Like Bandwidth this isn&rsquo;t constant. The Transmission Time can fluctuate at anytime.</p><h4 id=jitter>Jitter
<a class=anchor href=#jitter>#</a></h4><p>Jitter is the fact that <code>Transmission Time</code> may vary. Some times you will see packets arrive in bursts. Any piece of hardware along the network path can introduce issues.</p><h4 id=packet-loss>Packet Loss
<a class=anchor href=#packet-loss>#</a></h4><p>Packet Loss is when messages are lost in transmission. The loss could be steady, or it could come in spikes. This isn&rsquo;t an uncommon occurrence either!</p><h4 id=maximum-transmission-unit>Maximum transmission unit
<a class=anchor href=#maximum-transmission-unit>#</a></h4><p>Maximum Transmission Unit is the limit on how large a single packet can be. Networks don&rsquo;t allow you to send one giant message. At the protocol level you need to packetize your data into small packets.</p><p>The MTU will also differ depending on what network path you take. You can use a protocol like <a href=https://tools.ietf.org/html/rfc1191>Path MTU Discovery</a> to figure out what the largest packet size is you can send.</p><h2 id=media-101>Media 101
<a class=anchor href=#media-101>#</a></h2><h3 id=codec>Codec
<a class=anchor href=#codec>#</a></h3><h3 id=frame-types>Frame Types
<a class=anchor href=#frame-types>#</a></h3><h2 id=rtp>RTP
<a class=anchor href=#rtp>#</a></h2><h3 id=packet-format>Packet Format
<a class=anchor href=#packet-format>#</a></h3><p>Every RTP packet has the following structure:</p><pre><code> 0                   1                   2                   3
 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|V=2|P|X|  CC   |M|     PT      |       Sequence Number         |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|                           Timestamp                           |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|           Synchronization Source (SSRC) identifier            |
+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+
|            Contributing Source (CSRC) identifiers             |
|                             ....                              |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|                            Payload                            |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
</code></pre><h4 id=version-v>Version (V)
<a class=anchor href=#version-v>#</a></h4><p><code>Version</code> is always 2</p><h4 id=padding-p>Padding (P)
<a class=anchor href=#padding-p>#</a></h4><p><code>Padding</code> is a bool that controls if the payload has padding.</p><p>The last byte of the payload contains a count of how many padding bytes
were added.</p><h4 id=extension-x>Extension (X)
<a class=anchor href=#extension-x>#</a></h4><p>If set the RTP header will have extensions. This is described in greater detail below.</p><h4 id=csrc-count-cc>CSRC count (CC)
<a class=anchor href=#csrc-count-cc>#</a></h4><p>The amount of <code>CSRC</code> identifiers that follow after the <code>SSRC</code>, and before the payload.</p><h4 id=marker-m>Marker (M)
<a class=anchor href=#marker-m>#</a></h4><p>The marker bit has no pre-set meaning, and is up to the user.</p><p>It some cases it is set when a user is speaking. It is also commonly used to mark a keyframe.</p><h4 id=payload-type-pt>Payload Type (PT)
<a class=anchor href=#payload-type-pt>#</a></h4><p><code>Payload Type</code> is the unique identifier for what codec is being carried by this packet.</p><p>For WebRTC the <code>Payload Type</code> is dynamic. VP8 in one call may be different then another. The Offerer in the call determines the mapping of <code>Payload Types</code> to codecs in the <code>Session Description</code>.</p><h4 id=sequence-number>Sequence Number
<a class=anchor href=#sequence-number>#</a></h4><p><code>Sequence Number</code> is used for ordering packets in a stream. Every time a packet is sent the <code>Sequence Number</code> is incremented by one.</p><p>RTP is designed to be useful over lossy networks. This gives the receiver a way to detect when packets have been lost.</p><h4 id=timestamp>Timestamp
<a class=anchor href=#timestamp>#</a></h4><p><code>Timestamp</code> is the sampling instant for this packet. This is not a global clock, but how much time has passed in the media stream.</p><h4 id=synchronization-source-ssrc>Synchronization Source (SSRC)
<a class=anchor href=#synchronization-source-ssrc>#</a></h4><p>A <code>SSRC</code> is the unique identifier for this stream. This allows you to run multiple streams of media over a single stream.</p><h4 id=contributing-source-csrc>Contributing Source (CSRC)
<a class=anchor href=#contributing-source-csrc>#</a></h4><p>A list that communicates what <code>SSRC</code>es contributed to this packet.</p><p>This is commonly used for talking indicators. Lets say server side you combined multiple audio feeds into a single RTP stream. You could then use this field to say &lsquo;Input stream A and C were talking at this moment&rsquo;</p><h3 id=extensions>Extensions
<a class=anchor href=#extensions>#</a></h3><h3 id=mapping-payload-types-to-codecs>Mapping Payload Types to Codecs
<a class=anchor href=#mapping-payload-types-to-codecs>#</a></h3><h2 id=rtcp>RTCP
<a class=anchor href=#rtcp>#</a></h2><h3 id=packet-format-1>Packet Format
<a class=anchor href=#packet-format-1>#</a></h3><h2 id=rtprtcp-working-together>RTP/RTCP working together
<a class=anchor href=#rtprtcp-working-together>#</a></h2><h3 id=nack>NACK
<a class=anchor href=#nack>#</a></h3><h3 id=fec>FEC
<a class=anchor href=#fec>#</a></h3><h3 id=jitterbuffer>JitterBuffer
<a class=anchor href=#jitterbuffer>#</a></h3><h3 id=post-decode-audiovideo-improvements>Post-Decode Audio/Video Improvements
<a class=anchor href=#post-decode-audiovideo-improvements>#</a></h3></article><footer class=book-footer><div class="flex flex-wrap justify-between"><div><a class="flex align-center" href=https://github.com/webrtc-for-the-curious/webrtc-for-the-curious/commit/b4fdefca398e63104af9b6ae04efaf9eb2018edb title="Last modified by Sean DuBois | August 29, 2020" target=_blank rel=noopener><img src=/svg/calendar.svg class=book-icon alt=Calendar>
<span>August 29, 2020</span></a></div><div><a class="flex align-center" href=https://github.com/webrtc-for-the-curious/webrtc-for-the-curious/edit/master/content//docs/05-media-communication.md target=_blank rel=noopener><img src=/svg/edit.svg class=book-icon alt=Edit>
<span>Edit this page</span></a></div></div></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><nav id=TableOfContents><ul><li><a href=#what-do-i-get-from-webrtcs-media-communication>What do I get from WebRTC&rsquo;s media communication?</a></li><li><a href=#how-does-it-work>How does it work?</a></li><li><a href=#latency-vs-quality>Latency vs Quality</a><ul><li><a href=#real-world-limitations>Real World Limitations</a></li></ul></li><li><a href=#media-101>Media 101</a><ul><li><a href=#codec>Codec</a></li><li><a href=#frame-types>Frame Types</a></li></ul></li><li><a href=#rtp>RTP</a><ul><li><a href=#packet-format>Packet Format</a></li><li><a href=#extensions>Extensions</a></li><li><a href=#mapping-payload-types-to-codecs>Mapping Payload Types to Codecs</a></li></ul></li><li><a href=#rtcp>RTCP</a><ul><li><a href=#packet-format-1>Packet Format</a></li></ul></li><li><a href=#rtprtcp-working-together>RTP/RTCP working together</a><ul><li><a href=#nack>NACK</a></li><li><a href=#fec>FEC</a></li><li><a href=#jitterbuffer>JitterBuffer</a></li><li><a href=#post-decode-audiovideo-improvements>Post-Decode Audio/Video Improvements</a></li></ul></li></ul></nav></aside></main></body></html>