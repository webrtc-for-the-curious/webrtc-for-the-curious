[{"id":0,"href":"/fr/docs/01-what-why-and-how/","title":"Quoi, Pourquoi et Comment","section":"Docs","content":" Quoi, Pourquoi et Comment # Qu’est-ce que le WebRTC ? # WebRTC, raccourci pour Web Real-Time Communication, est une API et un protocole. Le protocole WebRTC est un ensemble de règles pour que deux agents WebRTC négocient une communication temps réel, bidirectionnelle et sécurisée. L’API WebRTC permet au développeur d’utiliser le protocole WebRTC. L’API WebRTC est seulement spécifiée pour le JavaScript.\nUne relation similaire serait celle entre HTTP et l’API Fetch. Le protocole WebRTC serait HTTP, et l’API WebRTC serait l’API Fetch.\nLe protocole WebRTC est disponible dans d’autres API et langages en plus du JavaScript. Vous pouvez aussi trouver des serveurs et des outils spécifiques au domaine du WebRTC. Toutes les implémentations utilisent le protocole WebRTC et peuvent donc interagir entre elles.\nLe protocole WebRTC est maintenue au sein de l’IETF par le groupe de travail rtcweb. L’API WebRTC est documentée par le W3C en tant que webrtc.\nPourquoi devrais-je apprendre le WebRTC ? # Il y a des choses que le WebRTC peut vous apporter. Cette liste n’est pas exhaustive, c’est juste un exemple de choses que vous pourriez apprécier dans votre voyage. Ne vous inquiétez pas si vous ne connaissez pas encore tous ces termes, ce livre va vous les apprendre en cours de lecture.\nStandards ouverts Implémentations multiples Disponible dans le navigateur Chiffrement obligatoire Traversé des NAT Repositionnement de technologies existantes Contrôle de congestion Latence inférieure à la seconde Le Protocole WebRTC est une collection d’autres technologies # C’est un sujet qui demanderait un livre entier pour l’expliquer. Cependant, pour démarrer, nous l’avons divisé en quatre étapes.\nLa signalisation La connexion La sécurité La communication Ces quatre étapes se déroulent séquentiellement. L’étape précédente doit être finalisée avec succès à 100 % avant d’entamer la suivante.\nUn des aspects particulier du WebRTC est que chacune des étapes est réellement constituée des nombreux autres protocoles ! Pour faire le WebRTC, nous devons assembler un grand nombre de technologies déjà existantes. En ce sens, le WebRTC est plus une combinaison et une configuration de technologies bien connues qui nous entourent depuis le début des années 2000.\nChacune de ces étapes possède un chapitre dédié, mais cela aide de les comprendre à un haut niveau pour commencer. Et comme elles dépendent les unes des autres, cela va aider à expliquer un peu plus le but de chacune de ces étapes.\nLa signalisation : Comment les agents se trouvent dans le WebRTC # Quand un agent WebRTC démarre, il n’a aucune idée avec qui il va communiquer et en quoi va consister cette communication. La signalisation résout ce problème ! La signalisation est utilisée pour amorcer l’appel pour que deux agents WebRTC puissent commencer à communiquer.\nLa signalisation utilise un protocole déjà existant appelé SDP (Session Description Protocol). Le SDP est un protocole en texte brut. Chaque message SDP est constitué de paire Clé/Valeur et contient une liste de “section média”. Les SDP que deux agents WebRTC échangent contiennent des détails tels que :\nIPs et Ports sur lesquels l’agent est joignable (les candidats); Combien de flux audio et vidéo l’agent désire recevoir; Quel codec audio et vidéo les agents supportent; Des valeurs utiles à la connexion (uFrag/uPwd); Des valeurs utiles à la sécurisation (la signature des certificats). Il est à noter que normalement la signalisation se réalise “out-of-band”, c\u0026rsquo;est-à-dire que les applications n’utilisent pas le WebRTC lui-même pour échanger les messages de signalisation. Toute architecture appropriée pour l’échange de message peut être utilisée pour relayer les SDP entre les agents. Bon nombre d’applications vont utiliser leur infrastructure déjà en place (comme des endpoints REST, connexion WebSocket ou autre proxy d’authentification) pour faciliter l’échange des SDP entre leurs propres clients.\nConnexion est traversée des NATs avec STUN/TURN # Les deux agents WebRTC connaissent maintenant suffisamment de détails pour tenter de se connecter l’un l’autre. Le WebRTC va alors utiliser une autre technologie bien rodée appelée ICE. L’ICE (Interactive Connectivity Establishement) est un protocole antérieur au WebRTC. L’ICE permet l’établissement d’une connexion entre deux agents. Ces agents peuvent être sur le même réseau, ou à l’autre bout du monde. L’ICE est la solution pour établir une connexion directe sans serveur central.\nLa véritable magie repose ici porte sur la traversée des NATs avec les serveurs STUN/TURN. Ces deux concepts sont tout ce dont vous avez besoin pour communiquer avec un agent ICE sur un autre sous réseau. Nous allons explorer ce sujet en profondeur plus loin.\nUne fois la connexion ICE établie, le WebRTC va alors passer à l’établissement d’un canal de transport chiffré des données. Ce canal de transport est utilisé pour l’audio, la vidéo et les données.\nSécuriser la couche de transport avec DTLS et SRTP # Maintenant que nous avons une communication bidirectionnelle (avec ICE), nous devons établir une connexion sécurisée. Ceci est fait au travers de deux protocoles antérieurs au WebRTC. Le premier protocole est le DTLS (Datagram Transport Layer Security) qui est juste du TLS sur UDP. Le TLS est le protocole cryptographique utilisé pour sécuriser les communications du HTTPS. Le second protocole est le SRTP (Secure Real-Time Transport Protocol).\nTout d\u0026rsquo;abord, le WebRTC se connecte par un HandCheck DTLS sur la connexion établie par ICE. À la différence du HTTPS, le WebRTC n’utilise pas une autorité centrale de gestion des certificats. À la place, le WebRTC s’assure juste que l’échange de certificat via DTLS correspond bien au Fingerprint partagé par l’étape de signalisation. Cette connexion DTLS est ensuite utilisée pour les messages du DataChannel.\nLe WebRTC utilise ensuite un protocole différent pour la transmission audio/vidéo appelé RTP (RealTime Transport Protocol). Nous sécurisons nos paquets RTP en utilisant SRTP. La session SRTP est initialisée par l’extraction des clés de la négociation de la session DTLS. Dans un chapitre ultérieur, nous discuterons pourquoi la transmission média à son propre protocole.\nMaintenant, nous avons réussi ! Vous avez une communication bidirectionnelle et sécurisée entre deux agents. Si vous avez une connexion stable entre vos deux agents WebRTC, c’est toute la complexité dont vous avez besoin. Malheureusement, le monde réel a des pertes de paquet et des limites de bande passante, nous allons voir comment traiter cela dans la prochaine section.\nCommuniquer entre agents via le RTP et le SCTP # Nous avons maintenant deux agents WebRTC avec un canal de communication bidirectionnel et sécurisé. Commençons à communiquer ! Encore une fois, nous utilisons deux protocoles préexistants : RTP (RealTime Transport Protocol) et SCTP (Stream Control Transmission Protocol). Le SRTP, pour RTP encrypté, est utilisé pour l’échange de média et le SCTP pour recevoir et envoyer des messages de donnée cryptée via le DTLS.\nLe RTP est assez minimaliste, mais fournit ce qu’il faut pour du streaming temps réel. La chose importante est que le RTP donne de la flexibilité aux développeurs, ils peuvent donc traiter la latence, la perte de paquets et la congestion comme ils le veulent. Nous discuterons de cela dans le chapitre sur les médias.\nLe dernier protocole dans la stack est le SCTP. Le SCTP autorise un grand nombre d’options dans la transmission des messages. Vous pouvez choisir d’avoir une transmission non fiable, désordonnée, ce qui permet d’attendre la latence nécessaire aux systèmes temps-réel.\nLe WebRTC, une collection de protocole # Le WebRTC résout un grand nombre de problèmes. Premièrement, cela peut sembler trop complexe. Le génie du WebRTC est en réalité son humilité. Il ne prétendait pas qu’il pouvait tout résoudre mieux que les autres. À la place, il reprend un grand nombre de technologies existantes ciblant un domaine précis et les rassemble dans un protocole unique.\nCela nous permet d’examiner et d’apprendre chaque partie de façon individuelle sans être submergé. Une bonne manière de visualiser un “Agent WebRTC” est de le voir comme un orchestrateur d’un ensemble de différents protocoles.\nComment marche le WebRTC (l’API) # Cette section montre comment l’API Javascript WebRTC se calque sur le protocole. Il ne s’agit pas de montrer une démo détaillée de l’API WebRTC, mais plus de créer une représentation mentale de la manière dont tout cela est lié. Si vous n’êtes pas familier avec cela, tout va bien. Cela pourra être une section intéressante à regarder une fois que vous en aurez appris un peu plus.\nnew RTCPeerConnection # La RTCPeerConnection est le niveau le plus haut d’une session WebRTC. Elle contient tous les protocoles mentionnés jusqu’ici. Les sous-systèmes sont tous initialisés, mais rien n’a encore commencé.\naddTrack # addTrack crée un nouveau flux RTP. Une source de synchronisation aléatoire (ssrc) sera générée pour ce flux. Ce flux sera ensuite ajouté dans dans la section média du SDP généré par createOffer. Chaque appel à addTrack va créer une nouvelle SSRC et une section média.\nImmédiatement après l’établissement d’une session SRTP, les paquets média vont commencer à être envoyés via ICE en étant chiffrés par le SRTP.\ncreateDataChannel # createDataChannel crée un nouveau flux SCTP si aucune association SCTP n’existe. Par défaut, SCTP n’est pas activé, mais juste démarré quand un agent demande un canal de données.\nImmédiatement après l’établissement de la session DTLS, l’association SCTP va commencer à envoyer des paquets via ICE en étant chiffré par DTLS.\ncreateOffer # createOffer génère la description de session de l’état de l’agent local afin de la partager avec l’autre agent. Le fait d’appeler createOffer ne change rien sur l’agent local.\nsetLocalDescription # setLocalDescription applique n’importe quelle demande de changement. addTrack, CreateDataChannel et les appels similaires sont tous temporaires avant cet appel. setLocalDescription est appelé avec la valeur générée par createOffer.\nHabituellement, après cet appel, vous allez envoyer cette description de session à l’agent distant, et il va appeler setRemoteDescription avec celle-ci.\nsetRemoteDescription # setRemoteDescription sert à informer l’agent local sur l’état des candidats distants. C’est de cette façon que la “Signalisation” est réalisée du côté de l\u0026rsquo;API Javascript.\nQuand setRemoteDescription est appelé des deux cotés, les agents WebRTC ont suffisamment d’information pour commencer leur communication paire à paire (P2P) !\naddIceCandidate # addIceCandidate permet à un agent WebRTC d’ajouter plus de candidats ICE distants quand il le veut. Cette API envoie le candidat ICE directement dans le sous-système ICE et n’a aucun autre effet dans la grande connexion WebRTC.\nontrack # ontrack est un callback appelé lorsqu’un paquet RTP est reçu de l’agent distant. Les paquets entrants doivent avoir été déclarés dans la description de session (SDP) qui a été passée à setRemoteDescription.\nLe WebRTC utilise le SSRC et regarde les MediaStream et MediaStreamTrack associé, il lance le callback quand tous les détails du flux sont récupérés.\noniceconnectionstatechange # oniceconnectionstatechange est un callback qui est appelé quand l’état de l’agent ICE est modifié. Quand vous avez une nouvelle connexion réseau ou bien lorsque vous êtes déconnecté, c’est comme cela que vous êtes notifié.\nonconnectionstatechange # onconnectionstatechange est une combinaison de l’état de l’agent ICE et de l’agent DTLS. Vous pouvez regarder ce callback pour être notifié lorsque ICE et DTLS ont tous les deux été connectés avec succès.\n"},{"id":1,"href":"/fr/docs/02-signaling/","title":"Signalisation","section":"Docs","content":" Signalisation # Qu\u0026rsquo;est-ce que la signalisation WebRTC ? # Lorsque vous créez un agent WebRTC, il ne sait rien sur l\u0026rsquo;autre pair. Il n\u0026rsquo;a aucune idée avec qui il va se connecter ni ce qu\u0026rsquo;ils vont envoyer ! La signalisation est l\u0026rsquo;amorçage initial qui rend un appel possible. Après l\u0026rsquo;échange de ces valeurs, les agents WebRTC peuvent communiquer directement entre eux.\nLes messages de signalisation sont simplement du texte. Les agents WebRTC ne se soucient pas de la manière dont ils sont transportés. Ils sont généralement partagés via Websockets, mais ce n\u0026rsquo;est pas une exigence.\nComment fonctionne la signalisation WebRTC ? # WebRTC utilise un protocole existant appelé Session Description Protocol. Via ce protocole, les deux agents WebRTC partageront tout l\u0026rsquo;état requis pour établir une connexion. Le protocole lui-même est simple à lire et à comprendre. La complexité vient de la compréhension de toutes les valeurs dont WebRTC le remplit.\nCe protocole n\u0026rsquo;est pas spécifique à WebRTC. Nous allons d\u0026rsquo;abord apprendre le Session Description Protocol sans même parler de WebRTC. WebRTC ne tire vraiment parti que d\u0026rsquo;un sous-ensemble du protocole, donc nous ne couvrirons que ce dont nous avons besoin. Après avoir compris le protocole, nous passerons à son utilisation appliquée dans WebRTC.\nQu\u0026rsquo;est-ce que le Session Description Protocol (SDP) ? # Le Session Description Protocol est défini dans la RFC 8866. Il s\u0026rsquo;agit d\u0026rsquo;un protocole clé/valeur avec un retour à la ligne après chaque valeur. Il ressemblera à un fichier INI. Une description de session contient zéro ou plusieurs descriptions de média. Mentalement, vous pouvez le modéliser comme une description de session qui contient un tableau de descriptions de média.\nUne description de média correspond généralement à un seul flux de média. Donc, si vous vouliez décrire un appel avec trois flux vidéo et deux pistes audio, vous auriez cinq descriptions de média.\nComment lire le SDP # Chaque ligne d\u0026rsquo;une description de session commencera par un seul caractère, c\u0026rsquo;est votre clé. Elle sera ensuite suivie d\u0026rsquo;un signe égal. Tout ce qui suit ce signe égal est la valeur. Après que la valeur est complète, vous aurez un retour à la ligne.\nLe Session Description Protocol définit toutes les clés qui sont valides. Vous ne pouvez utiliser que des lettres pour les clés telles que définies dans le protocole. Ces clés ont toutes une signification importante, qui sera expliquée plus tard.\nPrenez cet extrait de description de session :\na=my-sdp-value a=second-value Vous avez deux lignes. Chacune avec la clé a. La première ligne a la valeur my-sdp-value, la deuxième ligne a la valeur second-value.\nWebRTC n\u0026rsquo;utilise que certaines clés SDP # Toutes les valeurs de clé définies par le Session Description Protocol ne sont pas utilisées par WebRTC. Seules les clés utilisées dans le JavaScript Session Establishment Protocol (JSEP), défini dans la RFC 8829, sont importantes. Les sept clés suivantes sont les seules que vous devez comprendre pour le moment :\nv - Version, doit être égale à 0. o - Origin (Origine), contient un identifiant unique utile pour les renégociations. s - Session Name (Nom de session), doit être égal à -. t - Timing (Temporisation), doit être égal à 0 0. m - Media Description (Description de média) (m=\u0026lt;media\u0026gt; \u0026lt;port\u0026gt; \u0026lt;proto\u0026gt; \u0026lt;fmt\u0026gt; ...), décrite en détail ci-dessous. a - Attribute (Attribut), un champ de texte libre. C\u0026rsquo;est la ligne la plus courante dans WebRTC. c - Connection Data (Données de connexion), doit être égal à IN IP4 0.0.0.0. Descriptions de média dans une description de session # Une description de session peut contenir un nombre illimité de descriptions de média.\nUne définition de description de média contient une liste de formats. Ces formats correspondent aux types de charge utile RTP. Le codec réel est ensuite défini par un attribut avec la valeur rtpmap dans la description de média. L\u0026rsquo;importance de RTP et des types de charge utile RTP est discutée plus loin dans le chapitre sur les médias. Chaque description de média peut contenir un nombre illimité d\u0026rsquo;attributs.\nPrenez cet extrait de description de session comme exemple :\nv=0 m=audio 4000 RTP/AVP 111 a=rtpmap:111 OPUS/48000/2 m=video 4000 RTP/AVP 96 a=rtpmap:96 VP8/90000 a=my-sdp-value Vous avez deux descriptions de média, une de type audio avec le format 111 et une de type video avec le format 96. La première description de média n\u0026rsquo;a qu\u0026rsquo;un seul attribut. Cet attribut associe le type de charge utile 111 à Opus. La deuxième description de média a deux attributs. Le premier attribut associe le type de charge utile 96 à VP8, et le deuxième attribut est simplement my-sdp-value.\nExemple complet # Ce qui suit rassemble tous les concepts dont nous avons parlé. Ce sont toutes les fonctionnalités du Session Description Protocol que WebRTC utilise. Si vous pouvez lire ceci, vous pouvez lire n\u0026rsquo;importe quelle description de session WebRTC !\nv=0 o=- 0 0 IN IP4 127.0.0.1 s=- c=IN IP4 127.0.0.1 t=0 0 m=audio 4000 RTP/AVP 111 a=rtpmap:111 OPUS/48000/2 m=video 4002 RTP/AVP 96 a=rtpmap:96 VP8/90000 v, o, s, c, t sont définis, mais ils n\u0026rsquo;affectent pas la session WebRTC. Vous avez deux descriptions de média. Une de type audio et une de type video. Chacune d\u0026rsquo;elles a un attribut. Cet attribut configure les détails du pipeline RTP, qui est discuté dans le chapitre \u0026ldquo;Communication média\u0026rdquo;. Comment le Session Description Protocol et WebRTC fonctionnent ensemble # La pièce suivante du puzzle est de comprendre comment WebRTC utilise le Session Description Protocol.\nQue sont les offres et les réponses ? # WebRTC utilise un modèle offre/réponse. Tout cela signifie qu\u0026rsquo;un agent WebRTC fait une \u0026ldquo;offre\u0026rdquo; pour démarrer un appel, et l\u0026rsquo;autre agent WebRTC \u0026ldquo;répond\u0026rdquo; s\u0026rsquo;il est prêt à accepter ce qui a été offert.\nCela donne au répondeur une chance de rejeter les codecs non pris en charge dans les descriptions de média. C\u0026rsquo;est ainsi que deux pairs peuvent comprendre quels formats ils sont prêts à échanger.\nLes transceivers servent à envoyer et recevoir # Transceiver est un concept spécifique à WebRTC que vous verrez dans l\u0026rsquo;API. Ce qu\u0026rsquo;il fait, c\u0026rsquo;est exposer la \u0026ldquo;description de média\u0026rdquo; à l\u0026rsquo;API JavaScript. Chaque description de média devient un transceiver. Chaque fois que vous créez un transceiver, une nouvelle description de média est ajoutée à la description de session locale.\nChaque description de média dans WebRTC aura un attribut de direction. Cela permet à un agent WebRTC de déclarer \u0026ldquo;Je vais vous envoyer ce codec, mais je ne suis pas prêt à accepter quoi que ce soit en retour\u0026rdquo;. Il existe quatre valeurs valides :\nsend recv sendrecv inactive Valeurs SDP utilisées par WebRTC # Voici une liste de certains attributs communs que vous verrez dans une description de session provenant d\u0026rsquo;un agent WebRTC. Beaucoup de ces valeurs contrôlent les sous-systèmes que nous n\u0026rsquo;avons pas encore discutés.\ngroup:BUNDLE # Le bundling (regroupement) est un acte d\u0026rsquo;exécution de plusieurs types de trafic sur une seule connexion. Certaines implémentations WebRTC utilisent une connexion dédiée par flux média. Le bundling devrait être préféré.\nfingerprint:sha-256 # Il s\u0026rsquo;agit d\u0026rsquo;un hachage du certificat qu\u0026rsquo;un pair utilise pour DTLS. Après la fin de la négociation DTLS, vous comparez ceci au certificat réel pour confirmer que vous communiquez avec qui vous attendez.\nsetup: # Ceci contrôle le comportement de l\u0026rsquo;agent DTLS. Cela détermine s\u0026rsquo;il s\u0026rsquo;exécute en tant que client ou serveur après la connexion ICE. Les valeurs possibles sont :\nsetup:active - Exécuter en tant que client DTLS. setup:passive - Exécuter en tant que serveur DTLS. setup:actpass - Demander à l\u0026rsquo;autre agent WebRTC de choisir. mid # L\u0026rsquo;attribut \u0026ldquo;mid\u0026rdquo; est utilisé pour identifier les flux média dans une description de session.\nice-ufrag # Il s\u0026rsquo;agit de la valeur du fragment utilisateur pour l\u0026rsquo;agent ICE. Utilisé pour l\u0026rsquo;authentification du trafic ICE.\nice-pwd # Il s\u0026rsquo;agit du mot de passe pour l\u0026rsquo;agent ICE. Utilisé pour l\u0026rsquo;authentification du trafic ICE.\nrtpmap # Cette valeur est utilisée pour associer un codec spécifique à un type de charge utile RTP. Les types de charge utile ne sont pas statiques, donc pour chaque appel, l\u0026rsquo;offrant décide des types de charge utile pour chaque codec.\nfmtp # Définit des valeurs supplémentaires pour un type de charge utile. Ceci est utile pour communiquer un profil vidéo spécifique ou un paramètre d\u0026rsquo;encodeur.\ncandidate # Il s\u0026rsquo;agit d\u0026rsquo;un candidat ICE provenant de l\u0026rsquo;agent ICE. C\u0026rsquo;est une adresse possible sur laquelle l\u0026rsquo;agent WebRTC est disponible. Ceux-ci sont entièrement expliqués dans le chapitre suivant.\nssrc # Une source de synchronisation (SSRC) définit une seule piste de flux média.\nlabel est l\u0026rsquo;identifiant pour ce flux individuel. mslabel est l\u0026rsquo;identifiant pour un conteneur qui peut avoir plusieurs flux à l\u0026rsquo;intérieur.\nExemple d\u0026rsquo;une description de session WebRTC # Ce qui suit est une description de session complète générée par un client WebRTC :\nv=0 o=- 3546004397921447048 1596742744 IN IP4 0.0.0.0 s=- t=0 0 a=fingerprint:sha-256 0F:74:31:25:CB:A2:13:EC:28:6F:6D:2C:61:FF:5D:C2:BC:B9:DB:3D:98:14:8D:1A:BB:EA:33:0C:A4:60:A8:8E a=group:BUNDLE 0 1 m=audio 9 UDP/TLS/RTP/SAVPF 111 c=IN IP4 0.0.0.0 a=setup:active a=mid:0 a=ice-ufrag:CsxzEWmoKpJyscFj a=ice-pwd:mktpbhgREmjEwUFSIJyPINPUhgDqJlSd a=rtcp-mux a=rtcp-rsize a=rtpmap:111 opus/48000/2 a=fmtp:111 minptime=10;useinbandfec=1 a=ssrc:350842737 cname:yvKPspsHcYcwGFTw a=ssrc:350842737 msid:yvKPspsHcYcwGFTw DfQnKjQQuwceLFdV a=ssrc:350842737 mslabel:yvKPspsHcYcwGFTw a=ssrc:350842737 label:DfQnKjQQuwceLFdV a=msid:yvKPspsHcYcwGFTw DfQnKjQQuwceLFdV a=sendrecv a=candidate:foundation 1 udp 2130706431 192.168.1.1 53165 typ host generation 0 a=candidate:foundation 2 udp 2130706431 192.168.1.1 53165 typ host generation 0 a=candidate:foundation 1 udp 1694498815 1.2.3.4 57336 typ srflx raddr 0.0.0.0 rport 57336 generation 0 a=candidate:foundation 2 udp 1694498815 1.2.3.4 57336 typ srflx raddr 0.0.0.0 rport 57336 generation 0 a=end-of-candidates m=video 9 UDP/TLS/RTP/SAVPF 96 c=IN IP4 0.0.0.0 a=setup:active a=mid:1 a=ice-ufrag:CsxzEWmoKpJyscFj a=ice-pwd:mktpbhgREmjEwUFSIJyPINPUhgDqJlSd a=rtcp-mux a=rtcp-rsize a=rtpmap:96 VP8/90000 a=ssrc:2180035812 cname:XHbOTNRFnLtesHwJ a=ssrc:2180035812 msid:XHbOTNRFnLtesHwJ JgtwEhBWNEiOnhuW a=ssrc:2180035812 mslabel:XHbOTNRFnLtesHwJ a=ssrc:2180035812 label:JgtwEhBWNEiOnhuW a=msid:XHbOTNRFnLtesHwJ JgtwEhBWNEiOnhuW a=sendrecv Voici ce que nous savons de ce message :\nNous avons deux sections média, une audio et une vidéo. Les deux sont des transceivers sendrecv. Nous recevons deux flux et nous pouvons en renvoyer deux. Nous avons des candidats ICE et des détails d\u0026rsquo;authentification, donc nous pouvons tenter de nous connecter. Nous avons une empreinte de certificat, donc nous pouvons avoir un appel sécurisé. Sujets ultérieurs # Dans les versions ultérieures de ce livre, les sujets suivants seront également abordés :\nRenégociation Simulcast "},{"id":2,"href":"/fr/docs/03-connecting/","title":"Connexion","section":"Docs","content":" Connexion # Pourquoi WebRTC a-t-il besoin d\u0026rsquo;un sous-système dédié pour la connexion ? # La plupart des applications déployées aujourd\u0026rsquo;hui établissent des connexions client/serveur. Une connexion client/serveur nécessite que le serveur ait une adresse de transport stable et bien connue. Un client contacte un serveur, et le serveur répond.\nWebRTC n\u0026rsquo;utilise pas un modèle client/serveur, il établit des connexions pair-à-pair (P2P). Dans une connexion P2P, la tâche de créer une connexion est également répartie entre les deux pairs. C\u0026rsquo;est parce qu\u0026rsquo;une adresse de transport (IP et port) dans WebRTC ne peut pas être supposée, et peut même changer pendant la session. WebRTC rassemblera toutes les informations qu\u0026rsquo;il peut et fera de grands efforts pour réaliser une communication bidirectionnelle entre deux agents WebRTC.\nL\u0026rsquo;établissement de la connectivité pair-à-pair peut cependant être difficile. Ces agents pourraient être dans des réseaux différents sans connectivité directe. Dans les situations où une connectivité directe existe, vous pouvez encore avoir d\u0026rsquo;autres problèmes. Dans certains cas, vos clients ne parlent pas les mêmes protocoles réseau (UDP \u0026lt;-\u0026gt; TCP) ou utilisent peut-être différentes versions IP (IPv4 \u0026lt;-\u0026gt; IPv6).\nMalgré ces difficultés à établir une connexion P2P, vous obtenez des avantages par rapport à la technologie client/serveur traditionnelle en raison des attributs suivants que WebRTC offre.\nCoûts de bande passante réduits # Puisque la communication média se produit directement entre pairs, vous n\u0026rsquo;avez pas à payer pour, ou héberger un serveur séparé pour relayer les médias.\nLatence plus faible # La communication est plus rapide lorsqu\u0026rsquo;elle est directe ! Lorsqu\u0026rsquo;un utilisateur doit faire passer tout par votre serveur, cela rend les transmissions plus lentes.\nCommunication E2E sécurisée # La communication directe est plus sécurisée. Puisque les utilisateurs ne routent pas les données par votre serveur, ils n\u0026rsquo;ont même pas besoin de vous faire confiance pour ne pas les déchiffrer.\nComment cela fonctionne-t-il ? # Le processus décrit ci-dessus s\u0026rsquo;appelle Interactive Connectivity Establishment (ICE). Un autre protocole qui précède WebRTC.\nICE est un protocole qui essaie de trouver le meilleur moyen de communiquer entre deux agents ICE. Chaque agent ICE publie les moyens par lesquels il est joignable, ceux-ci sont connus comme des candidats. Un candidat est essentiellement une adresse de transport de l\u0026rsquo;agent qu\u0026rsquo;il croit que l\u0026rsquo;autre pair peut atteindre. ICE détermine ensuite le meilleur appariement de candidats.\nLe processus ICE réel est décrit plus en détail plus loin dans ce chapitre. Pour comprendre pourquoi ICE existe, il est utile de comprendre quels comportements réseau nous surmontons.\nContraintes des réseaux du monde réel # ICE consiste à surmonter les contraintes des réseaux du monde réel. Avant d\u0026rsquo;explorer la solution, parlons des problèmes réels.\nPas dans le même réseau # La plupart du temps, l\u0026rsquo;autre agent WebRTC ne sera même pas dans le même réseau. Un appel typique se fait généralement entre deux agents WebRTC dans des réseaux différents sans connectivité directe.\nCi-dessous est un graphique de deux réseaux distincts, connectés sur Internet public. Dans chaque réseau, vous avez deux hôtes.\nPour les hôtes du même réseau, il est très facile de se connecter. La communication entre 192.168.0.1 -\u0026gt; 192.168.0.2 est facile à faire ! Ces deux hôtes peuvent se connecter l\u0026rsquo;un à l\u0026rsquo;autre sans aucune aide extérieure.\nCependant, un hôte utilisant Router B n\u0026rsquo;a aucun moyen d\u0026rsquo;accéder directement à quoi que ce soit derrière Router A. Comment feriez-vous la différence entre 192.168.0.1 derrière Router A et la même IP derrière Router B ? Ce sont des IP privées ! Un hôte utilisant Router B pourrait envoyer du trafic directement à Router A, mais la requête s\u0026rsquo;arrêterait là. Comment Router A sait-il à quel hôte il doit transférer le message ?\nRestrictions de protocole # Certains réseaux n\u0026rsquo;autorisent pas du tout le trafic UDP, ou peut-être qu\u0026rsquo;ils n\u0026rsquo;autorisent pas TCP. Certains réseaux peuvent avoir une MTU (Maximum Transmission Unit) très faible. Il y a beaucoup de variables que les administrateurs réseau peuvent changer qui peuvent rendre la communication difficile.\nRègles de pare-feu/IDS # Un autre est l\u0026rsquo;\u0026ldquo;inspection approfondie des paquets\u0026rdquo; et d\u0026rsquo;autres filtrages intelligents. Certains administrateurs réseau exécutent des logiciels qui essaient de traiter chaque paquet. Souvent, ce logiciel ne comprend pas WebRTC, donc il le bloque parce qu\u0026rsquo;il ne sait pas quoi faire, par exemple en traitant les paquets WebRTC comme des paquets UDP suspects sur un port arbitraire qui n\u0026rsquo;est pas sur liste blanche.\nMappage NAT # Le mappage NAT (Network Address Translation) est la magie qui rend possible la connectivité de WebRTC. C\u0026rsquo;est ainsi que WebRTC permet à deux pairs dans des sous-réseaux complètement différents de communiquer, résolvant le problème \u0026ldquo;pas dans le même réseau\u0026rdquo; ci-dessus. Bien qu\u0026rsquo;il crée de nouveaux défis, expliquons d\u0026rsquo;abord comment fonctionne le mappage NAT.\nIl n\u0026rsquo;utilise pas de relais, de proxy ou de serveur. Encore une fois, nous avons Agent 1 et Agent 2 et ils sont dans des réseaux différents. Cependant, le trafic circule complètement. Visualisé, cela ressemble à ceci :\nPour faire fonctionner cette communication, vous établissez un mappage NAT. L\u0026rsquo;Agent 1 utilise le port 7000 pour établir une connexion WebRTC avec l\u0026rsquo;Agent 2. Cela crée une liaison de 192.168.0.1:7000 à 5.0.0.1:7000. Cela permet ensuite à l\u0026rsquo;Agent 2 d\u0026rsquo;atteindre l\u0026rsquo;Agent 1 en envoyant des paquets à 5.0.0.1:7000. Créer un mappage NAT comme dans cet exemple est comme une version automatisée de la redirection de port dans votre routeur.\nL\u0026rsquo;inconvénient du mappage NAT est qu\u0026rsquo;il n\u0026rsquo;y a pas une seule forme de mappage (par exemple, la redirection de port statique), et le comportement est incohérent entre les réseaux. Les FAI et les fabricants de matériel peuvent le faire de différentes manières. Dans certains cas, les administrateurs réseau peuvent même le désactiver.\nLa bonne nouvelle est que la gamme complète des comportements est comprise et observable, de sorte qu\u0026rsquo;un agent ICE est capable de confirmer qu\u0026rsquo;il a créé un mappage NAT, et les attributs du mappage.\nLe document qui décrit ces comportements est la RFC 4787.\nCréation d\u0026rsquo;un mappage # Créer un mappage est la partie la plus facile. Lorsque vous envoyez un paquet à une adresse en dehors de votre réseau, un mappage est créé ! Un mappage NAT est juste une IP publique temporaire et un port qui sont alloués par votre NAT. Le message sortant sera réécrit pour avoir son adresse source donnée par la nouvelle adresse de mappage. Si un message est envoyé au mappage, il sera automatiquement routé vers l\u0026rsquo;hôte à l\u0026rsquo;intérieur du NAT qui l\u0026rsquo;a créé. Les détails autour des mappages sont là où cela devient compliqué.\nComportements de création de mappage # La création de mappage se divise en trois catégories différentes :\nMappage indépendant du point de terminaison # Un mappage est créé pour chaque expéditeur à l\u0026rsquo;intérieur du NAT. Si vous envoyez deux paquets à deux adresses distantes différentes, le mappage NAT sera réutilisé. Les deux hôtes distants verraient la même IP et le même port source. Si les hôtes distants répondent, ce sera renvoyé au même écouteur local.\nC\u0026rsquo;est le meilleur scénario. Pour qu\u0026rsquo;un appel fonctionne, au moins un côté DOIT être de ce type.\nMappage dépendant de l\u0026rsquo;adresse # Un nouveau mappage est créé chaque fois que vous envoyez un paquet à une nouvelle adresse. Si vous envoyez deux paquets à différents hôtes, deux mappages seront créés. Si vous envoyez deux paquets au même hôte distant mais à des ports de destination différents, un nouveau mappage ne sera PAS créé.\nMappage dépendant de l\u0026rsquo;adresse et du port # Un nouveau mappage est créé si l\u0026rsquo;IP ou le port distant est différent. Si vous envoyez deux paquets au même hôte distant, mais à des ports de destination différents, un nouveau mappage sera créé.\nComportements de filtrage de mappage # Le filtrage de mappage est l\u0026rsquo;ensemble des règles concernant qui est autorisé à utiliser le mappage. Ils se répartissent en trois classifications similaires :\nFiltrage indépendant du point de terminaison # N\u0026rsquo;importe qui peut utiliser le mappage. Vous pouvez partager le mappage avec plusieurs autres pairs, et ils pourraient tous y envoyer du trafic.\nFiltrage dépendant de l\u0026rsquo;adresse # Seul l\u0026rsquo;hôte pour lequel le mappage a été créé peut utiliser le mappage. Si vous envoyez un paquet à l\u0026rsquo;hôte A, vous ne pouvez obtenir une réponse que de ce même hôte. Si l\u0026rsquo;hôte B tente d\u0026rsquo;envoyer un paquet à ce mappage, il sera ignoré.\nFiltrage dépendant de l\u0026rsquo;adresse et du port # Seuls l\u0026rsquo;hôte et le port pour lesquels le mappage a été créé peuvent utiliser ce mappage. Si vous envoyez un paquet à A:5000, vous ne pouvez obtenir une réponse que de ce même hôte et port. Si A:5001 tente d\u0026rsquo;envoyer un paquet à ce mappage, il sera ignoré.\nActualisation du mappage # Il est recommandé que si un mappage n\u0026rsquo;est pas utilisé pendant 5 minutes, il devrait être détruit. Ceci est entièrement à la discrétion du FAI ou du fabricant de matériel.\nSTUN # STUN (Session Traversal Utilities for NAT) est un protocole qui a été créé juste pour travailler avec les NAT. C\u0026rsquo;est une autre technologie qui précède WebRTC (et ICE !). Il est défini par la RFC 8489, qui définit également la structure des paquets STUN. Le protocole STUN est également utilisé par ICE/TURN.\nSTUN est utile car il permet la création programmatique de mappages NAT. Avant STUN, nous étions capables de créer un mappage NAT, mais nous n\u0026rsquo;avions aucune idée de quelle était l\u0026rsquo;IP et le port de celui-ci ! STUN vous donne non seulement la capacité de créer un mappage, mais vous donne également les détails afin que vous puissiez les partager avec d\u0026rsquo;autres, afin qu\u0026rsquo;ils puissent vous renvoyer du trafic via le mappage que vous venez de créer.\nCommençons par une description basique de STUN. Plus tard, nous développerons sur l\u0026rsquo;utilisation de TURN et ICE. Pour l\u0026rsquo;instant, nous allons juste décrire le flux requête/réponse pour créer un mappage. Ensuite, nous parlerons de comment obtenir les détails de celui-ci pour les partager avec d\u0026rsquo;autres. C\u0026rsquo;est le processus qui se produit lorsque vous avez un serveur stun: dans vos URL ICE pour une PeerConnection WebRTC. En bref, STUN aide un point de terminaison derrière un NAT à déterminer quel mappage a été créé en demandant à un serveur STUN à l\u0026rsquo;extérieur du NAT de rapporter ce qu\u0026rsquo;il observe.\nStructure du protocole # Chaque paquet STUN a la structure suivante :\n0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ |0 0| STUN Message Type | Message Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Magic Cookie | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | | | Transaction ID (96 bits) | | | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Data | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ Type de message STUN # Chaque paquet STUN a un type. Pour l\u0026rsquo;instant, nous ne nous soucions que des suivants :\nBinding Request - 0x0001 Binding Response - 0x0101 Pour créer un mappage NAT, nous faisons une Binding Request. Ensuite, le serveur répond avec une Binding Response.\nLongueur du message # C\u0026rsquo;est la longueur de la section Data. Cette section contient des données arbitraires qui sont définies par le Message Type.\nMagic Cookie # La valeur fixe 0x2112A442 en ordre d\u0026rsquo;octets réseau, elle aide à distinguer le trafic STUN des autres protocoles.\nID de transaction # Un identifiant de 96 bits qui identifie de manière unique une requête/réponse. Cela vous aide à associer vos requêtes et réponses.\nDonnées # Les données contiendront une liste d\u0026rsquo;attributs STUN. Un attribut STUN a la structure suivante :\n0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Type | Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Value (variable) .... +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ La STUN Binding Request n\u0026rsquo;utilise aucun attribut. Cela signifie qu\u0026rsquo;une STUN Binding Request ne contient que l\u0026rsquo;en-tête.\nLa STUN Binding Response utilise un XOR-MAPPED-ADDRESS (0x0020). Cet attribut contient une IP et un port. C\u0026rsquo;est l\u0026rsquo;IP et le port du mappage NAT qui est créé !\nCréer un mappage NAT # Créer un mappage NAT en utilisant STUN ne nécessite que l\u0026rsquo;envoi d\u0026rsquo;une requête ! Vous envoyez une STUN Binding Request au serveur STUN. Le serveur STUN répond alors avec une STUN Binding Response. Cette STUN Binding Response contiendra l\u0026rsquo;Adresse mappée. L\u0026rsquo;Adresse mappée est la façon dont le serveur STUN vous voit et est votre mappage NAT. L\u0026rsquo;Adresse mappée est ce que vous partageriez si vous vouliez que quelqu\u0026rsquo;un vous envoie des paquets.\nLes gens appelleront également l\u0026rsquo;Adresse mappée votre IP publique ou Candidat réflexif de serveur.\nDétermination du type de NAT # Malheureusement, l\u0026rsquo;Adresse mappée peut ne pas être utile dans tous les cas. Si elle est Dépendante de l'adresse, seul le serveur STUN peut vous renvoyer du trafic. Si vous la partagez et qu\u0026rsquo;un autre pair essaie d\u0026rsquo;envoyer des messages, ils seront abandonnés. Cela la rend inutile pour communiquer avec d\u0026rsquo;autres. Vous pouvez trouver que le cas Dépendant de l'adresse est en fait résolvable, si l\u0026rsquo;hôte qui exécute le serveur STUN peut également transférer des paquets pour vous au pair ! Cela nous mène à la solution utilisant TURN ci-dessous.\nLa RFC 5780 définit une méthode pour exécuter un test afin de déterminer votre type de NAT. Ceci est utile car vous sauriez à l\u0026rsquo;avance si une connectivité directe est possible.\nTURN # TURN (Traversal Using Relays around NAT) est défini dans la RFC 8656 et est la solution lorsque la connectivité directe n\u0026rsquo;est pas possible. Cela pourrait être parce que vous avez deux types de NAT incompatibles, ou peut-être ne peuvent-ils pas parler le même protocole ! TURN peut également être utilisé à des fins de confidentialité. En faisant passer toute votre communication par TURN, vous obscurcissez l\u0026rsquo;adresse réelle du client.\nTURN utilise un serveur dédié. Ce serveur agit comme un proxy pour un client. Le client se connecte à un serveur TURN et crée une Allocation. En créant une allocation, un client obtient une IP/Port/Protocole temporaire qui peut être utilisé pour renvoyer du trafic au client. Ce nouvel écouteur est connu comme l\u0026rsquo;Adresse de transport relayée. Pensez-y comme à une adresse de transfert, vous la donnez pour que d\u0026rsquo;autres puissent vous envoyer du trafic via TURN ! Pour chaque pair auquel vous donnez l\u0026rsquo;Adresse de transport relayée, vous devez créer une nouvelle Permission pour permettre la communication avec vous.\nLorsque vous envoyez du trafic sortant via TURN, il est envoyé via l\u0026rsquo;Adresse de transport relayée. Lorsqu\u0026rsquo;un pair distant reçoit du trafic, il le voit provenir du serveur TURN.\nCycle de vie TURN # Voici tout ce qu\u0026rsquo;un client qui souhaite créer une allocation TURN doit faire. Communiquer avec quelqu\u0026rsquo;un qui utilise TURN ne nécessite aucune modification. L\u0026rsquo;autre pair obtient une IP et un port, et il communique avec comme n\u0026rsquo;importe quel autre hôte.\nAllocations # Les allocations sont au cœur de TURN. Une allocation est essentiellement une \u0026ldquo;session TURN\u0026rdquo;. Pour créer une allocation TURN, vous communiquez avec l\u0026rsquo;Adresse de transport du serveur TURN (généralement le port 3478).\nLors de la création d\u0026rsquo;une allocation, vous devez fournir ce qui suit :\nNom d\u0026rsquo;utilisateur/Mot de passe - La création d\u0026rsquo;allocations TURN nécessite une authentification. Transport d\u0026rsquo;allocation - Le protocole de transport entre le serveur (Adresse de transport relayée) et les pairs, peut être UDP ou TCP. Even-Port - Vous pouvez demander des ports séquentiels pour plusieurs allocations, pas pertinent pour WebRTC. Si la requête réussit, vous obtenez une réponse avec le serveur TURN avec les attributs STUN suivants dans la section Data :\nXOR-MAPPED-ADDRESS - Adresse mappée du Client TURN. Lorsque quelqu\u0026rsquo;un envoie des données à l\u0026rsquo;Adresse de transport relayée, c\u0026rsquo;est là qu\u0026rsquo;elles sont transférées. RELAYED-ADDRESS - C\u0026rsquo;est l\u0026rsquo;adresse que vous donnez aux autres clients. Si quelqu\u0026rsquo;un envoie un paquet à cette adresse, il est relayé au client TURN. LIFETIME - Combien de temps jusqu\u0026rsquo;à ce que cette allocation TURN soit détruite. Vous pouvez prolonger la durée de vie en envoyant une requête Refresh. Permissions # Un hôte distant ne peut pas envoyer dans votre Adresse de transport relayée jusqu\u0026rsquo;à ce que vous créiez une permission pour lui. Lorsque vous créez une permission, vous dites au serveur TURN que cette IP et ce port sont autorisés à envoyer du trafic entrant.\nL\u0026rsquo;hôte distant doit vous donner l\u0026rsquo;IP et le port tels qu\u0026rsquo;ils apparaissent au serveur TURN. Cela signifie qu\u0026rsquo;il devrait envoyer une STUN Binding Request au serveur TURN. Un cas d\u0026rsquo;erreur courant est qu\u0026rsquo;un hôte distant enverra une STUN Binding Request à un serveur différent. Ils vous demanderont ensuite de créer une permission pour cette IP.\nDisons que vous voulez créer une permission pour un hôte derrière un Mappage dépendant de l'adresse. Si vous générez l\u0026rsquo;Adresse mappée à partir d\u0026rsquo;un serveur TURN différent, tout le trafic entrant sera abandonné. Chaque fois qu\u0026rsquo;ils communiquent avec un hôte différent, cela génère un nouveau mappage. Les permissions expirent après 5 minutes si elles ne sont pas actualisées.\nSendIndication/ChannelData # Ces deux messages sont pour que le client TURN envoie des messages à un pair distant.\nSendIndication est un message autonome. À l\u0026rsquo;intérieur se trouvent les données que vous souhaitez envoyer, et à qui vous souhaitez les envoyer. C\u0026rsquo;est du gaspillage si vous envoyez beaucoup de messages à un pair distant. Si vous envoyez 1 000 messages, vous répéterez leur adresse IP 1 000 fois !\nChannelData vous permet d\u0026rsquo;envoyer des données, mais pas de répéter une adresse IP. Vous créez un canal avec une IP et un port. Vous envoyez ensuite avec le ChannelId, et l\u0026rsquo;IP et le port seront remplis côté serveur. C\u0026rsquo;est le meilleur choix si vous envoyez beaucoup de messages.\nActualisation # Les allocations se détruiront automatiquement. Le client TURN doit les actualiser avant le LIFETIME donné lors de la création de l\u0026rsquo;allocation.\nUtilisation de TURN # L\u0026rsquo;utilisation de TURN existe sous deux formes. Habituellement, vous avez un pair agissant comme un \u0026ldquo;client TURN\u0026rdquo; et l\u0026rsquo;autre côté communiquant directement. Dans certains cas, vous pourriez avoir l\u0026rsquo;utilisation de TURN des deux côtés, par exemple parce que les deux clients sont dans des réseaux qui bloquent UDP et donc la connexion aux serveurs TURN respectifs se fait via TCP.\nCes diagrammes aident à illustrer à quoi cela ressemblerait.\nUne allocation TURN pour la communication # Deux allocations TURN pour la communication # ICE # ICE (Interactive Connectivity Establishment) est la façon dont WebRTC connecte deux agents. Défini dans la RFC 8445, c\u0026rsquo;est une autre technologie qui précède WebRTC ! ICE est un protocole pour établir la connectivité. Il détermine toutes les routes possibles entre les deux pairs et s\u0026rsquo;assure ensuite que vous restez connecté.\nCes routes sont connues comme des Paires de candidats, qui est un appariement d\u0026rsquo;une adresse de transport locale et distante. C\u0026rsquo;est là que STUN et TURN entrent en jeu avec ICE. Ces adresses peuvent être votre adresse IP locale plus un port, un mappage NAT, ou une Adresse de transport relayée. Chaque côté rassemble toutes les adresses qu\u0026rsquo;ils veulent utiliser, les échange, puis tente de se connecter !\nDeux agents ICE communiquent en utilisant des paquets ping ICE (ou formellement appelés vérifications de connectivité) pour établir la connectivité. Après l\u0026rsquo;établissement de la connectivité, ils peuvent envoyer toutes les données qu\u0026rsquo;ils veulent. Ce sera comme utiliser un socket normal. Ces vérifications utilisent le protocole STUN.\nCréation d\u0026rsquo;un agent ICE # Un agent ICE est soit Controlling soit Controlled. L\u0026rsquo;agent Controlling est celui qui décide de la Paire de candidats sélectionnée. Habituellement, le pair envoyant l\u0026rsquo;offre est le côté contrôlant.\nChaque côté doit avoir un fragment utilisateur et un mot de passe. Ces deux valeurs doivent être échangées avant même que les vérifications de connectivité puissent commencer. Le fragment utilisateur est envoyé en texte clair et est utile pour démultiplexer plusieurs sessions ICE. Le mot de passe est utilisé pour générer un attribut MESSAGE-INTEGRITY. À la fin de chaque paquet STUN, il y a un attribut qui est un hachage du paquet entier utilisant le mot de passe comme clé. Ceci est utilisé pour authentifier le paquet et s\u0026rsquo;assurer qu\u0026rsquo;il n\u0026rsquo;a pas été altéré.\nPour WebRTC, toutes ces valeurs sont distribuées via la Description de session comme décrit dans le chapitre précédent.\nCollecte de candidats # Nous devons maintenant rassembler toutes les adresses possibles auxquelles nous sommes joignables. Ces adresses sont connues comme des candidats.\nHost # Un candidat Host écoute directement sur une interface locale. Cela peut être UDP ou TCP.\nmDNS # Un candidat mDNS est similaire à un candidat host, mais l\u0026rsquo;adresse IP est obscurcie. Au lieu d\u0026rsquo;informer l\u0026rsquo;autre côté de votre adresse IP, vous leur donnez un UUID comme nom d\u0026rsquo;hôte. Vous configurez ensuite un écouteur multicast, et répondez si quelqu\u0026rsquo;un demande l\u0026rsquo;UUID que vous avez publié.\nSi vous êtes dans le même réseau que l\u0026rsquo;agent, vous pouvez vous trouver via Multicast. Si vous n\u0026rsquo;êtes pas dans le même réseau, vous ne pourrez pas vous connecter (à moins que l\u0026rsquo;administrateur réseau n\u0026rsquo;ait explicitement configuré le réseau pour permettre aux paquets Multicast de traverser).\nCeci est utile à des fins de confidentialité. Un utilisateur pourrait découvrir votre adresse IP locale via WebRTC avec un candidat Host (sans même essayer de se connecter à vous), mais avec un candidat mDNS, maintenant ils n\u0026rsquo;obtiennent qu\u0026rsquo;un UUID aléatoire.\nServer Reflexive # Un candidat Server Reflexive est généré en faisant une STUN Binding Request à un serveur STUN.\nLorsque vous obtenez la STUN Binding Response, le XOR-MAPPED-ADDRESS est votre candidat Server Reflexive.\nPeer Reflexive # Un candidat Peer Reflexive est créé lorsque le pair distant reçoit votre requête à partir d\u0026rsquo;une adresse précédemment inconnue du pair. À la réception, le pair rapporte (réfléchit) ladite adresse vers vous. Le pair sait que la requête a été envoyée par vous et non par quelqu\u0026rsquo;un d\u0026rsquo;autre parce qu\u0026rsquo;ICE est un protocole authentifié.\nCela se produit couramment lorsqu\u0026rsquo;un candidat Host communique avec un candidat Server Reflexive qui est dans un sous-réseau différent, ce qui entraîne la création d\u0026rsquo;un nouveau mappage NAT. Rappelez-vous que nous avons dit que les vérifications de connectivité sont en fait des paquets STUN ? Le format de la réponse STUN permet naturellement à un pair de rapporter l\u0026rsquo;adresse peer-reflexive.\nRelay # Un candidat Relay est généré en utilisant un serveur TURN.\nAprès la négociation initiale avec le serveur TURN, vous recevez une RELAYED-ADDRESS, c\u0026rsquo;est votre candidat Relay.\nVérifications de connectivité # Nous connaissons maintenant le fragment utilisateur, le mot de passe et les candidats de l\u0026rsquo;agent distant. Nous pouvons maintenant essayer de nous connecter ! Chaque candidat est apparié avec chaque autre. Donc, si vous avez 3 candidats de chaque côté, vous avez maintenant 9 paires de candidats.\nVisuellement, cela ressemble à ceci :\nSélection de candidat # Les agents Controlling et Controlled commencent tous deux à envoyer du trafic sur chaque paire. Ceci est nécessaire si un agent est derrière un Mappage dépendant de l'adresse, cela causera la création d\u0026rsquo;un Candidat Peer Reflexive.\nChaque Paire de candidats qui a vu du trafic réseau est ensuite promue en une paire Valid Candidate. L\u0026rsquo;agent Controlling prend ensuite une paire Valid Candidate et la nomme. Cela devient la Paire nominée. Les agents Controlling et Controlled tentent ensuite un autre tour de communication bidirectionnelle. Si cela réussit, la Paire nominée devient la Paire de candidats sélectionnée ! Cette paire est ensuite utilisée pour le reste de la session.\nRedémarrages # Si la Paire de candidats sélectionnée cesse de fonctionner pour une raison quelconque (le mappage NAT expire, le serveur TURN plante), l\u0026rsquo;agent ICE passera à l\u0026rsquo;état Failed. Les deux agents peuvent être redémarrés et feront tout le processus à nouveau.\n"},{"id":3,"href":"/fr/docs/04-securing/","title":"Sécurisation","section":"Docs","content":" Sécurisation # Quelle sécurité offre WebRTC ? # Chaque connexion WebRTC est authentifiée et chiffrée. Vous pouvez être sûr qu\u0026rsquo;un tiers ne peut pas voir ce que vous envoyez ou insérer de faux messages. Vous pouvez également être sûr que l\u0026rsquo;agent WebRTC qui a généré la description de session est celui avec lequel vous communiquez.\nIl est très important que personne ne modifie ces messages. Il est acceptable qu\u0026rsquo;un tiers lise la description de session en transit. Cependant, WebRTC n\u0026rsquo;a aucune protection contre sa modification. Un attaquant pourrait effectuer une attaque de l\u0026rsquo;homme du milieu sur vous en changeant les candidats ICE et en mettant à jour l\u0026rsquo;empreinte du certificat.\nComment cela fonctionne-t-il ? # WebRTC utilise deux protocoles préexistants, Datagram Transport Layer Security (DTLS) et le Secure Real-time Transport Protocol (SRTP).\nDTLS vous permet de négocier une session puis d\u0026rsquo;échanger des données en toute sécurité entre deux pairs. C\u0026rsquo;est un frère de TLS, la même technologie qui alimente HTTPS, mais DTLS utilise UDP au lieu de TCP comme couche de transport. Cela signifie que le protocole doit gérer la livraison non fiable. SRTP est spécifiquement conçu pour échanger des médias de manière sécurisée. Il y a quelques optimisations que nous pouvons faire en l\u0026rsquo;utilisant au lieu de DTLS.\nDTLS est utilisé en premier. Il effectue une négociation sur la connexion fournie par ICE. DTLS est un protocole client/serveur, donc un côté doit démarrer la négociation. Les rôles Client/Serveur sont choisis lors de la signalisation. Pendant la négociation DTLS, les deux côtés offrent un certificat. Une fois la négociation terminée, ce certificat est comparé au hachage du certificat dans la description de session. Ceci est pour s\u0026rsquo;assurer que la négociation s\u0026rsquo;est produite avec l\u0026rsquo;agent WebRTC attendu. La connexion DTLS est ensuite disponible pour être utilisée pour la communication DataChannel.\nPour créer une session SRTP, nous l\u0026rsquo;initialisons en utilisant les clés générées par DTLS. SRTP n\u0026rsquo;a pas de mécanisme de négociation, donc il doit être amorcé avec des clés externes. Une fois cela fait, les médias peuvent être échangés en étant chiffrés en utilisant SRTP !\nSécurité 101 # Pour comprendre la technologie présentée dans ce chapitre, vous devrez d\u0026rsquo;abord comprendre ces termes. La cryptographie est un sujet délicat, il vaudrait donc la peine de consulter d\u0026rsquo;autres sources également !\nTexte en clair et texte chiffré # Le texte en clair est l\u0026rsquo;entrée d\u0026rsquo;un chiffrement. Le texte chiffré est la sortie d\u0026rsquo;un chiffrement.\nChiffrement # Le chiffrement est une série d\u0026rsquo;étapes qui prend du texte en clair pour le transformer en texte chiffré. Le chiffrement peut ensuite être inversé, de sorte que vous puissiez ramener votre texte chiffré en texte en clair. Un chiffrement a généralement une clé pour changer son comportement. Un autre terme pour cela est le chiffrement et le déchiffrement.\nUn chiffrement simple est ROT13. Chaque lettre est déplacée de 13 caractères en avant. Pour annuler le chiffrement, vous déplacez 13 caractères en arrière. Le texte en clair HELLO deviendrait le texte chiffré URYYB. Dans ce cas, le chiffrement est ROT, et la clé est 13.\nFonctions de hachage # Une fonction de hachage cryptographique est un processus à sens unique qui génère un condensé. Étant donné une entrée, elle génère la même sortie à chaque fois. Il est important que la sortie ne soit pas réversible. Si vous avez une sortie, vous ne devriez pas être capable de déterminer son entrée. Le hachage est utile lorsque vous voulez confirmer qu\u0026rsquo;un message n\u0026rsquo;a pas été altéré.\nUne fonction de hachage simple (bien que certainement pas adaptée à la cryptographie réelle) serait de ne prendre qu\u0026rsquo;une lettre sur deux. HELLO deviendrait HLO. Vous ne pouvez pas supposer que HELLO était l\u0026rsquo;entrée, mais vous pouvez confirmer que HELLO correspondrait au condensé de hachage.\nCryptographie à clé publique/privée # La cryptographie à clé publique/privée décrit le type de chiffrements que DTLS et SRTP utilisent. Dans ce système, vous avez deux clés, une clé publique et une clé privée. La clé publique est pour chiffrer les messages et peut être partagée en toute sécurité. La clé privée est pour déchiffrer, et ne doit jamais être partagée. C\u0026rsquo;est la seule clé qui peut déchiffrer les messages chiffrés avec la clé publique.\nÉchange Diffie–Hellman # L\u0026rsquo;échange Diffie–Hellman permet à deux utilisateurs qui ne se sont jamais rencontrés auparavant de créer un secret partagé en toute sécurité sur Internet. L\u0026rsquo;utilisateur A peut envoyer un secret à l\u0026rsquo;utilisateur B sans se soucier de l\u0026rsquo;écoute clandestine. Cela dépend de la difficulté de casser le problème du logarithme discret. Vous n\u0026rsquo;avez pas besoin de comprendre pleinement comment cela fonctionne, mais il est utile de savoir que c\u0026rsquo;est ce qui rend possible la négociation DTLS.\nWikipédia a un exemple de ceci en action ici.\nFonction pseudo-aléatoire # Une fonction pseudo-aléatoire (PRF) est une fonction prédéfinie pour générer une valeur qui semble aléatoire. Elle peut prendre plusieurs entrées et générer une seule sortie.\nFonction de dérivation de clé # La dérivation de clé est un type de fonction pseudo-aléatoire. La dérivation de clé est une fonction utilisée pour rendre une clé plus forte. Un modèle courant est l\u0026rsquo;étirement de clé.\nDisons que vous recevez une clé de 8 octets. Vous pourriez utiliser une KDF pour la rendre plus forte.\nNonce # Un nonce est une entrée supplémentaire à un chiffrement. Ceci est utilisé pour que vous puissiez obtenir une sortie différente du chiffrement, même si vous chiffrez le même message plusieurs fois.\nSi vous chiffrez le même message 10 fois, le chiffrement vous donnera le même texte chiffré 10 fois. En utilisant un nonce, vous pouvez obtenir une sortie différente, tout en utilisant la même clé. Il est important d\u0026rsquo;utiliser un nonce différent pour chaque message ! Sinon, cela annule une grande partie de la valeur.\nCode d\u0026rsquo;authentification de message # Un code d\u0026rsquo;authentification de message est un hachage qui est placé à la fin d\u0026rsquo;un message. Un MAC prouve que le message provient de l\u0026rsquo;utilisateur attendu.\nSi vous n\u0026rsquo;utilisez pas de MAC, un attaquant pourrait insérer des messages invalides. Après déchiffrement, vous n\u0026rsquo;auriez que des ordures car ils ne connaissent pas la clé.\nRotation de clé # La rotation de clé est la pratique de changer votre clé à intervalles réguliers. Cela rend une clé volée moins impactante. Si une clé est volée ou divulguée, moins de données peuvent être déchiffrées.\nDTLS # DTLS (Datagram Transport Layer Security) permet à deux pairs d\u0026rsquo;établir une communication sécurisée sans aucune configuration préexistante. Même si quelqu\u0026rsquo;un écoute la conversation, il ne pourra pas déchiffrer les messages.\nPour qu\u0026rsquo;un client DTLS et un serveur communiquent, ils doivent se mettre d\u0026rsquo;accord sur un chiffrement et la clé. Ils déterminent ces valeurs en effectuant une négociation DTLS. Pendant la négociation, les messages sont en texte clair. Lorsqu\u0026rsquo;un client/serveur DTLS a échangé suffisamment de détails pour commencer à chiffrer, il envoie un Change Cipher Spec. Après ce message, chaque message suivant sera chiffré !\nFormat de paquet # Chaque paquet DTLS commence par un en-tête.\nType de contenu # Vous pouvez vous attendre aux types suivants :\n20 - Change Cipher Spec 22 - Handshake 23 - Application Data Handshake est utilisé pour échanger les détails pour démarrer la session. Change Cipher Spec est utilisé pour notifier l\u0026rsquo;autre côté que tout sera chiffré. Application Data sont les messages chiffrés.\nVersion # La version peut être soit 0x0000feff (DTLS v1.0) soit 0x0000fefd (DTLS v1.2), il n\u0026rsquo;y a pas de v1.1.\nÉpoque # L\u0026rsquo;époque commence à 0, mais devient 1 après un Change Cipher Spec. Tout message avec une époque non nulle est chiffré.\nNuméro de séquence # Le numéro de séquence est utilisé pour garder les messages dans l\u0026rsquo;ordre. Chaque message augmente le numéro de séquence. Lorsque l\u0026rsquo;époque est incrémentée, le numéro de séquence recommence.\nLongueur et charge utile # La charge utile est spécifique au Type de contenu. Pour un Application Data, la Charge utile est les données chiffrées. Pour Handshake, ce sera différent selon le message. La longueur indique la taille de la Charge utile.\nMachine à états de négociation # Pendant la négociation, le client/serveur échange une série de messages. Ces messages sont regroupés en vols. Chaque vol peut avoir plusieurs messages (ou juste un). Un vol n\u0026rsquo;est pas complet tant que tous les messages du vol n\u0026rsquo;ont pas été reçus. Nous décrirons le but de chaque message plus en détail ci-dessous.\nClientHello # ClientHello est le message initial envoyé par le client. Il contient une liste d\u0026rsquo;attributs. Ces attributs indiquent au serveur les chiffrements et fonctionnalités que le client prend en charge. Pour WebRTC, c\u0026rsquo;est ainsi que nous choisissons également le chiffrement SRTP. Il contient également des données aléatoires qui seront utilisées pour générer les clés de la session.\nHelloVerifyRequest # HelloVerifyRequest est envoyé par le serveur au client. C\u0026rsquo;est pour s\u0026rsquo;assurer que le client avait l\u0026rsquo;intention d\u0026rsquo;envoyer la requête. Le client renvoie ensuite le ClientHello, mais avec un jeton fourni dans le HelloVerifyRequest.\nServerHello # ServerHello est la réponse du serveur pour la configuration de cette session. Il contient quel chiffrement sera utilisé lorsque cette session sera terminée. Il contient également les données aléatoires du serveur.\nCertificate # Certificate contient le certificat pour le client ou le serveur. Ceci est utilisé pour identifier de manière unique avec qui nous communiquions. Après la fin de la négociation, nous nous assurerons que ce certificat, lorsqu\u0026rsquo;il est haché, correspond à l\u0026rsquo;empreinte dans la SessionDescription.\nServerKeyExchange/ClientKeyExchange # Ces messages sont utilisés pour transmettre la clé publique. Au démarrage, le client et le serveur génèrent tous deux une paire de clés. Après la négociation, ces valeurs seront utilisées pour générer le Pre-Master Secret.\nCertificateRequest # Un CertificateRequest est envoyé par le serveur notifiant le client qu\u0026rsquo;il veut un certificat. Le serveur peut soit demander soit exiger un certificat.\nServerHelloDone # ServerHelloDone notifie le client que le serveur a terminé avec la négociation.\nCertificateVerify # CertificateVerify est la façon dont l\u0026rsquo;expéditeur prouve qu\u0026rsquo;il a la clé privée envoyée dans le message Certificate.\nChangeCipherSpec # ChangeCipherSpec informe le récepteur que tout ce qui est envoyé après ce message sera chiffré.\nFinished # Finished est chiffré et contient un hachage de tous les messages. Ceci est pour affirmer que la négociation n\u0026rsquo;a pas été altérée.\nGénération de clé # Après la fin de la négociation, vous pouvez commencer à envoyer des données chiffrées. Le chiffrement a été choisi par le serveur et se trouve dans le ServerHello. Comment la clé a-t-elle été choisie cependant ?\nD\u0026rsquo;abord, nous générons le Pre-Master Secret. Pour obtenir cette valeur, Diffie–Hellman est utilisé sur les clés échangées par le ServerKeyExchange et le ClientKeyExchange. Les détails diffèrent selon le chiffrement choisi.\nEnsuite, le Master Secret est généré. Chaque version de DTLS a une fonction pseudo-aléatoire définie. Pour DTLS 1.2, la fonction prend le Pre-Master Secret et les valeurs aléatoires dans le ClientHello et le ServerHello. La sortie de l\u0026rsquo;exécution de la fonction pseudo-aléatoire est le Master Secret. Le Master Secret est la valeur qui est utilisée pour le chiffrement.\nÉchange d\u0026rsquo;ApplicationData # Le cheval de bataille de DTLS est ApplicationData. Maintenant que nous avons un chiffrement initialisé, nous pouvons commencer à chiffrer et à envoyer des valeurs.\nLes messages ApplicationData utilisent un en-tête DTLS comme décrit précédemment. La Charge utile est remplie avec du texte chiffré. Vous avez maintenant une session DTLS fonctionnelle et pouvez communiquer en toute sécurité.\nDTLS a beaucoup plus de fonctionnalités intéressantes comme la renégociation. Elles ne sont pas utilisées par WebRTC, donc elles ne seront pas couvertes ici.\nSRTP # SRTP est un protocole conçu spécifiquement pour chiffrer les paquets RTP. Pour démarrer une session SRTP, vous spécifiez vos clés et votre chiffrement. Contrairement à DTLS, il n\u0026rsquo;a pas de mécanisme de négociation. Toute la configuration et les clés ont été générées pendant la négociation DTLS.\nDTLS fournit une API dédiée pour exporter les clés à utiliser par un autre processus. Ceci est défini dans la RFC 5705.\nCréation de session # SRTP définit une fonction de dérivation de clé qui est utilisée sur les entrées. Lors de la création d\u0026rsquo;une session SRTP, les entrées sont passées à travers cela pour générer nos clés pour notre chiffrement SRTP. Après cela, vous pouvez passer au traitement des médias.\nÉchange de médias # Chaque paquet RTP a un numéro de séquence de 16 bits. Ces numéros de séquence sont utilisés pour garder les paquets dans l\u0026rsquo;ordre, comme une clé primaire. Pendant un appel, ceux-ci déborderont. SRTP garde une trace de cela et l\u0026rsquo;appelle le compteur de débordement.\nLors du chiffrement d\u0026rsquo;un paquet, SRTP utilise le compteur de débordement et le numéro de séquence comme nonce. Ceci est pour garantir que même si vous envoyez les mêmes données deux fois, le texte chiffré sera différent. Ceci est important pour empêcher un attaquant d\u0026rsquo;identifier des modèles ou de tenter une attaque par rejeu.\n"},{"id":4,"href":"/fr/docs/05-real-time-networking/","title":"Réseau en temps réel","section":"Docs","content":" Réseau en temps réel # Pourquoi le réseau est-il si important dans la communication en temps réel ? # Les réseaux sont le facteur limitant dans la communication en temps réel. Dans un monde idéal, nous aurions une bande passante illimitée et les paquets arriveraient instantanément. Ce n\u0026rsquo;est cependant pas le cas. Les réseaux sont limités, et les conditions peuvent changer à tout moment. Mesurer et observer les conditions du réseau est également un problème difficile. Vous pouvez obtenir des comportements différents selon le matériel, le logiciel et sa configuration.\nLa communication en temps réel pose également un problème qui n\u0026rsquo;existe pas dans la plupart des autres domaines. Pour un développeur web, ce n\u0026rsquo;est pas fatal si votre site web est plus lent sur certains réseaux. Tant que toutes les données arrivent, les utilisateurs sont satisfaits. Avec WebRTC, si vos données sont en retard, elles sont inutiles. Personne ne se soucie de ce qui a été dit dans une conférence téléphonique il y a 5 secondes. Donc, lors du développement d\u0026rsquo;un système de communication en temps réel, vous devez faire un compromis. Quelle est ma limite de temps, et combien de données puis-je envoyer ?\nCe chapitre couvre les concepts qui s\u0026rsquo;appliquent à la fois à la communication de données et de médias. Dans les chapitres ultérieurs, nous allons au-delà du théorique et discutons de la façon dont les sous-systèmes de médias et de données de WebRTC résolvent ces problèmes.\nQuels sont les attributs du réseau qui le rendent difficile ? # Le code qui fonctionne efficacement sur tous les réseaux est compliqué. Vous avez beaucoup de facteurs différents, et ils peuvent tous s\u0026rsquo;affecter mutuellement subtilement. Ce sont les problèmes les plus courants que les développeurs rencontreront.\nBande passante # La bande passante est le taux maximum de données qui peuvent être transférées sur un chemin donné. Il est important de se rappeler que ce n\u0026rsquo;est pas non plus un nombre statique. La bande passante changera le long de la route à mesure que plus (ou moins) de personnes l\u0026rsquo;utilisent.\nTemps de transmission et temps de trajet aller-retour # Le temps de transmission est le temps qu\u0026rsquo;il faut pour qu\u0026rsquo;un paquet arrive à sa destination. Comme la bande passante, ce n\u0026rsquo;est pas constant. Le temps de transmission peut fluctuer à tout moment.\ntransmission_time = receive_time - send_time\nPour calculer le temps de transmission, vous avez besoin d\u0026rsquo;horloges sur l\u0026rsquo;expéditeur et le récepteur synchronisées avec une précision à la milliseconde. Même une petite déviation produirait une mesure de temps de transmission peu fiable. Étant donné que WebRTC fonctionne dans des environnements hautement hétérogènes, il est presque impossible de s\u0026rsquo;appuyer sur une synchronisation temporelle parfaite entre les hôtes.\nLa mesure du temps de trajet aller-retour est une solution de contournement pour une synchronisation d\u0026rsquo;horloge imparfaite.\nAu lieu d\u0026rsquo;opérer sur des horloges distribuées, un pair WebRTC envoie un paquet spécial avec son propre horodatage sendertime1. Un pair coopérant reçoit le paquet et reflète l\u0026rsquo;horodatage vers l\u0026rsquo;expéditeur. Une fois que l\u0026rsquo;expéditeur original obtient le temps réfléchi, il soustrait l\u0026rsquo;horodatage sendertime1 du temps actuel sendertime2. Ce delta de temps est appelé \u0026ldquo;délai de propagation aller-retour\u0026rdquo; ou plus communément temps aller-retour.\nrtt = sendertime2 - sendertime1\nLa moitié du temps aller-retour est considérée comme une approximation suffisamment bonne du temps de transmission. Cette solution de contournement n\u0026rsquo;est pas sans inconvénients. Elle suppose qu\u0026rsquo;il faut un temps égal pour envoyer et recevoir des paquets. Cependant, sur les réseaux cellulaires, les opérations d\u0026rsquo;envoi et de réception peuvent ne pas être symétriques dans le temps. Vous avez peut-être remarqué que les vitesses de téléchargement sur votre téléphone sont presque toujours inférieures aux vitesses de téléchargement descendant.\ntransmission_time = rtt/2\nLes aspects techniques de la mesure du temps aller-retour sont décrits plus en détail dans le chapitre Rapports d\u0026rsquo;expéditeur et de récepteur RTCP.\nGigue # La gigue est le fait que le temps de transmission peut varier pour chaque paquet. Vos paquets pourraient être retardés, mais ensuite arriver en rafales.\nPerte de paquets # La perte de paquets est lorsque les messages sont perdus en transmission. La perte pourrait être régulière, ou elle pourrait venir en pics. Cela pourrait être dû au type de réseau comme le satellite ou le Wi-Fi. Ou cela pourrait être introduit par le logiciel en cours de route.\nUnité de transmission maximale # L\u0026rsquo;unité de transmission maximale est la limite de la taille d\u0026rsquo;un seul paquet. Les réseaux ne vous permettent pas d\u0026rsquo;envoyer un message géant. Au niveau du protocole, les messages peuvent devoir être divisés en plusieurs paquets plus petits.\nLa MTU différera également en fonction du chemin réseau que vous empruntez. Vous pouvez utiliser un protocole comme Path MTU Discovery pour déterminer la plus grande taille de paquet que vous pouvez envoyer.\nCongestion # La congestion est lorsque les limites du réseau ont été atteintes. C\u0026rsquo;est généralement parce que vous avez atteint le pic de bande passante que la route actuelle peut gérer. Ou cela pourrait être imposé par l\u0026rsquo;opérateur comme des limites horaires que votre FAI configure.\nLa congestion se manifeste de nombreuses façons différentes. Il n\u0026rsquo;y a pas de comportement standardisé. Dans la plupart des cas, lorsque la congestion est atteinte, le réseau abandonnera les paquets excédentaires. Dans d\u0026rsquo;autres cas, le réseau mettra en mémoire tampon. Cela augmentera le temps de transmission pour vos paquets. Vous pourriez également voir plus de gigue à mesure que votre réseau devient congestionné. C\u0026rsquo;est un domaine en évolution rapide et de nouveaux algorithmes pour la détection de congestion sont encore en cours d\u0026rsquo;écriture.\nDynamique # Les réseaux sont incroyablement dynamiques et les conditions peuvent changer rapidement. Au cours d\u0026rsquo;un appel, vous pouvez envoyer et recevoir des centaines de milliers de paquets. Ces paquets passeront par plusieurs sauts. Ces sauts seront partagés par des millions d\u0026rsquo;autres utilisateurs. Même dans votre réseau local, vous pourriez avoir des films HD en cours de téléchargement ou peut-être qu\u0026rsquo;un appareil décide de télécharger une mise à jour logicielle.\nAvoir un bon appel n\u0026rsquo;est pas aussi simple que de mesurer votre réseau au démarrage. Vous devez constamment évaluer. Vous devez également gérer tous les différents comportements qui proviennent d\u0026rsquo;une multitude de matériels et de logiciels réseau.\nRésolution de la perte de paquets # La gestion de la perte de paquets est le premier problème à résoudre. Il existe plusieurs façons de le résoudre, chacune avec ses propres avantages. Cela dépend de ce que vous envoyez et de votre tolérance à la latence. Il est également important de noter que toutes les pertes de paquets ne sont pas fatales. Perdre de la vidéo pourrait ne pas être un problème, l\u0026rsquo;œil humain pourrait ne pas même être capable de la percevoir. Perdre les messages texte d\u0026rsquo;un utilisateur est fatal.\nDisons que vous envoyez 10 paquets, et que les paquets 5 et 6 sont perdus. Voici les façons de le résoudre.\nAccusés de réception # Les accusés de réception sont lorsque le récepteur notifie l\u0026rsquo;expéditeur de chaque paquet qu\u0026rsquo;il a reçu. L\u0026rsquo;expéditeur est conscient de la perte de paquets lorsqu\u0026rsquo;il obtient un accusé de réception pour un paquet deux fois qui n\u0026rsquo;est pas final. Lorsque l\u0026rsquo;expéditeur obtient un ACK pour le paquet 4 deux fois, il sait que le paquet 5 n\u0026rsquo;a pas encore été vu.\nAccusés de réception sélectifs # Les accusés de réception sélectifs sont une amélioration des accusés de réception. Un récepteur peut envoyer un SACK qui accuse réception de plusieurs paquets et notifie l\u0026rsquo;expéditeur des lacunes. Maintenant l\u0026rsquo;expéditeur peut obtenir un SACK pour les paquets 4 et 7. Il sait alors qu\u0026rsquo;il doit renvoyer les paquets 5 et 6.\nAccusés de réception négatifs # Les accusés de réception négatifs résolvent le problème de manière opposée. Au lieu de notifier l\u0026rsquo;expéditeur de ce qu\u0026rsquo;il a reçu, le récepteur notifie l\u0026rsquo;expéditeur de ce qui a été perdu. Dans notre cas, un NACK sera envoyé pour les paquets 5 et 6. L\u0026rsquo;expéditeur ne connaît que les paquets que le récepteur souhaite recevoir à nouveau.\nCorrection d\u0026rsquo;erreur directe # La correction d\u0026rsquo;erreur directe corrige la perte de paquets de manière préventive. L\u0026rsquo;expéditeur envoie des données redondantes, ce qui signifie qu\u0026rsquo;un paquet perdu n\u0026rsquo;affecte pas le flux final. Un algorithme populaire pour cela est la correction d\u0026rsquo;erreur Reed–Solomon.\nCela réduit la latence/complexité de l\u0026rsquo;envoi et du traitement des accusés de réception. La correction d\u0026rsquo;erreur directe est un gaspillage de bande passante si le réseau dans lequel vous vous trouvez n\u0026rsquo;a aucune perte.\nRésolution de la gigue # La gigue est présente dans la plupart des réseaux. Même à l\u0026rsquo;intérieur d\u0026rsquo;un LAN, vous avez de nombreux appareils envoyant des données à des vitesses fluctuantes. Vous pouvez facilement observer la gigue en pinguant un autre appareil avec la commande ping et en remarquant les fluctuations de la latence aller-retour.\nPour résoudre la gigue, les clients utilisent un JitterBuffer. Le JitterBuffer garantit un temps de livraison stable des paquets. L\u0026rsquo;inconvénient est que JitterBuffer ajoute une certaine latence aux paquets qui arrivent tôt. L\u0026rsquo;avantage est que les paquets en retard ne causent pas de gigue. Imaginez que pendant un appel, vous voyez les temps d\u0026rsquo;arrivée de paquets suivants :\n* time=1.46 ms * time=1.93 ms * time=1.57 ms * time=1.55 ms * time=1.54 ms * time=1.72 ms * time=1.45 ms * time=1.73 ms * time=1.80 ms Dans ce cas, environ 1,8 ms serait un bon choix. Les paquets qui arrivent en retard utiliseront notre fenêtre de latence. Les paquets qui arrivent tôt seront retardés un peu et peuvent remplir la fenêtre épuisée par les paquets en retard. Cela signifie que nous n\u0026rsquo;avons plus de bégaiement et que nous fournissons un taux de livraison fluide au client.\nFonctionnement du JitterBuffer # Chaque paquet est ajouté au tampon de gigue dès qu\u0026rsquo;il est reçu. Une fois qu\u0026rsquo;il y a suffisamment de paquets pour reconstruire la trame, les paquets qui composent la trame sont libérés du tampon et émis pour le décodage. Le décodeur, à son tour, décode et dessine la trame vidéo sur l\u0026rsquo;écran de l\u0026rsquo;utilisateur. Étant donné que le tampon de gigue a une capacité limitée, les paquets qui restent trop longtemps dans le tampon seront abandonnés.\nEn savoir plus sur la façon dont les trames vidéo sont converties en paquets RTP, et pourquoi la reconstruction est nécessaire dans le chapitre communication média.\njitterBufferDelay fournit un excellent aperçu de vos performances réseau et de son influence sur la fluidité de lecture. Il fait partie de l\u0026rsquo;API de statistiques WebRTC pertinent pour le flux entrant du récepteur. Le délai définit le temps que les trames vidéo passent dans le tampon de gigue avant d\u0026rsquo;être émises pour le décodage. Un long délai de tampon de gigue signifie que votre réseau est fortement congestionné.\nDétection de la congestion # Avant même de pouvoir résoudre la congestion, nous devons la détecter. Pour la détecter, nous utilisons un contrôleur de congestion. C\u0026rsquo;est un sujet compliqué, et il change encore rapidement. De nouveaux algorithmes sont encore publiés et testés. À un niveau élevé, ils fonctionnent tous de la même manière. Un contrôleur de congestion fournit des estimations de bande passante étant donné certaines entrées. Voici quelques entrées possibles :\nPerte de paquets - Les paquets sont abandonnés à mesure que le réseau devient congestionné. Gigue - À mesure que l\u0026rsquo;équipement réseau devient plus surchargé, la mise en file d\u0026rsquo;attente des paquets rendra les temps erratiques. Temps aller-retour - Les paquets mettent plus de temps à arriver lorsqu\u0026rsquo;ils sont congestionnés. Contrairement à la gigue, le temps aller-retour continue d\u0026rsquo;augmenter. Notification explicite de congestion - Les réseaux plus récents peuvent marquer les paquets comme étant à risque d\u0026rsquo;être abandonnés pour soulager la congestion. Ces valeurs doivent être mesurées en continu pendant l\u0026rsquo;appel. L\u0026rsquo;utilisation du réseau peut augmenter ou diminuer, donc la bande passante disponible pourrait changer constamment.\nRésolution de la congestion # Maintenant que nous avons une bande passante estimée, nous devons ajuster ce que nous envoyons. La façon dont nous ajustons dépend du type de données que nous voulons envoyer.\nEnvoyer plus lentement # Limiter la vitesse à laquelle vous envoyez des données est la première solution pour prévenir la congestion. Le contrôleur de congestion vous donne une estimation, et c\u0026rsquo;est la responsabilité de l\u0026rsquo;expéditeur de limiter le débit.\nC\u0026rsquo;est la méthode utilisée pour la plupart des communications de données. Avec des protocoles comme TCP, tout cela est fait par le système d\u0026rsquo;exploitation et est complètement transparent pour les utilisateurs et les développeurs.\nEnvoyer moins # Dans certains cas, nous pouvons envoyer moins d\u0026rsquo;informations pour satisfaire nos limites. Nous avons également des délais stricts sur l\u0026rsquo;arrivée de nos données, donc nous ne pouvons pas envoyer plus lentement. Ce sont les contraintes sous lesquelles les médias en temps réel tombent.\nSi nous n\u0026rsquo;avons pas assez de bande passante disponible, nous pouvons réduire la qualité de la vidéo que nous envoyons. Cela nécessite une boucle de rétroaction étroite entre votre encodeur vidéo et le contrôleur de congestion.\n"},{"id":5,"href":"/fr/docs/06-media-communication/","title":"Communication média","section":"Docs","content":" Communication média # Que m\u0026rsquo;apporte la communication média de WebRTC ? # WebRTC vous permet d\u0026rsquo;envoyer et de recevoir une quantité illimitée de flux audio et vidéo. Vous pouvez ajouter et supprimer ces flux à tout moment pendant un appel. Ces flux peuvent tous être indépendants, ou ils peuvent être regroupés ! Vous pourriez envoyer un flux vidéo de votre bureau, puis inclure l\u0026rsquo;audio et la vidéo de votre webcam.\nLe protocole WebRTC est agnostique au codec. Le transport sous-jacent prend en charge tout, même des choses qui n\u0026rsquo;existent pas encore ! Cependant, l\u0026rsquo;agent WebRTC avec lequel vous communiquez peut ne pas avoir les outils nécessaires pour l\u0026rsquo;accepter.\nWebRTC est également conçu pour gérer des conditions réseau dynamiques. Pendant un appel, votre bande passante peut augmenter ou diminuer. Peut-être que vous subissez soudainement beaucoup de perte de paquets. Le protocole est conçu pour gérer tout cela. WebRTC répond aux conditions du réseau et essaie de vous donner la meilleure expérience possible avec les ressources disponibles.\nComment cela fonctionne-t-il ? # WebRTC utilise deux protocoles préexistants RTP et RTCP, tous deux définis dans la RFC 1889.\nRTP (Real-time Transport Protocol) est le protocole qui transporte les médias. Il a été conçu pour permettre la livraison en temps réel de vidéo. Il ne stipule aucune règle concernant la latence ou la fiabilité, mais vous donne les outils pour les implémenter. RTP vous donne des flux, afin que vous puissiez exécuter plusieurs flux de médias sur une seule connexion. Il vous donne également les informations de timing et d\u0026rsquo;ordonnancement dont vous avez besoin pour alimenter un pipeline média.\nRTCP (RTP Control Protocol) est le protocole qui communique les métadonnées sur l\u0026rsquo;appel. Le format est très flexible et vous permet d\u0026rsquo;ajouter toutes les métadonnées que vous souhaitez. Ceci est utilisé pour communiquer des statistiques sur l\u0026rsquo;appel. Il est également utilisé pour gérer la perte de paquets et pour implémenter le contrôle de congestion. Il vous donne la communication bidirectionnelle nécessaire pour répondre aux conditions réseau changeantes.\nLatence vs Qualité # Les médias en temps réel consistent à faire des compromis entre la latence et la qualité. Plus vous êtes prêt à tolérer de latence, plus la qualité vidéo que vous pouvez attendre est élevée.\nLimitations du monde réel # Ces contraintes sont toutes causées par les limitations du monde réel. Ce sont toutes des caractéristiques de votre réseau que vous devrez surmonter.\nLa vidéo est complexe # Transporter de la vidéo n\u0026rsquo;est pas facile. Pour stocker 30 minutes de vidéo 720 8 bits non compressée, vous avez besoin d\u0026rsquo;environ 110 GB. Avec ces chiffres, une conférence téléphonique à 4 personnes ne va pas se produire. Nous avons besoin d\u0026rsquo;un moyen de la rendre plus petite, et la réponse est la compression vidéo. Cela ne vient pas sans inconvénients cependant.\nVidéo 101 # Nous n\u0026rsquo;allons pas couvrir la compression vidéo en profondeur, mais juste assez pour comprendre pourquoi RTP est conçu de la manière dont il l\u0026rsquo;est. La compression vidéo encode la vidéo dans un nouveau format qui nécessite moins de bits pour représenter la même vidéo.\nCompression avec perte et sans perte # Vous pouvez encoder la vidéo pour qu\u0026rsquo;elle soit sans perte (aucune information n\u0026rsquo;est perdue) ou avec perte (l\u0026rsquo;information peut être perdue). Étant donné que l\u0026rsquo;encodage sans perte nécessite plus de données à envoyer à un pair, ce qui entraîne un flux de latence plus élevée et plus de paquets abandonnés, RTP utilise généralement une compression avec perte même si la qualité vidéo ne sera pas aussi bonne.\nCompression intra et inter-image # La compression vidéo se présente en deux types. Le premier est intra-image. La compression intra-image réduit les bits utilisés pour décrire une seule image vidéo. Les mêmes techniques sont utilisées pour comprimer les images fixes, comme la méthode de compression JPEG.\nLe deuxième type est la compression inter-image. Étant donné que la vidéo est composée de nombreuses images, nous cherchons des moyens de ne pas envoyer la même information deux fois.\nTypes d\u0026rsquo;images inter # Vous avez ensuite trois types d\u0026rsquo;images :\nI-Frame - Une image complète, peut être décodée sans rien d\u0026rsquo;autre. P-Frame - Une image partielle, ne contenant que les changements par rapport à l\u0026rsquo;image précédente. B-Frame - Une image partielle, est une modification des images précédentes et futures. Voici une visualisation des trois types d\u0026rsquo;images.\nLa vidéo est délicate # La compression vidéo est incroyablement avec état, ce qui la rend difficile à transférer sur Internet. Que se passe-t-il si vous perdez une partie d\u0026rsquo;une I-Frame ? Comment une P-Frame sait-elle quoi modifier ? À mesure que la compression vidéo devient plus complexe, cela devient un problème encore plus important. Heureusement, RTP et RTCP ont la solution.\nRTP # Format de paquet # Chaque paquet RTP a la structure suivante :\n0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ |V=2|P|X| CC |M| PT | Sequence Number | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Timestamp | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Synchronization Source (SSRC) identifier | +=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+ | Contributing Source (CSRC) identifiers | | .... | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Payload | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ Version (V) # Version est toujours 2\nRemplissage (P) # Remplissage est un booléen qui contrôle si la charge utile a du remplissage.\nLe dernier octet de la charge utile contient un décompte du nombre d\u0026rsquo;octets de remplissage qui ont été ajoutés.\nExtension (X) # S\u0026rsquo;il est défini, l\u0026rsquo;en-tête RTP aura des extensions. Ceci est décrit plus en détail ci-dessous.\nNombre CSRC (CC) # Le nombre d\u0026rsquo;identifiants CSRC qui suivent après le SSRC, et avant la charge utile.\nMarqueur (M) # Le bit de marqueur n\u0026rsquo;a pas de signification prédéfinie et peut être utilisé comme l\u0026rsquo;utilisateur le souhaite.\nDans certains cas, il est défini lorsqu\u0026rsquo;un utilisateur parle. Il est également couramment utilisé pour marquer une image clé.\nType de charge utile (PT) # Type de charge utile est un identifiant unique pour quel codec est transporté par ce paquet.\nPour WebRTC, le Type de charge utile est dynamique. VP8 dans un appel peut être différent d\u0026rsquo;un autre. L\u0026rsquo;offrant dans l\u0026rsquo;appel détermine le mappage des Types de charge utile aux codecs dans la Description de session.\nNuméro de séquence # Numéro de séquence est utilisé pour ordonner les paquets dans un flux. Chaque fois qu\u0026rsquo;un paquet est envoyé, le Numéro de séquence est incrémenté de un.\nRTP est conçu pour être utile sur des réseaux avec perte. Cela donne au récepteur un moyen de détecter quand des paquets ont été perdus.\nHorodatage # L\u0026rsquo;instant d\u0026rsquo;échantillonnage pour ce paquet. Ce n\u0026rsquo;est pas une horloge globale, mais combien de temps s\u0026rsquo;est écoulé dans le flux média. Plusieurs paquets RTP peuvent avoir le même horodatage s\u0026rsquo;ils font par exemple tous partie de la même image vidéo.\nSource de synchronisation (SSRC) # Un SSRC est l\u0026rsquo;identifiant unique pour ce flux. Cela vous permet d\u0026rsquo;exécuter plusieurs flux de médias sur un seul flux RTP.\nSource contributrice (CSRC) # Une liste qui communique quels SSRC ont contribué à ce paquet.\nCeci est couramment utilisé pour les indicateurs de conversation. Disons que côté serveur, vous avez combiné plusieurs flux audio en un seul flux RTP. Vous pourriez alors utiliser ce champ pour dire \u0026ldquo;Les flux d\u0026rsquo;entrée A et C parlaient à ce moment\u0026rdquo;.\nCharge utile # Les données de charge utile réelles. Peut se terminer par le décompte du nombre d\u0026rsquo;octets de remplissage qui ont été ajoutés, si le drapeau de remplissage est défini.\nExtensions # RTCP # Format de paquet # Chaque paquet RTCP a la structure suivante :\n0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ |V=2|P| RC | PT | length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Payload | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ Version (V) # Version est toujours 2.\nRemplissage (P) # Remplissage est un booléen qui contrôle si la charge utile a du remplissage.\nLe dernier octet de la charge utile contient un décompte du nombre d\u0026rsquo;octets de remplissage qui ont été ajoutés.\nNombre de rapports de réception (RC) # Le nombre de rapports dans ce paquet. Un seul paquet RTCP peut contenir plusieurs événements.\nType de paquet (PT) # Identifiant unique pour quel type de paquet RTCP c\u0026rsquo;est. Un agent WebRTC n\u0026rsquo;a pas besoin de prendre en charge tous ces types, et le support entre les agents peut être différent. Voici ceux que vous pouvez couramment voir cependant :\n192 - Requête d\u0026rsquo;image INTRA complète (FIR) 193 - Accusés de réception négatifs (NACK) 200 - Rapport d\u0026rsquo;expéditeur 201 - Rapport de récepteur 205 - Rétroaction RTP générique 206 - Rétroaction spécifique à la charge utile La signification de ces types de paquets sera décrite plus en détail ci-dessous.\nRequête d\u0026rsquo;image INTRA complète (FIR) et indication de perte d\u0026rsquo;image (PLI) # Les messages FIR et PLI servent un objectif similaire. Ces messages demandent une image clé complète de l\u0026rsquo;expéditeur. PLI est utilisé lorsque des images partielles ont été données au décodeur, mais qu\u0026rsquo;il n\u0026rsquo;a pas pu les décoder. Cela pourrait se produire parce que vous avez eu beaucoup de perte de paquets, ou peut-être que le décodeur s\u0026rsquo;est écrasé.\nSelon la RFC 5104, FIR ne doit pas être utilisé lorsque des paquets ou des images sont perdus. C\u0026rsquo;est le travail de PLI. FIR demande une image clé pour des raisons autres que la perte de paquets - par exemple lorsqu\u0026rsquo;un nouveau membre entre dans une conférence vidéo. Ils ont besoin d\u0026rsquo;une image clé complète pour commencer à décoder le flux vidéo, le décodeur abandonnera les images jusqu\u0026rsquo;à ce que l\u0026rsquo;image clé arrive.\nC\u0026rsquo;est une bonne idée pour un récepteur de demander une image clé complète juste après la connexion, cela minimise le délai entre la connexion et l\u0026rsquo;apparition d\u0026rsquo;une image sur l\u0026rsquo;écran de l\u0026rsquo;utilisateur.\nLes paquets PLI font partie des messages de rétroaction spécifiques à la charge utile.\nEn pratique, le logiciel qui est capable de gérer à la fois les paquets PLI et FIR agira de la même manière dans les deux cas. Il enverra un signal à l\u0026rsquo;encodeur pour produire une nouvelle image clé complète.\nAccusé de réception négatif # Un NACK demande qu\u0026rsquo;un expéditeur retransmette un seul paquet RTP. Cela est généralement causé par la perte d\u0026rsquo;un paquet RTP, mais pourrait également se produire parce qu\u0026rsquo;il est en retard.\nLes NACK sont beaucoup plus efficaces en bande passante que de demander que toute l\u0026rsquo;image soit envoyée à nouveau. Étant donné que RTP divise les paquets en très petits morceaux, vous ne demandez vraiment qu\u0026rsquo;une petite pièce manquante. Le récepteur crée un message RTCP avec le SSRC et le numéro de séquence. Si l\u0026rsquo;expéditeur n\u0026rsquo;a pas ce paquet RTP disponible pour le renvoyer, il ignore simplement le message.\nRapports d\u0026rsquo;expéditeur et de récepteur # Ces rapports sont utilisés pour envoyer des statistiques entre les agents. Cela communique la quantité de paquets réellement reçus et la gigue.\nLes rapports peuvent être utilisés pour les diagnostics et le contrôle de congestion.\nComment RTP/RTCP résolvent les problèmes ensemble # RTP et RTCP travaillent ensuite ensemble pour résoudre tous les problèmes causés par les réseaux. Ces techniques changent encore constamment !\nCorrection d\u0026rsquo;erreur directe # Également connu sous le nom de FEC. Une autre méthode pour gérer la perte de paquets. FEC, c\u0026rsquo;est lorsque vous envoyez les mêmes données plusieurs fois, sans même qu\u0026rsquo;elles soient demandées. Cela se fait au niveau RTP, ou même plus bas avec le codec.\nSi la perte de paquets pour un appel est stable, alors FEC est une solution de latence beaucoup plus faible que NACK. Le temps d\u0026rsquo;aller-retour pour avoir à demander, puis retransmettre le paquet manquant peut être significatif pour les NACK.\nDébit adaptatif et estimation de bande passante # Comme discuté dans le chapitre Réseau en temps réel, les réseaux sont imprévisibles et peu fiables. La disponibilité de la bande passante peut changer plusieurs fois au cours d\u0026rsquo;une session. Il n\u0026rsquo;est pas rare de voir la bande passante disponible changer de façon spectaculaire (ordres de grandeur) en une seconde.\nL\u0026rsquo;idée principale est d\u0026rsquo;ajuster le débit d\u0026rsquo;encodage en fonction de la bande passante réseau disponible prédite, actuelle et future. Cela garantit qu\u0026rsquo;un signal vidéo et audio de la meilleure qualité possible est transmis, et que la connexion n\u0026rsquo;est pas interrompue en raison de la congestion du réseau. Les heuristiques qui modélisent le comportement du réseau et essaient de le prédire sont connues sous le nom d\u0026rsquo;estimation de bande passante.\nIl y a beaucoup de nuances à cela, explorons donc plus en détail.\nIdentification et communication de l\u0026rsquo;état du réseau # RTP/RTCP fonctionne sur tous les types de réseaux différents, et en conséquence, il est courant qu\u0026rsquo;une partie de la communication soit abandonnée sur son chemin de l\u0026rsquo;expéditeur au récepteur. Étant construit sur UDP, il n\u0026rsquo;y a pas de mécanisme intégré pour la retransmission de paquets, et encore moins pour gérer le contrôle de congestion.\nPour offrir aux utilisateurs la meilleure expérience, WebRTC doit estimer les qualités du chemin réseau, et s\u0026rsquo;adapter à la façon dont ces qualités changent au fil du temps. Les traits clés à surveiller incluent : la bande passante disponible (dans chaque direction, car elle peut ne pas être symétrique), le temps d\u0026rsquo;aller-retour et la gigue (fluctuations du temps d\u0026rsquo;aller-retour). Il doit tenir compte de la perte de paquets et communiquer les changements dans ces propriétés à mesure que les conditions réseau évoluent.\nIl y a deux objectifs principaux pour ces protocoles :\nEstimer la bande passante disponible (dans chaque direction) prise en charge par le réseau. Communiquer les caractéristiques du réseau entre l\u0026rsquo;expéditeur et le récepteur. RTP/RTCP a trois approches différentes pour résoudre ce problème. Elles ont toutes leurs avantages et leurs inconvénients, et généralement chaque génération s\u0026rsquo;est améliorée par rapport à ses prédécesseurs. L\u0026rsquo;implémentation que vous utilisez dépendra principalement de la pile logicielle disponible pour vos clients et des bibliothèques disponibles pour construire votre application.\nRapports de récepteur / Rapports d\u0026rsquo;expéditeur # La première implémentation est la paire de rapports de récepteur et son complément, les rapports d\u0026rsquo;expéditeur. Ces messages RTCP sont définis dans la RFC 3550, et sont responsables de la communication de l\u0026rsquo;état du réseau entre les points de terminaison. Les rapports de récepteur se concentrent sur la communication des qualités du réseau (y compris la perte de paquets, le temps d\u0026rsquo;aller-retour et la gigue), et ils s\u0026rsquo;associent à d\u0026rsquo;autres algorithmes qui sont alors responsables de l\u0026rsquo;estimation de la bande passante disponible en fonction de ces rapports.\nLes rapports d\u0026rsquo;expéditeur et de récepteur (SR et RR) dressent ensemble un tableau de la qualité du réseau. Ils sont envoyés selon un calendrier pour chaque SSRC, et ce sont les entrées utilisées lors de l\u0026rsquo;estimation de la bande passante disponible. Ces estimations sont faites par l\u0026rsquo;expéditeur après avoir reçu les données RR, contenant les champs suivants :\nFraction perdue - Quel pourcentage de paquets a été perdu depuis le dernier rapport de récepteur. Nombre cumulatif de paquets perdus - Combien de paquets ont été perdus pendant tout l\u0026rsquo;appel. Numéro de séquence le plus élevé étendu reçu - Quel était le dernier numéro de séquence reçu, et combien de fois a-t-il débordé. Gigue d\u0026rsquo;interarrivée - La gigue glissante pour tout l\u0026rsquo;appel. Horodatage du dernier rapport d\u0026rsquo;expéditeur - Dernière heure connue sur l\u0026rsquo;expéditeur, utilisée pour le calcul du temps d\u0026rsquo;aller-retour. SR et RR travaillent ensemble pour calculer le temps d\u0026rsquo;aller-retour.\nL\u0026rsquo;expéditeur inclut son heure locale, sendertime1 dans SR. Lorsque le récepteur obtient un paquet SR, il renvoie RR. Entre autres choses, le RR inclut sendertime1 qui vient d\u0026rsquo;être reçu de l\u0026rsquo;expéditeur. Il y aura un délai entre la réception du SR et l\u0026rsquo;envoi du RR. Pour cette raison, le RR inclut également un temps \u0026ldquo;délai depuis le dernier rapport d\u0026rsquo;expéditeur\u0026rdquo; - DLSR. Le DLSR est utilisé pour ajuster l\u0026rsquo;estimation du temps d\u0026rsquo;aller-retour plus tard dans le processus. Une fois que l\u0026rsquo;expéditeur reçoit le RR, il soustrait sendertime1 et DLSR de l\u0026rsquo;heure actuelle sendertime2. Ce delta de temps est appelé délai de propagation aller-retour ou temps d\u0026rsquo;aller-retour.\nrtt = sendertime2 - sendertime1 - DLSR\nTemps d\u0026rsquo;aller-retour en langage clair :\nJe vous envoie un message avec la lecture actuelle de mon horloge, disons qu\u0026rsquo;il est 4:20pm, 42 secondes et 420 millisecondes. Vous me renvoyez ce même horodatage. Vous incluez également le temps écoulé entre la lecture de mon message et l\u0026rsquo;envoi du message de retour, disons 5 millisecondes. Une fois que je reçois l\u0026rsquo;heure de retour, je regarde à nouveau l\u0026rsquo;horloge. Maintenant mon horloge dit 4:20pm, 42 secondes 690 millisecondes. Cela signifie qu\u0026rsquo;il a fallu 265 millisecondes (690 - 420 - 5) pour vous atteindre et revenir vers moi. Par conséquent, le temps d\u0026rsquo;aller-retour est de 265 millisecondes. TMMBR, TMMBN, REMB et TWCC, associés à GCC # Contrôle de congestion Google (GCC) # L\u0026rsquo;algorithme de contrôle de congestion Google (GCC) (décrit dans draft-ietf-rmcat-gcc-02) relève le défi de l\u0026rsquo;estimation de la bande passante. Il s\u0026rsquo;associe à une variété d\u0026rsquo;autres protocoles pour faciliter les exigences de communication associées. Par conséquent, il est bien adapté pour s\u0026rsquo;exécuter soit du côté récepteur (lorsqu\u0026rsquo;il est exécuté avec TMMBR/TMMBN ou REMB) soit du côté expéditeur (lorsqu\u0026rsquo;il est exécuté avec TWCC).\nPour arriver à des estimations de la bande passante disponible, GCC se concentre sur la perte de paquets et les fluctuations du temps d\u0026rsquo;arrivée des images comme ses deux métriques principales. Il exécute ces métriques à travers deux contrôleurs liés : le contrôleur basé sur les pertes et le contrôleur basé sur les délais.\nLe premier composant de GCC, le contrôleur basé sur les pertes, est simple :\nSi la perte de paquets est supérieure à 10%, l\u0026rsquo;estimation de la bande passante est réduite. Si la perte de paquets est entre 2 et 10%, l\u0026rsquo;estimation de la bande passante reste la même. Si la perte de paquets est inférieure à 2%, l\u0026rsquo;estimation de la bande passante est augmentée. Les mesures de perte de paquets sont prises fréquemment. Selon le protocole de communication associé, la perte de paquets peut soit être explicitement communiquée (comme avec TWCC) soit déduite (comme avec TMMBR/TMMBN et REMB). Ces pourcentages sont évalués sur des fenêtres de temps d\u0026rsquo;environ une seconde.\nLe contrôleur basé sur les délais coopère avec le contrôleur basé sur les pertes, et examine les variations dans le temps d\u0026rsquo;arrivée des paquets. Ce contrôleur basé sur les délais vise à identifier quand les liens réseau deviennent de plus en plus congestionnés, et peut réduire les estimations de bande passante même avant que la perte de paquets ne se produise. La théorie est que l\u0026rsquo;interface réseau la plus occupée le long du chemin continuera à mettre en file d\u0026rsquo;attente des paquets jusqu\u0026rsquo;à ce que l\u0026rsquo;interface manque de capacité dans ses tampons. Si cette interface continue à recevoir plus de trafic qu\u0026rsquo;elle n\u0026rsquo;est capable d\u0026rsquo;envoyer, elle sera forcée d\u0026rsquo;abandonner tous les paquets qu\u0026rsquo;elle ne peut pas adapter dans son espace tampon. Ce type de perte de paquets est particulièrement perturbateur pour la communication à faible latence/en temps réel, mais il peut également dégrader le débit pour toute communication sur ce lien et devrait idéalement être évité. Ainsi, GCC essaie de déterminer si les liens réseau développent des profondeurs de file d\u0026rsquo;attente de plus en plus grandes avant que la perte de paquets ne se produise réellement. Il réduira l\u0026rsquo;utilisation de la bande passante s\u0026rsquo;il observe des délais de mise en file d\u0026rsquo;attente accrus au fil du temps.\nPour y parvenir, GCC essaie de déduire les augmentations de profondeur de file d\u0026rsquo;attente en mesurant des augmentations subtiles du temps d\u0026rsquo;aller-retour. Il enregistre le \u0026ldquo;temps d\u0026rsquo;inter-arrivée\u0026rdquo; des images, t(i) - t(i-1) : la différence de temps d\u0026rsquo;arrivée de deux groupes de paquets (généralement, des images vidéo consécutives). Ces groupes de paquets partent fréquemment à intervalles de temps réguliers (par exemple, toutes les 1/24 secondes pour une vidéo à 24 fps). En conséquence, mesurer le temps d\u0026rsquo;inter-arrivée est alors aussi simple que d\u0026rsquo;enregistrer la différence de temps entre le début de la première groupe de paquets (c\u0026rsquo;est-à-dire l\u0026rsquo;image) et la première image de la suivante.\nDans le diagramme ci-dessous, l\u0026rsquo;augmentation médiane du délai inter-paquets est de +20 msec, un indicateur clair de congestion du réseau.\nSi le temps d\u0026rsquo;inter-arrivée augmente au fil du temps, c\u0026rsquo;est une preuve présumée d\u0026rsquo;une profondeur de file d\u0026rsquo;attente accrue sur les interfaces réseau de connexion et considéré comme une congestion du réseau. (Note : GCC est assez intelligent pour contrôler ces mesures pour les fluctuations de taille d\u0026rsquo;octets d\u0026rsquo;image.) GCC affine ses mesures de latence en utilisant un filtre de Kalman et prend de nombreuses mesures des temps d\u0026rsquo;aller-retour du réseau (et de ses variations) avant de signaler la congestion. On peut penser au filtre de Kalman de GCC comme prenant la place d\u0026rsquo;une régression linéaire : aidant à faire des prédictions précises même lorsque la gigue ajoute du bruit dans les mesures de timing. Lors du signalement de la congestion, GCC réduira le débit disponible. Alternativement, dans des conditions réseau stables, il peut lentement augmenter ses estimations de bande passante pour tester des valeurs de charge plus élevées.\nTMMBR, TMMBN et REMB # Pour TMMBR/TMMBN et REMB, le côté récepteur estime d\u0026rsquo;abord la bande passante entrante disponible (en utilisant un protocole tel que GCC), puis communique ces estimations de bande passante aux expéditeurs distants. Ils n\u0026rsquo;ont pas besoin d\u0026rsquo;échanger des détails sur la perte de paquets ou d\u0026rsquo;autres qualités sur la congestion du réseau parce que fonctionner du côté récepteur leur permet de mesurer le temps d\u0026rsquo;inter-arrivée et la perte de paquets directement. Au lieu de cela, TMMBR, TMMBN et REMB échangent juste les estimations de bande passante elles-mêmes :\nDemande de débit binaire maximum temporaire du flux média - Une mantisse/exposant d\u0026rsquo;un débit binaire demandé pour un seul SSRC. Notification de débit binaire maximum temporaire du flux média - Un message pour notifier qu\u0026rsquo;un TMMBR a été reçu. Débit binaire maximum estimé du récepteur - Une mantisse/exposant d\u0026rsquo;un débit binaire demandé pour la session entière. TMMBR et TMMBN sont venus en premier et sont définis dans la RFC 5104. REMB est venu plus tard, il y avait un brouillon soumis dans draft-alvestrand-rmcat-remb, mais il n\u0026rsquo;a jamais été standardisé.\nUn exemple de session qui utilise REMB pourrait se comporter comme suit :\nCette méthode fonctionne bien sur le papier. L\u0026rsquo;expéditeur reçoit l\u0026rsquo;estimation du récepteur, règle le débit binaire de l\u0026rsquo;encodeur à la valeur reçue. Et voilà ! Nous nous sommes adaptés aux conditions du réseau.\nCependant, en pratique, l\u0026rsquo;approche REMB a plusieurs inconvénients.\nL\u0026rsquo;inefficacité de l\u0026rsquo;encodeur est la première. Lorsque vous définissez un débit binaire pour l\u0026rsquo;encodeur, il ne produira pas nécessairement exactement le débit binaire que vous avez demandé. L\u0026rsquo;encodage peut produire plus ou moins de bits, selon les paramètres de l\u0026rsquo;encodeur et l\u0026rsquo;image en cours d\u0026rsquo;encodage.\nPar exemple, utiliser l\u0026rsquo;encodeur x264 avec tune=zerolatency peut s\u0026rsquo;écarter significativement du débit binaire cible spécifié. Voici un scénario possible :\nDisons que nous commençons par définir le débit binaire à 1000 kbps. L\u0026rsquo;encodeur ne produit que 700 kbps, car il n\u0026rsquo;y a pas assez de fonctionnalités à haute fréquence à encoder. (AKA - \u0026ldquo;regarder un mur\u0026rdquo;.) Imaginons également que le récepteur obtienne la vidéo à 700 kbps avec zéro perte de paquets. Il applique ensuite la règle REMB 1 pour augmenter le débit binaire entrant de 8%. Le récepteur envoie un paquet REMB avec une suggestion de 756 kbps (700 kbps * 1.08) à l\u0026rsquo;expéditeur. L\u0026rsquo;expéditeur règle le débit binaire de l\u0026rsquo;encodeur à 756 kbps. L\u0026rsquo;encodeur produit un débit binaire encore plus faible. Ce processus continue à se répéter, abaissant le débit binaire au minimum absolu. Vous pouvez voir comment cela causerait un réglage lourd des paramètres de l\u0026rsquo;encodeur, et surprendrait les utilisateurs avec une vidéo impossible à regarder même sur une excellente connexion.\nContrôle de congestion étendu au transport # Le contrôle de congestion étendu au transport est le dernier développement dans la communication de l\u0026rsquo;état du réseau RTCP. Il est défini dans draft-holmer-rmcat-transport-wide-cc-extensions-01, mais n\u0026rsquo;a également jamais été standardisé.\nTWCC utilise un principe assez simple :\nAvec REMB, le récepteur instruit le côté émetteur du débit binaire de téléchargement disponible. Il utilise des mesures précises sur la perte de paquets déduite et des données qu\u0026rsquo;il possède uniquement sur le temps d\u0026rsquo;arrivée inter-paquets.\nTWCC est presque une approche hybride entre les générations de protocoles SR/RR et REMB. Il ramène les estimations de bande passante du côté de l\u0026rsquo;expéditeur (similaire à SR/RR), mais sa technique d\u0026rsquo;estimation de bande passante ressemble plus étroitement à la génération REMB.\nAvec TWCC, le récepteur fait savoir à l\u0026rsquo;expéditeur l\u0026rsquo;heure d\u0026rsquo;arrivée de chaque paquet. C\u0026rsquo;est suffisant d\u0026rsquo;informations pour que l\u0026rsquo;expéditeur mesure la variation du délai d\u0026rsquo;arrivée inter-paquets, ainsi que pour identifier quels paquets ont été abandonnés ou sont arrivés trop tard pour contribuer au flux audio/vidéo. Avec ces données échangées fréquemment, l\u0026rsquo;expéditeur est capable de s\u0026rsquo;adapter rapidement aux conditions réseau changeantes et de varier sa bande passante de sortie en utilisant un algorithme tel que GCC.\nL\u0026rsquo;expéditeur garde une trace des paquets envoyés, leurs numéros de séquence, tailles et horodatages. Lorsque l\u0026rsquo;expéditeur reçoit des messages RTCP du récepteur, il compare les délais inter-paquets d\u0026rsquo;envoi avec les délais de réception. Si les délais de réception augmentent, cela signale une congestion du réseau, et l\u0026rsquo;expéditeur doit prendre des mesures correctives.\nEn fournissant à l\u0026rsquo;expéditeur les données brutes, TWCC offre une excellente vue des conditions réseau en temps réel :\nComportement de perte de paquets presque instantané, jusqu\u0026rsquo;aux paquets perdus individuels Débit binaire d\u0026rsquo;envoi précis Débit binaire de réception précis Mesure de la gigue Différences entre les délais d\u0026rsquo;envoi et de réception des paquets Description de la façon dont le réseau a toléré la livraison de bande passante en rafale ou stable L\u0026rsquo;une des contributions les plus importantes de TWCC est la flexibilité qu\u0026rsquo;il offre aux développeurs WebRTC. En consolidant l\u0026rsquo;algorithme de contrôle de congestion du côté expéditeur, il permet un code client simple qui peut être largement utilisé et nécessite des améliorations minimales au fil du temps. Les algorithmes complexes de contrôle de congestion peuvent ensuite être itérés plus rapidement sur le matériel qu\u0026rsquo;ils contrôlent directement (comme l\u0026rsquo;unité de transfert sélectif, discutée dans la section 8). Dans le cas des navigateurs et des appareils mobiles, cela signifie que ces clients peuvent bénéficier d\u0026rsquo;améliorations d\u0026rsquo;algorithmes sans avoir à attendre la standardisation ou les mises à jour du navigateur (ce qui peut prendre beaucoup de temps pour être largement disponible).\nAlternatives d\u0026rsquo;estimation de bande passante # L\u0026rsquo;implémentation la plus déployée est \u0026ldquo;A Google Congestion Control Algorithm for Real-Time Communication\u0026rdquo; définie dans draft-alvestrand-rmcat-congestion.\nIl existe plusieurs alternatives à GCC, par exemple NADA: A Unified Congestion Control Scheme for Real-Time Media et SCReAM - Self-Clocked Rate Adaptation for Multimedia.\n"},{"id":6,"href":"/fr/docs/07-data-communication/","title":"Communication de données","section":"Docs","content":" Communication de données # Que m\u0026rsquo;apporte la communication de données de WebRTC ? # WebRTC fournit des canaux de données pour la communication de données. Entre deux pairs, vous pouvez ouvrir 65 534 canaux de données. Un canal de données est basé sur des datagrammes, et chacun a ses propres paramètres de durabilité. Par défaut, chaque canal de données garantit une livraison ordonnée.\nSi vous abordez WebRTC à partir d\u0026rsquo;un contexte média, les canaux de données peuvent sembler gaspilleurs. Pourquoi ai-je besoin de tout ce sous-système alors que je pourrais simplement utiliser HTTP ou WebSockets ?\nLe véritable pouvoir des canaux de données est que vous pouvez les configurer pour qu\u0026rsquo;ils se comportent comme UDP avec une livraison non ordonnée/avec perte. Ceci est nécessaire pour les situations de faible latence et de haute performance. Vous pouvez mesurer la contre-pression et vous assurer que vous n\u0026rsquo;envoyez que ce que votre réseau prend en charge.\nComment cela fonctionne-t-il ? # WebRTC utilise le Stream Control Transmission Protocol (SCTP), défini dans la RFC 4960. SCTP est un protocole de couche transport qui était destiné comme alternative à TCP ou UDP. Pour WebRTC, nous l\u0026rsquo;utilisons comme protocole de couche application qui s\u0026rsquo;exécute sur notre connexion DTLS.\nSCTP vous donne des flux et chaque flux peut être configuré indépendamment. Les canaux de données WebRTC ne sont que de minces abstractions autour d\u0026rsquo;eux. Les paramètres concernant la durabilité et l\u0026rsquo;ordonnancement sont simplement transmis directement à l\u0026rsquo;agent SCTP.\nLes canaux de données ont certaines fonctionnalités que SCTP ne peut pas exprimer, comme les étiquettes de canal. Pour résoudre cela, WebRTC utilise le Data Channel Establishment Protocol (DCEP) qui est défini dans la RFC 8832. DCEP définit un message pour communiquer l\u0026rsquo;étiquette et le protocole du canal.\nDCEP # DCEP n\u0026rsquo;a que deux messages DATA_CHANNEL_OPEN et DATA_CHANNEL_ACK. Pour chaque canal de données ouvert, le distant doit répondre avec un accusé de réception.\nDATA_CHANNEL_OPEN # Ce message est envoyé par l\u0026rsquo;agent WebRTC qui souhaite ouvrir un canal.\nFormat de paquet # 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Message Type | Channel Type | Priority | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Reliability Parameter | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Label Length | Protocol Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \\ \\ / Label / \\ \\ +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \\ \\ / Protocol / \\ \\ +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ Type de message # Le type de message est une valeur statique de 0x03.\nType de canal # Le type de canal contrôle les attributs de durabilité/ordonnancement du canal. Il peut avoir les valeurs suivantes :\nDATA_CHANNEL_RELIABLE (0x00) - Aucun message n\u0026rsquo;est perdu et arrivera dans l\u0026rsquo;ordre DATA_CHANNEL_RELIABLE_UNORDERED (0x80) - Aucun message n\u0026rsquo;est perdu, mais ils peuvent arriver dans le désordre. DATA_CHANNEL_PARTIAL_RELIABLE_REXMIT (0x01) - Les messages peuvent être perdus après avoir essayé le nombre de fois demandé, mais ils arriveront dans l\u0026rsquo;ordre. DATA_CHANNEL_PARTIAL_RELIABLE_REXMIT_UNORDERED (0x81) - Les messages peuvent être perdus après avoir essayé le nombre de fois demandé et peuvent arriver dans le désordre. DATA_CHANNEL_PARTIAL_RELIABLE_TIMED (0x02) - Les messages peuvent être perdus s\u0026rsquo;ils n\u0026rsquo;arrivent pas dans le délai demandé, mais ils arriveront dans l\u0026rsquo;ordre. DATA_CHANNEL_PARTIAL_RELIABLE_TIMED_UNORDERED (0x82) - Les messages peuvent être perdus s\u0026rsquo;ils n\u0026rsquo;arrivent pas dans le délai demandé et peuvent arriver dans le désordre. Priorité # La priorité du canal de données. Les canaux de données ayant une priorité plus élevée seront planifiés en premier. Les messages utilisateur volumineux de priorité inférieure ne retarderont pas l\u0026rsquo;envoi de messages utilisateur de priorité plus élevée.\nParamètre de fiabilité # Si le type de canal de données est DATA_CHANNEL_PARTIAL_RELIABLE, les suffixes configurent le comportement :\nREXMIT - Définit combien de fois l\u0026rsquo;expéditeur renverra le message avant d\u0026rsquo;abandonner. TIMED - Définit pendant combien de temps (en ms) l\u0026rsquo;expéditeur renverra le message avant d\u0026rsquo;abandonner. Étiquette # Une chaîne encodée UTF-8 contenant le nom du canal de données. Cette chaîne peut être vide.\nProtocole # Si c\u0026rsquo;est une chaîne vide, le protocole n\u0026rsquo;est pas spécifié. Si c\u0026rsquo;est une chaîne non vide, elle devrait spécifier un protocole enregistré dans le \u0026ldquo;WebSocket Subprotocol Name Registry\u0026rdquo;, défini dans la RFC 6455.\nDATA_CHANNEL_ACK # Ce message est envoyé par l\u0026rsquo;agent WebRTC pour accuser réception que ce canal de données a été ouvert.\nFormat de paquet # 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Message Type | +-+-+-+-+-+-+-+-+ Stream Control Transmission Protocol # SCTP est le véritable pouvoir derrière les canaux de données WebRTC. Il fournit toutes ces fonctionnalités du canal de données :\nMultiplexage Livraison fiable utilisant un mécanisme de retransmission similaire à TCP Options de fiabilité partielle Évitement de la congestion Contrôle de flux Pour comprendre SCTP, nous l\u0026rsquo;explorerons en trois parties. L\u0026rsquo;objectif est que vous en sachiez assez pour déboguer et apprendre les détails profonds de SCTP par vous-même après ce chapitre.\nConcepts # SCTP est un protocole riche en fonctionnalités. Cette section ne couvrira que les parties de SCTP utilisées par WebRTC. Les fonctionnalités de SCTP qui ne sont pas utilisées par WebRTC incluent le multi-homing et la sélection de chemin.\nAvec plus de vingt ans de développement, SCTP peut être difficile à saisir pleinement.\nAssociation # L\u0026rsquo;association est le terme utilisé pour une session SCTP. C\u0026rsquo;est l\u0026rsquo;état qui est partagé entre deux agents SCTP pendant qu\u0026rsquo;ils communiquent.\nFlux # Un flux est une séquence bidirectionnelle de données utilisateur. Lorsque vous créez un canal de données, vous ne créez en fait qu\u0026rsquo;un flux SCTP. Chaque association SCTP contient une liste de flux. Chaque flux peut être configuré avec différents types de fiabilité.\nWebRTC vous permet uniquement de configurer lors de la création du flux, mais SCTP permet en réalité de changer la configuration à tout moment.\nBasé sur les datagrammes # SCTP encadre les données comme des datagrammes et non comme un flux d\u0026rsquo;octets. L\u0026rsquo;envoi et la réception de données ressemblent à l\u0026rsquo;utilisation d\u0026rsquo;UDP plutôt que de TCP. Vous n\u0026rsquo;avez pas besoin d\u0026rsquo;ajouter de code supplémentaire pour transférer plusieurs fichiers sur un seul flux.\nLes messages SCTP n\u0026rsquo;ont pas de limites de taille comme UDP. Un seul message SCTP peut faire plusieurs gigaoctets de taille.\nMorceaux # Le protocole SCTP est composé de morceaux. Il existe de nombreux types différents de morceaux. Ces morceaux sont utilisés pour toute communication. Les données utilisateur, l\u0026rsquo;initialisation de connexion, le contrôle de congestion, et plus encore sont tous effectués via des morceaux.\nChaque paquet SCTP contient une liste de morceaux. Donc, dans un paquet UDP, vous pouvez avoir plusieurs morceaux transportant des messages de différents flux.\nNuméro de séquence de transmission # Le numéro de séquence de transmission (TSN) est un identifiant unique global pour les morceaux DATA. Un morceau DATA est ce qui transporte tous les messages qu\u0026rsquo;un utilisateur souhaite envoyer. Le TSN est important car il aide un récepteur à déterminer si des paquets sont perdus ou dans le désordre.\nSi le récepteur remarque un TSN manquant, il ne donne pas les données à l\u0026rsquo;utilisateur tant qu\u0026rsquo;il n\u0026rsquo;est pas satisfait.\nIdentifiant de flux # Chaque flux a un identifiant unique. Lorsque vous créez un canal de données avec un ID explicite, il est en fait simplement passé directement à SCTP comme identifiant de flux. Si vous ne passez pas d\u0026rsquo;ID, l\u0026rsquo;identifiant de flux est choisi pour vous.\nIdentifiant de protocole de charge utile # Chaque morceau DATA a également un identifiant de protocole de charge utile (PPID). Ceci est utilisé pour identifier de manière unique quel type de données est échangé. SCTP a de nombreux PPID, mais WebRTC n\u0026rsquo;utilise que les cinq suivants :\nWebRTC DCEP (50) - Messages DCEP. WebRTC String (51) - Messages de chaîne DataChannel. WebRTC Binary (53) - Messages binaires DataChannel. WebRTC String Empty (56) - Messages de chaîne DataChannel de longueur 0. WebRTC Binary Empty (57) - Messages binaires DataChannel de longueur 0. Protocole # Voici quelques-uns des morceaux utilisés par le protocole SCTP. Ce n\u0026rsquo;est pas une démonstration exhaustive. Cela fournit suffisamment de structures pour que la machine à états ait du sens.\nChaque morceau commence par un champ type. Avant une liste de morceaux, vous aurez également un en-tête.\nMorceau DATA # 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Type = 0 | Reserved|U|B|E| Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | TSN | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Stream Identifier | Stream Sequence Number | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Payload Protocol Identifier | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \\ \\ / User Data / \\ \\ +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ Le morceau DATA est la façon dont toutes les données utilisateur sont échangées. Lorsque vous envoyez quoi que ce soit sur le canal de données, c\u0026rsquo;est ainsi qu\u0026rsquo;il est échangé.\nLe bit U est défini si c\u0026rsquo;est un paquet non ordonné. Nous pouvons ignorer le numéro de séquence de flux.\nB et E sont les bits de début et de fin. Si vous voulez envoyer un message trop grand pour un morceau DATA, il doit être fragmenté en plusieurs morceaux DATA envoyés dans des paquets séparés. Avec le bit B et E et les numéros de séquence, SCTP est capable d\u0026rsquo;exprimer cela.\nB=1, E=0 - Première pièce d\u0026rsquo;un message utilisateur fragmenté. B=0, E=0 - Pièce intermédiaire d\u0026rsquo;un message utilisateur fragmenté. B=0, E=1 - Dernière pièce d\u0026rsquo;un message utilisateur fragmenté. B=1, E=1 - Message non fragmenté. TSN est le numéro de séquence de transmission. C\u0026rsquo;est l\u0026rsquo;identifiant unique global pour ce morceau DATA. Après 4 294 967 295 morceaux, cela reviendra à 0. Le TSN est incrémenté pour chaque morceau dans un message utilisateur fragmenté afin que le récepteur sache comment ordonner les morceaux reçus pour reconstruire le message original.\nIdentifiant de flux est l\u0026rsquo;identifiant unique pour le flux auquel ces données appartiennent.\nNuméro de séquence de flux est un nombre de 16 bits incrémenté à chaque message utilisateur et inclus dans l\u0026rsquo;en-tête du morceau de message DATA. Après 65 535 messages, cela reviendra à 0. Ce nombre est utilisé pour décider l\u0026rsquo;ordre de livraison des messages au récepteur si U est défini à 0. Semblable au TSN, sauf que le numéro de séquence de flux n\u0026rsquo;est incrémenté que pour chaque message dans son ensemble et non pour chaque morceau DATA individuel.\nIdentifiant de protocole de charge utile est le type de données qui circule à travers ce flux. Pour WebRTC, ce sera DCEP, String ou Binary.\nDonnées utilisateur est ce que vous envoyez. Toutes les données que vous envoyez via un canal de données WebRTC sont transmises via un morceau DATA.\nMorceau INIT # 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Type = 1 | Chunk Flags | Chunk Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Initiate Tag | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Advertised Receiver Window Credit (a_rwnd) | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Number of Outbound Streams | Number of Inbound Streams | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Initial TSN | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \\ \\ / Optional/Variable-Length Parameters / \\ \\ +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ Le morceau INIT démarre le processus de création d\u0026rsquo;une association.\nInitiate Tag est utilisé pour la génération de cookies. Les cookies sont utilisés pour la protection contre l\u0026rsquo;homme du milieu et le déni de service. Ils sont décrits plus en détail dans la section de la machine à états.\nAdvertised Receiver Window Credit est utilisé pour le contrôle de congestion de SCTP. Cela communique la taille du tampon que le récepteur a alloué pour cette association.\nNombre de flux sortants/entrants notifie le distant du nombre de flux que cet agent prend en charge.\nTSN initial est un uint32 aléatoire pour démarrer le TSN local.\nParamètres optionnels permet à SCTP d\u0026rsquo;introduire de nouvelles fonctionnalités dans le protocole.\nMorceau SACK # 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Type = 3 |Chunk Flags | Chunk Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Cumulative TSN Ack | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Advertised Receiver Window Credit (a_rwnd) | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Number of Gap Ack Blocks = N | Number of Duplicate TSNs = X | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Gap Ack Block #1 Start | Gap Ack Block #1 End | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ / / \\ ... \\ / / +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Gap Ack Block #N Start | Gap Ack Block #N End | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Duplicate TSN 1 | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ / / \\ ... \\ / / +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Duplicate TSN X | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ Le morceau SACK (Accusé de réception sélectif) est la façon dont un récepteur notifie un expéditeur qu\u0026rsquo;il a reçu un paquet. Jusqu\u0026rsquo;à ce qu\u0026rsquo;un expéditeur reçoive un SACK pour un TSN, il renverra le morceau DATA en question. Un SACK fait plus que simplement mettre à jour le TSN.\nTSN cumulatif ACK le TSN le plus élevé qui a été reçu.\nCrédit de fenêtre de récepteur annoncé taille du tampon du récepteur. Le récepteur peut changer cela pendant la session si plus de mémoire devient disponible.\nBlocs Ack TSN qui ont été reçus après le TSN cumulatif ACK. Ceci est utilisé s\u0026rsquo;il y a un écart dans les paquets livrés. Disons que des morceaux DATA avec des TSN 100, 102, 103 et 104 sont livrés. Le TSN cumulatif ACK serait 100, mais Blocs Ack pourrait être utilisé pour dire à l\u0026rsquo;expéditeur qu\u0026rsquo;il n\u0026rsquo;a pas besoin de renvoyer 102, 103 ou 104.\nTSN dupliqué informe l\u0026rsquo;expéditeur qu\u0026rsquo;il a reçu les morceaux DATA suivants plus d\u0026rsquo;une fois.\nMorceau HEARTBEAT # 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Type = 4 | Chunk Flags | Heartbeat Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \\ \\ / Heartbeat Information TLV (Variable-Length) / \\ \\ +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ Le morceau HEARTBEAT est utilisé pour affirmer que le distant répond toujours. Utile si vous n\u0026rsquo;envoyez aucun morceau DATA et devez maintenir un mappage NAT ouvert.\nMorceau ABORT # 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Type = 6 |Reserved |T| Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ / / \\ Zero or more Error Causes \\ / / +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ Un morceau ABORT ferme brusquement l\u0026rsquo;association. Utilisé lorsque un côté entre dans un état d\u0026rsquo;erreur. La fin gracieuse de la connexion utilise le morceau SHUTDOWN.\nMorceau SHUTDOWN # 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Type = 7 | Chunk Flags | Length = 8 | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Cumulative TSN Ack | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ Le morceau SHUTDOWN démarre une fermeture gracieuse de l\u0026rsquo;association SCTP. Chaque agent informe le distant du dernier TSN qu\u0026rsquo;il a envoyé. Cela garantit qu\u0026rsquo;aucun paquet n\u0026rsquo;est perdu. WebRTC n\u0026rsquo;effectue pas de fermeture gracieuse de l\u0026rsquo;association SCTP. Vous devez démonter chaque canal de données vous-même pour le gérer gracieusement.\nTSN cumulatif ACK est le dernier TSN qui a été envoyé. Chaque côté sait ne pas terminer jusqu\u0026rsquo;à ce qu\u0026rsquo;il ait reçu le morceau DATA avec ce TSN.\nMorceau ERROR # 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Type = 9 | Chunk Flags | Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \\ \\ / One or more Error Causes / \\ \\ +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ Un morceau ERROR est utilisé pour notifier l\u0026rsquo;agent SCTP distant qu\u0026rsquo;une erreur non fatale s\u0026rsquo;est produite.\nMorceau FORWARD TSN # 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Type = 192 | Flags = 0x00 | Length = Variable | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | New Cumulative TSN | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Stream-1 | Stream Sequence-1 | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \\ / / \\ +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Stream-N | Stream Sequence-N | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ Le morceau FORWARD TSN déplace le TSN global vers l\u0026rsquo;avant. SCTP fait cela, pour que vous puissiez sauter certains paquets qui ne vous intéressent plus. Disons que vous envoyez 10 11 12 13 14 15 et que ces paquets ne sont valides que s\u0026rsquo;ils arrivent tous. Ces données sont également sensibles au temps réel, donc si elles arrivent tard, elles ne sont pas utiles.\nSi vous perdez 12 et 13, il n\u0026rsquo;y a aucune raison d\u0026rsquo;envoyer 14 et 15 ! SCTP utilise le morceau FORWARD TSN pour y parvenir. Il dit au récepteur que 14 et 15 ne seront plus livrés.\nNouveau TSN cumulatif c\u0026rsquo;est le nouveau TSN de la connexion. Tous les paquets avant ce TSN ne seront pas conservés.\nFlux et Séquence de flux sont utilisés pour faire avancer le numéro de séquence de flux en avant. Reportez-vous au morceau DATA pour la signification de ce champ.\nMachine à états # Voici quelques parties intéressantes de la machine à états SCTP. WebRTC n\u0026rsquo;utilise pas toutes les fonctionnalités de la machine à états SCTP, nous avons donc exclu ces parties. Nous avons également simplifié certains composants pour les rendre compréhensibles par eux-mêmes.\nFlux d\u0026rsquo;établissement de connexion # Les morceaux INIT et INIT ACK sont utilisés pour échanger les capacités et configurations de chaque pair. SCTP utilise un cookie pendant la négociation pour valider le pair avec lequel il communique. Cela garantit que la négociation n\u0026rsquo;est pas interceptée et pour prévenir les attaques DoS.\nLe morceau INIT ACK contient le cookie. Le cookie est ensuite renvoyé à son créateur en utilisant le COOKIE ECHO. Si la vérification du cookie réussit, le COOKIE ACK est envoyé et les morceaux DATA sont prêts à être échangés.\nFlux de démontage de connexion # SCTP utilise le morceau SHUTDOWN. Lorsqu\u0026rsquo;un agent reçoit un morceau SHUTDOWN, il attendra jusqu\u0026rsquo;à ce qu\u0026rsquo;il reçoive le TSN cumulatif ACK demandé. Cela permet à un utilisateur de s\u0026rsquo;assurer que toutes les données sont livrées même si la connexion a des pertes.\nMécanisme de maintien en vie # SCTP utilise les morceaux HEARTBEAT REQUEST et HEARTBEAT ACK pour maintenir la connexion en vie. Ceux-ci sont envoyés à un intervalle configurable. SCTP effectue également un backoff exponentiel si le paquet n\u0026rsquo;est pas arrivé.\nLe morceau HEARTBEAT contient également une valeur temporelle. Cela permet à deux associations de calculer le temps de trajet entre deux agents.\n"},{"id":7,"href":"/fr/docs/08-applied-webrtc/","title":"WebRTC appliqué","section":"Docs","content":" WebRTC appliqué # Maintenant que vous savez comment fonctionne WebRTC, il est temps de construire avec ! Ce chapitre explore ce que les gens construisent avec WebRTC, et comment ils le construisent. Vous apprendrez toutes les choses intéressantes qui se passent avec WebRTC. Le pouvoir de WebRTC a un coût. La construction de services WebRTC de qualité production est difficile. Ce chapitre essaiera d\u0026rsquo;expliquer ces défis avant que vous ne les rencontriez.\nPar cas d\u0026rsquo;usage # Beaucoup pensent que WebRTC n\u0026rsquo;est qu\u0026rsquo;une technologie pour la conférence dans le navigateur web. C\u0026rsquo;est tellement plus que cela cependant ! WebRTC est utilisé dans une large gamme d\u0026rsquo;applications. De nouveaux cas d\u0026rsquo;usage apparaissent tout le temps. Dans ce chapitre, nous énumérerons quelques-uns des plus courants et comment WebRTC les révolutionne.\nConférence # La conférence est le cas d\u0026rsquo;usage original de WebRTC. Le protocole contient quelques fonctionnalités nécessaires qu\u0026rsquo;aucun autre protocole n\u0026rsquo;offre dans le navigateur. Vous pourriez construire un système de conférence avec WebSockets et il pourrait fonctionner dans des conditions optimales. Si vous voulez quelque chose qui peut être déployé dans des conditions réseau du monde réel, WebRTC est le meilleur choix.\nWebRTC fournit un contrôle de congestion et un débit adaptatif pour les médias. À mesure que les conditions du réseau changent, les utilisateurs obtiendront toujours la meilleure expérience possible. Les développeurs n\u0026rsquo;ont pas non plus à écrire de code supplémentaire pour mesurer ces conditions.\nLes participants peuvent envoyer et recevoir plusieurs flux. Ils peuvent également ajouter et supprimer ces flux à tout moment pendant l\u0026rsquo;appel. Les codecs sont négociés également. Toute cette fonctionnalité est fournie par le navigateur, aucun code personnalisé n\u0026rsquo;a besoin d\u0026rsquo;être écrit par le développeur.\nLa conférence bénéficie également des canaux de données. Les utilisateurs peuvent envoyer des métadonnées ou partager des documents. Vous pouvez créer plusieurs flux et les configurer si vous avez besoin de performances plutôt que de fiabilité.\nDiffusion # De nombreux nouveaux projets commencent à apparaître dans l\u0026rsquo;espace de diffusion qui utilisent WebRTC. Le protocole a beaucoup à offrir à la fois pour l\u0026rsquo;éditeur et le consommateur de médias.\nWebRTC étant dans le navigateur facilite la publication de vidéo pour les utilisateurs. Il supprime l\u0026rsquo;exigence pour les utilisateurs de télécharger un nouveau client. Toute plateforme qui a un navigateur web peut publier de la vidéo. Les éditeurs peuvent ensuite envoyer plusieurs pistes et les modifier ou les supprimer à tout moment. C\u0026rsquo;est une énorme amélioration par rapport aux protocoles hérités qui n\u0026rsquo;autorisaient qu\u0026rsquo;une piste audio ou une piste vidéo par connexion.\nWebRTC donne aux développeurs un plus grand contrôle sur les compromis latence versus qualité. S\u0026rsquo;il est plus important que la latence ne dépasse jamais un certain seuil, et que vous êtes prêt à tolérer certains artefacts de décodage. Vous pouvez configurer le visualiseur pour lire les médias dès qu\u0026rsquo;ils arrivent. Avec d\u0026rsquo;autres protocoles qui fonctionnent sur TCP, ce n\u0026rsquo;est pas aussi facile. Dans le navigateur, vous pouvez demander des données et c\u0026rsquo;est tout.\nAccès à distance # L\u0026rsquo;accès à distance, c\u0026rsquo;est lorsque vous accédez à distance à un autre ordinateur via WebRTC. Vous pourriez avoir un contrôle complet de l\u0026rsquo;hôte distant, ou peut-être juste une seule application. C\u0026rsquo;est génial pour exécuter des tâches coûteuses en calcul lorsque le matériel local ne peut pas le faire. Comme exécuter un nouveau jeu vidéo, ou un logiciel de CAO. WebRTC a pu révolutionner l\u0026rsquo;espace de trois manières.\nWebRTC peut être utilisé pour accéder à distance à un hôte qui n\u0026rsquo;est pas routable mondialement. Avec la traversée NAT, vous pouvez accéder à un ordinateur qui n\u0026rsquo;est disponible que via STUN. C\u0026rsquo;est génial pour la sécurité et la confidentialité. Vos utilisateurs n\u0026rsquo;ont pas à router la vidéo via une ingestion, ou une \u0026ldquo;jump box\u0026rdquo;. La traversée NAT facilite également les déploiements. Vous n\u0026rsquo;avez pas à vous soucier de la redirection de port ou de la configuration d\u0026rsquo;une IP statique à l\u0026rsquo;avance.\nLes canaux de données sont également vraiment puissants dans ce scénario. Ils peuvent être configurés pour que seules les dernières données soient acceptées. Avec TCP, vous courez le risque de rencontrer un blocage en tête de ligne. Un ancien clic de souris ou une frappe de touche pourrait arriver en retard et bloquer les suivants. Les canaux de données de WebRTC sont conçus pour gérer cela et peuvent être configurés pour ne pas renvoyer les paquets perdus. Vous pouvez également mesurer la contre-pression et vous assurer que vous n\u0026rsquo;envoyez pas plus de données que votre réseau ne peut en supporter.\nWebRTC étant disponible dans le navigateur a été une énorme amélioration de la qualité de vie. Vous n\u0026rsquo;avez pas à télécharger un client propriétaire pour démarrer la session. De plus en plus de clients arrivent avec WebRTC intégré, les téléviseurs intelligents obtiennent maintenant des navigateurs web complets.\nPartage de fichiers et contournement de la censure # Le partage de fichiers et le contournement de la censure sont des problèmes radicalement différents. Cependant, WebRTC résout les mêmes problèmes pour eux deux. Il les rend tous deux facilement disponibles et plus difficiles à bloquer.\nLe premier problème que WebRTC résout est l\u0026rsquo;obtention du client. Si vous voulez rejoindre un réseau de partage de fichiers, vous devez télécharger le client. Même si le réseau est distribué, vous devez toujours obtenir le client d\u0026rsquo;abord. Dans un réseau restreint, le téléchargement sera souvent bloqué. Même si vous pouvez le télécharger, l\u0026rsquo;utilisateur peut ne pas être en mesure d\u0026rsquo;installer et d\u0026rsquo;exécuter le client. WebRTC est déjà disponible dans chaque navigateur web, le rendant facilement disponible.\nLe deuxième problème que WebRTC résout est le blocage de votre trafic. Si vous utilisez un protocole qui est juste pour le partage de fichiers ou le contournement de la censure, il est beaucoup plus facile de le bloquer. Étant donné que WebRTC est un protocole à usage général, le bloquer impacterait tout le monde. Bloquer WebRTC pourrait empêcher d\u0026rsquo;autres utilisateurs du réseau de rejoindre des appels de conférence.\nInternet des objets # L\u0026rsquo;Internet des objets (IoT) couvre quelques cas d\u0026rsquo;usage différents. Pour beaucoup, cela signifie des caméras de sécurité connectées au réseau. En utilisant WebRTC, vous pouvez diffuser la vidéo vers un autre pair WebRTC comme votre téléphone ou un navigateur. Un autre cas d\u0026rsquo;usage consiste à avoir des appareils se connecter et échanger des données de capteurs. Vous pouvez avoir deux appareils dans votre LAN échanger des lectures de climat, de bruit ou de lumière.\nWebRTC a un énorme avantage en matière de confidentialité ici par rapport aux protocoles de flux vidéo hérités. Étant donné que WebRTC prend en charge la connectivité P2P, la caméra peut envoyer la vidéo directement à votre navigateur. Il n\u0026rsquo;y a aucune raison pour que votre vidéo soit envoyée à un serveur tiers. Même lorsque la vidéo est chiffrée, un attaquant peut faire des suppositions à partir des métadonnées de l\u0026rsquo;appel.\nL\u0026rsquo;interopérabilité est un autre avantage pour l\u0026rsquo;espace IoT. WebRTC est disponible dans beaucoup de langages différents ; C#, C++, C, Go, Java, Python, Rust et TypeScript. Cela signifie que vous pouvez utiliser le langage qui fonctionne le mieux pour vous. Vous n\u0026rsquo;avez pas non plus à vous tourner vers des protocoles ou des formats propriétaires pour pouvoir connecter vos clients.\nPontage de protocole média # Vous avez du matériel et des logiciels existants qui produisent de la vidéo, mais vous ne pouvez pas encore le mettre à niveau. Attendre des utilisateurs qu\u0026rsquo;ils téléchargent un client propriétaire pour regarder des vidéos est frustrant. La réponse est d\u0026rsquo;exécuter un pont WebRTC. Le pont traduit entre les deux protocoles afin que les utilisateurs puissent utiliser le navigateur avec votre configuration héritée.\nBeaucoup des formats avec lesquels les développeurs font le pont utilisent les mêmes protocoles que WebRTC. SIP est couramment exposé via WebRTC et permet aux utilisateurs de passer des appels téléphoniques depuis leur navigateur. RTSP est utilisé dans beaucoup de caméras de sécurité héritées. Ils utilisent tous deux les mêmes protocoles sous-jacents (RTP et SDP), donc c\u0026rsquo;est peu coûteux en calcul à exécuter. Le pont est juste nécessaire pour ajouter ou supprimer des choses qui sont spécifiques à WebRTC.\nPontage de protocole de données # Un navigateur web ne peut parler qu\u0026rsquo;un ensemble contraint de protocoles. Vous pouvez utiliser HTTP, WebSockets, WebRTC et QUIC. Si vous voulez vous connecter à autre chose, vous devez utiliser un pont de protocole. Un pont de protocole est un serveur qui convertit le trafic étranger en quelque chose que le navigateur peut accéder. Un exemple populaire est l\u0026rsquo;utilisation de SSH depuis votre navigateur pour accéder à un serveur. Les canaux de données de WebRTC ont deux avantages par rapport à la concurrence.\nLes canaux de données de WebRTC permettent une livraison non fiable et non ordonnée. Dans les cas où la faible latence est critique, cela est nécessaire. Vous ne voulez pas que de nouvelles données soient bloquées par d\u0026rsquo;anciennes données, c\u0026rsquo;est ce qu\u0026rsquo;on appelle le blocage en tête de ligne. Imaginez que vous jouez à un jeu de tir à la première personne multijoueur. Vous souciez-vous vraiment de l\u0026rsquo;endroit où le joueur était il y a deux secondes ? Si ces données n\u0026rsquo;arrivent pas à temps, cela n\u0026rsquo;a pas de sens de continuer à essayer de les envoyer. La livraison non fiable et non ordonnée vous permet d\u0026rsquo;utiliser les données dès qu\u0026rsquo;elles arrivent.\nLes canaux de données fournissent également une pression de rétroaction. Cela vous indique si vous envoyez des données plus rapidement que votre connexion ne peut le supporter. Vous avez alors deux choix lorsque cela se produit. Le canal de données peut soit être configuré pour mettre en mémoire tampon et livrer les données en retard, soit vous pouvez abandonner les données qui ne sont pas arrivées en temps réel.\nTéléopération # La téléopération est l\u0026rsquo;acte de contrôler un appareil à distance via des canaux de données WebRTC, et d\u0026rsquo;envoyer la vidéo en retour via RTP. Les développeurs conduisent des voitures à distance via WebRTC aujourd\u0026rsquo;hui ! Ceci est utilisé pour contrôler des robots sur des chantiers de construction et livrer des colis. Utiliser WebRTC pour ces problèmes a du sens pour deux raisons.\nL\u0026rsquo;ubiquité de WebRTC facilite le contrôle pour les utilisateurs. Tout ce dont l\u0026rsquo;utilisateur a besoin est un navigateur web et un périphérique d\u0026rsquo;entrée. Les navigateurs prennent même en charge la saisie depuis des joysticks et des manettes de jeu. WebRTC supprime complètement le besoin d\u0026rsquo;installer un client supplémentaire sur l\u0026rsquo;appareil de l\u0026rsquo;utilisateur.\nCDN distribué # Les CDN distribués sont un sous-ensemble du partage de fichiers. Les fichiers distribués sont configurés par l\u0026rsquo;opérateur CDN à la place. Lorsque les utilisateurs rejoignent le réseau CDN, ils peuvent télécharger et partager les fichiers autorisés. Les utilisateurs obtiennent tous les mêmes avantages que le partage de fichiers.\nCes CDN fonctionnent très bien lorsque vous êtes dans un bureau avec une mauvaise connectivité externe, mais une excellente connectivité LAN. Vous pouvez avoir un utilisateur télécharger une vidéo, et ensuite la partager avec tout le monde. Étant donné que tout le monde n\u0026rsquo;essaie pas de récupérer le même fichier via le réseau externe, le transfert se terminera plus rapidement.\nTopologies WebRTC # WebRTC est un protocole pour connecter deux agents, alors comment les développeurs connectent-ils des centaines de personnes à la fois ? Il existe quelques façons différentes de le faire, et elles ont toutes des avantages et des inconvénients. Ces solutions se répartissent globalement en deux catégories ; Pair-à-pair ou Client/Serveur. La flexibilité de WebRTC nous permet de créer les deux.\nUn à un # Un à un est le premier type de connexion que vous utiliserez avec WebRTC. Vous connectez deux agents WebRTC directement et ils peuvent envoyer des médias et des données bidirectionnels. La connexion ressemble à ceci.\nMaillage complet # Le maillage complet est la réponse si vous voulez construire une conférence téléphonique ou un jeu multijoueur. Dans cette topologie, chaque utilisateur établit une connexion avec chaque autre utilisateur directement. Cela vous permet de construire votre application, mais cela vient avec quelques inconvénients.\nDans une topologie de maillage complet, chaque utilisateur est connecté directement. Cela signifie que vous devez encoder et télécharger la vidéo indépendamment pour chaque membre de l\u0026rsquo;appel. Les conditions réseau entre chaque connexion seront différentes, vous ne pouvez donc pas réutiliser la même vidéo. La gestion des erreurs est également difficile dans ces déploiements. Vous devez considérer attentivement si vous avez perdu une connectivité complète, ou juste une connectivité avec un pair distant.\nEn raison de ces préoccupations, un maillage complet est mieux utilisé pour de petits groupes. Pour quoi que ce soit de plus grand, une topologie client/serveur est préférable.\nMaillage hybride # Le maillage hybride est une alternative au maillage complet qui peut alléger certains des problèmes du maillage complet. Dans un maillage hybride, les connexions ne sont pas établies entre chaque utilisateur. Au lieu de cela, les médias sont relayés via des pairs dans le réseau. Cela signifie que le créateur des médias n\u0026rsquo;a pas à utiliser autant de bande passante pour distribuer les médias.\nCela a cependant quelques inconvénients. Dans cette configuration, le créateur original des médias n\u0026rsquo;a aucune idée à qui sa vidéo est envoyée, ni si elle est arrivée avec succès. Vous aurez également une augmentation de la latence à chaque saut dans votre réseau de maillage hybride.\nUnité de transfert sélectif # Un SFU (Selective Forwarding Unit) résout également les problèmes du maillage complet, mais d\u0026rsquo;une manière entièrement différente. Un SFU implémente une topologie client/serveur, au lieu de P2P. Chaque pair WebRTC se connecte au SFU et télécharge ses médias. Le SFU transfère ensuite ces médias à chaque client connecté.\nAvec un SFU, chaque agent WebRTC ne doit encoder et télécharger sa vidéo qu\u0026rsquo;une seule fois. Le fardeau de la distribuer à tous les spectateurs incombe au SFU. La connectivité avec un SFU est également beaucoup plus facile que P2P. Vous pouvez exécuter un SFU sur une adresse routable mondiale, ce qui facilite la connexion des clients. Vous n\u0026rsquo;avez pas à vous soucier des mappages NAT. Vous devez toujours vous assurer que votre SFU est disponible via TCP (soit via ICE-TCP soit TURN).\nConstruire un SFU simple peut être fait en un week-end. Construire un bon SFU qui peut gérer tous les types de clients n\u0026rsquo;a jamais de fin. Régler le contrôle de congestion, la correction d\u0026rsquo;erreur et les performances est une tâche sans fin.\nMCU # Un MCU (Multi-point Conferencing Unit) est une topologie client/serveur comme un SFU, mais compose les flux de sortie. Au lieu de distribuer les médias sortants non modifiés, il les réencode en un seul flux.\n"},{"id":8,"href":"/fr/docs/09-debugging/","title":"Débogage","section":"Docs","content":" Débogage # Le débogage de WebRTC peut être une tâche décourageante. Il y a de nombreuses parties mobiles, et elles peuvent toutes se casser indépendamment. Si vous n\u0026rsquo;êtes pas prudent, vous pourriez perdre des semaines à chercher au mauvais endroit. Lorsque vous trouvez enfin la partie qui est cassée, vous devrez apprendre un peu pour comprendre pourquoi.\nCe chapitre vous mettra dans l\u0026rsquo;état d\u0026rsquo;esprit nécessaire pour déboguer WebRTC. Il vous montrera comment décomposer le problème. Après avoir identifié le problème, nous ferons un tour rapide des outils de débogage populaires.\nIsoler le problème # Lorsque vous déboguez, vous devez isoler d\u0026rsquo;où vient le problème. Commencez par le début de la pile WebRTC et descendez jusqu\u0026rsquo;à ce que vous trouviez le coupable. Voici comment la pile s\u0026rsquo;organise :\nÉchec de signalisation # L\u0026rsquo;échec de signalisation est lorsque vous ne pouvez pas obtenir une SessionDescription locale/distante avec succès. Cela signifie que même avant de créer une connexion réseau, quelque chose s\u0026rsquo;est mal passé. Y a-t-il des erreurs dans les attributs SDP que vous avez définies ? Les deux agents ont-ils un codec en commun ?\nVous devez vous assurer que les deux pairs peuvent effectuer l\u0026rsquo;échange entier. Si vous ne répondez pas avec une réponse dans un certain délai, certaines implémentations échoueront.\nÉchec réseau # L\u0026rsquo;échec réseau est lorsque les deux agents WebRTC ne peuvent pas se connecter. C\u0026rsquo;est la partie la plus difficile de WebRTC. Le débogage du réseau peut être assez difficile car l\u0026rsquo;échec peut survenir à différents endroits. Voici quelques endroits où chercher :\nAppairage de candidats # Avez-vous généré des candidats des deux côtés ? Vous devriez voir un candidat de chaque type défini dans votre SessionDescription si tout fonctionne correctement.\nSi vous ne générez pas de candidats de relais, cela signifie que votre connexion au serveur TURN échoue. Assurez-vous que vous utilisez le protocole correct (TURN s\u0026rsquo;exécute sur UDP, TCP ou TLS). Vous pourriez également avoir saisi des informations d\u0026rsquo;identification incorrectes.\nSi vous ne générez pas de candidats mDNS, cela signifie que l\u0026rsquo;agent réseau n\u0026rsquo;a pas pu interroger le LAN local. Cela peut être dû à des permissions ou parce que vous n\u0026rsquo;êtes tout simplement pas sur un LAN.\nSi vous ne générez pas de candidats réflexifs, cela signifie que vos requêtes STUN ne réussissent pas. Assurez-vous que rien n\u0026rsquo;est en train de bloquer les paquets UDP sortants. Vous pouvez tester votre serveur STUN avec des outils en ligne de commande comme netcat.\nMême si vous générez ces candidats, votre réseau peut toujours bloquer le trafic. Certains réseaux n\u0026rsquo;autorisent le trafic que vers/depuis des ports spécifiques ou des protocoles spécifiques. Vous pouvez avoir un candidat réflexif, mais le trafic est tout de même bloqué. Essayez d\u0026rsquo;utiliser un serveur TURN sur le port 443 sur TCP. 443 et 80 sont les ports les plus susceptibles de ne pas être filtrés car ils sont utilisés pour le trafic HTTPS et HTTP.\nConnectivité réseau # Même si vous avez plusieurs candidats, vous ne pouvez peut-être toujours pas vous connecter ! Un candidat contient une adresse IP, qui peut être bloquée. Les réseaux d\u0026rsquo;entreprise peuvent bloquer tout le trafic UDP. Les FAI peuvent ne pas autoriser les connexions pair-à-pair.\nDans ces cas, vous devrez utiliser un candidat de relais. Vous pouvez forcer WebRTC à utiliser uniquement des candidats de relais si vous le souhaitez. C\u0026rsquo;est utile pour tester !\nPare-feu/Équipement réseau # Certains réseaux ont du matériel qui tente d\u0026rsquo;être intelligent. Il y a des dispositifs qui inspectent et tentent de modifier le trafic WebRTC. Certains modems et routeurs tentent d\u0026rsquo;ouvrir des ports ou de réécrire les messages. Ces dispositifs peuvent causer des problèmes car ils ne sont pas toujours bien implémentés.\nÉchec de sécurité # L\u0026rsquo;échec de sécurité est lorsque la poignée de main DTLS échoue. Cela peut se produire pour plusieurs raisons. Si l\u0026rsquo;horloge d\u0026rsquo;un agent est incorrecte, il rejettera le certificat de l\u0026rsquo;autre. Si vous modifiez la SessionDescription entre les agents, l\u0026rsquo;empreinte digitale DTLS ne correspondra pas. Les agents réseau peuvent également bloquer ou modifier les messages DTLS.\nÉchec de média # L\u0026rsquo;échec de média est lorsque deux agents sont connectés, mais ils n\u0026rsquo;obtiennent pas les médias qu\u0026rsquo;ils attendent. Vous devez d\u0026rsquo;abord vous assurer que les médias sont même envoyés. Certains réseaux peuvent supprimer les types de paquets de manière agressive, créant ainsi des conditions difficiles à reproduire.\nEnsuite, vous devez déterminer si les codecs fonctionnent correctement. Assurez-vous que vous avez configuré votre MediaStream correctement. Certains déploiements peuvent échouer à encoder/décoder au début.\nÉchec de données # L\u0026rsquo;échec de données est lorsque les canaux de données d\u0026rsquo;un agent ne fonctionnent pas. Tout d\u0026rsquo;abord, assurez-vous que SCTP est activé. Certaines implémentations ne l\u0026rsquo;activent pas par défaut.\nComme avec les médias, certains réseaux peuvent bloquer les paquets SCTP. Vous pouvez constater que SCTP fonctionne sur certains réseaux, mais pas sur tous.\nOutils du métier # Ces outils vous aideront à isoler les problèmes. Certains de ces outils sont plus utilisables si vous avez accès au serveur ou au réseau. Dans d\u0026rsquo;autres cas, vous ne pourrez examiner que le code côté client.\nnetcat (nc) # netcat est un utilitaire réseau en ligne de commande pour lire et écrire vers des connexions réseau en utilisant TCP ou UDP. Il est généralement disponible sous la commande nc.\nTester votre serveur STUN en utilisant netcat :\nPréparez le paquet de requête de liaison de 20 octets :\necho -ne \u0026#34;\\x00\\x01\\x00\\x00\\x21\\x12\\xA4\\x42TESTTESTTEST\u0026#34; | hexdump -C 00000000 00 01 00 00 21 12 a4 42 54 45 53 54 54 45 53 54 |....!..BTESTTEST| 00000010 54 45 53 54 |TEST| 00000014 Interprétation :\n00 01 est le type de message. 00 00 est la longueur de la section de données. 21 12 a4 42 est le cookie magique. et 54 45 53 54 54 45 53 54 54 45 53 54 (Se décode en ASCII : TESTTESTTEST) est l\u0026rsquo;ID de transaction de 12 octets. Envoyez la requête et attendez la réponse de 32 octets :\nstunserver=stun1.l.google.com;stunport=19302;listenport=20000;echo -ne \u0026#34;\\x00\\x01\\x00\\x00\\x21\\x12\\xA4\\x42TESTTESTTEST\u0026#34; | nc -u -p $listenport $stunserver $stunport -w 1 | hexdump -C 00000000 01 01 00 0c 21 12 a4 42 54 45 53 54 54 45 53 54 |....!..BTESTTEST| 00000010 54 45 53 54 00 20 00 08 00 01 6f 32 7f 36 de 89 |TEST. ....o2.6..| 00000020 Interprétation :\n01 01 est le type de message 00 0c est la longueur de la section de données qui se décode en 12 en décimal 21 12 a4 42 est le cookie magique et 54 45 53 54 54 45 53 54 54 45 53 54 (Se décode en ASCII : TESTTESTTEST) est l\u0026rsquo;ID de transaction de 12 octets. 00 20 00 08 00 01 6f 32 7f 36 de 89 sont les 12 octets de données, interprétation : 00 20 est le type : XOR-MAPPED-ADDRESS 00 08 est la longueur de la section de valeur qui se décode en 8 en décimal 00 01 6f 32 7f 36 de 89 est la valeur des données, interprétation : 00 01 est le type d\u0026rsquo;adresse (IPv4) 6f 32 est le port XOR mappé 7f 36 de 89 est l\u0026rsquo;adresse IP XOR mappée Décoder la section XOR mappée est fastidieux, mais nous pouvons tromper le serveur STUN pour qu\u0026rsquo;il effectue un mappage XOR fictif, en fournissant un cookie magique fictif (invalide) défini sur 00 00 00 00 :\nstunserver=stun1.l.google.com;stunport=19302;listenport=20000;echo -ne \u0026#34;\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00TESTTESTTEST\u0026#34; | nc -u -p $listenport $stunserver $stunport -w 1 | hexdump -C 00000000 01 01 00 0c 00 00 00 00 54 45 53 54 54 45 53 54 |........TESTTEST| 00000010 54 45 53 54 00 01 00 08 00 01 4e 20 5e 24 7a cb |TEST......N ^$z.| 00000020 Faire un XOR contre le cookie magique fictif est idempotent, donc le port et l\u0026rsquo;adresse seront clairs dans la réponse. Cela ne fonctionnera pas dans toutes les situations, car certains routeurs manipulent les paquets qui passent, en trichant sur l\u0026rsquo;adresse IP. Si nous regardons la valeur de données retournée (derniers huit octets) :\n00 01 4e 20 5e 24 7a cb est la valeur de données, interprétation : 00 01 est le type d\u0026rsquo;adresse (IPv4) 4e 20 est le port mappé, qui se décode en 20000 en décimal 5e 24 7a cb est l\u0026rsquo;adresse IP, qui se décode en 94.36.122.203 en notation décimale pointée. tcpdump # tcpdump est un analyseur de paquets réseau de données en ligne de commande.\nCommandes courantes :\nCapturer les paquets UDP vers et depuis le port 19302, imprimer un hexdump du contenu du paquet :\nsudo tcpdump 'udp port 19302' -xx\nIdem, mais sauvegarder les paquets dans un fichier PCAP (capture de paquets) pour inspection ultérieure :\nsudo tcpdump 'udp port 19302' -w stun.pcap\nLe fichier PCAP peut être ouvert avec l\u0026rsquo;application Wireshark : wireshark stun.pcap\nWireshark # Wireshark est un analyseur de protocoles réseau largement utilisé.\nOutils WebRTC du navigateur # Les navigateurs sont livrés avec des outils intégrés que vous pouvez utiliser pour inspecter les connexions que vous établissez. Chrome a chrome://webrtc-internals et chrome://webrtc-logs. Firefox a about:webrtc.\nLatence # Comment savez-vous que vous avez une latence élevée ? Vous avez peut-être remarqué que votre vidéo est en retard, mais savez-vous précisément de combien elle est en retard ? Pour pouvoir réduire cette latence, vous devez d\u0026rsquo;abord la mesurer.\nLa vraie latence est censée être mesurée de bout en bout. Cela signifie non seulement la latence du chemin réseau entre l\u0026rsquo;expéditeur et le récepteur, mais la latence combinée de la capture de caméra, de l\u0026rsquo;encodage des trames, de la transmission, de la réception, du décodage et de l\u0026rsquo;affichage, ainsi que des files d\u0026rsquo;attente possibles entre l\u0026rsquo;une de ces étapes.\nLa latence de bout en bout n\u0026rsquo;est pas une simple somme des latences de chaque composant.\nBien que vous puissiez théoriquement mesurer la latence des composants d\u0026rsquo;un pipeline de streaming vidéo en direct séparément puis les additionner, en pratique, au moins certains composants seront inaccessibles pour l\u0026rsquo;instrumentation, ou produiront des résultats significativement différents lorsqu\u0026rsquo;ils seront mesurés en dehors du pipeline. Les profondeurs de file d\u0026rsquo;attente variables entre les étapes du pipeline, la topologie réseau et les changements d\u0026rsquo;exposition de la caméra ne sont que quelques exemples de composants qui affectent la latence de bout en bout.\nLa latence intrinsèque de chaque composant dans votre système de streaming en direct peut changer et affecter les composants en aval. Même le contenu de la vidéo capturée affecte la latence. Par exemple, il faut beaucoup plus de bits pour les caractéristiques haute fréquence comme les branches d\u0026rsquo;arbres, par rapport à un ciel bleu clair de basse fréquence. Une caméra avec exposition automatique activée peut prendre beaucoup plus que les 33 millisecondes attendues pour capturer une trame, même si le taux de capture est réglé sur 30 trames par seconde. La transmission sur le réseau, en particulier cellulaire, est également très dynamique en raison de la demande changeante. Plus d\u0026rsquo;utilisateurs introduisent plus de bruit dans l\u0026rsquo;air. Votre emplacement physique (zones de signal faible notoires) et de multiples autres facteurs augmentent la perte de paquets et la latence. Que se passe-t-il lorsque vous envoyez un paquet à une interface réseau, disons un adaptateur WiFi ou un modem LTE pour livraison ? S\u0026rsquo;il ne peut pas être livré immédiatement, il est mis en file d\u0026rsquo;attente dans l\u0026rsquo;interface, plus la file d\u0026rsquo;attente est grande, plus de latence cette interface réseau introduit.\nMesure manuelle de la latence de bout en bout # Lorsque nous parlons de latence de bout en bout, nous entendons le temps entre le moment où un événement se produit et où il est observé, c\u0026rsquo;est-à-dire les trames vidéo apparaissant sur l\u0026rsquo;écran.\nLatenceDeBoutEnBout = T(observer) - T(se produire) Une approche naïve consiste à enregistrer l\u0026rsquo;heure lorsqu\u0026rsquo;un événement se produit et à la soustraire de l\u0026rsquo;heure à l\u0026rsquo;observation. Cependant, à mesure que la précision descend aux millisecondes, la synchronisation temporelle devient un problème. Essayer de synchroniser les horloges à travers des systèmes distribués est principalement futile, même une petite erreur dans la synchronisation temporelle produit une mesure de latence peu fiable.\nUne solution simple aux problèmes de synchronisation d\u0026rsquo;horloge est d\u0026rsquo;utiliser la même horloge. Mettez l\u0026rsquo;expéditeur et le récepteur dans le même cadre de référence.\nImaginez que vous avez une horloge en millisecondes qui fait tic-tac ou toute autre source d\u0026rsquo;événements réellement. Vous voulez mesurer la latence dans un système qui diffuse en direct l\u0026rsquo;horloge sur un écran distant en pointant une caméra vers elle. Une façon évidente de mesurer le temps entre le tic du minuteur en millisecondes (Tse produire) et les trames vidéo de l\u0026rsquo;horloge apparaissant sur l\u0026rsquo;écran (Tobserver) est la suivante :\nPointez votre caméra vers l\u0026rsquo;horloge en millisecondes. Envoyez les trames vidéo à un récepteur qui se trouve au même emplacement physique. Prenez une photo (utilisez votre téléphone) du minuteur en millisecondes et de la vidéo reçue sur l\u0026rsquo;écran. Soustrayez les deux temps. C\u0026rsquo;est la mesure de latence de bout en bout la plus vraie pour vous. Elle prend en compte toutes les latences des composants (caméra, encodeur, réseau, décodeur) et ne dépend d\u0026rsquo;aucune synchronisation d\u0026rsquo;horloge.\n. Dans la photo ci-dessus, la latence de bout en bout mesurée est de 101 msec. L\u0026rsquo;événement qui se produit maintenant est 10:16:02.862, mais l\u0026rsquo;observateur du système de streaming en direct voit 10:16:02.761.\nMesure automatique de la latence de bout en bout # Au moment de la rédaction (mai 2021), la norme WebRTC pour le délai de bout en bout est activement discutée. Firefox a implémenté un ensemble d\u0026rsquo;API pour permettre aux utilisateurs de créer des mesures de latence automatiques sur les API WebRTC standard.\nConseils de débogage de la latence # Étant donné que le débogage affectera probablement la latence mesurée, la règle générale est de simplifier votre configuration à la plus petite possible qui peut encore reproduire le problème. Plus vous pouvez éliminer de composants, plus il sera facile de déterminer quel composant cause le problème de latence.\nDébogage de la latence de la caméra # Pour tester uniquement la latence de la caméra, sautez complètement le streaming vidéo. Accédez simplement au flux de la caméra sur le navigateur à l\u0026rsquo;aide de getUserMedia et passez-le à l\u0026rsquo;élément \u0026lt;video\u0026gt;. Cela vous donnera les limites inférieures de la latence, puisque la latence de bout en bout inclut la latence de la caméra. Si vous avez un problème de latence de caméra, toutes les optimisations de pipeline de streaming vidéo seront inutiles.\nDébogage de la latence de l\u0026rsquo;encodeur # La latence de l\u0026rsquo;encodeur dépend de nombreux facteurs. Les fabricants d\u0026rsquo;encodeurs peuvent sacrifier un peu de latence pour obtenir un débit plus élevé dans la même bande passante. Ils peuvent également compter sur des techniques de codage qui utilisent des trames futures pour réduire la taille des trames actuelles. Habituellement, il y a un compromis entre latence et qualité. Les encodeurs logiciels et matériels exposent parfois des indicateurs pour contrôler ce compromis. L\u0026rsquo;encodeur d\u0026rsquo;un fabricant peut également être tout simplement meilleur qu\u0026rsquo;un autre. Réduire la résolution de la vidéo source ou diminuer la qualité de codage peut réduire la latence de l\u0026rsquo;encodeur.\nDébogage de la latence du réseau # Le débogage de la latence du réseau dans un pipeline de streaming vidéo est difficile. Le meilleur indicateur de la latence du réseau dans WebRTC est le temps aller-retour. WebRTC utilise RTCP Receiver Reports pour mesurer le temps aller-retour. La mesure du temps aller-retour est décrite dans le chapitre 6 Communication média.\nLe temps aller-retour mesure le temps qu\u0026rsquo;il faut à un paquet pour voyager de vous au pair et revenir. Les paquets envoyés d\u0026rsquo;un pair distant traversent la même route réseau sur le chemin du retour, donc le temps aller-retour devrait être un indicateur fiable de votre latence réseau approximative. Pourquoi approximative ? Parce que les conditions du réseau fluctuent et changent, mais cela vous donnera une idée approximative. Pour voir l\u0026rsquo;impact des conditions du réseau sur votre latence de bout en bout, exécutez votre pipeline de streaming vidéo localement sur une machine. Cela élimine tous les effets de la latence réseau et du tampon de gigue. Comparez votre latence de bout en bout à travers le réseau avec celle sur la machine locale. Ajoutez 1/2 du temps aller-retour, que vous avez obtenu à partir de la mesure RTCP Receiver Report, à la latence de bout en bout locale. Vous devriez obtenir quelque chose de similaire à la latence de bout en bout à travers le réseau réel.\nUne autre chose à considérer qui affecte la latence de bout en bout est le tampon de gigue. Il est utilisé par le décodeur pour lisser le flux vidéo entrant et lisser les tremblements du réseau. L\u0026rsquo;API WebRTC Stats expose les statistiques sur le tampon de gigue pour le flux entrant. Essayez de réduire la taille du tampon de gigue, si votre implémentation WebRTC l\u0026rsquo;expose, et observez comment cela affecte votre latence de bout en bout.\nDébogage de la latence du décodeur # La latence du décodeur dépend de nombreux facteurs. Le décodeur peut avoir besoin de trames futures pour construire la trame actuelle. Ou il peut être configuré pour supprimer des trames afin de rattraper le retard, ce qui peut introduire de la latence lorsque les conditions du réseau deviennent mauvaises. Essayez d\u0026rsquo;utiliser différents décodeurs et voyez comment ils affectent la latence de bout en bout.\n"},{"id":9,"href":"/fr/docs/10-history-of-webrtc/","title":"Histoire","section":"Docs","content":" Histoire # En apprenant WebRTC, les développeurs se sentent souvent frustrés par la complexité. Ils voient des fonctionnalités de WebRTC non pertinentes pour leur projet actuel et souhaitent que WebRTC soit plus simple. Le problème est que tout le monde a un ensemble différent de cas d\u0026rsquo;usage. La communication en temps réel a une histoire riche avec de nombreuses personnes différentes construisant de nombreuses choses différentes.\nCe chapitre contient des entretiens avec les auteurs des protocoles qui composent WebRTC. Il donne un aperçu des conceptions réalisées lors de la construction de chaque protocole, et se termine par un entretien sur WebRTC lui-même. Si vous comprenez les intentions et les conceptions du logiciel, vous pouvez construire des systèmes plus efficaces avec lui.\nRTP # RTP et RTCP sont les protocoles qui gèrent tout le transport des médias pour WebRTC. Il a été défini dans la RFC 1889 en janvier 1996. Nous avons beaucoup de chance que l\u0026rsquo;un des auteurs Ron Frederick parle de lui-même. Ron a récemment téléchargé Network Video tool sur GitHub, un projet qui a informé RTP.\nDans ses propres mots # En octobre 1992, j\u0026rsquo;ai commencé à expérimenter avec la carte de capture d\u0026rsquo;images Sun VideoPix avec l\u0026rsquo;idée d\u0026rsquo;écrire un outil de vidéoconférence réseau basé sur le multicast IP. Il était modélisé d\u0026rsquo;après \u0026ldquo;vat\u0026rdquo;, un outil d\u0026rsquo;audioconférence développé au LBL, en ce sens qu\u0026rsquo;il utilisait un protocole de session léger similaire pour que les utilisateurs rejoignent des conférences, où vous envoyiez simplement des données à un groupe multicast particulier et observiez ce groupe pour tout trafic d\u0026rsquo;autres membres du groupe.\nPour que le programme soit vraiment réussi, j\u0026rsquo;avais besoin de compresser les données vidéo avant de les mettre sur le réseau. Mon objectif était de faire un flux de données d\u0026rsquo;apparence acceptable qui tiendrait dans environ 128 kbps, ou la bande passante disponible sur une ligne ISDN domestique standard.\nDébut novembre 1992, j\u0026rsquo;ai lancé l\u0026rsquo;outil de vidéoconférence \u0026ldquo;nv\u0026rdquo; (sous forme binaire) à la communauté Internet. Après quelques tests initiaux, il a été utilisé pour diffuser en vidéo des parties du Groupe de travail d\u0026rsquo;ingénierie Internet de novembre dans le monde entier.\nLe protocole réseau utilisé pour \u0026ldquo;nv\u0026rdquo; et d\u0026rsquo;autres outils de conférence Internet est devenu la base du Real-time Transport Protocol (RTP), normalisé par l\u0026rsquo;Internet Engineering Task Force (IETF).\nWebRTC # WebRTC a nécessité un effort de normalisation qui éclipse tous les autres efforts décrits dans ce chapitre. Il a nécessité une coopération entre deux organismes de normalisation différents (IETF et W3C) et des centaines d\u0026rsquo;individus à travers de nombreuses entreprises et pays. Pour nous donner un aperçu des motivations et de l\u0026rsquo;effort monumental qu\u0026rsquo;il a fallu pour faire en sorte que WebRTC se produise, nous avons Serge Lachapelle.\nSerge est un chef de produit chez Google, servant actuellement de chef de produit pour Google Workspace. Voici mon résumé de l\u0026rsquo;entretien.\nQu\u0026rsquo;est-ce qui vous a amené à travailler sur WebRTC ? # J\u0026rsquo;ai été passionné par la construction de logiciels de communication depuis que j\u0026rsquo;étais à l\u0026rsquo;université. Dans les années 90, des technologies comme nv ont commencé à apparaître, mais elles étaient difficiles à utiliser. J\u0026rsquo;ai créé un projet qui vous permettait de rejoindre un appel vidéo directement depuis votre navigateur.\nJ\u0026rsquo;ai apporté cette expérience à Marratech, une entreprise que j\u0026rsquo;ai cofondée. Nous avons créé des logiciels pour la vidéoconférence de groupe. Marratech a été acquis par Google en 2007. Je passerais ensuite à travailler sur le projet qui informerait WebRTC.\nLe premier projet de Google # Le premier projet sur lequel la future équipe WebRTC a travaillé était la voix et le chat vidéo de Gmail. Obtenir de l\u0026rsquo;audio et de la vidéo dans le navigateur n\u0026rsquo;était pas une tâche facile.\nLa naissance de WebRTC # Pour moi, WebRTC est né avec quelques motivations. Combinées, elles ont donné naissance à l\u0026rsquo;effort.\nIl ne devrait pas être si difficile de construire des expériences RTC. Tant d\u0026rsquo;efforts sont gaspillés à réimplémenter la même chose par différents développeurs.\nLa communication humaine devrait être sans entraves et devrait être ouverte. Comment est-il acceptable que le texte et le HTML soient ouverts, mais que ma voix et mon image en temps réel ne le soient pas ?\nLa sécurité est une priorité. C\u0026rsquo;était aussi une opportunité de créer un protocole qui serait sécurisé par défaut.\nL\u0026rsquo;avenir # WebRTC est dans une excellente position aujourd\u0026rsquo;hui. Il y a beaucoup de changements itératifs en cours, mais rien de particulier sur lequel j\u0026rsquo;ai travaillé.\nJe suis plus enthousiaste à propos de ce que le cloud computing peut faire pour la communication. En utilisant des algorithmes avancés, nous pouvons éliminer le bruit de fond d\u0026rsquo;un appel et rendre la communication possible là où elle ne l\u0026rsquo;était pas auparavant.\n"},{"id":10,"href":"/fr/docs/11-faq/","title":"FAQ","section":"Docs","content":" FAQ # Pourquoi WebRTC utilise-t-il UDP ? La traversée NAT nécessite UDP. Sans traversée NAT, l\u0026rsquo;établissement d\u0026rsquo;une connexion P2P ne serait pas possible. UDP ne fournit pas de \u0026ldquo;livraison garantie\u0026rdquo; comme TCP, donc WebRTC la fournit au niveau utilisateur.\nVoir Connexion pour plus d\u0026rsquo;informations.\nCombien de DataChannels puis-je avoir ? 65534 canaux car l\u0026rsquo;identifiant de flux a 16 bits. Vous pouvez fermer et ouvrir un nouveau à tout moment. WebRTC impose-t-il des limites de bande passante ? Les DataChannels et RTP utilisent tous deux le contrôle de congestion. Cela signifie que WebRTC mesure activement votre bande passante et tente d\u0026rsquo;utiliser la quantité optimale. C\u0026rsquo;est un équilibre entre envoyer autant que possible, sans surcharger la connexion. Puis-je envoyer des données binaires ? Oui, vous pouvez envoyer à la fois des données texte et binaires via les DataChannels. Quelle latence puis-je attendre avec WebRTC ? Pour les médias non ajustés, vous pouvez vous attendre à moins de 500 millisecondes. Si vous êtes prêt à ajuster ou à sacrifier la qualité pour la latence, les développeurs ont obtenu une latence inférieure à 100 ms.\nLes DataChannels prennent en charge l\u0026rsquo;option \u0026ldquo;Partial-reliability\u0026rdquo; qui peut réduire la latence causée par les retransmissions de données sur une connexion avec perte. S\u0026rsquo;il est configuré correctement, il a été démontré qu\u0026rsquo;il bat les connexions TCP TLS.\nPourquoi voudrais-je une livraison non ordonnée pour les DataChannels ? Lorsque de nouvelles informations rendent les anciennes obsolètes, comme les informations de position d\u0026rsquo;un objet, ou lorsque chaque message est indépendant des autres et doit éviter le délai de blocage en tête de ligne. Puis-je envoyer de l\u0026rsquo;audio ou de la vidéo sur un DataChannel ? Oui, vous pouvez envoyer n\u0026rsquo;importe quelle donnée sur un DataChannel. Dans le cas du navigateur, il sera de votre responsabilité de décoder les données et de les transmettre à un lecteur multimédia pour le rendu, alors que tout cela est fait automatiquement si vous utilisez des canaux médias. "},{"id":11,"href":"/fr/docs/12-glossary/","title":"Glossaire","section":"Docs","content":" Glossaire # ACK: Acknowledgment (Accusé de réception) AVP: Audio and Video profile (Profil audio et vidéo) B-Frame: Bi-directional Predicted Frame (Image prédite bidirectionnelle). Une image partielle, est une modification des images précédentes et futures. DCEP: Data Channel Establishment Protocol (Protocole d\u0026rsquo;établissement de canal de données) défini dans la RFC 8832 DeMux: Demultiplexer (Démultiplexeur) DLSR: Delay since last sender report (Délai depuis le dernier rapport d\u0026rsquo;expéditeur) DTLS: Datagram Transport Layer Security (Sécurité de la couche de transport de datagramme) défini dans la RFC 6347 E2E: End-to-End (De bout en bout) FEC: Forward Error Correction (Correction d\u0026rsquo;erreur directe) FIR: Full INTRA-frame Request (Demande d\u0026rsquo;image INTRA complète) G.711: Un codec audio à bande étroite GCC: Google Congestion Control (Contrôle de congestion Google) défini dans le draft-ietf-rmcat-gcc-02 H.264: Codage vidéo avancé pour les services audiovisuels génériques H.265: Spécification de conformité pour le codage vidéo haute efficacité ITU-T H.265 HEVC: High Efficiency Video Coding (Codage vidéo haute efficacité) HTTP: Hypertext Transfer Protocol (Protocole de transfert hypertexte) HTTPS: HTTP Over TLS, défini dans la RFC 2818 I-Frame: Intra-coded Frame (Image intra-codée). Une image complète, peut être décodée sans rien d\u0026rsquo;autre. ICE: Interactive Connectivity Establishment (Établissement de connectivité interactive) défini dans la RFC 8445 INIT: Initiate (Initier) IoT: Internet of Things (Internet des objets) IPv4: Internet Protocol, Version 4 (Protocole Internet, version 4) IPv6: Internet Protocol, Version 6 (Protocole Internet, version 6) ITU-T: International Telecommunication Union Telecommunication Standardization Sector (Secteur de normalisation des télécommunications de l\u0026rsquo;Union internationale des télécommunications) JSEP: JavaScript Session Establishment Protocol (Protocole d\u0026rsquo;établissement de session JavaScript) défini dans la RFC 8829 MCU: Multi-point Conferencing Unit (Unité de conférence multipoint) mDNS: Multicast DNS défini dans la RFC 6762 MITM: Man-In-The-Middle (Homme au milieu) MTU: Maximum Transmission Unit (Unité de transmission maximale), la taille du paquet MUX: Multiplexing (Multiplexage) NACK: Negative Acknowledgment (Accusé de réception négatif) NADA: network-assisted dynamic adaptation (adaptation dynamique assistée par réseau) défini dans le draft-zhu-rmcat-nada-04 NAT: Network Address Translation (Traduction d\u0026rsquo;adresse réseau) défini dans la RFC 4787 Opus: Un codec audio totalement ouvert, libre de droits et très polyvalent P-Frame: Predicted Frame (Image prédite). Une image partielle, contenant uniquement les changements par rapport à l\u0026rsquo;image précédente. P2P: Peer-to-Peer (Pair-à-pair) PLI: Picture Loss Indication (Indication de perte d\u0026rsquo;image) PPID: Payload Protocol Identifier (Identifiant de protocole de charge utile) REMB: Receiver Estimated Maximum Bitrate (Débit binaire maximum estimé par le récepteur) RFC: Request for Comments (Demande de commentaires) RMCAT: RTP Media Congestion Avoidance Techniques (Techniques d\u0026rsquo;évitement de congestion média RTP) RR: Receiver Report (Rapport du récepteur) RTCP: RTP Control Protocol (Protocole de contrôle RTP) défini dans la RFC 3550 RTP: Real-time transport protocol (Protocole de transport en temps réel) défini dans la RFC 3550 RTT: Round-Trip Time (Temps aller-retour) SACK: Selective Acknowledgment (Accusé de réception sélectif) SCReAM: Self-Clocked Rate Adaptation for Multimedia (Adaptation de débit auto-synchronisée pour multimédia) défini dans le draft-johansson-rmcat-scream-cc-05 SCTP: Stream Control Transmission Protocol (Protocole de transmission de contrôle de flux) défini dans la RFC 4960 SDP: Session Description Protocol (Protocole de description de session) défini dans la RFC 8866 SFU: Selective Forwarding Unit (Unité de transfert sélectif) SR: Sender Report (Rapport de l\u0026rsquo;expéditeur) SRTP: Secure Real-time Transport Protocol (Protocole de transport en temps réel sécurisé) défini dans la RFC 3711 SSRC: Synchronization Source (Source de synchronisation) STUN: Session Traversal Utilities for NAT (Utilitaires de traversée de session pour NAT) défini dans la RFC 8489 TCP: Transmission Control Protocol (Protocole de contrôle de transmission) TLS: The Transport Layer Security (Sécurité de la couche de transport) défini dans la RFC 8446 TMMBN: Temporary Maximum Media Stream Bit Rate Notification (Notification de débit binaire de flux média maximum temporaire) TMMBR: Temporary Maximum Media Stream Bit Rate Request (Demande de débit binaire de flux média maximum temporaire) TSN: Transmission Sequence Number (Numéro de séquence de transmission) TURN: Traversal Using Relays around NAT (Traversée utilisant des relais autour de NAT) défini dans la RFC 8656 TWCC: Transport Wide Congestion Control (Contrôle de congestion large transport) UDP: User Datagram Protocol (Protocole de datagramme utilisateur) VP8, VP9: Technologies de compression vidéo hautement efficaces (\u0026ldquo;codecs\u0026rdquo; vidéo) développées par le WebM Project. Tout le monde peut utiliser ces codecs sans frais de licence. WebM: Un format de fichier multimédia ouvert conçu pour le web. WebRTC: Web Real-Time Communications (Communications en temps réel sur le web). W3C WebRTC 1.0: Real-Time Communication Between Browsers "},{"id":12,"href":"/fr/docs/13-reference/","title":"Référence","section":"Docs","content":" Référence # WebRTC(W3C) # WebRTC 1.0: Real-Time Communication Between Browsers [26 January 2021] (Status: Recommendation) Web Real-Time Communications Working Group - Publications WebRTC(RFC) # RFC8825: Overview: Real-Time Protocols for Browser-Based Applications H. Alvestrand [January 2021] (Status: PROPOSED STANDARD) RFC8826: Security Considerations for WebRTC E. Rescorla [January 2021] (Status: PROPOSED STANDARD) RFC8836: Congestion Control Requirements for Interactive Real-Time Media R. Jesup, Z. Sarker [January 2021] (Status: INFORMATIONAL) RFC8854: WebRTC Forward Error Correction Requirements J. Uberti [January 2021] (Status: PROPOSED STANDARD) DTLS # RFC6347: Datagram Transport Layer Security Version 1.2 E. Rescorla, N. Modadugu [January 2012] (Obsoletes RFC4347) (Obsoleted-By RFC9147) (Updated-By RFC7507, RFC7905, RFC8996, RFC9146) (Status: PROPOSED STANDARD) RFC9147: The Datagram Transport Layer Security (DTLS) Protocol Version 1.3 E. Rescorla, H. Tschofenig, N. Modadugu [April 2022] (Obsoletes RFC6347) (Status: PROPOSED STANDARD) (See also: OpenSSL DTLS 1.3 status) DataChannel # RFC8831: WebRTC Data Channels R. Jesup, S. Loreto, M. Tüxen [January 2021] (Status: PROPOSED STANDARD) RFC8832: WebRTC Data Channel Establishment Protocol R. Jesup, S. Loreto, M. Tüxen [January 2021] (Status: PROPOSED STANDARD) RFC8864: Negotiation Data Channels Using the Session Description Protocol (SDP) K. Drage, M. Makaraju, R. Ejzak, J. Marcon, R. Even [January 2021] (Status: PROPOSED STANDARD) MediaTransport # RFC8834: Media Transport and Use of RTP in WebRTC C. Perkins, M. Westerlund, J. Ott [January 2021] (Status: PROPOSED STANDARD) RFC8837: Differentiated Services Code Point (DSCP) Packet Markings for WebRTC QoS P. Jones, S. Dhesikan, C. Jennings, D. Druta [January 2021] (Status: PROPOSED STANDARD) SCTP # RFC3758: Stream Control Transmission Protocol (SCTP) Partial Reliability Extension R. Stewart, M. Ramalho, Q. Xie, M. Tuexen, P. Conrad [May 2004] (Status: PROPOSED STANDARD) RFC5061: Stream Control Transmission Protocol (SCTP) Dynamic Address Reconfiguration R. Stewart, Q. Xie, M. Tuexen, S. Maruyama, M. Kozuka [September 2007] (Status: PROPOSED STANDARD) RFC5827: Early Retransmit for TCP and Stream Control Transmission Protocol (SCTP) M. Allman, K. Avrachenkov, U. Ayesta, J. Blanton, P. Hurtig [May 2010] (Status: EXPERIMENTAL) RFC6083: Datagram Transport Layer Security (DTLS) for Stream Control Transmission Protocol (SCTP) M. Tuexen, R. Seggelmann, E. Rescorla [January 2011] (Updated-By RFC8996) (Status: PROPOSED STANDARD) RFC6525: Stream Control Transmission Protocol (SCTP) Stream Reconfiguration R. Stewart, M. Tuexen, P. Lei [February 2012] (Status: PROPOSED STANDARD) RFC6951: UDP Encapsulation of Stream Control Transmission Protocol (SCTP) Packets for End-Host to End-Host Communication M. Tuexen, R. Stewart [May 2013] (Updated-By RFC8899) (Status: PROPOSED STANDARD) RFC7765: TCP and Stream Control Transmission Protocol (SCTP) RTO Restart P. Hurtig, A. Brunstrom, A. Petlund, M. Welzl [February 2016] (Status: EXPERIMENTAL) RFC8260: Stream Schedulers and User Message Interleaving for the Stream Control Transmission Protocol R. Stewart, M. Tuexen, S. Loreto, R. Seggelmann [November 2017] (Status: PROPOSED STANDARD) RFC8261: Datagram Transport Layer Security (DTLS) Encapsulation of SCTP Packets M. Tuexen, R. Stewart, R. Jesup, S. Loreto [November 2017] (Updated-By RFC8899, RFC8996) (Status: PROPOSED STANDARD) RFC8841: Session Description Protocol (SDP) Offer/Answer Procedures for Stream Control Transmission Protocol (SCTP) over Datagram Transport Layer Security (DTLS) Transport C. Holmberg, R. Shpount, S. Loreto, G. Camarillo [January 2021] (Status: PROPOSED STANDARD) RFC8899: Packetization Layer Path MTU Discovery for Datagram Transports G. Fairhurst, T. Jones, M. Tüxen, I. Rüngeler, T. Völker [September 2020] (Updates RFC4821, RFC4960, RFC6951, RFC8085, RFC8261) (Status: PROPOSED STANDARD) RFC9260: Stream Control Transmission Protocol R. Stewart, M. Tüxen, K. Nielsen [June 2022] (Obsoletes RFC4460, RFC4960, RFC6096, RFC7053, RFC8540) (Status: PROPOSED STANDARD) SDP # RFC8829: JavaScript Session Establishment Protocol (JSEP) J. Uberti, C. Jennings, E. Rescorla [January 2021] (Status: PROPOSED STANDARD) RFC8830: WebRTC MediaStream Identification in the Session Description Protocol H. Alvestrand [January 2021] (Status: PROPOSED STANDARD) RFC8839: Session Description Protocol (SDP) Offer/Answer Procedures for Interactive Connectivity Establishment (ICE) M. Petit-Huguenin, S. Nandakumar, C. Holmberg, A. Keränen, R. Shpount [January 2021] (Obsoletes RFC5245, RFC6336) (Status: PROPOSED STANDARD) RFC8841: Session Description Protocol (SDP) Offer/Answer Procedures for Stream Control Transmission Protocol (SCTP) over Datagram Transport Layer Security (DTLS) Transport C. Holmberg, R. Shpount, S. Loreto, G. Camarillo [January 2021] (Status: PROPOSED STANDARD) RFC8843: Negotiating Media Multiplexing Using the Session Description Protocol (SDP) C. Holmberg, H. Alvestrand, C. Jennings [January 2021] (Obsoleted-By RFC9143) (Updates RFC3264, RFC5888, RFC7941) (Status: PROPOSED STANDARD) RFC8844: Unknown Key-Share Attacks on Uses of TLS with the Session Description Protocol (SDP) M. Thomson, E. Rescorla [January 2021] (Updates RFC8122) (Status: PROPOSED STANDARD) RFC8851: RTP Payload Format Restrictions A.B. Roach [January 2021] (Updates RFC4855) (Status: PROPOSED STANDARD) RFC8852: RTP Stream Identifier Source Description (SDES) A.B. Roach, S. Nandakumar, P. Thatcher [January 2021] (Status: PROPOSED STANDARD) RFC8853: Using Simulcast in Session Description Protocol (SDP) and RTP Sessions B. Burman, M. Westerlund, S. Nandakumar, M. Zanaty [January 2021] (Status: PROPOSED STANDARD) RFC8866: SDP: Session Description Protocol A. Begen, P. Kyzivat, C. Perkins, M. Handley [January 2021] (Obsoletes RFC4566) (Status: PROPOSED STANDARD) RTP # RFC3550: RTP: A Transport Protocol for Real-Time Applications H. Schulzrinne, S. Casner, R. Frederick, V. Jacobson [July 2003] (Obsoletes RFC1889) (Updated-By RFC5506, RFC5761, RFC6051, RFC6222, RFC7022, RFC7160, RFC7164, RFC8083, RFC8108, RFC8860) (Also STD0064) (Status: INTERNET STANDARD) RFC3611: RTP Control Protocol Extended Reports (RTCP XR) T. Friedman, R. Caceres, A. Clark [November 2003] (Status: PROPOSED STANDARD) RFC3711: The Secure Real-time Transport Protocol (SRTP) M. Baugher, D. McGrew, M. Naslund, E. Carrara, K. Norrman [March 2004] (Updated-By RFC5506, RFC6904) (Status: PROPOSED STANDARD) RFC4585: Extended RTP Profile for Real-time Transport Control Protocol (RTCP)-Based Feedback (RTP/AVPF) J. Ott, S. Wenger, N. Sato, C. Burmeister, J. Rey [July 2006] (Updated-By RFC5506, RFC8108) (Status: PROPOSED STANDARD) RFC5104: Codec Control Messages in the RTP Audio-Visual Profile with Feedback (AVPF) S. Wenger, U. Chandra, M. Westerlund, B. Burman [February 2008] (Updated-By RFC7728, RFC8082) (Status: PROPOSED STANDARD) RFC5764: Datagram Transport Layer Security (DTLS) Extension to Establish Keys for the Secure Real-time Transport Protocol (SRTP) D. McGrew, E. Rescorla [May 2010] (Updated-By RFC7983) (Status: PROPOSED STANDARD) RFC6904: Encryption of Header Extensions in the Secure Real-time Transport Protocol (SRTP) J. Lennox [April 2013] (Updates RFC3711) (Status: PROPOSED STANDARD) RFC7741: RTP Payload Format for VP8 Video P. Westin, H. Lundin, M. Glover, J. Uberti, F. Galligan [March 2016] (Status: PROPOSED STANDARD) RFC8285: A General Mechanism for RTP Header Extensions D. Singer, H. Desineni, R. Even [October 2017] (Obsoletes RFC5285) (Status: PROPOSED STANDARD) RFC8852: RTP Stream Identifier Source Description (SDES) A.B. Roach, S. Nandakumar, P. Thatcher [January 2021] (Status: PROPOSED STANDARD) RFC8858: Indicating Exclusive Support of RTP and RTP Control Protocol (RTCP) Multiplexing Using the Session Description Protocol (SDP) C. Holmberg [January 2021] (Updates RFC5761) (Status: PROPOSED STANDARD) RFC8860: Sending Multiple Types of Media in a Single RTP Session M. Westerlund, C. Perkins, J. Lennox [January 2021] (Updates RFC3550, RFC3551) (Status: PROPOSED STANDARD) RFC8867: Test Cases for Evaluating Congestion Control for Interactive Real-Time Media Z. Sarker, V. Singh, X. Zhu, M. Ramalho [January 2021] (Status: INFORMATIONAL) RFC8868: Evaluating Congestion Control for Interactive Real-Time Media V. Singh, J. Ott, S. Holmer [January 2021] (Status: INFORMATIONAL) RFC8869: Evaluation Test Cases for Interactive Real-Time Media over Wireless Networks Z. Sarker, X. Zhu, J. Fu [January 2021] (Status: INFORMATIONAL) RFC8872: Guidelines for Using the Multiplexing Features of RTP to Support Multiple Media Streams M. Westerlund, B. Burman, C. Perkins, H. Alvestrand, R. Even [January 2021] (Status: INFORMATIONAL) RFC8888: RTP Control Protocol (RTCP) Feedback for Congestion Control Z. Sarker, C. Perkins, V. Singh, M. Ramalho [January 2021] (Status: PROPOSED STANDARD) ICE, TURN et STUN # RFC5780: NAT Behavior Discovery Using Session Traversal Utilities for NAT (STUN) D. MacDonald, B. Lowekamp [May 2010] (Updated-By RFC8553) (Status: EXPERIMENTAL) RFC8445: Interactive Connectivity Establishment (ICE): A Protocol for Network Address Translator (NAT) Traversal A. Keranen, C. Holmberg, J. Rosenberg [July 2018] (Obsoletes RFC5245) (Updated-By RFC8863) (Status: PROPOSED STANDARD) RFC8489: Session Traversal Utilities for NAT (STUN) M. Petit-Huguenin, G. Salgueiro, J. Rosenberg, D. Wing, R. Mahy, P. Matthews [February 2020] (Obsoletes RFC5389) (Status: PROPOSED STANDARD) RFC8656: Traversal Using Relays around NAT (TURN): Relay Extensions to Session Traversal Utilities for NAT (STUN) T. Reddy, A. Johnston, P. Matthews, J. Rosenberg [February 2020] (Obsoletes RFC5766, RFC6156) (Status: PROPOSED STANDARD) RFC8835: Transports for WebRTC H. Alvestrand [January 2021] (Status: PROPOSED STANDARD) RFC8838: Trickle ICE: Incremental Provisioning of Candidates for the Interactive Connectivity Establishment (ICE) Protocol E. Ivov, J. Uberti, P. Saint-Andre [January 2021] (Updated-By RFC8863) (Status: PROPOSED STANDARD) RFC8839: Session Description Protocol (SDP) Offer/Answer Procedures for Interactive Connectivity Establishment (ICE) M. Petit-Huguenin, S. Nandakumar, C. Holmberg, A. Keränen, R. Shpount [January 2021] (Obsoletes RFC5245, RFC6336) (Status: PROPOSED STANDARD) RFC8863: Interactive Connectivity Establishment Patiently Awaiting Connectivity (ICE PAC) C. Holmberg, J. Uberti [January 2021] (Updates RFC8445, RFC8838) (Status: PROPOSED STANDARD) "}]