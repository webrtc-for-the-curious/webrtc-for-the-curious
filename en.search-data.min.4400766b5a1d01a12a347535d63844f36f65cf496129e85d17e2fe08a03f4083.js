'use strict';(function(){const indexCfg={cache:true};indexCfg.doc={id:'id',field:['title','content'],store:['title','href','section'],};const index=FlexSearch.create('balance',indexCfg);window.bookSearchIndex=index;index.add({'id':0,'href':'/docs/01-what-why-and-how/','title':"What, Why and How",'section':"Docs",'content':"What is WebRTC. #  WebRTC is both an API and Protocol. The WebRTC protocol is a set of rules for two agents to negotiate bi-directional secure communication. The WebRTC API was designed just for Javascript. This Javascript API then allows web developers to use the WebRTC protocol in the browser.\nA similar relationship would be HTTP and the fetch API. WebRTC the protocol would be HTTP, and WebRTC the API would be the fetch API.\nMany other APIs besides Javascript, servers and tools exist for WebRTC. All of these implementations can interact with each others.\nWhy should I learn WebRTC? #  These are the things that WebRTC will give you. This list is not exhaustive but is some of the things you may appreciate during your journey. Don\u0026rsquo;t worry if you don\u0026rsquo;t know some of these terms yet, this book will teach you them along tne way.\n Open Standard Multiple Implementations Available in Browsers Mandatory Encryption NAT Traversal Repurposed existing technology Congestion Control Sub-Second Latency  How does WebRTC (the protocol) Work #  This is a question that takes an entire book to explain. However, to start off we break it into four steps.\n Signaling Connecting Securing Communicating  These four steps happen sequentially. The prior step must be 100% successful for the subsequent one to even begin. At a high level this is what each one of these steps is accomplishing.\nOne peculiar fact about WebRTC is that it actually made up of many other protocols! To make WebRTC we stitch together many existing technologies. In that sense WebRTC is more a combination and configuration of well understood tech that has been around since the early 2000s.\nEach of these steps have dedicated chapters, but it is helpful to understand them at a high level first. Since they are dependant on each other it will help explain each steps purpose more.\nSignaling #  When a WebRTC Agent starts it has no idea who it is going to communicate with and what they are going to communicate about. Signaling solves this issue! Signaling is used to bootstrap the call so that the two WebRTC agents can start communicating directly.\nSignaling uses an existing protocol SDP. SDP is a plain text buffer made up off key/value pairs and contains a list of \u0026lsquo;media sections\u0026rsquo;. The SDP that the two WebRTC Agents exchange contains details like.\n IPs and Ports that the agent is reachable on (candidates) How many audio and video tracks the agent wishes to send What audio and video codecs the agent supports Values used while connecting (uFrag/uPwd) Values used while securing (certificate fingerprint)  Connecting #  The two WebRTC Agents now know enough details to attempt to connect to each other. WebRTC again uses an existing technology called ICE.\nICE (Interactive Connectivity Establishment) is a protocol that pre-dates WebRTC. ICE allows the establishment of a connection between two Agents. These Agents could be in the same network, or on the other side of the world. ICE is the solution to establishing a direct connection without a central server.\nThe real magic here is \u0026lsquo;NAT Traversal\u0026rsquo; and TURN Servers. These two concepts are all you need to communicate with an IP/Port in another subnet. This is where STUN and TURN come into play. We will explore these topics in depth later.\nOnce ICE successfully connects, WebRTC then moves on to establishing an encrypted transport. This transport is used for the audio, video and data.\nSecuring #  Now that we have bi-directional communication (via ICE) we need to establish secure communication. This is done through two protocols that pre-date WebRTC. The first protocol is DTLS (Datagram Transport Layer Security) which is just TLS over UDP. TLS is the technology that powers HTTPS. The second protocol is SRTP (Secure Real-time Transport Protocol).\nFirst WebRTC connects by doing a DTLS handshake over the connection established by ICE. Unlike HTTPS WebRTC doesn\u0026rsquo;t use a central authority for certificates. Instead WebRTC just asserts that the certificate exchanged via DTLS matches the the fingerprint shared via signaling. This DTLS connection is then used for DataChannel messages.\nWebRTC then uses a different protocol for audio/video transmission called RTP. We secure our RTP packets using SRTP. We initialize our SRTP session by extracting the keys from the negotiated DTLS session. In a later chapter we discuss why media transmission has its own protocol.\nWe are done! You now have bi-directional and secure communication. If you have a stable connection between your WebRTC Agents this is all the complexity you may need. Unfortunately the real world has packet loss and bandwidth limits, and the next section is about how we deal with them.\nCommunicating #  We now have two WebRTC Agents with secure bi-directional communication. Lets start communicating! Again we use two pre-existing protocol RTP (Real-time Transport Protocol) and SCTP (Stream Control Transmission Protocol).\nRTP is used to carry media, and is encrypted using SRTP. The RTP protocol is quite minimal, but gives us what we need to implement real-time streaming. The important thing is that RTP gives flexibility to the developer so they can handle latency, loss and congestion as they please. We will discuss this further in the media chapter!\nThe final protocol in the stack is SCTP. SCTP is used to send DataChannel messages and those messages are encrypted with DTLS. SCTP allows many different delivery options for messages. You can optionally choose to have unreliable, out of order delivery so you can get the latency needed for real-time systems.\nWebRTC, a collection of protocols #  TODO a diagram of protocols working together\nWebRTC solves a lot of problems. At first this may even seem over-engineered. The genius of WebRTC is really the humility. It didn\u0026rsquo;t assume it could solve everything better. Instead it embraced many existing single purpose technologies and bundled them together.\nThis allows us to examine and learn each part individually without being overwhelmed.\nHow does WebRTC (the API) work #  This section shows how the Javascript API maps to the protocol. This isn\u0026rsquo;t meant as an extensive demo of the WebRTC API, but more to create a mental model of how it all ties together. If you aren\u0026rsquo;t familiar with either that is ok. This is a fun section to return to as you learn more!\nnew PeerConnection #  The PeerConnection is the top level \u0026lsquo;WebRTC Session\u0026rsquo;. It contains all the protocols mentioned above. The subsystems are all allocated but nothing happens yet.\naddTrack #  addTrack creates a new RTP stream. A random SSRC will be generated for this stream. This stream will then be inside the Session Description generated by createOffer inside a media section. Each call to addTrack will create a new SSRC and media section.\nImmediately after a SRTP Session is established these media packets will start being sent via ICE after encrypted using SRTP.\ncreateDataChannel #  createDataChannel creates a new SCTP stream. If no SCTP assocation existed before one is created. By default SCTP is not enabled, but is only started when one side requests a data channel.\nImmediately after a DTLS Session is established the SCTP assocation will start sending packets via ICE and encrypted with DTLS.\ncreateOffer #  createOffer generates a Session Description of the local state to be shared with the remote peer.\nThe act of calling createOffer doesn\u0026rsquo;t change anything for the local peer.\nsetLocalDescription #  setLocalDescription commits any requsted changes. addTrack, createDataChannel and similar calls are all temporary until this call. setLocalDescription is called with the value generated by createOffer.\nUsually after this call you will send the offer to the remote peer, and they will call setRemoteDescription with it.\nsetRemoteDescription #  setRemoteDescription is how we inform the local agent about the remote candidates state. This is how the act of \u0026lsquo;Signaling\u0026rsquo; is done with the Javascript API.\nWhen setRemoteDescription has been called on both sides the WebRTC Agents now have enough info to start communicating P2P!\naddicecandidate #  addIceCandidate allows a WebRTC agent to add more remote ICE Candidates whenever they want. This API sends the ICE Candidate right into the ICE subsystem and has no other effect on the greater WebRTC connection.\nontrack #  ontrack is a callback that is fired when a RTP packet is received from the remote peer. The incoming packets would have been declared in the Session Description that was passed to setRemoteDescription\nWebRTC uses the SSRC and looks up the associated MediaStream and MediaStreamTrack and fires this callback with these details populated.\noniceconnectionstatechange #  oniceconnectionstatechange is a callback that is fired that reflects the state of the ICE Agent. When you have network connectivity or when you become disconnected this is how you are notified.\nonstatechange #  onstatechange is a combination of ICE and DTLS state. You can watch this to be notified when ICE and DTLS has completed successfully.\n"});index.add({'id':1,'href':'/docs/02-signaling/','title':"Signaling",'section':"Docs",'content':"Why do I need signaling? #  When you create a WebRTC agent it knows nothing about the other peer. It has no idea who it is going to connect with or what they are going to send! Signaling is the inital bootstrapping that makes the call possible. After these values are exhanged the WebRTC agents then can communicate directly with each other.\nSignaling messages are just text. The WebRTC agents don\u0026rsquo;t care how they are transported. They are commonly shared via Websockets, but not a requirement.\nHow does it work? #  WebRTC uses an existing protcol called the Session Description Protocol. Via this protocol the two WebRTC Agents will share all the state required to establish a connection. The protocol itself is simple to read and understand. The complexity comes from understanding all the values that WebRTC populates it with.\nThis protocol is not specific to WebRTC, so we can learn the Session Description Protocol first without even talking about WebRTC. WebRTC only really takes advantage of a subset of the protcol so we are only going to cover that. After we understand the protocol we will move on to its applied usage in WebRTC.\nSession Description Protocol #  The Session Description Protocol is defined in RFC 4566. It is a key/value protocol with a newline after each value. It will feel similar to an ini file.\nThe protocol is used to communicate a list of Media Descriptions. A Media Description usually maps to a single stream of media. So if you wanted to describe a call with three video streams and two audio tracks you would beed five Media Descriptions.\nWhat does Key/Value mean #  Every line in a Session Description will start with a single character, this is your key. It will then be followed by an equal sign. Everything after that equal sign is the value. After the value is complete you will have a newline.\nThe Session Description Protocol defines all the keys that are valid. You can only use letters for keys as defined bt the protocol. These keys all have significant meaning, which will be explained later.\nTake this example Session Description.\na=my-sdp-value a=second-value You have two lines. Each with the key a. The first line has the value my-sdp-value, the second line has the value second-value.\nWebRTC only uses some keys #  Not all key values defined by the Session Description Protocol are used by WebRTC. The following are the only keys you need to understand. Don\u0026rsquo;t worry about fully understanding yet, but this will be a handy reference in the future.\n v - Version, should be equal to \u0026lsquo;0\u0026rsquo; o - Origin, contains a unique ID useful for renegotiations s - Session Name, should be equal to \u0026lsquo;-\u0026rsquo; t - Timing, should be equal to \u0026lsquo;0 0\u0026rsquo; m - Meda Description, described in detail below a - Attribute, free text field this is the most common line in WebRTC c - Connection Data, should be equal to \u0026lsquo;IN IP4 0.0.0.0\u0026rsquo;  Media Descriptions #  The Media Description key is unlike any other. It is not just a value, but is the start if a block.\nFull Example #  v=0 o=- 0 0 IN IP4 127.0.0.1 s=- c=IN IP4 127.0.0.1 t=0 0 m=audio 4000 RTP/AVP 111 a=rtpmap:111 OPUS/48000/2 m=video 4002 RTP/AVP 96 a=rtpmap:96 VP8/90000 Session Description Protocol and WebRTC #  Offers and Answers #  Transceivers #  Renegotiation #  Values used by WebRTC #  Simulcast #  Examples #  v=0 o=- 3546004397921447048 1596742744 IN IP4 0.0.0.0 s=- t=0 0 a=fingerprint:sha-256 0F:74:31:25:CB:A2:13:EC:28:6F:6D:2C:61:FF:5D:C2:BC:B9:DB:3D:98:14:8D:1A:BB:EA:33:0C:A4:60:A8:8E a=group:BUNDLE 0 1 m=audio 9 UDP/TLS/RTP/SAVPF 111 c=IN IP4 0.0.0.0 a=setup:active a=mid:0 a=ice-ufrag:CsxzEWmoKpJyscFj a=ice-pwd:mktpbhgREmjEwUFSIJyPINPUhgDqJlSd a=rtcp-mux a=rtcp-rsize a=rtpmap:111 opus/48000/2 a=fmtp:111 minptime=10;useinbandfec=1 a=ssrc:350842737 cname:yvKPspsHcYcwGFTw a=ssrc:350842737 msid:yvKPspsHcYcwGFTw DfQnKjQQuwceLFdV a=ssrc:350842737 mslabel:yvKPspsHcYcwGFTw a=ssrc:350842737 label:DfQnKjQQuwceLFdV a=msid:yvKPspsHcYcwGFTw DfQnKjQQuwceLFdV a=sendrecv a=candidate:foundation 1 udp 2130706431 192.168.1.1 53165 typ host generation 0 a=candidate:foundation 2 udp 2130706431 192.168.1.1 53165 typ host generation 0 a=candidate:foundation 1 udp 1694498815 1.2.3.4 57336 typ srflx raddr 0.0.0.0 rport 57336 generation 0 a=candidate:foundation 2 udp 1694498815 1.2.3.4 57336 typ srflx raddr 0.0.0.0 rport 57336 generation 0 a=end-of-candidates m=video 9 UDP/TLS/RTP/SAVPF 96 c=IN IP4 0.0.0.0 a=setup:active a=mid:1 a=ice-ufrag:CsxzEWmoKpJyscFj a=ice-pwd:mktpbhgREmjEwUFSIJyPINPUhgDqJlSd a=rtcp-mux a=rtcp-rsize a=rtpmap:96 VP8/90000 a=ssrc:2180035812 cname:XHbOTNRFnLtesHwJ a=ssrc:2180035812 msid:XHbOTNRFnLtesHwJ JgtwEhBWNEiOnhuW a=ssrc:2180035812 mslabel:XHbOTNRFnLtesHwJ a=ssrc:2180035812 label:JgtwEhBWNEiOnhuW a=msid:XHbOTNRFnLtesHwJ JgtwEhBWNEiOnhuW a=sendrecv a=candidate:foundation 1 udp 2130706431 192.168.1.1 53165 typ host generation 0 a=candidate:foundation 2 udp 2130706431 192.168.1.1 53165 typ host generation 0 a=candidate:foundation 1 udp 1694498815 1.2.3.4 57336 typ srflx raddr 0.0.0.0 rport 57336 generation 0 a=candidate:foundation 2 udp 1694498815 1.2.3.4 57336 typ srflx raddr 0.0.0.0 rport 57336 generation 0 a=end-of-candidates "});index.add({'id':2,'href':'/docs/03-connecting/','title':"Connecting",'section':"Docs",'content':"Why a dedicated chapter for connecting? #  How does it work? #  Networking real world constraints #  Not in the same network #  Protocol Restrictions #  Firewall Rules #  Network Address Translation #  Port Mapping #  Filtering #  STUN () #  TURN () #  ICE () #  Candidate Gathering #  Connectivity Checks #  Candidate Selection #  "});index.add({'id':3,'href':'/docs/04-securing/','title':"Securing",'section':"Docs",'content':"Securing #  DTLS #  SRTP #  "});index.add({'id':4,'href':'/docs/05-media-communication/','title':"Media Communication",'section':"Docs",'content':"Audio and Video Communication #  RTP/RTCP #  Protocol Basics Loss and Error Resilience Congestion Control\n"});index.add({'id':5,'href':'/docs/06-data-communication/','title':"Data Communication",'section':"Docs",'content':"SCTP #  "});index.add({'id':7,'href':'/docs/08-debugging/','title':"Debugging",'section':"Docs",'content':"Debugging #  Reduce Surface Area #  Network Debugging #  Media Debugging #  Data Debugging #  "});index.add({'id':8,'href':'/docs/09-history-of-webrtc/','title':"History",'section':"Docs",'content':"History #  This section is ongoing and we donâ€™t have all the facts yet. We are conducting interviews and build a history of digital communication.\nPre-RTP #  RTP #  SDP #  ICE #  SRTP #  SCTP #  DTLS #  "});index.add({'id':9,'href':'/docs/10-faq/','title':"FAQ",'section':"Docs",'content':"FAQ #  "});})();