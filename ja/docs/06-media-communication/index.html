<!doctype html><html lang=ja dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="メディア・コミュニケーション # WebRTCのメディア通信では何ができるのですか？ # WebRTCでは、オーディオやビデオのストリームを無制限に送受信できます。これらのストリームは、通話中にいつでも追加・削除できます。これらのストリームはすべて独立していることもあれば、まとめて送信することもできます。例えば、自分のデスクトップのビデオフィードを送信し、ウェブカムからのオーディオ／ビデオを含めることができます。
WebRTCプロトコルは、コーデックに依存しません。基礎となるトランスポートは、まだ存在しないものも含めて、すべてをサポートしています。ただし、通信相手であるWebRTCエージェントが、それを受け入れるために必要なツールを持っていない場合もあります。
また、WebRTCは、動的なネットワーク状況に対応できるように設計されています。通話中に帯域が増えたり減ったりすることがあります。また、突然パケットロスが多発することもあります。WebRTCはこのような状況にも対応できるように設計されています。WebRTCはネットワークの状態に対応し、利用可能なリソースで最高の体験を提供しようとします。
どのような仕組みになっているのですか？ # WebRTCは、RFC 3550で定義されている2つの既存のプロトコルRTPとRTCPを使用しています。
RTP（Real-time Transport Protocol）は、メディアを伝送するプロトコルです。動画をリアルタイムに配信することを目的に設計されています。遅延や信頼性に関するルールは規定されていませんが、それらを実装するためのツールが提供されています。RTPはストリームを提供し、1つの接続で複数のメディアフィードを実行できます。また、メディアパイプラインに供給するために必要な、タイミングや順序の情報も提供します。
RTCP（RTP Control Protocol）は、コールに関するメタデータを通信するためのプロトコルです。このフォーマットは非常に柔軟で、必要なメタデータを追加できます。通話に関する統計情報を通信するために使用されます。また、パケットロスの処理や輻輳制御の実装にも使用されます。これにより、変化するネットワークの状況に対応するために必要な双方向の通信が可能になります。
レイテンシー vs クオリティ # リアルタイムメディアは、遅延と品質のトレードオフの関係にあります。遅延を許容すればするほど、高品質な映像が期待できます。
現実の制約 # これらの制約は、すべて現実世界の制約に起因するもので、お客様が克服しなければならないネットワークの特性です。
ビデオは複雑 # 動画の転送は簡単ではありません。30分の非圧縮720 8bitビデオを保存するには、約110Gb必要です。この数字では、4人での電話会議は不可能です。もっと小さくする方法が必要ですが、その答えは映像の圧縮です。しかし、これにはデメリットもあります。
ビデオ101 # ここでは、動画圧縮について詳しく説明しませんが、RTPがなぜこのように設計されているのかを理解するには十分です。動画圧縮とは、動画を新しいフォーマットにエンコードすることで、同じ動画をより少ないビット数で表現することです。
非可逆圧縮と可逆圧縮 # 動画のエンコードは、ロスレス（情報が失われない）とロッシー（情報が失われる可能性がある）の2種類があります。ロスレス圧縮の場合、相手に送るデータ量が多くなり、ストリームの遅延が大きくなったり、パケットの損失が多くなるため、RTPでは映像の品質が悪くなってもロッシー圧縮を行うのが一般的です。
イントラフレームとインターフレームの圧縮 # 動画の圧縮には2種類あります。1つ目はイントラフレームです。フレーム内圧縮では、1つのビデオフレームを記述するためのビットを削減します。静止画の圧縮にも同じ手法が使われており、JPEG圧縮法などがあります。
2つ目は、フレーム間圧縮です。動画は多くの画像で構成されているので、同じ情報を2度送らない方法を考えます。
フレーム間の種類 # フレームには3つの種類があります。
I-Frame - 完全な画像で、何もなくてもデコードできます。 P-Frame - 部分的な画像で、前の画像を修正したもの。 B-Frame - 部分的な画像で、以前の画像と未来の画像を組み合わせたもの。 3つのフレームタイプを視覚化すると以下のようになります。
動画はデリケート # 動画の圧縮は非常にステートフルであり、インターネットでの転送は困難です。I-Frameの一部が失われるとどうなるのか？P-Frameはどうやって修正すべき箇所を知るのでしょうか？映像圧縮がより複雑になるにつれ、この問題はさらに深刻になっています。幸いなことに、RTPとRTCPには解決策があります。
RTP # パケットフォーマット # すべてのRTPパケットは、以下のような構造になっています。
0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ |V=2|P|X| CC |M| PT | Sequence Number | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Timestamp | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Synchronization Source (SSRC) identifier | +=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+ | Contributing Source (CSRC) identifiers | | ."><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://webrtcforthecurious.com/ja/docs/06-media-communication/"><meta property="og:site_name" content="好奇心旺盛な人のためのWebRTC"><meta property="og:title" content="メディア・コミュニケーション"><meta property="og:description" content="メディア・コミュニケーション # WebRTCのメディア通信では何ができるのですか？ # WebRTCでは、オーディオやビデオのストリームを無制限に送受信できます。これらのストリームは、通話中にいつでも追加・削除できます。これらのストリームはすべて独立していることもあれば、まとめて送信することもできます。例えば、自分のデスクトップのビデオフィードを送信し、ウェブカムからのオーディオ／ビデオを含めることができます。
WebRTCプロトコルは、コーデックに依存しません。基礎となるトランスポートは、まだ存在しないものも含めて、すべてをサポートしています。ただし、通信相手であるWebRTCエージェントが、それを受け入れるために必要なツールを持っていない場合もあります。
また、WebRTCは、動的なネットワーク状況に対応できるように設計されています。通話中に帯域が増えたり減ったりすることがあります。また、突然パケットロスが多発することもあります。WebRTCはこのような状況にも対応できるように設計されています。WebRTCはネットワークの状態に対応し、利用可能なリソースで最高の体験を提供しようとします。
どのような仕組みになっているのですか？ # WebRTCは、RFC 3550で定義されている2つの既存のプロトコルRTPとRTCPを使用しています。
RTP（Real-time Transport Protocol）は、メディアを伝送するプロトコルです。動画をリアルタイムに配信することを目的に設計されています。遅延や信頼性に関するルールは規定されていませんが、それらを実装するためのツールが提供されています。RTPはストリームを提供し、1つの接続で複数のメディアフィードを実行できます。また、メディアパイプラインに供給するために必要な、タイミングや順序の情報も提供します。
RTCP（RTP Control Protocol）は、コールに関するメタデータを通信するためのプロトコルです。このフォーマットは非常に柔軟で、必要なメタデータを追加できます。通話に関する統計情報を通信するために使用されます。また、パケットロスの処理や輻輳制御の実装にも使用されます。これにより、変化するネットワークの状況に対応するために必要な双方向の通信が可能になります。
レイテンシー vs クオリティ # リアルタイムメディアは、遅延と品質のトレードオフの関係にあります。遅延を許容すればするほど、高品質な映像が期待できます。
現実の制約 # これらの制約は、すべて現実世界の制約に起因するもので、お客様が克服しなければならないネットワークの特性です。
ビデオは複雑 # 動画の転送は簡単ではありません。30分の非圧縮720 8bitビデオを保存するには、約110Gb必要です。この数字では、4人での電話会議は不可能です。もっと小さくする方法が必要ですが、その答えは映像の圧縮です。しかし、これにはデメリットもあります。
ビデオ101 # ここでは、動画圧縮について詳しく説明しませんが、RTPがなぜこのように設計されているのかを理解するには十分です。動画圧縮とは、動画を新しいフォーマットにエンコードすることで、同じ動画をより少ないビット数で表現することです。
非可逆圧縮と可逆圧縮 # 動画のエンコードは、ロスレス（情報が失われない）とロッシー（情報が失われる可能性がある）の2種類があります。ロスレス圧縮の場合、相手に送るデータ量が多くなり、ストリームの遅延が大きくなったり、パケットの損失が多くなるため、RTPでは映像の品質が悪くなってもロッシー圧縮を行うのが一般的です。
イントラフレームとインターフレームの圧縮 # 動画の圧縮には2種類あります。1つ目はイントラフレームです。フレーム内圧縮では、1つのビデオフレームを記述するためのビットを削減します。静止画の圧縮にも同じ手法が使われており、JPEG圧縮法などがあります。
2つ目は、フレーム間圧縮です。動画は多くの画像で構成されているので、同じ情報を2度送らない方法を考えます。
フレーム間の種類 # フレームには3つの種類があります。
I-Frame - 完全な画像で、何もなくてもデコードできます。 P-Frame - 部分的な画像で、前の画像を修正したもの。 B-Frame - 部分的な画像で、以前の画像と未来の画像を組み合わせたもの。 3つのフレームタイプを視覚化すると以下のようになります。
動画はデリケート # 動画の圧縮は非常にステートフルであり、インターネットでの転送は困難です。I-Frameの一部が失われるとどうなるのか？P-Frameはどうやって修正すべき箇所を知るのでしょうか？映像圧縮がより複雑になるにつれ、この問題はさらに深刻になっています。幸いなことに、RTPとRTCPには解決策があります。
RTP # パケットフォーマット # すべてのRTPパケットは、以下のような構造になっています。
0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ |V=2|P|X| CC |M| PT | Sequence Number | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Timestamp | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Synchronization Source (SSRC) identifier | +=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+ | Contributing Source (CSRC) identifiers | | ."><meta property="og:locale" content="ja"><meta property="og:type" content="article"><meta property="article:section" content="docs"><meta property="article:modified_time" content="2022-02-24T14:43:00+08:00"><title>メディア・コミュニケーション | 好奇心旺盛な人のためのWebRTC</title>
<link rel=manifest href=/manifest.json><link rel=icon href=/favicon.png><link rel=canonical href=https://webrtcforthecurious.com/ja/docs/06-media-communication/><link rel=alternate hreflang=en href=https://webrtcforthecurious.com/docs/06-media-communication/ title="Media Communication"><link rel=alternate hreflang=ru href=https://webrtcforthecurious.com/ru/docs/06-media-communication/ title="Media Communication"><link rel=alternate hreflang=sv href=https://webrtcforthecurious.com/sv/docs/06-media-communication/ title=Mediakommunikation><link rel=alternate hreflang=zh href=https://webrtcforthecurious.com/zh/docs/06-media-communication/ title=媒体通信><link rel=alternate hreflang=fa href=https://webrtcforthecurious.com/fa/docs/06-media-communication/ title="ارتباط رسانه ای"><link rel=alternate hreflang=fr href=https://webrtcforthecurious.com/fr/docs/06-media-communication/ title="Media Communication"><link rel=alternate hreflang=id href=https://webrtcforthecurious.com/id/docs/06-media-communication/ title="Media Communication"><link rel=alternate hreflang=es href=https://webrtcforthecurious.com/es/docs/06-media-communication/ title="Media Communication"><link rel=alternate hreflang=tr href=https://webrtcforthecurious.com/tr/docs/06-media-communication/ title="Medya İletişimi"><link rel=alternate hreflang=ko href=https://webrtcforthecurious.com/ko/docs/06-media-communication/ title="미디어 통신"><link rel=stylesheet href=/book.min.309b7ed028807cdb68d8d61e26d609f48369c098dbf5e4d8c0dcf4cdf49feafc.css integrity="sha256-MJt+0CiAfNto2NYeJtYJ9INpwJjb9eTYwNz0zfSf6vw=" crossorigin=anonymous><script defer src=/fuse.min.js></script><script defer src=/ja.search.min.b65272d5bf660afe8aa74038f8c9e7bbfcffaf9f174aa08435c489e245616282.js integrity="sha256-tlJy1b9mCv6Kp0A4+Mnnu/z/r58XSqCENcSJ4kVhYoI=" crossorigin=anonymous></script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/ja/><span>好奇心旺盛な人のためのWebRTC</span></a></h2><div class="book-search hidden"><input type=text id=book-search-input placeholder=検索 aria-label=検索 maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script><ul class=book-languages><li><input type=checkbox id=languages class=toggle>
<label for=languages class="flex justify-between"><a role=button class="flex align-center"><img src=/svg/translate.svg class=book-icon alt=Languages>
日本語</a></label><ul><li><a href=https://webrtcforthecurious.com/docs/06-media-communication/>English</a></li><li><a href=https://webrtcforthecurious.com/ru/docs/06-media-communication/>Русский</a></li><li><a href=https://webrtcforthecurious.com/sv/docs/06-media-communication/>Svenska</a></li><li><a href=https://webrtcforthecurious.com/zh/docs/06-media-communication/>简体中文</a></li><li><a href=https://webrtcforthecurious.com/fa/docs/06-media-communication/>Persian</a></li><li><a href=https://webrtcforthecurious.com/fr/docs/06-media-communication/>Français</a></li><li><a href=https://webrtcforthecurious.com/id/docs/06-media-communication/>Bahasa Indonesia</a></li><li><a href=https://webrtcforthecurious.com/es/docs/06-media-communication/>Español</a></li><li><a href=https://webrtcforthecurious.com/tr/docs/06-media-communication/>Türkçe</a></li><li><a href=https://webrtcforthecurious.com/ko/docs/06-media-communication/>한국어</a></li></ul></li></ul><ul><li><a href=/ja/docs/01-what-why-and-how/>何を、なぜ、どのように</a></li><li><a href=/ja/docs/02-signaling/>シグナリング</a></li><li><a href=/ja/docs/03-connecting/>接続</a></li><li><a href=/ja/docs/04-securing/>セキュリティ対策</a></li><li><a href=/ja/docs/05-real-time-networking/>リアルタイム・ネットワーキング</a></li><li><a href=/ja/docs/06-media-communication/ class=active>メディア・コミュニケーション</a></li><li><a href=/ja/docs/07-data-communication/>データ・コミュニケーション</a></li><li><a href=/ja/docs/08-applied-webrtc/>応用WebRTC</a></li><li><a href=/ja/docs/09-debugging/>デバッグ</a></li><li><a href=/ja/docs/10-history-of-webrtc/>歴史</a></li><li><a href=/ja/docs/11-faq/>FAQ</a></li><li><a href=/ja/docs/12-glossary/>用語集</a></li><li><a href=/ja/docs/13-reference/>参考文献</a></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu>
</label><strong>メディア・コミュニケーション</strong>
<label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#webrtcのメディア通信では何ができるのですか>WebRTCのメディア通信では何ができるのですか？</a></li><li><a href=#どのような仕組みになっているのですか>どのような仕組みになっているのですか？</a></li><li><a href=#レイテンシー-vs-クオリティ>レイテンシー vs クオリティ</a><ul><li><a href=#現実の制約>現実の制約</a></li><li><a href=#ビデオは複雑>ビデオは複雑</a></li></ul></li><li><a href=#ビデオ101>ビデオ101</a><ul><li><a href=#非可逆圧縮と可逆圧縮>非可逆圧縮と可逆圧縮</a></li><li><a href=#イントラフレームとインターフレームの圧縮>イントラフレームとインターフレームの圧縮</a></li><li><a href=#フレーム間の種類>フレーム間の種類</a></li><li><a href=#動画はデリケート>動画はデリケート</a></li></ul></li><li><a href=#rtp>RTP</a><ul><li><a href=#パケットフォーマット>パケットフォーマット</a></li><li><a href=#拡張機能>拡張機能</a></li></ul></li><li><a href=#rtcp>RTCP</a><ul><li><a href=#packet-format>Packet Format</a></li><li><a href=#full-intra-frame-request-firとpicture-loss-indication-pli>Full INTRA-frame Request (FIR)とPicture Loss Indication (PLI)</a></li><li><a href=#negative-acknowledgements>Negative ACKnowledgements</a></li><li><a href=#送信者受信者レポート>送信者/受信者レポート</a></li></ul></li><li><a href=#rtprtcpが共に問題を解決する方法>RTP/RTCPが共に問題を解決する方法</a><ul><li><a href=#negative-acknowledgment>Negative Acknowledgment</a></li><li><a href=#前方誤り訂正-forward-error-correction>前方誤り訂正 (Forward Error Correction)</a></li><li><a href=#適応型ビットレートと帯域幅の推定-adaptive-bitrate-and-bandwidth-estimation>適応型ビットレートと帯域幅の推定 (Adaptive Bitrate and Bandwidth Estimation)</a></li></ul></li><li><a href=#ネットワーク状況の把握と伝達>ネットワーク状況の把握と伝達</a><ul><li><a href=#receiver-reports--sender-reports>Receiver Reports / Sender Reports</a></li><li><a href=#tmmbrtmmbnrembtwccgccと対になる>TMMBR、TMMBN、REMB、TWCC、GCCと対になる</a></li></ul></li><li><a href=#帯域幅の推定の代替案>帯域幅の推定の代替案</a></li></ul></nav></aside></header><article class="markdown book-article"><h1 id=メディアコミュニケーション>メディア・コミュニケーション
<a class=anchor href=#%e3%83%a1%e3%83%87%e3%82%a3%e3%82%a2%e3%82%b3%e3%83%9f%e3%83%a5%e3%83%8b%e3%82%b1%e3%83%bc%e3%82%b7%e3%83%a7%e3%83%b3>#</a></h1><h2 id=webrtcのメディア通信では何ができるのですか>WebRTCのメディア通信では何ができるのですか？
<a class=anchor href=#webrtc%e3%81%ae%e3%83%a1%e3%83%87%e3%82%a3%e3%82%a2%e9%80%9a%e4%bf%a1%e3%81%a7%e3%81%af%e4%bd%95%e3%81%8c%e3%81%a7%e3%81%8d%e3%82%8b%e3%81%ae%e3%81%a7%e3%81%99%e3%81%8b>#</a></h2><p>WebRTCでは、オーディオやビデオのストリームを無制限に送受信できます。これらのストリームは、通話中にいつでも追加・削除できます。これらのストリームはすべて独立していることもあれば、まとめて送信することもできます。例えば、自分のデスクトップのビデオフィードを送信し、ウェブカムからのオーディオ／ビデオを含めることができます。</p><p>WebRTCプロトコルは、コーデックに依存しません。基礎となるトランスポートは、まだ存在しないものも含めて、すべてをサポートしています。ただし、通信相手であるWebRTCエージェントが、それを受け入れるために必要なツールを持っていない場合もあります。</p><p>また、WebRTCは、動的なネットワーク状況に対応できるように設計されています。通話中に帯域が増えたり減ったりすることがあります。また、突然パケットロスが多発することもあります。WebRTCはこのような状況にも対応できるように設計されています。WebRTCはネットワークの状態に対応し、利用可能なリソースで最高の体験を提供しようとします。</p><h2 id=どのような仕組みになっているのですか>どのような仕組みになっているのですか？
<a class=anchor href=#%e3%81%a9%e3%81%ae%e3%82%88%e3%81%86%e3%81%aa%e4%bb%95%e7%b5%84%e3%81%bf%e3%81%ab%e3%81%aa%e3%81%a3%e3%81%a6%e3%81%84%e3%82%8b%e3%81%ae%e3%81%a7%e3%81%99%e3%81%8b>#</a></h2><p>WebRTCは、<a href=https://tools.ietf.org/html/rfc3550#section-6.4>RFC 3550</a>で定義されている2つの既存のプロトコルRTPとRTCPを使用しています。</p><p>RTP（Real-time Transport Protocol）は、メディアを伝送するプロトコルです。動画をリアルタイムに配信することを目的に設計されています。遅延や信頼性に関するルールは規定されていませんが、それらを実装するためのツールが提供されています。RTPはストリームを提供し、1つの接続で複数のメディアフィードを実行できます。また、メディアパイプラインに供給するために必要な、タイミングや順序の情報も提供します。</p><p>RTCP（RTP Control Protocol）は、コールに関するメタデータを通信するためのプロトコルです。このフォーマットは非常に柔軟で、必要なメタデータを追加できます。通話に関する統計情報を通信するために使用されます。また、パケットロスの処理や輻輳制御の実装にも使用されます。これにより、変化するネットワークの状況に対応するために必要な双方向の通信が可能になります。</p><h2 id=レイテンシー-vs-クオリティ>レイテンシー vs クオリティ
<a class=anchor href=#%e3%83%ac%e3%82%a4%e3%83%86%e3%83%b3%e3%82%b7%e3%83%bc-vs-%e3%82%af%e3%82%aa%e3%83%aa%e3%83%86%e3%82%a3>#</a></h2><p>リアルタイムメディアは、遅延と品質のトレードオフの関係にあります。遅延を許容すればするほど、高品質な映像が期待できます。</p><h3 id=現実の制約>現実の制約
<a class=anchor href=#%e7%8f%be%e5%ae%9f%e3%81%ae%e5%88%b6%e7%b4%84>#</a></h3><p>これらの制約は、すべて現実世界の制約に起因するもので、お客様が克服しなければならないネットワークの特性です。</p><h3 id=ビデオは複雑>ビデオは複雑
<a class=anchor href=#%e3%83%93%e3%83%87%e3%82%aa%e3%81%af%e8%a4%87%e9%9b%91>#</a></h3><p>動画の転送は簡単ではありません。30分の非圧縮720 8bitビデオを保存するには、約110Gb必要です。この数字では、4人での電話会議は不可能です。もっと小さくする方法が必要ですが、その答えは映像の圧縮です。しかし、これにはデメリットもあります。</p><h2 id=ビデオ101>ビデオ101
<a class=anchor href=#%e3%83%93%e3%83%87%e3%82%aa101>#</a></h2><p>ここでは、動画圧縮について詳しく説明しませんが、RTPがなぜこのように設計されているのかを理解するには十分です。動画圧縮とは、動画を新しいフォーマットにエンコードすることで、同じ動画をより少ないビット数で表現することです。</p><h3 id=非可逆圧縮と可逆圧縮>非可逆圧縮と可逆圧縮
<a class=anchor href=#%e9%9d%9e%e5%8f%af%e9%80%86%e5%9c%a7%e7%b8%ae%e3%81%a8%e5%8f%af%e9%80%86%e5%9c%a7%e7%b8%ae>#</a></h3><p>動画のエンコードは、ロスレス（情報が失われない）とロッシー（情報が失われる可能性がある）の2種類があります。ロスレス圧縮の場合、相手に送るデータ量が多くなり、ストリームの遅延が大きくなったり、パケットの損失が多くなるため、RTPでは映像の品質が悪くなってもロッシー圧縮を行うのが一般的です。</p><h3 id=イントラフレームとインターフレームの圧縮>イントラフレームとインターフレームの圧縮
<a class=anchor href=#%e3%82%a4%e3%83%b3%e3%83%88%e3%83%a9%e3%83%95%e3%83%ac%e3%83%bc%e3%83%a0%e3%81%a8%e3%82%a4%e3%83%b3%e3%82%bf%e3%83%bc%e3%83%95%e3%83%ac%e3%83%bc%e3%83%a0%e3%81%ae%e5%9c%a7%e7%b8%ae>#</a></h3><p>動画の圧縮には2種類あります。1つ目はイントラフレームです。フレーム内圧縮では、1つのビデオフレームを記述するためのビットを削減します。静止画の圧縮にも同じ手法が使われており、JPEG圧縮法などがあります。</p><p>2つ目は、フレーム間圧縮です。動画は多くの画像で構成されているので、同じ情報を2度送らない方法を考えます。</p><h3 id=フレーム間の種類>フレーム間の種類
<a class=anchor href=#%e3%83%95%e3%83%ac%e3%83%bc%e3%83%a0%e9%96%93%e3%81%ae%e7%a8%ae%e9%a1%9e>#</a></h3><p>フレームには3つの種類があります。</p><ul><li><strong>I-Frame</strong> - 完全な画像で、何もなくてもデコードできます。</li><li><strong>P-Frame</strong> - 部分的な画像で、前の画像を修正したもの。</li><li><strong>B-Frame</strong> - 部分的な画像で、以前の画像と未来の画像を組み合わせたもの。</li></ul><p>3つのフレームタイプを視覚化すると以下のようになります。</p><p><img src=../../images/06-frame-types.png alt="Frame types" title="Frame types"></p><h3 id=動画はデリケート>動画はデリケート
<a class=anchor href=#%e5%8b%95%e7%94%bb%e3%81%af%e3%83%87%e3%83%aa%e3%82%b1%e3%83%bc%e3%83%88>#</a></h3><p>動画の圧縮は非常にステートフルであり、インターネットでの転送は困難です。I-Frameの一部が失われるとどうなるのか？P-Frameはどうやって修正すべき箇所を知るのでしょうか？映像圧縮がより複雑になるにつれ、この問題はさらに深刻になっています。幸いなことに、RTPとRTCPには解決策があります。</p><h2 id=rtp>RTP
<a class=anchor href=#rtp>#</a></h2><h3 id=パケットフォーマット>パケットフォーマット
<a class=anchor href=#%e3%83%91%e3%82%b1%e3%83%83%e3%83%88%e3%83%95%e3%82%a9%e3%83%bc%e3%83%9e%e3%83%83%e3%83%88>#</a></h3><p>すべてのRTPパケットは、以下のような構造になっています。</p><pre tabindex=0><code> 0                   1                   2                   3
 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|V=2|P|X|  CC   |M|     PT      |       Sequence Number         |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|                           Timestamp                           |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|           Synchronization Source (SSRC) identifier            |
+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+
|            Contributing Source (CSRC) identifiers             |
|                             ....                              |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|                            Payload                            |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
</code></pre><h4 id=バージョン-v>バージョン (V)
<a class=anchor href=#%e3%83%90%e3%83%bc%e3%82%b8%e3%83%a7%e3%83%b3-v>#</a></h4><p><code>バージョン</code> は常に <code>2</code> です。</p><h4 id=パディング-p>パディング (P)
<a class=anchor href=#%e3%83%91%e3%83%87%e3%82%a3%e3%83%b3%e3%82%b0-p>#</a></h4><p><code>パディング</code> はペイロードにパディングがあるかどうかを制御する bool です。</p><p>ペイロードの最後のバイトには、何バイトのパディングが追加されたかのカウントが入っています。</p><h4 id=拡張-x>拡張 (X)
<a class=anchor href=#%e6%8b%a1%e5%bc%b5-x>#</a></h4><p>セットされている場合、RTPヘッダーは拡張機能を持つことになります。これについては、以下で詳しく説明します。</p><h4 id=csrc-数-cc>CSRC 数 (CC)
<a class=anchor href=#csrc-%e6%95%b0-cc>#</a></h4><p><code>SSRC</code>の後、ペイロードの前に続く<code>CSRC</code>の識別子の数です。</p><h4 id=マーカー-m>マーカー (M)
<a class=anchor href=#%e3%83%9e%e3%83%bc%e3%82%ab%e3%83%bc-m>#</a></h4><p>マーカービットには事前に設定された意味はなく、ユーザーが好きなように使うことができます。</p><p>場合によっては、ユーザーが話しているときに設定されることもあります。また、キーフレームのマークとしてもよく使われます。</p><h4 id=ペイロードタイプ-pt>ペイロードタイプ (PT)
<a class=anchor href=#%e3%83%9a%e3%82%a4%e3%83%ad%e3%83%bc%e3%83%89%e3%82%bf%e3%82%a4%e3%83%97-pt>#</a></h4><p><code>ペイロードタイプ</code> は、このパケットで伝送されるコーデックを示す一意の識別子です。</p><p>WebRTCでは、<code>ペイロードタイプ</code>は動的なものです。ある通話での VP8 は、別の通話では異なる可能性があります。通話中の提供者は、<code>Session Description</code> の中で<code>ペイロードタイプ</code>とコーデックのマッピングを決定します。</p><h4 id=シーケンス番号>シーケンス番号
<a class=anchor href=#%e3%82%b7%e3%83%bc%e3%82%b1%e3%83%b3%e3%82%b9%e7%95%aa%e5%8f%b7>#</a></h4><p><code>シーケンス番号</code>は、ストリームのパケットの順序付けに使用されます。パケットが送信されるたびに、<code>シーケンス番号</code>は1ずつ増加します。</p><p>RTPは、損失の多いネットワーク上で役立つように設計されています。これにより、受信者はパケットが失われたことを検出できます。</p><h4 id=タイムスタンプ>タイムスタンプ
<a class=anchor href=#%e3%82%bf%e3%82%a4%e3%83%a0%e3%82%b9%e3%82%bf%e3%83%b3%e3%83%97>#</a></h4><p>このパケットのサンプリング秒数です。これはグローバルクロックではなく、メディアストリームの中でどれだけ時間が経過したかを示します。複数のRTPパケットが同じタイムスタンプを持つこともあります(例: すべてのパケットが同じビデオフレームに含まれる場合)。</p><h4 id=同期ソース-ssrc>同期ソース (SSRC)
<a class=anchor href=#%e5%90%8c%e6%9c%9f%e3%82%bd%e3%83%bc%e3%82%b9-ssrc>#</a></h4><p><code>SSRC</code>は、このストリームの一意の識別子です。これにより、複数のメディアストリームを1つのストリーム上で実行できます。</p><h4 id=コントリビューションソースcsrc>コントリビューションソース(CSRC)
<a class=anchor href=#%e3%82%b3%e3%83%b3%e3%83%88%e3%83%aa%e3%83%93%e3%83%a5%e3%83%bc%e3%82%b7%e3%83%a7%e3%83%b3%e3%82%bd%e3%83%bc%e3%82%b9csrc>#</a></h4><p>どの <code>SSRC</code> がこのパケットに貢献したかを伝えるリストです。</p><p>これは一般的にトーキングインジケーターに使用されます。例えば、サーバー側で複数のオーディオフィードを1つのRTPストリームにまとめたとします。このフィールドを使用して、「入力ストリームAとCがこの瞬間に話していた」と言うことができます。</p><h4 id=ペイロード>ペイロード
<a class=anchor href=#%e3%83%9a%e3%82%a4%e3%83%ad%e3%83%bc%e3%83%89>#</a></h4><p>実際のペイロードデータです。パディングフラグが設定されている場合は、何バイトのパディングが追加されたかが最後に表示されます。</p><h3 id=拡張機能>拡張機能
<a class=anchor href=#%e6%8b%a1%e5%bc%b5%e6%a9%9f%e8%83%bd>#</a></h3><h2 id=rtcp>RTCP
<a class=anchor href=#rtcp>#</a></h2><h3 id=packet-format>Packet Format
<a class=anchor href=#packet-format>#</a></h3><p>RTCPのパケットは、以下のような構造になっています。</p><pre tabindex=0><code> 0                   1                   2                   3
 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|V=2|P|    RC   |       PT      |             length            |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|                            Payload                            |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
</code></pre><h4 id=バージョン-v-1>バージョン (V)
<a class=anchor href=#%e3%83%90%e3%83%bc%e3%82%b8%e3%83%a7%e3%83%b3-v-1>#</a></h4><p><code>バージョン</code> は常に <code>2</code> です。</p><h4 id=パディング-p-1>パディング (P)
<a class=anchor href=#%e3%83%91%e3%83%87%e3%82%a3%e3%83%b3%e3%82%b0-p-1>#</a></h4><p><code>パディング</code> は bool で、ペイロードにパディングがあるかどうかを制御します。</p><p>ペイロードの最後のバイトには、何バイトのパディングが追加されたかのカウントが含まれています。</p><h4 id=受信レポート数-rc>受信レポート数 (RC)
<a class=anchor href=#%e5%8f%97%e4%bf%a1%e3%83%ac%e3%83%9d%e3%83%bc%e3%83%88%e6%95%b0-rc>#</a></h4><p>このパケットに含まれるレポートの数です。1つのRTCPパケットに複数のイベントを含めることができます。</p><h4 id=パケットタイプ-pt>パケットタイプ (PT)
<a class=anchor href=#%e3%83%91%e3%82%b1%e3%83%83%e3%83%88%e3%82%bf%e3%82%a4%e3%83%97-pt>#</a></h4><p>この RTCP パケットがどのタイプであるかを示す一意の識別子です。WebRTCエージェントは、これらのタイプをすべてサポートする必要はなく、エージェントによってサポートが異なる場合があります。しかし、一般的に目にするのはこれらのタイプです。</p><ul><li>Full INTRA-frame Request (FIR) - <code>192</code></li><li>Negative ACKnowledgements (NACK) - <code>193</code></li><li>Sender Report - <code>200</code></li><li>Receiver Report - <code>201</code></li><li>Generic RTP Feedback - <code>205</code></li><li>Payload Specific Feedback - <code>206</code></li></ul><p>これらのパケットタイプの意義については、以下で詳しく説明します。</p><h3 id=full-intra-frame-request-firとpicture-loss-indication-pli>Full INTRA-frame Request (FIR)とPicture Loss Indication (PLI)
<a class=anchor href=#full-intra-frame-request-fir%e3%81%a8picture-loss-indication-pli>#</a></h3><p>FIRとPLIの目的は似ています。これらのメッセージは、送信者にフルキーフレームを要求します。
PLIは、デコーダにパーシャルフレームが到着し、デコードできない場合に使用します。
これは、パケットロスが多い場合や、デコーダがクラッシュした場合などに起こります。</p><p><a href=https://tools.ietf.org/html/rfc5104#section-4.3.1.2>RFC5104</a>によると、パケットやフレームが失われたときには <code>FIR</code> を使用してはならないとされており、それは <code>PLI</code> の仕事です。<code>FIR</code> はパケットロス以外の理由でキーフレームを要求します。例えば、ビデオ会議に新しいメンバーが入ってきたときなどです。FIRはビデオストリームのデコードを開始するために完全なキーフレームを必要とし、デコーダはキーフレームが到着するまでフレームを破棄します。</p><p>これにより、接続してからユーザーの画面に画像が表示されるまでの遅延を最小限に抑えることができます。</p><p><code>PLI</code> パケットは、Payload Specific Feedback メッセージの一部です。</p><p>実際には、<code>PLI</code> パケットと <code>FIR</code> パケットの両方を扱うことができるソフトウェアは、どちらの場合も同じように動作します。
エンコーダーに信号を送り、新しいフルキーフレームを生成します。</p><h3 id=negative-acknowledgements>Negative ACKnowledgements
<a class=anchor href=#negative-acknowledgements>#</a></h3><p>NACKは、送信者に1つのRTPパケットの再送を要求するものです。これは通常、RTP パケットが失われたときに発生しますが、遅延した場合にも発生します。</p><p>NACKは、フレーム全体の再送信を要求するよりも、はるかに帯域幅を効率的に利用できます。RTPはパケットを非常に小さなチャンクに分割するので、実際には1つの小さな欠落部分を要求しているに過ぎません。</p><h3 id=送信者受信者レポート>送信者/受信者レポート
<a class=anchor href=#%e9%80%81%e4%bf%a1%e8%80%85%e5%8f%97%e4%bf%a1%e8%80%85%e3%83%ac%e3%83%9d%e3%83%bc%e3%83%88>#</a></h3><p>これらのレポートは、エージェント間で統計情報を送信するために使用します。このレポートでは、実際に受信したパケット量やジッターを伝えます。</p><p>このレポートは、診断や輻輳制御に利用できます。</p><h2 id=rtprtcpが共に問題を解決する方法>RTP/RTCPが共に問題を解決する方法
<a class=anchor href=#rtprtcp%e3%81%8c%e5%85%b1%e3%81%ab%e5%95%8f%e9%a1%8c%e3%82%92%e8%a7%a3%e6%b1%ba%e3%81%99%e3%82%8b%e6%96%b9%e6%b3%95>#</a></h2><p>このように、RTPとRTCPが連携することで、ネットワークに起因するあらゆる問題を解決できます。これらの技術は今でも常に変化しています。</p><h3 id=negative-acknowledgment>Negative Acknowledgment
<a class=anchor href=#negative-acknowledgment>#</a></h3><p>NACKとも呼ばれます。これは、RTPのパケットロスに対処する方法のひとつです。</p><p>NACKは、再送信を要求するために送信者に送り返されるRTCPメッセージです。受信者は、SSRCとシーケンス番号を含むRTCPメッセージを作ります。送信者は、再送信可能なこのRTPパケットを持っていない場合、そのメッセージを無視します。</p><h3 id=前方誤り訂正-forward-error-correction>前方誤り訂正 (Forward Error Correction)
<a class=anchor href=#%e5%89%8d%e6%96%b9%e8%aa%a4%e3%82%8a%e8%a8%82%e6%ad%a3-forward-error-correction>#</a></h3><p>FECとも呼ばれます。パケットロスに対処するもう一つの方法です。FEC は、同じデータを要求されてもいないのに複数回送信することです。これは、RTP レベルで行われ、さらに下位のコーデックでも行われます。</p><p>通話中のパケットロスが安定している場合、FECはNACKよりもはるかに低遅延のソリューションです。NACKの場合は、パケットを要求してから再送信するまでの往復時間が大きくなります。</p><h3 id=適応型ビットレートと帯域幅の推定-adaptive-bitrate-and-bandwidth-estimation>適応型ビットレートと帯域幅の推定 (Adaptive Bitrate and Bandwidth Estimation)
<a class=anchor href=#%e9%81%a9%e5%bf%9c%e5%9e%8b%e3%83%93%e3%83%83%e3%83%88%e3%83%ac%e3%83%bc%e3%83%88%e3%81%a8%e5%b8%af%e5%9f%9f%e5%b9%85%e3%81%ae%e6%8e%a8%e5%ae%9a-adaptive-bitrate-and-bandwidth-estimation>#</a></h3><p><a href=../05-real-time-networking/>リアルタイムネットワーキング</a>で説明したように、ネットワークは予測不可能で信頼性がありません。帯域幅の利用可能性は、セッション中に何度も変化する可能性があります。
利用可能な帯域幅が1秒以内に劇的に（桁違いに）変化することも珍しくありません。</p><p>主なアイデアは、予測される、現在および将来の利用可能なネットワーク帯域幅に基づいて、エンコーディングのビットレートを調整することです。
これにより、可能な限り最高の品質の映像・音声信号を伝送し、ネットワークの輻輳によって接続が切断されることがないようにします。
ネットワークの挙動をモデル化し、それを予測するヒューリスティックな手法を「帯域推定」といいます。</p><p>これには様々なニュアンスがありますので、詳しくご紹介しましょう。</p><h2 id=ネットワーク状況の把握と伝達>ネットワーク状況の把握と伝達
<a class=anchor href=#%e3%83%8d%e3%83%83%e3%83%88%e3%83%af%e3%83%bc%e3%82%af%e7%8a%b6%e6%b3%81%e3%81%ae%e6%8a%8a%e6%8f%a1%e3%81%a8%e4%bc%9d%e9%81%94>#</a></h2><p>RTP/RTCPはあらゆる種類の異なるネットワーク上で動作するため、送信者から受信者への通信が途中で途切れることはよくあることです。UDPの上に構築されているため、輻輳制御の処理はもちろん、パケット再送のためのビルトインメカニズムは存在しません。</p><p>ユーザーに最高の体験を提供するために、WebRTC はネットワーク経路の品質を推定し、その品質が時間と共にどのように変化するかに適応する必要があります。監視すべき重要な特性には、利用可能な帯域幅（対称でない場合があるため各方向）、往復時間、ジッター（往復時間の変動）などがあります。また、パケットロスを考慮し、ネットワーク状況の変化に応じてこれらの特性の変化を伝える必要があります。</p><p>これらのプロトコルの主な目的は2つあります。</p><ol><li>ネットワークがサポートする利用可能な帯域幅（各方向）を推定する。</li><li>送り手と受け手の間でネットワークの特性を伝達する</li></ol><p>RTP/RTCPは、この問題に対処するために3つの異なるアプローチを持っています。どれも長所と短所があり、一般に、各世代は前の世代よりも改善されています。どの実装を使用するかは、主にクライアントが使用できるソフトウェアスタックと、アプリケーションを構築するために使用できるライブラリに依存します。</p><h3 id=receiver-reports--sender-reports>Receiver Reports / Sender Reports
<a class=anchor href=#receiver-reports--sender-reports>#</a></h3><p>最初の実装は、Receiver Reportsとその補集合である Sender Reportsのペアです。これらのRTCPメッセージは<a href=https://tools.ietf.org/html/rfc3550#section-6.4>RFC 3550</a>で定義されており、エンドポイント間のネットワークステータスを通信する役割を担っています。受信者レポートは、ネットワークの品質(パケットロス、往復時間、ジッターなど)の通信に重点を置いており、これらのレポートに基づいて利用可能な帯域幅を推定する責任を負う他のアルゴリズムと対になっています。</p><p>送信者レポートと受信者レポート（SRとRR）を合わせて、ネットワーク品質の全体像を描きます。これらは各SSRCのスケジュールに従って送信され、利用可能な帯域幅を推定する際に使用される入力となります。これらの推定は、以下のフィールドを含むRRデータを受信した後に送信者によって行われます。</p><ul><li><strong>Fraction Lost</strong> &ndash; 前回のReceiver Report以降、何パーセントのパケットが失われたか。</li><li><strong>Cumulative Number of Packets Lost</strong> &ndash; 通話全体で失われたパケット数。</li><li><strong>Extended Highest Sequence Number Received</strong> &ndash; 最後に受信したシーケンス番号と、それが何回ロールオーバーしたかを示しています。</li><li><strong>Interarrival Jitter</strong> &ndash; 通話全体のローリングジッターです。</li><li><strong>Last Sender Report Timestamp</strong> &ndash; ラウンドトリップタイムの計算に使用される、送信者の最後の既知の時間。</li></ul><p>SRとRRは連動して往復時間を計算します。</p><p>送信者は、SRに自分のローカルタイム <code>sendertime1</code> を含めます。受信者はSRパケットを受信すると、RRを送り返します。このとき、RRには送信者から受け取ったばかりの <code>sendertime1</code> が含まれます。 SRを受信してからRRを送信するまでの間に遅延が発生します。そのため、RRは「最後の送信者レポートからの遅延」時間 - <code>DLSR</code> も含まれています。 <code>DLSR</code> は後の処理でラウンドトリップタイムの見積もりを調整するために使用されます。送信者はRRを受け取ると、現在の時刻 <code>sendertime2</code> から <code>sendertime1</code> と <code>DLSR</code> を差し引きます。この時間差をラウンドトリッププロパゲーションディレイまたはラウンドトリップタイムと呼びます。</p><p><code>rtt = sendertime2 - sendertime1 - DLSR</code></p><p>往復の時間をわかりやすく解説:</p><ul><li>私があなたにメッセージを送るとき、私の時計の現在の表示は「午後4時20分、42秒と420ミリ秒」です。</li><li>あなたはこの同じタイムスタンプを私に送り返します。</li><li>あなたはまた、私のメッセージを読んでからメッセージを送り返すまでの経過時間、例えば5ミリ秒を入れます。</li><li>このタイムスタンプを受け取った私は、再び時計を見ます。</li><li>今、私の時計は午後4時20分、42秒690ミリ秒と表示されています。</li><li>つまり、あなたに届いてから私に戻ってくるまでに265ミリ秒（690 - 420 - 5）かかったことになります。</li><li>したがって、往復の時間は265ミリ秒です。</li></ul><p><img src=../../images/06-rtt.png alt=RTT title=RTT></p><h3 id=tmmbrtmmbnrembtwccgccと対になる>TMMBR、TMMBN、REMB、TWCC、GCCと対になる
<a class=anchor href=#tmmbrtmmbnrembtwccgcc%e3%81%a8%e5%af%be%e3%81%ab%e3%81%aa%e3%82%8b>#</a></h3><h4 id=google輻輳制御gcc>Google輻輳制御（GCC)
<a class=anchor href=#google%e8%bc%bb%e8%bc%b3%e5%88%b6%e5%be%a1gcc>#</a></h4><p>Google Congestion Control (GCC) アルゴリズム (概要は <a href=https://tools.ietf.org/html/draft-ietf-rmcat-gcc-02>draft-ietf-rmcat-gcc-02</a>) は、帯域幅の推定という難題に対処しています。GCCは、他のさまざまなプロトコルと組み合わせて、関連する通信要件を容易にします。その結果、受信側(TMMBR/TMMBNまたはREMBで実行する場合)または送信側 (TWCCで実行する場合)のどちらかで実行するのに適しています。</p><p>利用可能な帯域幅の推定値を得るために、GCC は、パケット損失とフレーム到着時間の変動という 2 つの主要なメトリックスに着目しています。これらのメトリックは、ロスベース・コントローラと遅延ベース・コントローラという 2 つのリンクされたコントローラを介して実行されます。</p><p>GCCの最初のコンポーネントであるロス・ベース・コントローラはシンプルなものです．</p><ul><li>パケットロスが 10%を超えると，推定帯域幅が縮小されます。</li><li>パケットロスが2～10％の場合、推定帯域は変わりません。</li><li>パケットロスが2%以下の場合、推定帯域を増加させます。</li></ul><p>パケットロスの測定は頻繁に行われています。ペアとなる通信プロトコルによって、パケットロスは明示的に伝達される場合（TWCCなど）と推定される場合（TMMBR/TMBNやREMBなど）があります。これらの割合は、約1秒の間隔で評価されます。</p><p>2 番目の機能は、損失ベースのコントローラと協力し、パケット到着時間の変動を見ます。この遅延ベースのコントローラーは、ネットワークリンクの混雑が深刻化するタイミングを特定することを目的としており、パケットロスが発生する前であっても帯域幅の見積もりを減らすことがあります。理論的には、パスに沿って最も忙しいネットワークインターフェイスは、そのバッファ内の容量を使い果たすまでパケットをキューに入れ続けることになります。そのインターフェイスが送信可能なトラフィックよりも多くのトラフィックを受信し続ける場合、そのバッファスペースに収まりきらないすべてのパケットをドロップすることを余儀なくされるでしょう。このようなパケットロスは、特に低遅延／リアルタイム通信において破壊的ですが、そのリンク上のすべての通信のスループットを低下させることもあり、理想的には避けるべきものです。したがって、GCC は、パケットロスが実際に発生する <em>前</em> に、ネットワークリンクがより大きく、より大きなキューの深さを増しているかどうかを把握しようとします。もし、時間の経過とともにキューの遅延が増加するのを観測したら、それは帯域幅の使用を減らすでしょう。</p><p>これを達成するために、GCC はラウンドトリップタイムの微妙な増加を測定することによって、 キューの深さの増加を推測しようとします。これは、フレームの「到着間時間」，<code>t(i) - t(i-1)</code> を記録するもので、パケットの 2 つのグループ（一般に，連続したビデオフレーム）の到着時間の差です．これらのパケット群は一定の時間間隔（例えば24fpsの映像の場合1/24秒間隔）で頻繁に創出します。その結果、到着間時間の測定は、最初のパケットグループ（すなわちフレーム）の開始と次のフレームの最初のフレームとの間の時間差を記録するのと同じくらい簡単です。</p><p>下図では、パケット間遅延の増加の中央値は+20ミリ秒であり、ネットワーク輻輳の明確な指標となっています。</p><p><img src=../images/06-twcc.png alt="TWCC with delay" title="TWCC with delay"></p><p>到着間時間が時間とともに長くなる場合は、接続するネットワーク・インターフェイスのキューの深さが増している証拠と推定され、ネットワークの輻輳とみなされる。(注：GCCはフレームバイトサイズの変動に対して、これらの測定値を制御するのに十分な賢さを持っています)。GCCは輻輳にフラグを立てる前に、<a href=https://en.wikipedia.org/wiki/Kalman_filter>カルマンフィルター</a>を使ってそのレイテンシー測定を改良し、ネットワークのラウンドトリップタイム（とその変動）の多くの測定を行います。GCCのカルマンフィルタを線形回帰の代わりと考えることができます：ジッターがタイミング測定にノイズを加えても正確な予測をするのに役立ちます。輻輳のフラグが立てられると、GCC は利用可能なビットレートを下げます。また、ネットワークが安定している場合は、帯域幅の推定値を徐々に増やして、より高い負荷の値をテストすることもできます。</p><h4 id=tmmbrtmmbnおよび-remb>TMMBR、TMMBN、および REMB
<a class=anchor href=#tmmbrtmmbn%e3%81%8a%e3%82%88%e3%81%b3-remb>#</a></h4><p>TMMBR/TMMBNおよびREMBの場合、受信側はまず利用可能な受信帯域幅を推定し (GCCなどのプロトコルを使用)、次にその推定帯域幅をリモート送信側に伝達します。受信側で動作することにより、到着間時間やパケットロスを直接測定できるため、パケットロスやネットワークの混雑に関する他の品質に関する詳細を交換する必要はありません。その代わり、TMMBR、TMMBN、およびREMBは、帯域幅の推定値のみを交換します。</p><ul><li><strong>一時的な最大メディアストリームビットレート要求(Temporary Maximum Media Stream Bit Rate Request)</strong> - 1つのSSRCに対する要求ビットレートの仮数/指数。</li><li><strong>一時的な最大メディアストリームビットレート通知(Temporary Maximum Media Stream Bit Rate Notification)</strong> - TMMBRを受信したことを通知するためのメッセージ。</li><li><strong>受信機推定最大ビットレート(Receiver Estimated Maximum Bitrate)</strong> - セッション全体の要求ビットレートの仮数/指数。</li></ul><p>TMMBRとTMMBNが最初に登場し、<a href=https://tools.ietf.org/html/rfc5104>RFC 5104</a>で定義されています。REMBは後に登場し、<a href=https://tools.ietf.org/html/draft-alvestrand-rmcat-remb-03>draft-alvestrand-rmcat-remb</a>でドラフトが提出されましたが、標準化されるには至りませんでした。</p><p>REMBを使用するセッションの例は、以下のように動作します。</p><p><img src=../../images/06-remb.png alt=REMB title=REMB></p><p>この方法は、理論的にはとてもうまくいきます。送信側は受信側から推定値を受け取り、エンコーダのビットレートを受け取った値に設定します。なんということでしょう！これでネットワークの状況に合わせた調整ができました。</p><p>しかし実際には、REMB 方式には複数の欠点があります。</p><p>エンコーダの非効率性が第一です。エンコーダーにビットレートを設定しても、必ずしも要求された通りのビットレートで出力されるとは限りません。エンコーダーの設定やエンコードされるフレームによって、出力されるビットが多くなったり少なくなったりすることがあります。</p><p>たとえば、tune=zerolatency で x264 エンコーダーを使用すると、指定したターゲットビットレートから大きく外れることがあります。以下に考えられるシナリオを示します。</p><ul><li>まず、ビットレートを 1000kbps に設定したとします。</li><li>エンコーダーは 700kbps しか出力しない。（別名 - 壁を見つめる）。</li><li>また、受信機がパケットロスゼロで 700kbps の映像を受信した場合、REMB ルール 1 を適用して受信ビットレートを8％増加させたとします。</li><li>受信機は 756kbps の提案(700kbps * 1.08)をした REMB パケットを送信機に送ります。</li><li>送信者は、エンコーダのビットレートを 756kbps に設定します。</li><li>エンコーダーはさらに低いビットレートを出力します。</li><li>これを繰り返して、ビットレートを極限まで下げていきます。</li></ul><p>これでは、エンコーダのパラメータ調整が大変になってしまい、素晴らしい接続環境であっても、ユーザーが見られない映像になってしまうことがわかります。</p><h4 id=トランスポートワイド輻輳制御-transport-wide-congestion-control>トランスポートワイド輻輳制御 (Transport Wide Congestion Control)
<a class=anchor href=#%e3%83%88%e3%83%a9%e3%83%b3%e3%82%b9%e3%83%9d%e3%83%bc%e3%83%88%e3%83%af%e3%82%a4%e3%83%89%e8%bc%bb%e8%bc%b3%e5%88%b6%e5%be%a1-transport-wide-congestion-control>#</a></h4><p>トランスポートワイド輻輳制御は、RTCPのネットワーク状態通信における最新の開発です。<a href=https://datatracker.ietf.org/doc/html/draft-holmer-rmcat-transport-wide-cc-extensions-01>draft-holmer-rmcat-transport-wide-cc-extensions-01</a>で定義されていますが、標準化されたことはありません。</p><p>TWCCは非常にシンプルな原理を使用しています。</p><p><img src=../../images/06-twcc-idea.png alt=TWCC title=TWCC></p><p>REMBでは、受信側が送信側にダウンロード可能なビットレートを指示します。また、パケットロスやパケット間到着時間などのデータを事前に測定しておく必要があります。</p><p>TWCCは、SR/RRとREMB世代のプロトコルの間のハイブリッドアプローチに近いものです。帯域幅の推定を送信側に戻しますが (SR/RRと同様)、その帯域幅推定技法はREMB世代により近いものであるためです。</p><p>TWCCでは、受信機から送信機に対して、各パケットの到着時刻が通知されます。これは送信側にとって、パケット間の到着遅延の変動を測定し、どのパケットがドロップされたか、あるいは到着が遅すぎてオーディオ／ビデオフィードに貢献しなかったかを特定するのに十分な情報です。このデータが頻繁に交換されることで、送信者はネットワークの状況の変化に迅速に対応し、GCCなどのアルゴリズムを使用して出力帯域幅を変化させることができます。</p><p>送信者は、送信されたパケット、そのシーケンス番号、サイズ、およびタイムスタンプを追跡します。 送信側は受信側からRTCPメッセージを受信すると、送信パケット間遅延と受信遅延を比較します。 受信遅延が大きくなると、ネットワークの輻輳を意味し、送信者は是正措置を講じなければなりません。</p><p>TWCCは、送信者に生データを提供することで、リアルタイムのネットワーク状況を把握することができます。</p><ul><li>パケットロスの挙動をほぼ瞬時に把握し、個々のパケットロスまで把握可能</li><li>正確な送信ビットレート</li><li>正確な受信ビットレート</li><li>ジッター測定</li><li>送信パケット遅延と受信パケット遅延の違い</li><li>ネットワークがバースト的または安定的な帯域幅の配信をどのように許容しているかの説明</li></ul><p>TWCCの最も大きな貢献の一つは、WebRTCの開発者に柔軟性を与えることです。輻輳制御アルゴリズムを送信側に集約することで、広く使用できるシンプルなクライアントコードを実現し、時間の経過とともに必要な拡張を最小限に抑えることができます。複雑な輻輳制御アルゴリズムは、その後、それらが直接制御するハードウェア（セクション 8 で説明する選択的転送ユニットなど）上でより迅速に反復することができます。ブラウザとモバイルデバイスの場合、これは、これらのクライアントが標準化またはブラウザの更新（広く利用できるようになるまでかなり長い時間がかかる）を待つことなく、アルゴリズムの強化の恩恵を受けられることを意味します。</p><h2 id=帯域幅の推定の代替案>帯域幅の推定の代替案
<a class=anchor href=#%e5%b8%af%e5%9f%9f%e5%b9%85%e3%81%ae%e6%8e%a8%e5%ae%9a%e3%81%ae%e4%bb%a3%e6%9b%bf%e6%a1%88>#</a></h2><p>最も多く導入されているのは、<a href=https://tools.ietf.org/html/draft-alvestrand-rmcat-congestion-02>draft-alvestrand-rmcat-congestion</a>で定義されている「A Google Congestion Control Algorithm for Real-Time Communication」です。</p><p>GCC に代わるものとして、<a href=https://tools.ietf.org/html/draft-zhu-rmcat-nada-04>NADA: A Unified Congestion Control Scheme for Real-Time Media</a> や <a href=https://tools.ietf.org/html/draft-johansson-rmcat-scream-cc-05>SCReAM - Self-Clocked Rate Adaptation for Multimedia</a> などの実装があります。</p></article><footer class=book-footer><div class="flex flex-wrap justify-between"><div><a class="flex align-center" href=https://github.com/webrtc-for-the-curious/webrtc-for-the-curious/commit/4251664c92082620156c14b31266ff8a3f209a79 title='最終更新者 Pang | 2月 24, 2022' target=_blank rel=noopener><img src=/svg/calendar.svg class=book-icon alt>
<span>2月 24, 2022</span></a></div><div><a class="flex align-center" href=https://github.com/webrtc-for-the-curious/webrtc-for-the-curious/edit/master/content/docs/06-media-communication.md target=_blank rel=noopener><img src=/svg/edit.svg class=book-icon alt>
<span>このページを編集する</span></a></div></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#webrtcのメディア通信では何ができるのですか>WebRTCのメディア通信では何ができるのですか？</a></li><li><a href=#どのような仕組みになっているのですか>どのような仕組みになっているのですか？</a></li><li><a href=#レイテンシー-vs-クオリティ>レイテンシー vs クオリティ</a><ul><li><a href=#現実の制約>現実の制約</a></li><li><a href=#ビデオは複雑>ビデオは複雑</a></li></ul></li><li><a href=#ビデオ101>ビデオ101</a><ul><li><a href=#非可逆圧縮と可逆圧縮>非可逆圧縮と可逆圧縮</a></li><li><a href=#イントラフレームとインターフレームの圧縮>イントラフレームとインターフレームの圧縮</a></li><li><a href=#フレーム間の種類>フレーム間の種類</a></li><li><a href=#動画はデリケート>動画はデリケート</a></li></ul></li><li><a href=#rtp>RTP</a><ul><li><a href=#パケットフォーマット>パケットフォーマット</a></li><li><a href=#拡張機能>拡張機能</a></li></ul></li><li><a href=#rtcp>RTCP</a><ul><li><a href=#packet-format>Packet Format</a></li><li><a href=#full-intra-frame-request-firとpicture-loss-indication-pli>Full INTRA-frame Request (FIR)とPicture Loss Indication (PLI)</a></li><li><a href=#negative-acknowledgements>Negative ACKnowledgements</a></li><li><a href=#送信者受信者レポート>送信者/受信者レポート</a></li></ul></li><li><a href=#rtprtcpが共に問題を解決する方法>RTP/RTCPが共に問題を解決する方法</a><ul><li><a href=#negative-acknowledgment>Negative Acknowledgment</a></li><li><a href=#前方誤り訂正-forward-error-correction>前方誤り訂正 (Forward Error Correction)</a></li><li><a href=#適応型ビットレートと帯域幅の推定-adaptive-bitrate-and-bandwidth-estimation>適応型ビットレートと帯域幅の推定 (Adaptive Bitrate and Bandwidth Estimation)</a></li></ul></li><li><a href=#ネットワーク状況の把握と伝達>ネットワーク状況の把握と伝達</a><ul><li><a href=#receiver-reports--sender-reports>Receiver Reports / Sender Reports</a></li><li><a href=#tmmbrtmmbnrembtwccgccと対になる>TMMBR、TMMBN、REMB、TWCC、GCCと対になる</a></li></ul></li><li><a href=#帯域幅の推定の代替案>帯域幅の推定の代替案</a></li></ul></nav></div></aside></main></body></html>