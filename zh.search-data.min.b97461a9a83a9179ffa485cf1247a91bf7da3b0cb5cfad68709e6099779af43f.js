'use strict';(function(){const indexCfg={encode:false,tokenize:function(str){return str.replace(/[\x00-\x7F]/g,'').split('');}};indexCfg.doc={id:'id',field:['title','content'],store:['title','href','section'],};const index=FlexSearch.create('balance',indexCfg);window.bookSearchIndex=index;index.add({'id':0,'href':'/zh/docs/01-what-why-and-how/','title':"是什么，为什么，如何使用",'section':"Docs",'content':"是什么，为什么，如何使用 #  WebRTC 是什么？ #  WebRTC 是 Web 实时通信（Real-Time Communication）的缩写，它既是 API 也是协议。WebRTC 协议是两个 WebRTC Agent 协商双向安全实时通信的一组规则。开发人员可以通过 WebRTC API 使用 WebRTC 协议。目前 WebRTC API 仅有 JavaScript 版本。\n可以用 HTTP 和 Fetch API 之间的关系作为类比。WebRTC 协议就是 HTTP，而 WebRTC API 就是 Fetch API。\n除了 JavaScript 语言，WebRTC 协议也可以在其他 API 和语言中使用。你还可以找到 WebRTC 的服务器和特定领域的工具。所有这些实现都使用 WebRTC 协议，以便它们可以彼此交互。\nWebRTC 协议由 IETF 工作组在rtcweb中维护。WebRTC API 的 W3C 文档在webrtc。\n为什么我应该学习 WebRTC？ #  下面这些是 WebRTC 可以带给你的东西。这并不是一份详尽的清单，只是列举一些你在学习中可能感兴趣的点。如果你还不了解所有这些术语，请不要担心，本书将陆续将这些概念教给你。\n 开放标准 多种实现 在浏览器中可用 强制加密 NAT 穿透 复用现有技术 拥塞控制 亚秒级延迟  WebRTC 协议是一组其他技术的集合体 #  这个主题需要整本书来解释。但是，首先，我们将其分为四个步骤。\n 信令（Signaling） 连接（Connecting） 安全加密（Securing） 通信（Communicating）  这四个步骤依次发生。上一个步骤必须 100％成功，随后的步骤才能开始。\n关于 WebRTC 的一个特殊事实是，每个步骤实际上都是由许多其他协议组成的！为了让 WebRTC 工作起来，我们将许多现有技术结合在一起。从这个意义上讲，WebRTC 更像是 2000 年代早期以来就已经存在的一些易于理解的技术的组合和配置。\n每个步骤都有专门的章节，但是首先从较高的层次上理解它们会有所帮助。由于它们彼此依赖，因此理解这些在进一步解释每个步骤的目的时会有所帮助。\n信令：peer 如何在 WebRTC 中找到彼此 #  当 WebRTC Agent 启动时，它不知道与谁通信以及他们将要通信的内容。信令解决了这个问题！信令用于引导呼叫，以便两个 WebRTC Agent 可以开始通信。\n信令使用一种现有的协议 SDP（会话描述协议）。SDP 是一种纯文本协议。每个 SDP 消息均由键 / 值对组成，并包含“media sections（媒体部分）”列表。两个 WebRTC Agent 交换的 SDP 所包含一些详细信息，如：\n Agent 可供外部访问的（候选的）IP 和端口。 Agent 希望发送多少路音频和视频流。 Agent 支持哪些音频和视频编解码器。 连接时需要用到的值（uFrag/uPwd）。 加密传输时需要用到的值（证书指纹）。  注意，信令通常发生在“out-of-band”。也就是说，应用通常不使用 WebRTC 本身来交换信令消息。在连接的 peer 中，任何适合发送消息的架构均可被用于传递 SDP 信息，许多应用程序都使用其现有的基础设施（例如 REST 端点，WebSocket 连接或身份验证代理）来解决适当客户端之间的 SDP 传递问题。\n使用 STUN/TURN 进行连接和 NAT 穿透 #  现在，两个 WebRTC Agent 知道足够的详细信息以尝试相互连接。接下来，WebRTC 将使用另一种成熟的技术，称为 ICE。\nICE（交互式连接建立）是 WebRTC 前现有的协议。ICE 允许在两个 Agent 之间建立连接。这些 Agent 可以在同一网络上，也可以在世界的另一端。ICE 是无需中央服务器即可建立直接连接的解决方案。\n这里真正的魔法是“ NAT 穿透”和 STUN/TURN 服务器。这两个概念是与另一个子网中的 ICE Agent 进行通信所需的全部。稍后我们将深入探讨这些主题。\nICE 成功连接后，WebRTC 就会继续建立加密传输。加密传输用于音频，视频和数据。\n使用 DTLS 和 SRTP 加密传输层 #  现在我们有了双向通信（基于 ICE），我们需要建立安全的通信。这是基于 WebRTC 前已有的两种协议完成的。第一个协议是 DTLS（数据报传输层安全性），即基于 UDP 的 TLS。TLS 是一个加密协议，用于保护基于 HTTPS 的安全通信。第二种协议是 SRTP（安全实时传输协议）。\n首先，WebRTC 通过在 ICE 建立的连接上进行 DTLS 握手来进行连接。与 HTTPS 不同，WebRTC 不使用中央授权来颁发证书。相反，WebRTC 只是判断通过 DTLS 交换的证书是否与通过信令共享的签名相符。然后，此 DTLS 连接可以被用于传输 DataChannel 消息。\n接下来，WebRTC 使用 RTP 协议进行音频 / 视频的传输。我们使用 SRTP 来保护我们的 RTP 数据包。我们从协商的 DTLS 会话中提取密钥，用来初始化 SRTP 会话。在后续章节中，我们会讨论为什么媒体传输需要有它自己的协议。\n现在我们完成了！你现在可以进行安全的双向通信。如果你的 WebRTC Agent 之间具有稳定的连接，以上这些就是你可能需要解决的所有复杂问题了。不幸的是，现实世界中存在数据包丢失和带宽限制等问题，下一节我们会介绍如何处理这些问题。\n通过 RTP 和 SCTP 进行点对点通信 #  现在，我们有了两个具有安全的双向通信功能的 WebRTC Agent。让我们开始通信！跟前面一样，我们使用两个现有的协议：RTP（实时传输协议）和 SCTP（流控制传输协议）。我们使用 RTP 来交换用 SRTP 加密过的媒体数据，使用 SCTP 发送和接收那些用 DTLS 加密过的 DataChannel 消息。\nRTP 很轻量，但是提供了实现实时流式传输所需的功能。最重要的是，RTP 为开发人员提供了灵活性，因此他们可以根据需要来处理延迟，丢失和拥塞。我们将在媒体章节中对此进行进一步讨论。\n协议栈中的最后一个协议是 SCTP。SCTP 支持许多不同的消息传送选项。你可以根据需要开启不可靠传输，无序传输等选项，以便获得实时系统所需的低延迟。\nWebRTC 是一系列协议的集合 #  WebRTC 解决了许多问题。初看起来，这似乎是过度设计的。实际上，WebRTC 非常克制。它并未认为它可以更好的解决所有问题。相反，它采纳了许多现有的解决某个特定问题的技术，然后将它们有机地结合起来。\n这使得我们可以独立的检查和学习每个部分，而不会毫无头绪。实际上，从另一个角度去看“ WebRTC Agent”，它只是许多不同协议的协调器。\nWebRTC（API）如何工作 #  本部分显示 JavaScript API 是如何跟协议相对应的。这不是一个 WebRTC API 的详细演示，更多的是为了创建一个思维模型，展现各个模块是如何串联起来的。如果你对各个模块都还不熟悉，那也不要紧。当你了解更多信息时，再回头看看这一部分，可能会很有趣！\nnew RTCPeerConnection #  RTCPeerConnection 是最顶层的 \u0026ldquo;WebRTC 会话 \u0026ldquo;。它包含上述所有协议。调用后，所有子系统都会被创建，但是此时什么都还没有发生。\naddTrack #  addTrack 创建一个新的 RTP 流。会为这个 RTP 流生成一个随机的 SSRC（Synchronization Source/ 同步源）。在后续 createOffer 生成会话描述中，这个 RTP 流会被放入一个 media section。每次调用 addTrack 都会创建一个新的 SSRC 和一个对应的 media section。\n在建立 SRTP 会话后，这些媒体数据包将被 SRTP 加密，然后立即通过 ICE 开始发送。\ncreateDataChannel #  当没有 SCTP 关联 (SCTP Association) 存在时，createDataChannel 将创建一个新的 SCTP 流。默认情况下，SCTP 是不启用的，只有在一方请求数据通道时才启动。\n在 DTLS 会话建立之后，SCTP 关联将立即通过 ICE 发送数据包，并使用 DTLS 加密。\ncreateOffer #  createOffer 生成会话描述，里面是需要与远端 Peer 分享的本地信息。\n调用 createOffer 的行为对于本地 Peer 没有任何改变。\nsetLocalDescription #  setLocalDescription 提交所有请求的更改。 addTrack createDataChannel 和其他类似的调用都是临时的 (调用 setLocalDescription 后生效)。 调用 setLocalDescription 时，使用由 createOffer 生成的值。\n通常，在此调用之后，你会将 offer 发送给远端 Peer，他们将调用 setRemoteDescription，将此 offer 设入。\nsetRemoteDescription #  收到远端 Peer 发来的 offer 之后，我们通过 setRemoteDescription 通知本地 Agent。这就是使用 JavaScript API 传递“信令”的方式。\n双方都调用过 setRemoteDescription 后，WebRTC Agent 现在拥有足够的信息来开始进行点对点（P2P）通信！\naddIceCandidate #  addIceCandidate 允许 WebRTC Agent 随时添加更多的远程 ICE 候选对象。该 API 将 ICE 候选对象发送到 ICE 子系统，并且对更大的 WebRTC 连接没有其他影响。\nontrack #  ontrack 是收到远端 Peer 的 RTP 数据包时触发的回调。传入的 RTP 数据包的格式应该已在传递给 setRemoteDescription 的会话描述中声明。\nWebRTC 使用 SSRC 并查找关联的 MediaStream 和 MediaStreamTrack，并使用 MediaStream 和 MediaStreamTrack 中的详细信息来触发此回调。\noniceconnectionstatechange #  oniceconnectionstatechange 是 ICE Agent 的状态变化时触发的回调。当网络连接或断开时，你将得到此通知。\nonconnectionstatechange #  onconnectionstatechange 是 ICE Agent 和 DTLS Agent 状态的组合。当 ICE 和 DTLS 都成功完成时，你将得到此通知。\n"});index.add({'id':1,'href':'/zh/docs/02-signaling/','title':"信令",'section':"Docs",'content':"信令 #  什么是 WebRTC 信令？ #  当一个 WebRTC Agent 被创建时，它对其他 peer 一无所知。它不知道它将与谁联系，也不知道它们将发送些什么！ 信令是使呼叫成为可能的初始引导程序。交换信令消息后，WebRTC Agent 才可以直接相互通信。\n信令消息只是文本。WebRTC Agent 并不关心它们的传递方式。信令通常使用 Websockets 分享，但这不是必需的。\nWebRTC 信令如何工作？ #  WebRTC 使用到一种现有的协议，称为会话描述协议（Session Description Protocol，简称 SDP）。两个 WebRTC Agent 会将建立连接所需的所有状态通过此协议来分享。该协议本身亦易于阅读和理解。 但要理解 WebRTC 填充于协议中的所有值，是有些复杂的。\nSDP 并不是 WebRTC 特有的。我们将首先学习会话描述协议，这里甚至不用提到 WebRTC。WebRTC 实际上仅是利用了 SDP 协议的子集，因此我们将仅介绍我们所需的内容。 理解协议后，我们将继续结合 WebRTC 来说明其在实际中的应用方法。\n什么是 会话描述协议（SDP）？ #  会话描述协议定义于 RFC 8866 中。它是一个 key/value 协议，每一行是一个值。看起来类似于 INI 文件。 一个会话描述包含零个或多个媒体描述。对此模型，可以理解为会话描述包含了一个媒体描述的数组。\n一个媒体描述通常映射到单个媒体流。因此，如果你想描述一个包含三个视频流和两个音轨的呼叫，需要五个媒体描述。\n如何阅读 SDP 信息 #  会话描述中的每一行都将以一个单字符开始，这是你的 key。单字符后面将跟随一个等号。等号后的所有内容都是 value。value 结束的地方将有一个换行符。\n会话描述协议定义了所有有效的 key。对于协议中定义的 key，你只能使用字母。这些 key 都有重要的意义，稍后将对此进行解释。\n作为参考，下面是一个会话描述的部分内容：\na=my-sdp-value a=second-value 这里有两行。每行的 key 都是 a。第一行的 value 为 my-sdp-value，第二行的 value 为 second-value。\nWebRTC 仅使用了部分 SDP 的 key #  WebRTC 并未使用会话描述协议定义的所有 key，只有那些在 JavaScript Session Establishment Protocol (JSEP，协议定义在RFC 8829) 中被使用到的 key 是重要的。你当前只需要理解下面的 7 个 key。\n v - Version，版本，版本，应等于 0。 o - Origin，源，包含一个唯一 ID，用于重新协商。 s - Session Name，会话名称，应等于-。 t - Timing，时间，应等于 0 0。 m - Media Description(m=\u0026lt;media\u0026gt; \u0026lt;port\u0026gt; \u0026lt;proto\u0026gt; \u0026lt;fmt\u0026gt; ...)，媒体描述，下面有详细说明。 a - Attribute，属性，一个自由文本字段，这是 WebRTC 中最常见的行。 c - Connection Data，连接数据，应等于 IN IP4 0.0.0.0。  会话描述中的媒体描述 #  一个会话描述中，可以包含无限数量的媒体描述。\n一个媒体描述定义中，包含一个格式列表。这些格式映射到 RTP 有效负载类型。然后，实际的编解码器由媒体描述中的 rtpmap 属性定义。 RTP 和 RTP 有效负载类型的重要性将在后面的媒体章节中讨论。每个媒体描述可以包含无限数量的属性。\n作为参考例子，下面是一个会话描述的部分内容：\nv=0 m=audio 4000 RTP/AVP 111 a=rtpmap:111 OPUS/48000/2 m=video 4000 RTP/AVP 96 a=rtpmap:96 VP8/90000 a=my-sdp-value 这里面有两个媒体描述，第一个是音频，格式为 111，另一个是视频，格式为 96。第一个媒体描述只有一个属性。该属性将有效载荷类型 111 映射到 Opus 编解码器。 第二个媒体描述具有两个属性。第一个属性将有效负载类型 96 映射到 VP8 编解码器，第二个属性只是 my-sdp-value。\n译注：参照前面 key 的定义，第 1 行的 v=0 表示版本为 0，第 2/3 行是第一个媒体描述，第 4/5/6 行是第二个媒体描述  完整示例 #  以下内容将我们讨论过的所有概念整合在一起。这些是 WebRTC 所使用的会话描述协议的所有特性。 如果你可以读懂这个例子，那么你可以读懂任何 WebRTC 会话描述！\nv=0 o=- 0 0 IN IP4 127.0.0.1 s=- c=IN IP4 127.0.0.1 t=0 0 m=audio 4000 RTP/AVP 111 a=rtpmap:111 OPUS/48000/2 m=video 4002 RTP/AVP 96 a=rtpmap:96 VP8/90000  v, o, s, c, t 虽然被定义，但他们不对 WebRTC 会话产生影响。 这里有两个媒体描述。一个是 audio 即音频类型，一个是 video 即视频类型。 每个媒体描述都有一个属性。这个属性配置了 RTP 管道的详细信息，这部分将在 \u0026quot; 媒体通信 \u0026quot; 章节详细讨论  会话描述协议 和 WebRTC 如何协同工作 #  下一块拼图是理解 WebRTC _ 如何 _ 使用会话描述协议。\n什么是 Offer 和 Answer？ #  WebRTC 使用 Offer/Answer 模型。这指的是，一个 WebRTC Agent 发出 \u0026ldquo;Offer\u0026rdquo; 以开始呼叫，如果另一个 WebRTC Agent 愿意接受 \u0026ldquo;Offer\u0026rdquo; 的内容，它会响应 \u0026ldquo;Answer\u0026rdquo;。\n这使得应答者有机会拒绝媒体描述中的某些不支持的编解码器，也是两个 peer 互相理解他们希望交换何种格式的方式。\n用于发送和接收的收发器（Transceivers） #  收发器是 WebRTC 中特有的概念，你将在 API 中看到它。它的作用是将 \u0026quot; 媒体描述 \u0026quot; 暴露给 JavaScript API。每个媒体描述都将成为一个收发器。每次创建收发器时，都会将新的媒体描述添加到本地会话描述中。\nWebRTC 中的每个媒体描述都包含一个 direction 属性。这样，WebRTC Agent 可以声明 \u0026quot; 我将向你发送此编解码器，但我不打算接受任何返回的内容 \u0026ldquo;。direction 属性有四个有效值：\n send recv sendrecv inactive  WebRTC 用到的 SDP 值 #  这个列表包含了你将在 WebRTC Agent 的会话描述中看到的一些常见属性。这些值控制着我们尚未讨论到的子系统。\ngroup:BUNDLE #  BUNDLE 是一种在单个连接上传输多种类型流量的行为。一些 WebRTC 实现对每个媒体流会使用专用的连接。但 BUNDLE 方式应该是首选。\nfingerprint:sha-256 #  该属性是 peer 用于 DTLS 证书的哈希值。DTLS 握手完成后，你可以将其与实际证书进行比较，以确认你正在与预期的对象进行通信。\n译注：下面是RFC 4572中的一个例子\na=fingerprint:SHA-1 \\ 4A:AD:B9:B1:3F:82:18:3B:54:02:12:DF:3E:5D:49:6B:19:E5:7C:AB   setup: #  该属性控制了 DTLS Agent 的行为。在 ICE 连接后，该属性将确定 DTLS Agent 是作为客户端还是服务器来运行。有以下几个可能的值：\n setup:active - 作为 DTLS 客户端运行。 setup:passive - 作为 DTLS 服务器运行。 setup:actpass - 要求另一个 WebRTC Agent 选择。  mid #  该属性是每个 Media Description 的唯一 ID。用于标识媒体。\nice-ufrag #  该属性是 ICE Agent 的用户片段值。用于 ICE 流量的身份验证。\nice-pwd #  该属性是 ICE Agent 的密码。用于 ICE 流量的身份验证。\nrtpmap #  该属性用于将特定的编解码器映射到 RTP 有效负载类型。有效负载类型不是静态的，因此对于每次呼叫，发起者都需要确定每个编解码器的有效负载类型。\nfmtp #  该属性为一种有效负载类型定义附加的值。要传递特定的视频配置文件或编码器设置时，这很有用。\ncandidate #  该属性是来自 ICE Agent 的 ICE 候选地址。这是一个可能被 WebRTC Agent 使用的地址。这些将在下一章中详细说明。\nssrc #  一个同步源（SSRC）定义了一个单独的媒体流。\nlabel 是此媒体流的 ID。mslabel 是容器的 ID，该容器中可以有多个流。\nWebRTC 会话描述示例 #  下面是一个 WebRTC 客户端生成的一套完整会话描述：\nv=0 o=- 3546004397921447048 1596742744 IN IP4 0.0.0.0 s=- t=0 0 a=fingerprint:sha-256 0F:74:31:25:CB:A2:13:EC:28:6F:6D:2C:61:FF:5D:C2:BC:B9:DB:3D:98:14:8D:1A:BB:EA:33:0C:A4:60:A8:8E a=group:BUNDLE 0 1 m=audio 9 UDP/TLS/RTP/SAVPF 111 c=IN IP4 0.0.0.0 a=setup:active a=mid:0 a=ice-ufrag:CsxzEWmoKpJyscFj a=ice-pwd:mktpbhgREmjEwUFSIJyPINPUhgDqJlSd a=rtcp-mux a=rtcp-rsize a=rtpmap:111 opus/48000/2 a=fmtp:111 minptime=10;useinbandfec=1 a=ssrc:350842737 cname:yvKPspsHcYcwGFTw a=ssrc:350842737 msid:yvKPspsHcYcwGFTw DfQnKjQQuwceLFdV a=ssrc:350842737 mslabel:yvKPspsHcYcwGFTw a=ssrc:350842737 label:DfQnKjQQuwceLFdV a=msid:yvKPspsHcYcwGFTw DfQnKjQQuwceLFdV a=sendrecv a=candidate:foundation 1 udp 2130706431 192.168.1.1 53165 typ host generation 0 a=candidate:foundation 2 udp 2130706431 192.168.1.1 53165 typ host generation 0 a=candidate:foundation 1 udp 1694498815 1.2.3.4 57336 typ srflx raddr 0.0.0.0 rport 57336 generation 0 a=candidate:foundation 2 udp 1694498815 1.2.3.4 57336 typ srflx raddr 0.0.0.0 rport 57336 generation 0 a=end-of-candidates m=video 9 UDP/TLS/RTP/SAVPF 96 c=IN IP4 0.0.0.0 a=setup:active a=mid:1 a=ice-ufrag:CsxzEWmoKpJyscFj a=ice-pwd:mktpbhgREmjEwUFSIJyPINPUhgDqJlSd a=rtcp-mux a=rtcp-rsize a=rtpmap:96 VP8/90000 a=ssrc:2180035812 cname:XHbOTNRFnLtesHwJ a=ssrc:2180035812 msid:XHbOTNRFnLtesHwJ JgtwEhBWNEiOnhuW a=ssrc:2180035812 mslabel:XHbOTNRFnLtesHwJ a=ssrc:2180035812 label:JgtwEhBWNEiOnhuW a=msid:XHbOTNRFnLtesHwJ JgtwEhBWNEiOnhuW a=sendrecv 从这个会话描述中，我们可以知道以下内容：\n 我们有两个媒体描述，一个是音频，一个是视频 这两个媒体描述都是 sendrecv 收发器。我们将得到两个流，也可以发送两个流回去。 我们有 ICE 候选地址和身份验证的详细信息，因此我们可以尝试连接 我们有一个证书指纹，因此我们可以进行安全的呼叫  译注：对照以上 4 点\n 两个媒体描述即是两个 m= 段 两个 m 段中都有 a=sendrecv，即是说可以收也可以发 ICE 候选地址对应 a=candidate:foundation 到 a=end-of-candidates 之间的部分，身份验证信息参考前面的 ice-ufrag 和 ice-pwd 等 指的是 fingerprint:sha-256 属性   进一步的话题 #  在本书的后续版本中，还将讨论以下主题：\n 重新协商（Renegotiation） 同步广播（Simulcast）  "});index.add({'id':2,'href':'/zh/docs/03-connecting/','title':"连接",'section':"Docs",'content':"连接 #  为什么 WebRTC 需要专用的子系统进行连接？ #  目前，大多数部署的应用程序都通过客户端 / 服务器方式进行连接。客户端 / 服务器方式连接要求服务器具有稳定且公开可用的传输地址。客户端与服务器联系，然后服务器做出响应。\nWebRTC 不使用客户端 / 服务器模型，它建立点对点（P2P）连接。 在 P2P 连接中，创建连接的任务被平均分配给两个对等方。这是因为无法猜测 WebRTC 中的传输地址（IP 和端口），而且，在会话过程中，传输地址甚至可能会变更。WebRTC 将收集所有可能收集的信息，并将尽力实现两个 WebRTC Agent 之间的双向通信。\n听起来简单，建立点对点连接实际上可能会非常困难。这些 Agent 可能位于没有直接连接的不同网络中。即使在两个 Agent 可以直接连接的情况下，你可能还会遇到其他问题。比如在某些情况下，两个客户端使用不同的网络协议（UDP \u0026lt;-\u0026gt; TCP）或使用不同的 IP 版本（IPv4 \u0026lt;-\u0026gt; IPv6）。\n尽管在建立点对点连接方面存在一些困难，在 WebRTC 提供的下面这些属性的帮助下，你仍然可以获得相对于传统客户端 / 服务器技术的一些优势。\n降低带宽成本 #  由于媒体通信直接发生在 peer 之间，因此你无需为之付费，也无需托管一个单独的服务器来转发媒体。\n更低延迟 #  直接通信时速度更快！当用户必须通过你的服务器运行所有内容时，这会使传输速度变慢。\n安全的端到端通信 #  直接通信更安全。由于用户数据根本没有通过你的服务器，因此用户压根不需要考虑你的服务器会不会解密其数据。\n它是如何工作的？ #  上面描述的连接过程是通过 Interactive Connectivity Establishment（交互式连接建立 /ICE） 实现的。这是另一个在 WebRTC 之前就已经出现的协议。\nICE 是一种用来寻找两个 ICE Agent 之间通信的最佳方式的协议。每个 ICE Agent 都会发布如何访问自己的方式，这些路径被称为候选地址（candidates）。候选地址本质上是一个传输地址，ICE Agent 认为这个传输地址可能可以被对端访问到。接下来 ICE 将确定候选地址的最佳搭配。\n本章稍后将详细介绍实际的 ICE 过程。要了解 ICE 为什么存在，最好先了解我们要面临的网络特性。\n现实世界的网络限制 #  ICE 就是克服现实世界网络限制的方法。在我们开始讨论 ICE 如何解决问题之前，先讨论一下有哪些实际问题。\n不在同一个网络中 #  在大多数情况下，两个 WebRTC Agent 不在同一个网络中。典型的呼叫通常是在没有直接连接的不同网络中的两个 WebRTC Agent 之间进行的。\n下面是通过公共互联网连接的两个不同网络的示意图。在每个网络中，你拥有两个主机。\n对于同一网络中的主机来说，互相连接非常容易。例如在 192.168.0.1 -\u0026gt; 192.168.0.2 之间通讯就很容易！这两个主机无需任何外部帮助即可相互连接。\n但是，使用 Router B 的主机无法直接访问 Router A 背后的任何主机。你如何区分 Router A 后面的 192.168.0.1 主机和 Router B 后面相同 IP 的主机之间的区别呢？它们都使用内网 IP！使用 Router B 的主机可以将数据直接发送到 Router A，但是请求在那里就结束了。Router A 怎么知道它应该将消息转发给哪台主机呢？\n协议限制 #  有些网络不允许 UDP 通信，或者也有可能不允许 TCP。有些网络的 MTU（Maximum Transmission Unit/ 最大传输单元）可能非常低。网络管理员可以更改许多变量，这些修改可能会使通信变得困难。\n防火墙 /IDS 规则 #  另一个问题是深度数据包检查和其他智能过滤方式。某些网络管理员将运行一些软件，这些软件会试图处理每个数据包。很多时候，这些软件无法识别 WebRTC 的数据包，由于它们不知道如何处理，它们可能会阻拦这些数据包，例如，它们可能将 WebRTC 数据包视为不在端口白名单上的可疑 UDP 数据包。\nNAT 映射 #  NAT（网络地址转换）映射是使得 WebRTC 连接成为可能的魔法。WebRTC 就是使用 NAT 让处于完全不同的子网中的两个 peer 进行通信，从而解决了上述 \u0026quot; 不在同一网络中 \u0026quot; 的问题。尽管它带来了新的挑战，但让我们先来解释一下 NAT 映射是如何工作的。\nNAT 映射不使用中继，代理或服务器。跟上一个例子一样，我们有 Agent 1 和 Agent 2，它们位于不同的网络中。然而，流量穿透了路由器。看起来就像这样：\n想要这样通信的话，你需要创建一个 NAT 映射。Agent 1 使用端口 7000 与 Agent 2 建立 WebRTC 连接。这将创建一个 192.168.0.1:7000 到 5.0.0.1:7000 的绑定。然后，Agent 2 将数据包发送到 5.0.0.1:7000 时，数据包会被转发给 Agent 1。在这个例子中，创建一个 NAT 映射，就像是在路由器中做了一次自动化的端口转发。\nNAT 映射的缺点是：映射的形式不止一种（例如静态端口转发），并且映射的实现方式在不同的网络中也是不一样的。ISP 和硬件制造商可能会以不同的方式来实现 NAT 映射。在某些情况下，网络管理员甚至可能禁用它。\n好消息是，NAT 映射的所有行为都是可以理解和观察到的，因此 ICE Agent 能够确认其创建了 NAT 映射，并确认该映射的属性。\n描述这些行为的文档是 RFC 4787。\n创建映射 #  创建映射是最简单的部分。当你将数据包发送到网络外部的地址时，一个映射就被创建出来了！NAT 映射只是由 NAT 分配的一个临时的公共 IP 和端口。出站的消息将被重写，使得其源地址变为新创建的映射地址。如果有消息被成功发到映射地址，消息会被自动路由返回给 NAT 网络中创建这个映射地址的主机。说到映射相关的细节，这就开始变得复杂了。\n映射创建的行为 #  映射创建分为三类：\n端点无关的映射 #  这种创建方式为 NAT 网络中的所有发送者只创建一个映射。如果你将两个数据包发送到两个不同的远程地址，这个 NAT 映射将被重用。两个远程主机将看到相同的源 IP 和端口。如果远程主机响应，它将被发送回相同的本地侦听器。\n这是最好的情况。要使得呼叫能够建立起来，至少一侧必须是这种类型。\n地址相关的映射 #  每次将数据包发送到新地址时，都会创建一个新的映射。如果你将两个数据包发送到不同的主机，则会创建两个映射。如果将两个数据包发送到同一远程主机，但目标端口不同，则不会创建新的映射。\n地址和端口相关的映射 #  如果远程 IP 或端口不同，则会创建一个新的映射。如果将两个数据包发送到同一远程主机，但目标端口不同，则将创建一个新的映射。\n映射过滤行为 #  映射过滤是关于允许谁使用映射的规则。它们分为三个类似的类别：\n端点无关的过滤 #  任何人都可以使用该映射。你可以与其他多个 peer 共享该映射，他们都可以向该映射发送流量。\n地址相关的过滤 #  只有为其创建映射的主机才能使用该映射。如果你将数据包发送到主机 A，则它可以根据需要响应任意数量的数据包。如果主机 B 尝试将数据包发送到该映射，将被忽略。\n地址和端口相关的过滤 #  仅有创建映射的主机和端口可以使用该映射。如果你将数据包发送到主机 A:5000，则它可以根据需要响应任意数量的数据包。如果主机 A：5001 尝试将数据包发送到该映射，将被忽略。\n映射的刷新 #  通常的建议是，如果 5 分钟未使用映射，则应将其销毁。但这完全取决于 ISP 或硬件制造商。\n译注：换个说法，NAT 映射的创建即是 NAT 网络中的主机发送数据时，路由器的处理方式；而过滤即是接收数据时，路由器的处理方式。映射的刷新即是路由器释放映射的处理方式。不同网络情况不同，因此某些特定的搭配会导致两个网络间无法建立 P2P 连接。在穿透相关的技术中，将不同的情况称为不同的锥形。  STUN #  STUN（NAT 会话传输实用程序）是一种用来配合 NAT 使用的协议。这是 WebRTC（和 ICE！）之前的另一项技术。它由RFC 8489定义，该文件还定义了 STUN 数据包结构。STUN 协议也在 ICE/TURN 中被使用。\nSTUN 很有用，因为它允许以编程方式创建 NAT 映射。在 STUN 之前，我们能够创建 NAT 映射，但是我们不知道映射的 IP 和端口是什么！STUN 不仅使你能够创建映射，还可以让你获取映射的详细信息，你可以他人分享这些详细信息，然后他们便可以通过你刚刚创建的映射向你传回数据。\n让我们从对 STUN 的基本描述开始。稍后，我们再将话题扩展到 TURN 和 ICE 的用法。现在，我们只打算描述请求 / 响应流程来创建映射。然后，我们将讨论如何获取该映射的详细信息以便与他人共享。当你在 ICE URLs 中有一个用于 WebRTC PeerConnection 的 stun: 服务器时，此过程就会发生。简而言之，STUN 向 NAT 外部的 STUN 服务器发送请求，服务器返回其在请求中观察到的内容，STUN 根据这些内容来帮助 NAT 后面的端点找出已创建的映射。\n协议结构 #  每个 STUN 数据包都具有以下结构：\n 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ |0 0| STUN Message Type | Message Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Magic Cookie | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | | | Transaction ID (96 bits) | | | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Data | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ STUN 消息类型 #  每个 STUN 数据包都有一个类型。目前，我们仅关心以下几种：\n Binding Request - 0x0001 Binding Response - 0x0101  为了创建一个 NAT 映射，我们发出一个 Binding Request。然后服务器回应一个 Binding Response。\n消息长度 #  这就是 Data 段的长度。这一段中包含由消息类型所定义的任意数据。\nMagic Cookie #  指的是固定值 0x2112A442，以网络字节顺序发送。这个值有助于将 STUN 流量与其他协议区分开。\n交互（Transaction）ID #  一个 96-bit 的标识符，用于唯一标识一个请求 / 响应对。这可以帮助你配对请求和响应。\n数据 #  数据将包含一个 STUN 属性的列表。一个 STUN 属性具有以下结构：\n0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Type | Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Value (variable) .... +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ STUN Binding Request 不使用任何属性。这意味着一个 STUN Binding Request 仅包含 header。\nSTUN Binding Response 使用一个 XOR-MAPPED-ADDRESS (0x0020)。此属性包含一个 IP 和一个端口。这正是所创建的 NAT 映射的 IP 和端口！\n创建 NAT 映射 #  使用 STUN 创建 NAT 映射只需要发送一个请求！你向 STUN 服务器发送一个 STUN Binding Request。然后，STUN 服务器回应一个 STUN Binding Response。 该 STUN Binding Response 将包含映射地址。映射地址是 STUN 服务器看到你的方式，也是你的 NAT 映射。 如果你希望某人向你发送数据包，那么你应该共享该映射地址。\n人们还会将映射地址称为公网 IP 或 Server Reflexive Candidate。\n确定 NAT 类型 #  不幸的是，映射地址可能并非在所有情况下都可用。如果是地址相关的映射，则只有 STUN 服务器才能将流量发送回给你。如果你共享它，那么另一个 peer 尝试向该地址发送的消息将被丢弃。这使得该 peer 无法与别的 peer 交流。如果 STUN 服务器还可以为你将数据包转发给对端 peer，你可能会发现地址相关的映射问题实际上是可以解决的！这也就是下面将要说到的 TURN 解决方案。\nRFC 5780定义了一种方法，可以运行一个测试来确定你的 NAT 类型。这很有用，因为你可能会提前知道是否可以进行直接连接。\nTURN #  在无法建立直接连接的情况下，RFC 8656中定义了 TURN（使用中继穿透 NAT）。当你的两个 peer 的 NAT 类型不兼容，或者双方使用不同协议时，就需要使用 TURN！TURN 也可以被用于保护隐私的目的。如果通过 TURN 运行所有通讯，客户的真实地址在对端是被隐藏的。\nTURN 使用专用服务器。该服务器充当客户端的代理。客户端连接到 TURN 服务器并创建一个对应的 Allocation。通过创建该 Allocation，客户端将获得一个临时 IP/ 端口 / 协议三元组，其他 peer 可以使用该 IP/ 端口 / 协议将数据发送给该客户端。这个新的监听地址被称为中继传输地址。你可将其视为转发地址并分享给他人，以便其他人可以通过 TURN 向你发送流量！对于每个将获得该中继传输地址的 peer，你必须为其创建一个新的 Permission，以允许它与你进行通信。\n当你通过 TURN 发送出站流量时，它会通过中继传输地址发送。当远程 peer 获得该出站流量时，他们会看到数据来自 TURN 服务器。\nTURN 生命周期 #  下面就是一个客户端创建 TURN allocation 时必须做的所有事情。对于其他 peer 而言，与使用 TURN 服务器的客户端进行通信和其他客户端没有任何区别，先获得 IP 和端口，然后像跟其他任何主机一样通信。\nAllocations #  Allocations 是 TURN 的核心。本质上，一个 allocation 就是一个 \u0026ldquo;TURN 会话 \u0026ldquo;。要创建一个 TURN allocation，你需要与 TURN Server Transport Address（服务器传输地址，通常在 3478 端口）进行通信。\n创建 allocation 时，你需要提供 / 确定以下内容：\n 用户名 / 密码 - 创建 TURN allocation 时需要身份验证。 Allocation 传输方式 - 服务器（中继传输地址）与 peer 之间的传输协议， 可以是 UDP 或 TCP。 连续端口 - 你可以为多个 allocation 请求顺序排列的一系列端口，这点与 WebRTC 无关。  如果请求成功，你将在 TURN 服务器上获得响应，在响应的数据部分，包含以下的 STUN 属性：\n XOR-MAPPED-ADDRESS - TURN Client 的 Mapped Address。当有人将数据发送到中继传输地址时，数据将被转发到该地址。 RELAYED-ADDRESS - 这是你提供给其他客户端的地址。如果有人将数据包发送到该地址，数据包会被转发到 TURN 客户端。 LIFETIME - Allocation 被销毁的时间。你可以通过发送 Refresh 请求来延长这一时间。  译注：上面两个地址很拗口，但实际上理解起来并不复杂。Mapped Address 是 Turn Client 的实际地址，也就是 Turn Server 收到数据包时的目标地址。而 Relayed Address 是 Turn Client 的名义地址，也就是其他 WebRTC Agent 要发送数据给这个 Turn Client 时，所使用的地址。  权限 #  在你为远程主机创建权限之前，远程主机是无法通过你的中继传输地址发送数据的。所谓创建权限，即是告知 TURN 服务器一个 \u0026quot; 可以用来发送入站流量 \u0026quot; 的 IP 和端口。\n远程主机需要先为你提供 TURN 服务器上使用的 IP 和端口。这意味着它应该先向 TURN 服务器发送一个 STUN 绑定请求。 有时会发生这样一个常见的错误情况，即是远程主机发送 STUN 绑定请求到另外一台服务器，然后再要求 TURN 服务器为此 IP 创建权限。\n对于上面那种错误情况，假设你要为一个使用地址相关的映射的 NAT 网络的主机创建权限，如果你从其他 TURN 服务器生成映射地址，则所有入站流量都将被丢弃。因为每次他们与其他主机通信时，它都会生成一个新的映射。如果未被刷新，权限将在 5 分钟后过期。\n译注：对于这个常见的错误情况，实际指的是被连接的主机从 TURN 服务器以外的 STUN/TURN 服务器获取本机 IP，再告知发起连接的主机这样的情况。当被连接的主机使用地址相关的映射类型的 NAT 时，它获取的 IP 在当前的 TURN 服务器上是无效的。  SendIndication/ChannelData #  这是 TURN 客户端将消息发送到远端 peer 时所使用的两个消息。\nSendIndication 是一个自包含的消息。它包含你希望发送的数据，以及你希望发送的目标。如果你要向远端 peer 发送大量消息的话，这种方式很昂贵。因为如果要发送 1,000 条消息，目标 IP 地址就被重复了 1,000 次！\nChannelData 允许你发送数据，但不需要重复 IP 地址。你需要先创建一个具有 IP 和端口的通道（Channel）。然后使用 ChannelId 发送，IP 和端口将在服务器端被填充进去。如果你要发送大量消息，这是更好的选择。\n刷新 #  Allocations 将自动销毁。要避免其过早销毁，TURN 客户端必须在创建 allocation 时指定的 LIFETIME 到来之前，及时刷新它们。\nTURN 使用方法 #  TURN 有两种用法。通常情况下，一个 peer 会作为 \u0026ldquo;TURN 客户端 \u0026quot; 连接，而另一方则直接进行通信。在某些情况下，你可能在两侧都需要使用 TURN 服务。举例来说，当两个客户端都位于在禁用 UDP 的网络中时，只能通过 TCP 连接到各自的 TURN 服务器来建立连接。\n下面这些图有助于说明 TURN 的用法。\n单个 TURN Allocation 通信 #  双重 TURN Allocation 通信 #  译注：单个 TURN Allocation 的情况，指的是一个 TURN Client 和另一个可访问的 UDP Client 的通信。双重 TURN Allocation 的情况，指的是两个 TURN Client 之间通信。  ICE #  ICE（交互式连接建立）是 WebRTC 连接两个 Agent 的方式。这也是一项 WebRTC 前就有的技术，在RFC 8445中定义！ICE 是用于建立连接的协议。它会确定两个 peer 之间所有可能的路由，然后确保你保持连接状态。\n这些路由被称为 Candidate Pair（候选地址对），也就是本地地址和远程地址的配对。这就是 STUN 和 TURN 在 ICE 中发挥作用的地方。这些地址可以是你的本地 IP 地址，NAT 映射或中继传输地址。通信双方需要收集它们要使用的所有地址，交换这些地址，然后尝试连接！\n两个 ICE Agent 使用 ICE ping 数据包（正式名称为连通性检查）通信以建立连接。一旦建立连接后，他们就可以发送任何数据。感觉就像使用普通 socket 一样。连通性检查使用 STUN 协议。\n创建 ICE Agent #  ICE Agent 要么处于控制中，要么处于受控中。控制中的 Agent 是决定选择候选对的 Agent。通常来说，发送 offer 的 peer 是控制中的一方。\n每一方都必须有一个用户片段和一个密码。必须先交换这两个值，接下来才能进行连接性检查。用户片段以纯文本形式发送，用于多个 ICE 会话的解复用（demux）。 密码用于生成 MESSAGE-INTEGRITY 属性。在每个 STUN 数据包的末尾，都有这个属性，该属性是使用密码作为密钥的整个数据包的哈希值。这用于验证数据包并确保它未被篡改。\n对于 WebRTC，所有这些值都通过上一章中所述的会话描述进行分发。\n候选地址收集 #  现在，我们需要收集所有可能联通的地址。这些地址被称为候选地址 (Candidate)。\n主机 #  主机候选地址直接在本地接口上侦听。可以是 UDP 或 TCP 方式。\nmDNS #  mDNS 候选地址类似于主机候选地址，但是其 IP 地址是隐藏的。你不必给对方提供你的 IP 地址，只需要给他们提供一个 UUID 作为主机名。然后设置一个多播监听器，并在有人请求你发布的 UUID 时进行响应。\n如果你与 Agent 位于同一网络中，则可以通过多播找到彼此。如果不在同一网络中，则将无法连接（除非网络管理员明确配置网络以允许多播数据包通过）。\n这对于保护隐私很有用。以前，用户可以通过 WebRTC 使用主机候选地址（甚至无需尝试与你连接）来找出你的本地 IP 地址。而使用 mDNS 候选地址的话，他们只能获得随机的 UUID。\n服务器自反（Server Reflextive） #  服务器自反候选地址是通过对 STUN 服务器执行 STUN 绑定请求时生成的。\n当你收到 STUN 绑定响应时，XOR-MAPPED-ADDRESS 就是你的服务器自反候选地址。\nPeer 自反 #  Peer 自反候选地址是指，当你从你不知道的地址收到入站请求时，由于 ICE 是经过身份验证的协议，因此你知道这些传输是合法的，这只是意味着远端 Peer 是通过它也不知道的地址与你通信。\n这通常会发生在这样的情况下，当主机候选地址与服务器自反候选地址进行通信时，由于你是在子网外部进行通信，因此创建了一个新的 NAT 映射。还记得我们说过的连通性检查实际上是 STUN 数据包吗？STUN 响应的格式自然允许 peer 报告 Peer 自反地址。\n中继 #  中继候选地址是通过使用 TURN 服务器生成的。\n在与 TURN 服务器进行初始握手之后，你将获得 RELAYED-ADDRESS，这就是你的中继候选地址。\n连通性检查 #  现在我们知道了远程 Agent 的用户片段，密码和候选地址。我们可以尝试连接了！ 候选地址可以相互配对。因此，如果每边有 3 个候选地址，那么现在就有 9 个候选地址对。\n看起来像这样\n候选地址选择 #  控制中的 Agent 和受控中的 Agent 都开始在每个候选地址对上发送流量数据。这样是必须的，因为如果一个 Agent 位于一个地址相关映射的网络中，这样会创建 Peer 自反候选地址。\n每个收到流量数据的候选地址对，会被提升为有效候选地址对。接下来，控制中的 Agent 将指定一个有效候选地址对。这就是提名候选地址对。然后，控制中的 Agent 和受控中的 Agent 再尝试进行一轮双向通信。如果成功，则提名候选地址对将成为选定的候选地址对！它将被用于后面的会话中。\n重新启动 #  如果选定的候选地址对由于任何原因停止工作（如：NAT 映射到期，TURN 服务器崩溃等），则 ICEAgent 将进入失败状态。此时可以重新启动两个 Agent，然后重新完整执行整个过程。\n"});index.add({'id':3,'href':'/zh/docs/04-securing/','title':"安全性",'section':"Docs",'content':"安全性 #  WebRTC 具有哪些安全性保障？ #  每个 WebRTC 连接都经过身份验证和加密。你可以确信第三方看不到你发送的内容，也无法插入虚假消息。你还可以确保与你进行通信的 WebRTC Agent 正是生成会话描述的 Agent。\n没有人能够篡改消息这一点非常重要。如果第三方在传输中读取了会话描述，这不会产生什么影响。然而，WebRTC 无法防止会话描述被修改。攻击者可以通过更改 ICE 候选地址和证书指纹来对你进行中间人攻击（man-in-the-middle）。\n译注：这里指的是，P2P 连接建立之后，双方之间的通信安全是有保障的。但在连接建立的过程中，攻击者可以通过 man-in-the-middle 方式伪装中间人同时与通信双方建立连接并通信。  它是如何做到的？ #  WebRTC 使用两个预先存在的协议，数据报传输层安全（Datagram Transport Layer Security / DTLS）和 安全实时传输协议（Secure Real-time Transport Protocol / SRTP）。\nDTLS 使你可以协商会话，然后在两个 peer 之间安全地交换数据。它是 TLS 的同类产品，TLS 是 HTTPS 所使用的技术，而 DTLS 与 TLS 的区别仅在与其使用 UDP 而不是 TCP 作为其传输层。这也意味着 DTLS 协议必须处理不可靠的数据传输。SRTP 是专为安全的交换媒体数据而设计的。相对于 DTLS 而言，使用 SRTP 对传输媒体数据有一些优化。\nDTLS 先被使用。它通过 ICE 提供的连接进行一次握手。DTLS 是一种客户端 / 服务器协议，因此其中一侧需要开始握手。客户端 / 服务器的角色是在信令中被确定的。在 DTLS 握手期间，双方都会提供证书。 握手完成后，需要将收到的证书与会话描述中的证书哈希进行比较。这是为了确定握手的目标就是你所期望的 WebRTC Agent。接下来，可以将 DTLS 连接用于 DataChannel 通信。\n要创建 SRTP 会话，我们使用 DTLS 生成的密钥对其进行初始化。SRTP 没有握手机制，因此必须使用外部密钥进行引导。一旦完成此操作，媒体数据即可以用 SRTP 加密并进行交换！\n安全性 101 #  要了解本章介绍的技术，你首先需要了解这些术语。密码学是一个棘手的主题，因此其他资源也是值得参考的！\n明文和密文 #  明文是 cipher 的输入。密文是 cipher 的输出。\nCipher #  Cipher 是将明文转换为密文的一系列步骤。Cipher 可以反过来运行，因此你可以将密文恢复为明文。一个 cipher 通常拥有一个更改其行为的密钥。还有一个术语是加密和解密。\n举例来说，一个简单的 cipher 是 ROT13。也就是每个字母向前移动 13 个字符。要解密这个 cipher，需要每个字母向后移动 13 个字符。明文 HELLO 将成为密文 URYYB。 在这种情况下，Cipher 是 ROT，密钥是 13。\n哈希函数 #  哈希函数是一种生成摘要的单向过程。给定一个输入，它每次都会生成相同的输出。其重要特点是输出不可逆。也就是说，根据输出的摘要，无法确定其输入。当你要确认消息未被篡改时，哈希函数很有用。\n哈希函数可以很简单，比如只是对输入间隔取字母。这样 HELLO 将变成 HLO。你不能认为 HELLO 就是输入，但可以确认如果输入的是 HELLO，那么结果是匹配的。\n公钥 / 私钥加密 #  公钥 / 私钥加密描述了 DTLS 和 SRTP 使用的 cipher 类型。在此系统中，你有两个密钥，即公钥和私钥。公钥用于加密消息，可以安全共享。 私钥用于解密消息，永远不应共享。当解密那些使用对应的公钥加密的消息时，它是唯一的密钥。\nDiffie-Hellman 交换 #  Diffie-Hellman 交换允许两个以前从未见过的用户通过 Internet 安全的创建一个共享的秘密信息。用户 A 可以将秘密信息发送给用户 B，而不必担心被窃听。破解该信息的难度将取决于破解离散对数问题的难度。 你不必完全理解该算法是如何工作的，但这可以帮助你了解是什么使得 DTLS 握手变得可行的。\nWikipedia 在此处中有一个实际的例子。\n伪随机函数（PRF） #  伪随机函数是一个预定义函数，用于生成随机出现的值。它可能需要多个输入并生成一个输出。\n密钥派生（KDF） #  密钥派生是一类伪随机函数。是一种用于增强密钥的安全性的方法。一种常见的模式是密钥扩展。\n假设你获得的密钥为 8 字节。你可以使用 KDF 使其更坚固。\nNonce #  Nonce 是 cipher 的附加输入。这样，即使你多次加密同一条消息，也可以从 cipher 中获得不同的输出。\n如果将同一条消息加密 10 次，cipher 将为你提供 10 次相同的密文。通过使用 nonce，在使用同一个密钥的情况下，你将得到不同的输入。需要注意的是，每条消息都要使用不同的 nonce！ 否则就没有太大意义了。\n消息身份验证代码（Message Authentication Code） #  消息身份验证代码（MAC）是放在消息末尾的哈希值。MAC 能证明该消息来自你期望的用户。\n如果你不使用 MAC，攻击者可能会插入无效的消息。因为他们不知道密钥，所以这些消息解密后是无意义的垃圾内容。\n密钥轮换 #  密钥轮换是一种间隔一段时间便更改密钥的做法。这种做法会使得被窃取的密钥影响较小。如果密钥被窃取或泄漏，那么只有很少的数据可以被解密。\nDTLS #  DTLS（数据报传输层安全协议）允许两个 peer 在没有预先存在的配置的情况下建立安全的通信。即使有人窃听了通信，他们也将无法解密消息。\n为了使 DTLS 客户端和服务器进行通信，他们需要就 cipher 和密钥达成一致。他们通过进行 DTLS 握手来确定这些值。在握手期间，消息为纯文本格式。 当 DTLS 客户端 / 服务器交换了足够的详细信息以开始加密时，它会发送 Change Cipher Spec（更改 Cipher 规格）消息。在此消息之后，后续的每个消息都将会被加密！\n数据包格式 #  每个 DTLS 数据包开头都包含一个头部信息。\n内容类型 #  你可以看到数据包包括以下几种类型：\n 20 - Change Cipher Spec（更改 Cipher 规格） 22 - Handshake（握手） 23 - Application Data（应用程序数据）  握手用于交换详细信息以开始会话。 更改 Cipher 规格用于通知另一端所有内容都将被加密。应用程序数据是加密的消息。\n版本 #  版本可以是 0x0000feff（DTLS v1.0）或 0x0000fefd（DTLS v1.2），没有 v1.1。\nEpoch（时段） #  时段从 0 开始，但在更改 Cipher 规格之后变为 1。在非零时段的任何消息都将被加密。\n序列号 #  序列号用于保持消息顺序。每条消息都会增加序列号。当 Epoch（时段）增加时，序列号重新开始。\n长度和有效载荷 #  有效载荷是特定于内容类型的。对于应用程序数据而言，有效载荷是加密的数据。对于握手，它会根据消息而有所不同。长度是指有效载荷的大小。\n握手状态机 #  在握手期间，客户端 / 服务器交换一系列消息。这些消息被分为多个 Flight。每个 Flight 中可能有多个消息（或只有一个）。 直到收到 Flight 中的所有消息，该 Flight 才算完成。我们将在下面更详细地描述每条消息的目的。\nClientHello #  ClientHello 是客户端发送的初始消息。它包含一个属性列表。这些属性告诉服务器客户端支持的 cipher 和功能。对于 WebRTC，这也是我们选择 SRTP cipher 方式的原因。它还包含将用于生成会话密钥的随机数据。\nHelloVerifyRequest #  服务器将 HelloVerifyRequest 发送到客户端。这是为了确认客户端准备继续发送请求。然后，客户端重新发送 ClientHello，但这一次需要携带 HelloVerifyRequest 中提供的令牌。\nServerHello #  ServerHello 是服务器响应消息，是此次会话的配置信息。它包含此会话直到结束时将使用的 cipher。它还包含服务器端的随机数据。\nCertificate #  Certificate 包含客户端或服务器的证书。它被用来唯一识别我们与之通信的对方。握手结束后，我们将确保这个证书的哈希与 SessionDescription 中的指纹相匹配。\nServerKeyExchange/ClientKeyExchange #  这些消息用于传输公共密钥。在启动时，客户端和服务器都会生成密钥对。握手后，这些值将被用来生成 Pre-Master Secret。\nCertificateRequest #  CertificateRequest 由服务端发送，用来通知客户端需要一个证书。服务端既可以请求一个证书，也可以要求必须提供证书。\nServerHelloDone #  ServerHelloDone 通知客户端此时服务器已完成握手动作。\nCertificateVerify #  发送者用 CertificateVerify 消息来证明他已经获得了 Certificate 消息中发送的私钥。\nChangeCipherSpec #  ChangeCipherSpec 通知接收者在此消息之后发送的所有内容都将被加密。\nFinished #  Finished 消息是加密的，它包含所有消息的哈希。用来断言握手过程未被篡改。\n密钥的生成 #  握手完成后，你可以开始发送加密数据。Cipher 是由服务器选择的，位于 ServerHello 消息中。但接下来如何生成密钥呢？\n首先，我们需要生成 Pre-Master Secret。为了获得该值，我们通过 ServerKeyExchange 和 ClientKeyExchange 消息，使用 Diffie-Hellman 算法来交换密钥。细节因选定的 Cipher 而异。\n接下来，生成 Master Secret。每个版本的 DTLS 都有一个定义的 Pseudorandom function（伪随机函数）。对于 DTLS 1.2，伪随机函数会在 ClientHello 和 ServerHello 中获取 Pre-Master Secret 和随机值。 运行 Pseudorandom function 后，获得的输出是 Master Secret。Master Secret 是用于 Cipher 的值。\n交换 ApplicationData #  DTLS 的主要内容是 ApplicationData。现在我们有了一个初始化好的 Cipher，我们可以开始加密和发送数据了。\n如前所述，ApplicationData 消息使用一个 DTLS 标头。Payload 中填充了密文。你现在可以正常使用 DTLS 会话，并且可以安全地进行通信。\nDTLS 具有更多有趣的功能，例如重新协商等。WebRTC 中不使用这些功能，因此此处不作介绍。\nSRTP #  SRTP 是针对加密 RTP 数据包专门涉及的协议。要启动 SRTP 会话，需要指定密钥和 cipher。与 DTLS 不同，它没有握手机制。所有的配置和密钥都是在 DTLS 握手期间生成的。\nDTLS 提供了专用的 API，用来导出密钥以供另一个进程使用。这是在RFC 5705中定义的\n会话创建 #  SRTP 定义了一个密钥派生函数，用于处理输入。在创建 SRTP 会话时，密钥派生函数将被执行，用输入数据生成 SRTP Cipher 的密钥。之后，你可以继续处理媒体。\n交换媒体数据 #  每个 RTP 数据包都有一个 16 位的 SequenceNumber（序列号）。这些序列号用于使数据包保持顺序，就像主键一样。在通话期间，这些序列号将滚动累加。SRTP 会对其进行跟踪，并将其称为滚动计数器。\n加密数据包时，SRTP 使用滚动计数器和序列号作为 nonce。这是为了确保即使两次发送相同的数据，密文也会有所不同。这样做很重要，可以阻止攻击者识别模式或尝试重播攻击。\n"});index.add({'id':4,'href':'/zh/docs/05-real-time-networking/','title':"搭建实时网络",'section':"Docs",'content':"实时网络 #  为什么网络在实时通信中如此重要？ #  网络是实时通信中的限制因素。在理想的世界中，我们将拥有无限的带宽，并且数据包会即时到达。但事实并非如此。网络是受限的，且其限定条件随时可能更改。测量和观察网络状况也是一个难题。根据你所使用的硬件，软件及其配置，你可能看到不同的表现。\n实时通信也带来了其他大多数领域中不存在的问题。对于网站开发人员来说，如果你的网站在某些网络上运行速度较慢，那不是致命问题。只要所有数据到达，用户都会感到满意。但对于 WebRTC，如果你的数据延迟了，那就没用了。没有人在乎 5 秒钟前的电话会议中所说过的话。因此，在开发一个实时通信系统时，必须作出权衡。我的时间限制是多少，可以发送多少数据？\n本章介绍了适用于数据和媒体通信的概念。在后面的章节中，我们将超出理论范围，讨论一下 WebRTC 的媒体和数据子系统如何解决这些问题。\n网络的哪些属性让它很难 ? #  在所有网络上都能有效工作的代码很复杂。你会面对许多不同的因素，它们都可以相互影响。这些是开发人员将遇到的最常见问题。\n带宽 #  带宽是可以在给定路径上传输的最大数据速率。请记住，它不是一个静态数字，这一点很重要。带宽会随着使用者的增多（或减少）而改变。\n传输时间和往返时间 #  传输时间指的是一个数据包需要多长时间到达。像带宽一样，这不是恒定的。传输时间随时可能波动。\n传输时间 = 接收时间 - 发送时间\n要计算传输时间，你需要将发送方和接收方的时钟以毫秒级精度同步。 即使一个很小的偏差也会导致传输时间的测量结果不可靠。 由于 WebRTC 在高度异构的环境中运行，因此依靠主机之间完美的时间同步（来测量传输时间）几乎是不可能的。\n往返时间测量是对不完美的时钟同步的一种解决方法。\n（要测量往返时间，）WebRTC peer 不使用分布式时钟，而是发送一个特殊数据包，携带名为 sendertime1 的自己的时间戳。 合作的 peer 接收到这个特殊数据包后，会将时间戳返还给发送方。 当原始发送方获得返还的时间戳时，它会用当前时间 sendertime2 减去 sendertime1 时间戳。 得到的时间差称为 \u0026quot; 往返传播延迟（round-trip propagation delay）\u0026quot;，或者就使用更常见的 \u0026quot; 往返时间 \u0026ldquo;。\nrtt（往返时间） = sendertime2 - sendertime1\n一般认为，往返时间的一半可以用来较好地近似传输时间。 但此解决方法并非没有缺点。 它假设发送和接收数据包花费的时间是相等的。 但是，在蜂窝网络上，发送和接收操作可能不是时间对称的。 你可能已经注意到了，手机上的上传速度几乎总是低于下载速度。\n传输时间 = rtt（往返时间）/2\n关于往返时间测量的技术，在RTCP 的发送方和接收方报告章节中有更详细的描述。\n抖动 #  抖动是每个数据包的传输时间可能会有所不同的现实表现。你的数据包可能会延迟，但随后会突然大量集中到达。\n数据包丢失 #  数据包丢失是指消息在传输中丢失。数据损失率可能是稳定的，也可能出现波峰和波谷。 这可能是由于网络类型的原因造成的，例如卫星或 Wi-Fi 等。或者也可能是传输路径上的软件导致的。\n最大传输单位（MTU） #  最大传输单位指的是单个数据包大小的限制。网络不允许你发送一个巨大的消息。在协议级别，消息可能必须被拆分为多个较小的数据包。\n根据你采用的网络路径，MTU 也将有所不同。你可以使用MTU 路径发现之类的协议来确定可以发送的最大数据包大小。\n拥塞 #  拥塞是指网络达到极限时的情况。这通常是因为你已达到当前路由可以处理的峰值带宽。或者可能是运营商对你的 ISP 配置导致，比如限制了每小时的流量。\n拥塞会以多种不同的方式展现出来。没有标准化的表现。在大多数情况下，当拥塞发生时，网络将丢弃多余的数据包。在其他一些情况下，网络将缓存数据包。这将导致数据包的传输时间增加。随着网络的拥塞，你还会看到更多的抖动。这是一个快速变化的领域，并且还有其他用于拥塞检测的新算法目前仍在编写中。\n动态变化 #  网络是动态的，各种状况可能会迅速变化。在通话过程中，你可能会发送和接收数十万个数据包。 这些数据包可能经过多个跃点。这些跃点可能由数百万其他用户共享。即使在你的本地网络中，你也可能正在下载高清电影，或者可能有设备正要下载软件更新。\n保证通话质量不能仅仅是在启动时简单的度量你的网络。你需要持续不断的评估。还需要处理来自于多种网络硬件和软件的所有不同表现。\n解决数据包丢失问题 #  处理数据包损失是需要解决的首要问题。有多种解决方法，每种方法都有自己的优势。这取决于你要发送的内容以及对延迟的容忍度。同样重要的一点是，并非所有数据包丢失都是致命的。丢失一些视频可能不是什么问题，人眼甚至可能无法感觉到。但丢掉用户的短信就是不可接受的了。\n假设你发送了 10 个数据包，而数据包 5 和 6 丢失了。下面是一些解决问题的方法。\n确认（Acknowledgments） #  确认是指接收方收到每个数据包时，都去通知发送方。如果发送方收到一个数据包的两次确认消息，且该数据包不是最终数据包时，发送方就会意识到有数据包已经丢失。例如，当发送方两次收到数据包 4 的 ACK 消息时，它就知道接收方没有收到数据包 5。\n选择性确认（Selective Acknowledgments） #  选择性确认是对确认的改进。接收方可以发送一个 SACK 消息来确认多个数据包已经收到，并通知发送者间隔时间。 例如，发送方可能收到一个包含数据包 4 和 7 的 SACK 消息。这样它就知道需要重新发送数据包 5 和 6。\n否定应答（Negative Acknowledgments） #  否定应答以相反的方式解决了问题。接收方并不通知发送方自己已经收到了什么，而是通知发送方丢失了什么。在我们的例子里，将为数据包 5 和 6 发送一个 NACK。发送方仅知道接收方希望再次发送的数据包。\n前向纠错（FEC） #  前向纠错可以抢先解决丢包问题。发送方将发送冗余数据，这意味着部分数据包丢失不会影响最终流。一种流行的算法是 Reed–Solomon 纠错算法。\n这减少了发送和处理确认的延迟 / 复杂度。如果你所在的网络的损耗为零，则前向纠错会浪费带宽。\n解决抖动问题 #  大多数网络都存在抖动。即使在局域网内部，你也有许多设备以变化的速率发送数据。你可以通过运行 ping 命令对其他设备执行 ping 操作，并注意往返延迟的波动，从而轻松地观察到抖动。\n要解决抖动问题，客户端使用 JitterBuffer。JitterBuffer 确保数据包的稳定传递时间。不利的一面是，JitterBuffer 为提前到达的数据包增加了一些延迟。好处是延迟的数据包不会引起抖动。想象一下，在通话期间，你可能会看到类似下面这样的数据包到达时间。\n* time=1.46 ms * time=1.93 ms * time=1.57 ms * time=1.55 ms * time=1.54 ms * time=1.72 ms * time=1.45 ms * time=1.73 ms * time=1.80 ms 在这个例子里，1.8ms 左右将是一个不错的选择。较晚到达的数据包将使用我们的延迟窗口。较早到达的数据包将被延后一点，并可以填充由较晚的数据包耗尽的延迟窗口。这意味着我们不会再陷入无数据包可用的困境，从而为客户提供顺畅的传输率。\nJitterBuffer（抖动缓冲区）操作 #  每个数据包到达时，将立即被添加到抖动缓冲区。 一旦有了足够的数据包来重建帧，组成该帧的数据包将被从缓冲区中释放出来，并发给解码器进行解码。 解码器按顺序进行解码，并在用户屏幕上绘制视频帧。 由于抖动缓冲区的容量是有限的，因此在缓冲区中停放时间过长的数据包将被丢弃。\n关于视频帧是如何转换为 RTP 数据包，以及为何需要重建视频帧的知识，你可以在媒体通信章节中读到更多。\njitterBufferDelay（抖动缓冲延迟）为了解你的网络性能及其对播放平滑度的影响提供了一个很好的视角。 它是WebRTC 统计 API中的一部分，与接收方的入站流有关。 该延迟定义了视频帧在被发给解码器之前在 JitterBuffer 中所花费的时间。 较长的抖动缓冲延迟，意味着你的网络处于高度拥塞状态。\n检测拥塞问题 #  在我们解决拥塞问题之前，我们需要先检测到拥塞。为了检测到它，我们使用拥塞控制器。这是一个复杂的主题，并且仍在迅速变化中。 一些新算法仍在持续被发布和测试。总的来看，它们都以相同的方式运行。即是说，拥塞控制器在给定某些输入的情况下提供带宽估计值。 这里是一些可能的输入：\n 数据包丢失 - 随着网络逐渐变得拥塞，数据包开始被丢弃。 抖动 - 随着网络设备变得越来越过载，将导致数据包排队时间变得不稳定。 封包往返时间（RTT） - 拥塞时，数据包将需要更长的时间才能到达。与抖动不同的是，往返时间是持续增加的。 显式拥塞通知（ECN） - 较新的网络可能会将数据包标记为有拥塞造成丢失的风险，这样可以缓解拥塞。  这些值需要在通话期间持续不断的测量。网络的利用率可能会增加或减少，因此可用带宽可能会不断变化。\n解决拥塞问题 #  现在我们有了一个估计的带宽值，我们需要调整发送的内容。如何调整取决于我们要发送的数据类型。\n降低发送速度 #  限制发送数据的速度是防止拥塞的第一个解决方案。拥塞控制器为你提供了带宽的估计值，发送方有责任对发送速率进行限制。\n这是适用于大多数数据通信的方法。对于像 TCP 这样的协议，这全部由操作系统完成，并且对用户和开发人员都是完全透明的。\n减少发送的数据 #  在某些情况下，我们可以发送更少的信息来满足我们的限制。对于数据的到达时间，我们可能有严格的限制，因此我们发送速度不能太慢。这些是实时媒体所受的限制。\n如果我们没有足够的可用带宽，我们可以降低发送的视频质量。这要求你的视频编码器和拥塞控制器之间存在紧密的反馈回路。\n"});index.add({'id':5,'href':'/zh/docs/06-media-communication/','title':"媒体通信",'section':"Docs",'content':"媒体通信 #  我可以从 WebRTC 的媒体通信中得到什么？ #  WebRTC 允许你发送和接收无限多条音频和视频流。你可以在通话期间随时添加和删除这些流。这些流可以全部独立，也可以捆绑在一起！你甚至可以将网络摄像头的音频和视频放到你桌面的视频中，然后将此视频以 feed 的形式发送出去。\nWebRTC 协议与编解码器无关。底层传输支持所有格式的内容，即使是还不存在的格式！ 但是，你正与之通信的 WebRTC Agent 可能没有必要的工具来接受它。\nWebRTC 针对动态网络状况也有对应的处理方案。在通话过程中，带宽可能会增加或减少。甚至可能突然间大量丢包。该协议对所有这类问题的处理都做了相应的设计。WebRTC 根据网络状况作出响应，并尝试利用可用资源为你提供最佳体验。\n它是如何工作的？ #  WebRTC 使用RFC 1889中定义的两个既有协议 RTP 和 RTCP。\nRTP（实时传输协议 /Real-time Transport Protocol）是承载媒体的协议。它为视频的实时传输而设计。它没有规定有关延迟或可靠性的任何规则，但是为你提供了实现这些规则的工具。RTP 提供了流的设计，因此你可以通过一个连接发布多个媒体源。它还为你提供了完善媒体传递途径所需的计时和排序信息。\nRTCP（RTP 控制协议 /RTP Control Protocol）是用于传达有关呼叫的元数据的协议。其格式非常灵活，并允许你可以添加所需的任何元数据。这点被用来传达有关呼叫的统计信息。也是处理分组丢失和实现拥塞控制的必备特性。它为你提供了响应变化的网络状况所必需的双向通信能力。\n延迟与质量 #  实时媒体就是要在延迟和质量之间进行权衡。你愿意忍受的延迟时间越长，可以预期的视频质量就越高。\n现实世界的局限性 #  下面这些限制都是由现实世界的局限性引起的。它们都是你需要考虑的网络特性。\n视频是复杂的 #  传输视频并不容易。要存储 30 分钟未经压缩的 720p 的 8-bit 视频，你需要大约 110GB。按照这个数据，4 人电话会议就开不成了。我们需要一种缩小容量的方法，而答案就是视频压缩。但是，这并非没有缺点。\n视频 101 #  我们不会深入介绍视频压缩，只需要让大家足以理解为什么 RTP 是这么设计的。视频压缩会将视频编码为一种新格式，这样可以需要较少的 bit 数来表示同一视频。\n有损和无损压缩 #  你可以将视频编码为无损（无信息丢失）或有损（信息可能丢失）压缩。由于无损编码需要将更多的数据发送到对端，这样会导致更高的流延迟和更多的丢包，因此 RTP 通常使用有损压缩，即使这样可能会导致视频质量不佳。\n帧内和帧间压缩 #  视频压缩有两种类型。首先是帧内压缩。帧内压缩减少了用于描述单个视频帧的 bit 数。相同的技术被用来压缩静态图片，例如 JPEG 压缩方法。\n第二种类型是帧间压缩。由于视频是由许多图片组成的，因此我们需要寻找无需将相同信息发送两次的方式。\n帧间压缩 #  帧有三种类型：\n I 帧 - 一张完整的图片，无需任何其他内容即可解码。 P 帧 - 一张图片的一部分，仅包含对之前图片的修改。 B 帧 - 一张图片的一部分，包含对之前图片和将来图片的修改。  以下是对这三种类型帧的图解。\n视频很脆弱 #  压缩后的视频是有状态的，（视频解码）非常依赖其上下文，这使得视频很难通过 Internet 进行传输。想像一下，如果 I 帧的一部分丢失了会怎样？这样 P 帧如何知道要修改的内容？ 随着视频压缩变得越来越复杂，这成为一个更大的问题。幸运的是，RTP 和 RTCP 对此都有解决方案。\nRTP #  Packet Format（包格式） #  每个 RTP 数据包都具有以下结构：\n 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ |V=2|P|X| CC |M| PT | Sequence Number | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Timestamp | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Synchronization Source (SSRC) identifier | +=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+ | Contributing Source (CSRC) identifiers | | .... | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Payload | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ Version (V) #  Version 总是 2。\nPadding (P) #  Padding 是控制有效载荷是否具有填充值的布尔值。\n有效负载的最后一个字节包含添加了多少填充字节的计数。\nExtension (X) #  如果设置的话，RTP 报头将有扩展段（可选）。这点将在下面更详细地描述。\nCSRC count (CC) #  在 SSRC 之后，有效负载之前的 CSRC 标识符的数量。\nMarker (M) #  标记位没有预设含义，用户可以根据自己的需求随意使用它。\n在某些情况下，它是在用户讲话时设置的。它还通常用于标记关键帧。\nPayload Type (PT) #  Payload Type（负载类型）是此数据包所承载的编解码器的一个唯一标识符。\n对于 WebRTC，Payload Type 是动态的。一个呼叫中的 VP8 的 PT 可能与另一个呼叫中的不同。呼叫中的 offerer 确定 Payload Type 到 Session Description（会话描述符）中的编解码器的映射。\nSequence Number #  Sequence Number（序列号）用于对流中的数据包进行排序。每次发送数据包时，Sequence Number 都会增加 1。\nRTP 被设计为可以在有损网络上使用。这为接收器提供了一种检测数据包何时丢失的方法。\nTimestamp #  此数据包的采样时刻。这不是全局时钟，而是在当前媒体流中所经过的时间。举例来说，如果多个 RTP 包都属于同一视频帧，那么它们可能具有相同的时间戳。\nSynchronization Source (SSRC) #  SSRC 是此流的唯一标识符。这使你可以在单个 RTP 流上传输多个媒体流。\nContributing Source (CSRC) #  一个列表，用于表示哪些 SSRC 参与到了这个数据包中。\n这通常用于语音指示器。假设在服务器端，你将多个音频源组合到一个单独的 RTP 流中。然后，你可以在此字段中表示 \u0026quot; 输入流 A 和 C 此时正在讲话 \u0026ldquo;。\nPayload #  实际有效负载数据。如果设置了填充（padding）标记，则可能以添加的填充字节数结尾。\nExtensions（扩展） #  RTCP #  Packet Format #  每个 RTCP 数据包都具有以下结构：\n 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ |V=2|P| RC | PT | length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Payload | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ Version (V) #  Version 总是 2。\nPadding (P) #  Padding 是控制有效载荷是否具有填充值的布尔值。\n有效负载的最后一个字节包含添加了多少填充字节的计数。\nReception Report Count (RC) #  此数据包中的报告数。单个 RTCP 数据包可以包含多个事件。\nPacket Type (PT) #  指示 RTCP 数据包类型的唯一标识符。WebRTC Agent 不需要支持所有这些类型，并且 Agent 之间的支持能力可以是不同的。下面这些是你可能经常看到的类型：\n 192 - 完整的帧内请求（FIR）- 193 - 否定确认（NACK） 200 - 发送方报告 201 - 接收方报告 205 - 通用 RTP 反馈 206 - 有效负载特定反馈  这些分组类型的意义将在下面更详细地描述。\n完整的帧内请求（FIR）和图片丢失指示（PLI） #  FIR 和 PLI 消息的目的是类似的。这些消息都是向发送方请求一个完整的关键帧。 PLI 用于解码器得到了部分帧，但却无法解码的情况。 之所以会发生这种情况，是因为你有很多数据包丢失，或者解码器崩溃了。\n根据RFC 5104，当数据包或帧丢失时，不应使用 FIR，那是 PLI 的任务。用 FIR 请求关键帧适用于丢包以外的其他原因（例如，当新成员进入视频会议时）。他们需要一个完整的关键帧才能开始对视频流进行解码，解码器将丢弃一些帧，直到关键帧到达为止。\n对于接收方来说，在连接建立后立即请求一个完整的关键帧是个好主意，这可以最大程度地减少连接建立和在用户屏幕上显示图像之间的延迟。\nPLI 数据包是 \u0026quot; 有效负载特定反馈 \u0026quot; 消息的组成部分。\n在实践中，能够同时处理 PLI 和 FIR 数据包的软件在两种场景下的行为是相同的。它会向编码器发送信号以产生新的完整关键帧。\nNegative ACKnowledgements（否定确认） #  NACK 请求发送方重新发送单个 RTP 数据包。这通常是由于 RTP 数据包丢失而引起的，但是也可能由于延迟而发生。\n与请求重新发送整个帧相比，NACK 的带宽使用效率要高得多。由于 RTP 将数据包分解成很小的块，因此你实际上只是在请求丢失的一个很小的部分。接收方使用 SSRC 和序列号制作 RTCP 消息。如果发送方没有可用于重新发送的 RTP 数据包，那么它只会忽略该消息。\nSender and Receiver Reports（发送方和接收方报告） #  这些报告用于在 Agent 之间发送统计信息。它传达了实际接收到的和抖动的数据包数量。\n这些报告可用于诊断以及控制拥塞。\nRTP/RTCP 是如何协作解决问题的 #  RTP 和 RTCP 需要协同解决网络引起的所有问题。这些技术仍在不断进化中！\nForward Error Correction（前向纠错） #  简称为 FEC。处理丢包的另一种方法。FEC 指的是发送方多次重复发送相同的数据，甚至是在接收方没有要求的情况下发送。这是在 RTP 协议层级完成的，甚至也可以在编解码器以下的层级完成。\n在呼叫的数据丢包率比较稳定的情况下，作为延迟处理方案，FEC 比 NACK 好的多。对于 NACK，必须先请求，然后重新传输丢失的数据包，数据往返的时间对性能的影响可能是很明显的。\n自适应比特率和带宽估计 #  正如搭建实时网络章节中讨论的那样，网络是不可预测且不可靠的。带宽的可用性在整个会话中可能会多次变化。 在一秒钟之内看到可用的带宽急剧变化（差别达到数量级），这样的情况并不少见。\n这里的主要思路是根据预测的，当前的和将来的可用网络带宽来调整编码比特率。 这样可以确保传输质量最佳的视频和音频信号，并且不会因为网络拥塞而断开连接。 对网络行为建模并尝试对其进行预测的启发式方法称为带宽估计。\n这里有很多细微的差别，因此，让我们来探索一下更多细节。\n识别和传递网络状态 #  RTP/RTCP 可能运行在各种不同的网络上，因此，通讯中出现丢包是很常见的。建立在 UDP 传输协议之上，没有内置的丢包重传机制，更不用说处理拥塞控制了。\n为了给用户提供最好的体验，WebRTC 必须评估网络路径的质量，并且随时适应网络质量的波动。要监控的关键特征包括： 带宽（在每个方向上，因为双向带宽可能是不对称的）、往返时间和抖动。它需要考虑数据包丢失，并随时传递这些属性特征的变化情况。\n这些协议有两个主要目标：\n 评估网络支持的可用带宽（双向） 发送者和接收者之间的通信网络特性  RTP/RTCP 有三种不同的方法来解决这个问题。他们都有自己的优点和缺点， 总的来说，每一代都比其上一代有所改进。使用哪种实现方式主要取决于客户可用的软件堆栈和可用的基础库。\nReceiver Reports / Sender Reports #  第一种实现是一对接收者报告及其补充——发送者报告。这些 RTCP 消息在 RFC 3550 中定义，并且是 负责在端点之间传递网络状态。 Receiver Reports 侧重于 关于网络的通信质量（包括丢包、往返时间和抖动），可以配合其他算法，利用这些报告信息进行评估。\nSender / Receiver Reports（SR 和 RR）共同描绘了网络质量。他们是以每个 SSRC 为粒度按计划发送，作为评估可用带宽的输入数据。这些评估是由发送者在收到 RR 数据后做出的，其中包含 以下字段：\n Fraction Lost(丢包率) - 自上次接收者报告以来丢失了数据包的百分比。 Cumulative Number of Packets Lost(累计丢包数) - 在整个通话过程中丢了多少包。 Extended Highest Sequence Number Received(接收到的最高序列号扩展) - 接收到的最后一个序列号，以及它的重置次数。 到达间隔抖动（Interarrival Jitter） - 整个通话过程中的抖动滚动。（译注：RTP 数据包到达时间的统计方差的估计值，以时间戳为单位进行度量，并表示为无符号整数。） 上次发送方报告时间戳（Last Sender Report Timestamp） - 已知的最后一次的发送方报告的时间戳，用于往返时间的计算。  发送方和接收方报告（SR 和 RR）配合，可以计算往返时间。\n发送方在 SR 中包含其本地时间 sendertime1。 当接收方获得 SR 数据包时，发回 RR。 除了其他一些信息，RR 还要包括刚从发送方接收到的 sendertime1。 在接收 SR 和发送 RR 之间，会有一个延迟。因此，RR 还包括 \u0026quot; 自上次发送方报告以来的延迟 \u0026quot; 时间 - DLSR（delay since last sender report）。 DLSR 用于在该过程的稍后阶段调整往返时间的估计。 一旦发送者接收到 RR，它就从当前时间 sendertime2 中减去 sendertime1 和 DLSR。 这个时间增量称为往返传播延迟或往返时间。\nrtt（往返时间） = sendertime2 - sendertime1 - DLSR\n换个简单的说法来解释，就是这样：\n 我看了看表，向你发送了一条消息，说这是下午 4 点 20 分 42 秒 420 毫秒。 你再将相同的时间戳发回给我。 （返回的消息中）还包括了从阅读我的消息到发回消息所花费的时间，例如 5 毫秒。 收到时间后，我会再次看时钟。 现在我的表是下午 4 点 20 分 42 秒 690 毫秒。 这意味着消息需要 265 毫秒（690-420-5）才能到达你，并返回到我。 因此，往返时间为 265 毫秒。  TMMBR，TMMBN，REMB 和 TWCC, 与 GCC 配合 #  Google Congestion Control (GCC) #  Google 拥塞控制 (GCC) 算法（在draft-ietf-rmcat-gcc-02) 解决了带宽估计的挑战。 它与各种其他协议配合，以应对相应的通信需求。 因此，它非常适合在任一接收端（当使用 TMMBR/TMMBN 或 REMB 运行时）或发送端（当使用 TWCC 运行时）。\n为了估算可用带宽，GCC 关注数据包丢失和帧到达时间的波动作为其两个主要指标。 它通过两个链接的控制器运行这些指标： 基于损失的 (loss-based) 控制器和基于延迟的 (delay-based) 控制器。\nGCC 的第一个控制器是基于丢失的控制器，原理很简单：\n 如果丢包率超过 10%，带宽估计会降低 如果丢包率在 2-10% 之间，带宽估计保持不变 如果丢包率低于 2%，带宽估计会增加  频繁地进行丢包测量。 根据配对的通信协议，丢包可能是明确传达的（如 TWCC）或推断的（如 TMMBR/TMMBN 和 REMB）。 这些百分比是在大约一秒的时间窗口内评估的。\n第二个控制器与基于丢失的控制器合作，并关注数据包的变化到达时间。这种基于延迟的控制器旨在识别网络链接何时变得越来越拥挤，甚至可能在丢包发生之前就降低带宽估计。理论上，路径上最繁忙的网络接口将继续将数据包排队直到接口耗尽其缓冲区内的容量。如果该接口继续接收超过它能够发送的流量，它将被迫丢弃缓冲空间中无法容纳的所有数据包。这种类型的数据包丢失对于低延迟 / 实时通信场景尤其具有破坏性，同时它也会降低该链路上所有通信的吞吐量，所以最好应该避免。因此，GCC 试图在丢包实际发生之前，弄清楚网络链接是否越来越大队列深度。如果它观察到，随着时间的推移排队延迟增加了，它将主动减少带宽使用。\n为了实现这一点，GCC 尝试通过测量往返时间的微量增加，来推断队列深度的增加。 它记录帧的“到达间隔时间”，t(i) - t(i-1)：即两组数据包（通常是连续的视频帧）的到达时间差。这些数据包组经常 以固定的时间间隔出发（例如，对于 24 fps 的视频，每 1/24 秒）。 因此，测量到达间隔时间，就像记录第一个数据包组（即帧）的开始和下一个数据包组的第一帧之间的时间差一样简单。\n在下图中，数据包间延迟增加的中位数为 +20 毫秒，这是一个明确的指标网络拥塞。\n如果到达间隔时间随着时间的推移而增加，则假定连接网络接口上的队列深度增加并被认为是网络拥塞的证据。 （注意：GCC 足够聪明，可以控制这些测量以应对帧字节大小的波动。）GCC 使用 Kalman 滤波器改进其延迟测量，并在标记拥塞之前多次测量网络往返时间（及其变化）。可以将 GCC 的卡尔曼滤波器视为代替线性回归：即使在抖动将噪声添加到时序测量中时，也有助于做出准确的预测。在标记拥塞时，GCC 将降低可用比特率。或者，在稳定的网络条件下，它可以缓慢增加其带宽评估以测试更高的负载值。\nTMMBR, TMMBN, and REMB #  对于 TMMBR/TMMBN 和 REMB，接收方首先估计可用的入口带宽（使用 GCC 等协议），然后将这些带宽评估值传达给远程发送者。他们不需要交换有关丢包的详细信息或有关网络拥塞的其他质量（因为在接收端进行操作可以直接测量到达的间隔时间和丢包） 而是只交换带宽评估值本身：\n TMMBR（临时最大媒体码率请求） - 单个 SSRC 请求码率的尾数 / 指数。（译注：接收端当前带宽受限，告诉发送端控制码率。） TMMBN（临时最大媒体码率通知） - （发送端）通知（接收端）已经收到 TMMBR 的消息。 REMB（接收方估计的最大码率） - 整个会话中请求码率的尾数 / 指数。  TMMBR 和 TMMBN 是先出现的，它们在RFC 5104中定义。REMB 是后来出现的，是在draft-alvestrand-rmcat-remb中提交的一个草案，但从未被标准化。\n使用 REMB 的会话如下图所示：\n这个方法在纸面上看起来效果很好。发送方从接收方接收估计值，然后将编码器比特率设置为接收到的值。啊哈！我们已经根据网络条件作出了调节。\n然而，在实践中，REMB 方法有几个缺点。\n首先就是编码器效率低下。当您为编码器设置比特率时，它不一定 输出您要求的确切比特率。编码可能会输出更多或更少的位，具体取决于 编码器设置和被编码的帧。\n举例来说，x264 编码器，配置为 tune=zerolatency，跟指定的目标比特率相比，其输出可能会产生明显的偏离。下面是一种可能的场景：\n 假设我们一开始将比特率设置为 1000kbps。 由于没有很多高频特征值需要编码，编码器只能输出 700kbps。（亦称为：\u0026rdquo; 凝视一堵墙 \u0026ldquo;。） 我们再假设接收方获得了 700kbps 的视频，没有发生数据包丢失，然后它将应用 REMB 的规则 1，把输入比特率提升 8％。 接收方向发送方发送了一个 REMB 包，建议将输入比特率提高到 756kbps（700kbps * 1.08）。 发送方将编码器的比特率设置为 756kbps。 编码器输出更低的比特率。 这个过程会继续重复进行，这样，比特率会被降低到绝对最小值。  你可以看到，这会导致编码器多次触发参数调整；同时用户会惊讶的发现，虽然连接状况良好，但视频质量看起来却让人难以接受。\n传输范围内的拥塞控制（TWCC） #  Transport Wide Congestion Control 是 RTCP 网络状态的最新发展 沟通。 它定义在draft-holmer-rmcat-transport-wide-cc-extensions-01, 但一直未被标准化。\nTWCC 使用了一个非常简单的原理：\n使用 REMB，接收方以可用的下载比特率指示发送方。它使用关于推断的数据包丢失的精确测量和仅它具有的关于数据包间到达时间的数据。\nTWCC 可以看作是 SR/RR 和 REMB 协议的混合方法。它将带宽估计带回发送方（类似于 SR/RR），但其带宽估计技术更类似于 REMB 生成。\n使用 TWCC，接收方让发送方知道每个数据包的到达时间。这是足以让发送者测量数据包之间到达延迟的变化，以及识别哪些数据包丢失或到达太晚而不能提供音频 / 视频源。随着这些数据的频繁交换，发送方能够快速调整以适应不断变化的网络条件，并使用诸如 GCC 的算法改变其输出带宽。\n发送者跟踪发送的数据包、它们的序列号、大小和时间戳。当发送方接收到来自接收方的 RTCP 消息时，它会将发送包间延迟与接收延迟进行比较。如果接收延迟增加，则表明网络拥塞，发送方必须采取纠正措施。\n通过向发送者提供原始数据，TWCC 提供了实时网络状况的绝佳视图：\n 几乎是即时的丢包行为，具体到单个丢包 准确的发送比特率 准确的接收比特率 抖动测量 发送和接收数据包延迟之间的差异 描述网络如何容忍突发或稳定的带宽传输  TWCC 最重要的贡献之一是它为 WebRTC 开发人员提供的灵活性。通过将拥塞控制算法整合到发送端，它允许简单的客户端代码被广泛使用，并且随着时间的推移需要最少的增强。然后可以在它们直接控制的硬件上更快地迭代复杂的拥塞控制算法（如第 8 节中讨论的选择性转发单元）。对于浏览器和移动设备，这意味着这些客户端可以从算法增强中受益，而无需等待标准化或浏览器更新（这可能需要很长时间才能被广泛使用）。\n生成带宽估计值 #  部署最多的实现是“A Google Congestion Control Algorithm for Real-Time Communication”，定义在 draft-alvestrand-rmcat-congestion。\nGCC 有几种替代方案，例如\n NADA: A Unified Congestion Control Scheme forReal-Time Media SCReAM - 自时钟多媒体速率适应。  "});index.add({'id':6,'href':'/zh/docs/07-data-communication/','title':"数据通信",'section':"Docs",'content':"数据通信 #  我可以从 WebRTC 的数据通信中获得什么？ #  WebRTC 提供用于数据通信的数据通道。在两个 peer 之间，你可以打开 65,534 个数据通道。 数据通道基于数据报，并且每个通道都有其自己的持久性设置。默认设置下，每个数据通道都能保证有序交付。\n如果你从传递媒体数据的角度开始接触 WebRTC，可能数据通道看起来是一种浪费。当我只使用 HTTP 或 WebSocket 就能传递数据的时候，为什么需要整个数据通道子系统呢？\n数据通道的真正强大之处在于，你可以将它们配置为像 UDP 一样进行无序 / 有损传递。 对于低延迟和高性能的情况，这是必需的。你可以测量背压，并确保你仅发送网络支持的最大数据量。\n它是如何工作的？ #  WebRTC 使用RFC 4960中定义的流控制传输协议（SCTP）。SCTP 是一种传输层协议，旨在替代 TCP 或 UDP。对于 WebRTC，我们将 SCTP 用作在 DTLS 连接上运行的应用层协议。\nSCTP 为你提供流，并且每个流都可以独立配置。WebRTC 数据通道只是基于流的简单抽象。有关持久性和顺序的设置会被直接传递到 SCTP Agent 中。\n数据通道具有 SCTP 无法表达的某些功能，例如通道标签。为了解决该问题，WebRTC 使用了RFC 8832中定义的数据通道建立协议（DCEP）。DCEP 定义了一条消息，用于传递通道标签和协议。\nDCEP #  DCEP 只有两个消息 DATA_CHANNEL_OPEN 和 DATA_CHANNEL_ACK。对于打开的每个数据通道，远端必须以 ack 响应。\nDATA_CHANNEL_OPEN #  该消息由希望打开数据通道的 WebRTC Agent 发送。\n封包格式 #   0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Message Type | Channel Type | Priority | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Reliability Parameter | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Label Length | Protocol Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \\ \\ / Label / \\ \\ +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \\ \\ / Protocol / \\ \\ +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ 消息类型（Message Type） #  消息类型是一个静态值 0x03。\n通道类型（Channel Type） #  Channel Type controls durability/ordering attributes of the channel. It may have the following values: 通道类型控制通道的持久性 / 排序属性。它可能具有以下值：\n DATA_CHANNEL_RELIABLE (0x00) - 没有消息丢失，消息依序到达。 DATA_CHANNEL_RELIABLE_UNORDERED (0x80) - 没有消息丢失，但消息可能乱序到达。 DATA_CHANNEL_PARTIAL_RELIABLE_REXMIT (0x01) - 按照请求中的次数重试发送后，消息可能会丢失，但消息将依序到达。 DATA_CHANNEL_PARTIAL_RELIABLE_REXMIT_UNORDERED (0x81) - 按照请求中的次数重试发送后，消息可能会丢失，且消息可能乱序到达。 DATA_CHANNEL_PARTIAL_RELIABLE_TIMED (0x02) - 如果没有在请求的时间内到达，消息可能会丢失，但消息将依序到达。 DATA_CHANNEL_PARTIAL_RELIABLE_TIMED_UNORDERED (0x82) - 如果没有在请求的时间内到达，消息可能会丢失，且消息可能乱序到达。  优先级（Priority） #  数据通道的优先级。具有较高优先级的数据通道将首先被调度。较大的低优先级用户消息不会耽误高优先级用户消息的发送。\n可靠性参数 #  如果数据通道类型的前缀为 DATA_CHANNEL_PARTIAL_RELIABLE，则不同的后缀对应的参数配置如下：\n REXMIT - 定义发送方重试发送消息的次数，超出此次数将放弃尝试。 TIMED - 定义发送方重试发送消息的时间（以毫秒为单位），超出此时间将放弃尝试。  标签（Label） #  一个包含数据通道名称的 UTF-8 编码的字符串。可能为空。\n协议（Protocol） #  如果这里为空字符串，则协议未指定。如果是非空字符串，则这里应指定一个协议，可指定的协议请参考RFC 6455中定义的 \u0026ldquo;WebSocket 子协议名称注册表 \u0026quot; 中的注册协议。\nDATA_CHANNEL_ACK #  WebRTC Agent 发送此消息以确认此数据通道已打开。\n封包格式 #   0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Message Type | +-+-+-+-+-+-+-+-+ 流控传输协议（SCTP） #  SCTP 是 WebRTC 数据通道背后的真正动力。它提供了数据通道的以下所有功能：\n 多路复用 使用类似 TCP 的重传机制进行可靠传递 部分可靠性选项 避免拥塞 流量控制  为了理解 SCTP，我们将分三个部分进行探讨。我们的目标是，在本章之后，你将拥有足够的知识来自行调试和学习 SCTP 的详细信息。\n概念 #  SCTP 协议功能很多。本节仅涵盖 WebRTC 使用的 SCTP 部分。 SCTP 中，WebRTC 不使用的功能包括多宿主（multi-homing）和路径选择。\n经过 20 多年的发展，SCTP 变得难以完全掌握。\n关联（Association） #  关联是用于 SCTP 会话的术语。这是两个 SCTP Agent 在通信时共享的状态。\n流 #  一个流是用户数据的一个双向序列。创建数据通道时，实际上只是在创建一个 SCTP 流。每个 SCTP 关联都包含一个流列表。可以为每个流配置不同的可靠性类型。\nWebRTC 只允许你在创建流时进行配置，而 SCTP 实际上允许随时更改配置。\n基于数据报 #  SCTP 将数据构造为数据报，而不是字节流。发送和接收数据就像是使用 UDP 而不是 TCP。 你无需添加任何额外的代码即可通过一个流传输多个文件。\nSCTP 消息没有像 UDP 这样的大小限制。单个 SCTP 消息的大小可以达到几个 GB。\n块（Chunks） #  SCTP 协议由块组成。有许多不同类型的块。这些块用于所有通信。 用户数据，连接初始化，拥塞控制等，全部通过块完成。\n每个 SCTP 数据包都包含一个块列表。因此，在一个 UDP 数据包中，你可以有多个块承载来自不同流的消息。\n传输序列号 #  传输序列号（TSN）是 DATA 块的全局唯一标识符。DATA 块承载用户希望发送的所有消息。TSN 很重要，因为它可以帮助接收方确定数据包是否丢失或乱序。\n如果接收方注意到缺少 TSN，则在数据完整获取之前，它不应将数据提供给用户。\n流标识符 #  每个流都有一个唯一的标识符。当你创建带有显式 ID 的数据通道时，实际上是将其作为流标识符直接传递到 SCTP 中。如果你没有传递 ID，则会为你自动选择流标识符。\n有效负载协议标识符 #  每个 DATA 块还具有一个有效负载协议标识符（PPID）。这用于唯一地标识正在交换的数据类型。 SCTP 具有许多 PPID，但是 WebRTC 仅使用以下五种：\n WebRTC DCEP (50) - DCEP 消息。 WebRTC String (51) - Datachannel 字符串消息。 WebRTC Binary (53) - Datachannel 二进制消息。 WebRTC String Empty (56) - 长度为 0 的 Datachannel 字符串消息。 WebRTC Binary Empty (57) - 长度为 0 的 Datachannel 二进制消息。  协议 #  以下是 SCTP 协议使用的一些块。这不是一个详尽的演示。只提供了足够的结构让状态机运作起来。\n每个块均以 type 字段开头。在块列表之前，还有一个头字段。\nDATA 块 #   0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Type = 0 | Reserved|U|B|E| Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | TSN | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Stream Identifier | Stream Sequence Number | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Payload Protocol Identifier | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \\ \\ / User Data / \\ \\ +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ DATA 块是交换所有用户数据的方式。下面是对 DATA 块更详细的说明，数据就是这样通过数据通道被发送的。\n如果是无序数据包，则将 U 位设置为 1。我们可以忽略流序列号（Stream Sequence Number）。\nB 和 E 是开始位和结束位。如果要发送的消息对于单个 DATA 块而言太大，则需要将其分片成多个 DATA 块发送。 SCTP 使用 比特位 B 和 E 以及序列号（TSN）来描述消息分包。\n B=1, E=0 - 用户消息的第一个分片。 B=0, E=0 - 用户消息的中间的分片。 B=0, E=1 - 用户消息的最后一个分片。 B=1, E=1 - 未分片的用户消息。  TSN 是 Transmission Sequence Number，一个 DATA chunk 的唯一标识符。它是一个递增的 32-bit 数，在达到最大值 4,294,967,295 之后，继续从 0 开始递增。\nStream Identifier（流标识符）是该数据所属流的唯一标识符。\nStream Sequence Number , 标识一个用户消息。它是一个递增的 16-bit 数，在 达到最大值 65535 之后，继续从 0 开始递增。 比特位 U 设置为 1 时，表示无序消息包，Stream Sequence Number 可以忽略。 比特位 U 设置为 0 时，表示有序消息包，该编号用于确定消息包的顺序。 与 TSN 类似，但是 Stream Sequence Number 以一个用户消息的粒度递增，TSN 以一个 Chunk 的粒度递增。\nPayload Protocol Identifier（有效负载协议标识符）是流过此流的数据类型。对于 WebRTC 而言，它可能是 DCEP，String 或 Binary。\nUser Data（用户数据）就是你要发送的内容。通过 WebRTC Data Channel 发送的所有数据均通过 DATA 块传输。\nINIT 块 #   0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Type = 1 | Chunk Flags | Chunk Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Initiate Tag | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Advertised Receiver Window Credit (a_rwnd) | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Number of Outbound Streams | Number of Inbound Streams | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Initial TSN | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \\ \\ / Optional/Variable-Length Parameters / \\ \\ +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ INIT 块开始创建一个关联（association）的过程。\nInitiate Tag（启动标签）用于生成 Cookie。Cookies 技术在中间人攻击和 DoS 保护中可能会被用到。在状态机章节中对它们进行了更详细的描述。\nAdvertised Receiver Window Credit（广播接收者窗口信用值）用于 SCTP 的拥塞控制。它传达了接收方已为此关联分配了多大的缓冲区。\nNumber of Outbound/Inbound Streams（出站 / 入站流的数量）通知该 Agent 支持多少个流。\nInitial TSN（初始 TSN）是随机的 uint32，本地 TSN 以这个值开始计数。\nOptional Parameters（可选参数）允许 SCTP 向协议引入新功能。\nSACK 块 #   0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Type = 3 |Chunk Flags | Chunk Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Cumulative TSN Ack | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Advertised Receiver Window Credit (a_rwnd) | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Number of Gap Ack Blocks = N | Number of Duplicate TSNs = X | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Gap Ack Block #1 Start | Gap Ack Block #1 End | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ / / \\ ... \\ / / +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Gap Ack Block #N Start | Gap Ack Block #N End | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Duplicate TSN 1 | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ / / \\ ... \\ / / +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Duplicate TSN X | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ SACK（选择性确认）块是接收方通知发送方它已收到数据包信息的方式。在发送方获得针对 TSN 的 SACK 之前，它将重新发送有问题的 DATA 块。然而，SACK 的作用不只是更新 TSN 信息。\nCumulative TSN ACK（累积 TSN ACK）是已收到的最高 TSN。\nAdvertised Receiver Window Credit（广播接收者窗口信用值）是接收方的缓冲区大小。如果可用内存增加，接收方可以在会话期间更改此设置。\n在 Cumulative TSN ACK（累积 TSN ACK）后面，是 Ack Blocks 的 TSN。 这个方法用来解决传送的数据包中有缺口的问题。假设我们收到了带有 TSN100,102,103 和 104 的 DATA 块。Cumulative TSN ACK 应该是 100，但可以使用 Ack Blocks 来告诉发送方不需要重新发送 102,103 或 104。\nDuplicate TSN（重复 TSN）会通知发送方，它已经不止一次的接收了哪些 DATA 数据块。\nHEARTBEAT 块 #   0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Type = 4 | Chunk Flags | Heartbeat Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \\ \\ / Heartbeat Information TLV (Variable-Length) / \\ \\ +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ HEARTBEAT 块用于断言远端仍能响应。 当你不发送任何 DATA 数据块，且需要保持 NAT 映射打开时，这很有用。\nABORT 块 #   0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Type = 6 |Reserved |T| Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ / / \\ Zero or more Error Causes \\ / / +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ ABORT 块用于关联的突然关闭。当一侧进入错误状态时使用。正常结束连接使用 SHUTDOWN 块。\nSHUTDOWN 块 #   0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Type = 7 | Chunk Flags | Length = 8 | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Cumulative TSN Ack | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ SHUTDOWN 块将正常关闭 SCTP 关联。 每个 Agent 将其发送的最后一个 TSN 通知给远端。这样可以确保不会丢失任何数据包。（如果有资源仍在使用中的话，）WebRTC 不能正常关闭 SCTP 关联。你需要自行关闭所有数据通道。\nCumulative TSN ACK（累积 TSN ACK）是发送的最后一个 TSN。双方都知道在接收到此 TSN 对应的 DATA 块之前不要终止。\nERROR 块 #   0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Type = 9 | Chunk Flags | Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \\ \\ / One or more Error Causes / \\ \\ +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ ERROR 块用于通知远端 SCTP Agent：本端发生了非致命错误。\nFORWARD TSN 块 #   0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Type = 192 | Flags = 0x00 | Length = Variable | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | New Cumulative TSN | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Stream-1 | Stream Sequence-1 | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \\ / / \\ +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Stream-N | Stream Sequence-N | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ FORWARD TSN 块将全局 TSN 向前移动。SCTP 这样做是为了允许跳过一些你不再关心的数据包。假设你发送了 10 11 12 13 14 15，这些数据包只有在它们全部到达后才有意义。而这些数据又对实时性很敏感，在这种情况下，如果数据收晚了，它们就没有用了。\n如果你丢失了 12 和 13，则不需要再发送 14 和 15！ SCTP 使用 FORWARD TSN 块来实现这一点。它告诉接收方，14 和 15 将不再传递。\nNew Cumulative TSN（新的累积 TSN），是连接的新 TSN。此 TSN 之前的任何数据包都不会被保留。\nStream（流）和 Stream Sequence（流序列）用于将 Stream Sequence Number 的编号向前跳转。请参阅前面的 DATA 块以了解该字段的重要性。\n状态机 #  这里是 SCTP 状态机中一些有趣的部分。WebRTC 并未使用 SCTP 状态机的所有功能，因此我们将没有用到的部分排除在外。我们还简化了一些组件，使它们更易于理解。\n连接建立流程 #  INIT 和 INIT ACK 块用于交换 peer 的能力和配置。SCTP 在握手期间使用 cookie 来验证与之通信的 peer。 这是为了确保握手不会被拦截并防止 DoS 攻击。\nINIT ACK 块包含 cookie。然后，使用 COOKIE ECHO 将 cookie 返回给其创建者。如果 cookie 验证成功，则发送 COOKIE ACK，并且准备交换 DATA 块。\n连接关闭流程 #  SCTP 使用 SHUTDOWN 块。当 Agent 收到 SHUTDOWN 块时，它将等待直到收到请求的 Cumulative TSN ACK。这样，即使连接有损，用户也可以确保传送了所有数据。\nKeep-Alive（保持活动）机制 #  SCTP 使用 HEARTBEAT REQUEST 和 HEARTBEAT ACK 块使连接保持活动状态。它们以固定间隔发送，间隔时间可配置。如果数据包尚未到达，SCTP 还会将指数回退。\nHEARTBEAT 块还包含一个时间值。两个关联可以用此来计算两个 Agent 之间的数据传递时间。\n"});index.add({'id':7,'href':'/zh/docs/08-applied-webrtc/','title':"WebRTC 应用场景",'section':"Docs",'content':"WebRTC 应用场景 #  现在你已经知道 WebRTC 的工作原理，到了使用它的时候了！本章探讨人们使用 WebRTC 构建什么以及他们是如何实现的。你将学到基于 WebRTC 发生的所有有趣的事情。WebRTC 的功能是有代价的。建立产品级的 WebRTC 服务相当有挑战性。本章将尝试解释这些挑战性的根源，这样你遇到问题时就能有所准备。\n用例 #  许多人认为 WebRTC 只是一种在 web 浏览器中实现电话会议的技术。实际上，它能做的不仅如此！ WebRTC 被广泛用于各种用例。新的用例一直在出现。在本章中，我们将列出一些常见的用例，并探讨一下 WebRTC 是如何对它们进行革新的。\n电话会议 #  电话会议是 WebRTC 的原始用例。该协议包含浏览器中几个必要功能，这些功能没有其他协议提供支持。你可以使用 WebSockets 构建会议系统，在各种条件都满足的情况下，它可能可以工作。但如果你希望在现实世界的网络条件下部署一些服务，那么 WebRTC 是最佳选择。\nWebRTC 为媒体提供拥塞控制和自适应比特率。随着网络条件的变化，用户仍将获得最佳体验。开发人员不必编写任何其他代码来处理这些情况。\n参与者可以发送和接收多个流。在呼叫过程中，他们还可以随时添加和删除这些流。编解码器也经过协商。所有这些功能都是由浏览器提供的，开发人员无需编写任何自定义代码。\n数据通道也对电话会议有所助益。用户可以发送元数据或共享文档。如果更看重性能而不是可靠性，可以创建多个流并对其进行配置。\n广播 #  许多使用 WebRTC 的新项目开始出现在广播领域中。协议为媒体的发布者和消费者都提供了很多支持。\n浏览器中的 WebRTC 使得用户可以轻松发布视频。这样用户不需要下载新的客户端。 任何具有 Web 浏览器的平台都可以发布视频。发布者可以发送多个音轨 / 视频流，并可以随时对其进行修改或删除。传统协议中每个连接只允许一个音频或一个视频流，与之相比，这是一个巨大的改进。\nWebRTC 使开发人员可以更好地控制延迟和质量之间的权衡。如果不允许延迟超过特定阈值更重要，那么为此你可能愿意容忍对解码质量做一些让步。你也可以将播放器配置为在媒体到达时立即播放。如果是使用在 TCP 之上的其他协议，要完成这一点并不是那么容易。但在浏览器中，你只需要请求数据，就这么简单。\n远程访问 #  远程访问是当你通过 WebRTC 访问远端的另一台计算机。你可以完全控制远程主机，也可以只控制一个应用程序。当本地硬件无法执行繁重的计算任务时，这非常有用。例如，运行新的视频游戏或 CAD 软件。WebRTC 能够通过下面三种方式彻底改变对物理空间的需求。\nWebRTC 可用于远程访问那些无法直接路由的主机。使用 NAT 遍历，你可以访问仅通过 STUN 可用的计算机。这对于安全性和隐私性非常有用。你的用户不必通过中转或所谓 \u0026quot; 跳转盒 \u0026quot; 来路由视频。NAT 遍历还使得部署更加容易。你不必担心端口转发问题或提前设置静态 IP。\n在这种场景下，数据通道也非常强大。可以对它们进行配置，以便仅接受最新数据。使用 TCP 运行时，可能会遇到队头阻塞的风险。旧式的鼠标点击或按键可能会迟到，并阻止后续的鼠标被接受。 WebRTC 的数据通道的设计可以处理此问题，并且可以配置为不重试丢失的数据包。你还可以测量背压，并确保你不会发送更多的数据以至于网络无法支持。\n浏览器中提供的 WebRTC 极大地改善了生活质量。你无需下载专有客户端即可开始会话。捆绑了 WebRTC 的客户端越来越多，智能电视现在也开始拥有了完整的 Web 浏览器。\n文件共享和审查制度 #  文件共享和审查规避是截然不同的问题。然而，WebRTC 同时解决了他们两者的相同问题。它使得文件既容易获得又更难以阻止。\nWebRTC 解决的第一个问题是客户端的获取。如果要加入文件共享网络，需要下载客户端。即使网络是分布式的，你仍然需要首先获得客户端。在受限制的网络中，下载通常会被阻止。即使你可以下载它，用户也可能无法安装和运行客户端。而 WebRTC 在每个 Web 浏览器中都可用，这点使得它无处不在。\nWebRTC 解决的第二个问题是流量被阻止的情况。如果你使用的协议仅用于文件共享或审查制度，那么阻止它会容易得多。由于 WebRTC 是通用协议，阻止它将影响所有人。阻止 WebRTC 可能会影响网络中的其他用户加入电话会议。\n分布式 CDN #  物联网（IoT） #  物联网（IoT）部分涵盖了几种不同的用例。许多人都见过网络连接的安防摄像头。使用 WebRTC，你可以将视频流式地传输到另一个 WebRTC 对等设备，例如电话或浏览器。另一个用例是让设备连接并交换传感器数据。你的局域网中可以有两个设备，互相交换天气，噪音或明亮度的读数。\n与传统的视频流协议相比，WebRTC 具有巨大的隐私优势。由于 WebRTC 支持 P2P 连接，因此摄像头可以将视频直接发送到你的浏览器。没有必要将你的视频发送到第三方服务器。即使视频是经过加密的，攻击者也可以根据通话的元数据做出一些猜测。\n互操作性是物联网领域的另一个优势。WebRTC 支持多种不同的语言，包括 C＃，C ++，C，Go，Java，Python，Rust 和 TypeScript。这意味着你可以使用最适合你的语言。而且你无需求助于专有协议或格式就可以连接你的客户端。\n媒体协议桥接 #  如果你现有的硬件和软件已经在产生视频，但是你还不能对其进行升级。期望用户下载专有客户端来观看视频是一件令人沮丧的事。解决问题的答案是运行一个 WebRTC 桥接器。桥接器在两种协议之间进行转换，因此用户可以在浏览器中使用旧的设置。\n开发人员桥接使用的许多格式都使用与 WebRTC 一致的协议。SIP 通常通过 WebRTC 暴露接口，并允许用户从其浏览器拨打电话。RTSP 用于许多旧式安保摄像头。它们都使用相同的基础协议（RTP 和 SDP），因此其计算成本很低。只需要添加或删除 WebRTC 特定的内容即可完成桥接工作。\n数据协议桥接 #  Web 浏览器只能通过一组受限制的协议通信。你可以使用 HTTP，WebSockets，WebRTC 和 QUIC。如果要连接到其他设备，你需要使用协议桥。协议桥是将外部流量转换为浏览器可访问内容的服务器。一个流行的示例是从浏览器使用 SSH 访问服务器。使用 WebRTC 的数据通道构建协议桥的话，具有下面两个优势。\nWebRTC 的数据通道允许不可靠且无序的交付。这在低延迟至关重要的情况下是必需的。你不会希望新数据被旧数据阻挡，这就是所谓的队头阻塞。假设你正在玩多人参与的第一人称射击游戏。你真的在乎玩家在两秒钟前的位置吗？如果这些数据没有及时到达，那么继续尝试发送就没有意义了。不可靠和无序的传送使你在一收到数据时就可以立即得到它。\n数据通道还提供压力反馈。这可以告诉你发送数据的速度是否超过了连接所能支持的速度。然后，当这种情况发生时，有两个选择。可以将数据通道配置为缓冲并延迟传送数据，也可以删除尚未实时到达的数据。\n远程操作 #  远程操作是指通过 WebRTC 数据通道控制远端设备，并通过 RTP 将视频数据发送回来。现在的开发人员已经可以通过 WebRTC 远程驾驶汽车了！这种技术可以用来控制施工现场和运送包裹的机器人。使用 WebRTC 解决这些问题很有意义，原因有两个。\nWebRTC 的普及使用户可以轻松控制。用户所需的只是一个 Web 浏览器和一个输入设备。浏览器甚至支持从操纵杆和游戏手柄获取输入。WebRTC 完全不需要在用户设备上安装其他客户端。\n分布式 CDN #  分布式 CDN 是文件共享的子集。分发的文件由 CDN 操作员配置。当用户加入 CDN 网络时，他们可以下载和共享允许的文件。用户获得与文件共享相同的所有好处。\n当你在外部连接很差但 LAN 连接很好的办公室中时，这些 CDN 效果很好。你可以让一个用户下载视频，然后与其他人共享。由于不需要每个人都尝试通过外部网络获取相同的文件，因此传输将更快地完成。\nWebRTC 拓扑 #  WebRTC 是用于连接两个 Agent 的协议，那么开发人员如何能同时连接上百人呢？你可以通过下面几种不同的方式来做到这一点，它们各有利弊。这些解决方案大致分为两类；点对点或客户端 / 服务器。WebRTC 的灵活性使我们能够同时创建两者。\n一对一 #  一对一是你使用 WebRTC 的第一种连接方式。将两个 WebRTC Agent 直接连接，它们可以双向发送媒体和数据。 连接看起来像这样。\n全网格 #  如果要建立电话会议或多人游戏，那么要使用全网格。在这种拓扑中，每一个用户都直接与其他各个用户建立连接。你可以这样构建应用，但是它有一些缺点。\n在全网格拓扑中，每个用户都直接连接（到其他用户）。这意味着你必须为参与通话的每个成员独立编码和上传视频。 由于各个连接的网络条件会有所不同，因此你无法重用同一视频。在这些部署中，错误处理也很困难。你需要仔细考虑连接是不是已经彻底断开了，还是只是丢掉了与单个远端 peer 的连接。\n由于这些问题，全网格最好用于小型群组。对于更大的群组，最好还是使用客户端 / 服务器拓扑。\n混合网格 #  混合网格是全网格的替代方案，可以减轻全网格的某些问题。在混合网格中，并不是所有每个用户之间都建立连接。作为替代，媒体是通过网络中的 peer 转发的。这意味着分发媒体时，创建者可以不必使用那么多的带宽。\n这种方案确实也有一些缺点。在这种配置下，就算是媒体最初的创建者也不知道视频是谁发送的，也不知道视频是否成功的到达了目标。在混合网格网络中，每增加一跳，延迟也会相应地增加。\n选择性转发单元（Selective Forwarding Unit） #  SFU（选择性转发单元）同样解决了全网格网络的问题，但它使用了一种完全不同的方案。SFU 以客户端 / 服务器拓扑实现，而不是 P2P 网络。 每个 WebRTC peer 都连接到 SFU 并上传其媒体。然后，SFU 将此媒体转发到其他每个连接的客户端。\n使用 SFU，每个 WebRTC Agent 只需要执行一次视频的编码和上传。SFU 负责将视频分发给所有观看者。 与 SFU 的连接也比 P2P 方式容易得多。你可以让 SFU 运行于一个全世界都可以访问的地址上，从而使得客户端连接更加容易。 你无需担心 NAT 映射。但你仍然需要确保 SFU 是可以通过 TCP（ICE-TCP 或 TURN）使用的。\n要创建一个简单的 SFU，一个周末就可以完成。但建立一个可以处理所有类型客户的高质量 SFU，是永无止境的。因为，拥塞控制调优、纠错和提高性能，是一项永无止境的任务。\n多点会议单元（Multi-point Conferencing Unit） #  MCU（多点会议单元）与 SFU 的客户端 / 服务器拓扑类似，但它会对输出流进行组合。MCU 将要出站的媒体重新编码为一个聚合流，而不是直接分发未经修改的版本。 "});index.add({'id':8,'href':'/zh/docs/09-debugging/','title':"调试",'section':"Docs",'content':"调试 #  调试 WebRTC 可能是一项艰巨的任务。有很多部分都处于运行状态，每一个部分都可能出现问题。如果你不够细心，可能会浪费数周的时间来查看错误的模块。当你最终找到出错的部分时，你还需要学习一些知识才能理解问题的根源。\n本章将带你学习 WebRTC 的调试。它将向你展示如何分析并定位相关问题。确定问题后，我们将快速介绍一下流行的调试工具。\n分解问题 #  开始调试时，你需要先分解问题的源头。从以下题目开始：\n信令故障 #  网络故障 #  使用 netcat 测试你的 STUN 服务器：\n  准备 20 字节的绑定请求数据包：\necho -ne \u0026quot;\\x00\\x01\\x00\\x00\\x21\\x12\\xA4\\x42TESTTESTTEST\u0026quot; | hexdump -C 00000000 00 01 00 00 21 12 a4 42 54 45 53 54 54 45 53 54 |....!..BTESTTEST| 00000010 54 45 53 54 |TEST| 00000014 解释：\n 00 01 是消息类型。 00 00 是数据段的长度。 21 12 a4 42 是 magic cookie。 54 45 53 54 54 45 53 54 54 45 53 54 （解码成 ASCII 就是 TESTTESTTEST） 是 12 字节的 transaction ID。    发送请求并等待 32 字节的响应：\nstunserver=stun1.l.google.com;stunport=19302;listenport=20000;echo -ne \u0026quot;\\x00\\x01\\x00\\x00\\x21\\x12\\xA4\\x42TESTTESTTEST\u0026quot; | nc -u -p $listenport $stunserver $stunport -w 1 | hexdump -C 00000000 01 01 00 0c 21 12 a4 42 54 45 53 54 54 45 53 54 |....!..BTESTTEST| 00000010 54 45 53 54 00 20 00 08 00 01 6f 32 7f 36 de 89 |TEST. ....o2.6..| 00000020 解释：\n 01 01 是消息类型。 00 0c 是数据段的长度，解码后是十进制的 12。 21 12 a4 42 是 magic cookie。 54 45 53 54 54 45 53 54 54 45 53 54 （解码成 ASCII 就是 TESTTESTTEST）是 12 字节的 transaction ID。 00 20 00 08 00 01 6f 32 7f 36 de 89 是 12 字节的数据，解释：  00 20 是类型：XOR-MAPPED-ADDRESS。 00 08 是 value 段的长度，以十进制解码就是 8。 00 01 6f 32 7f 36 de 89 是数据值，解释：  00 01 是地址类型（IPv4）。 6f 32 是经过 XOR 映射的端口。 7f 36 de 89 是经过 XOR 映射的 IP 地址。        解码 XOR 映射的部分很麻烦，但是我们可以通过提供设置为 00 00 00 00 的（无效）伪 magic cookie 来诱骗 stun 服务器执行伪 XOR 映射：\nstunserver=stun1.l.google.com;stunport=19302;listenport=20000;echo -ne \u0026quot;\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00TESTTESTTEST\u0026quot; | nc -u -p $listenport $stunserver $stunport -w 1 | hexdump -C 00000000 01 01 00 0c 00 00 00 00 54 45 53 54 54 45 53 54 |........TESTTEST| 00000010 54 45 53 54 00 01 00 08 00 01 4e 20 5e 24 7a cb |TEST......N ^$z.| 00000020 对伪 magic cookie 的 XOR 运算是幂等的，因此响应中的端口和地址将是清楚的。这并非在所有情况下都有效，因为某些路由器会操纵传递的数据包，伪装 IP 地址。如果我们查看返回的数据值（最后八个字节）：\n 00 01 4e 20 5e 24 7a cb 是数据值，解释：  00 01 是地址类型（IPv4）。 4e 20 是映射的端口，解码成十进制就是 20000。 5e 24 7a cb 是 IP 地址，解码成点分十进制表示法就是 94.36.122.203。    安全故障 #  媒体故障 #  数据故障 #  用到的工具 #  netcat (nc) #  netcat 是用于使用 TCP 或 UDP 读取和写入网络连接的命令行网络实用程序。通常它可以用 nc 命令来调用。\ntcpdump #  tcpdump是一个命令行数据网络数据包分析器。\n常用命令：\n  捕获与端口 19302 之间的 UDP 数据包，并打印数据包内容的十六进制转储：\nsudo tcpdump 'udp port 19302' -xx\n  与上一条相同，但将数据包保存在 PCAP（数据包捕获）文件中以供以后检查\nsudo tcpdump 'udp port 19302' -w stun.pcap\n可以使用 wireshark GUI 打开 PCAP 文件：wireshark stun.pcap\n  wireshark #  wireshark 是一个使用广泛的网络协议分析器\nwebrtc-internals #  Chrome 内置了一个 WebRTC 指标数据页面 chrome://webrtc-internals 。\n延迟 (Latency) #  我们该如何感知高延迟？你会注意到视频出现延迟了，但你知道它具体延迟了多少吗？ 想要降低延迟，你首先必须知道如何测量延迟。\n真正的延迟应该是端到端测量的。这不仅仅是指发送方和接收方之间网络路径的延迟，还包括相机拍摄、帧编码、传输、接收、解码和视频播放等一系列步骤延迟的综合，以及这些步骤之间可能存在的队列。\n端到端延迟不是各个组件延迟的简单叠加。\n虽然在理论上，你可以单独测量整个视频传输管线中各个模块的延迟，然后累加到一起；但是在实践中，至少有些组件没有方法去测量延迟，或者在外部测量延迟的结果存在明显的偏差。 各个步骤之间的队列大小，网络拓扑，乃至是相机的曝光度变化，都可能会对分步骤的测量结果产生影响，进而影响端到端延迟的测量结果。\n直播系统中每个组件内部的延迟都可能改变并影响下游组件。 甚至拍摄的内容也会影响延迟。 例如，与晴朗的蓝天这种低频图像相比，树枝等高频特征需要更多的比特数 (译者注：编码的本质是压缩，压缩的本质是减少数据冗余，复杂的图像编码后需要更多的空间)。 开启自动曝光的相机拍摄一帧图像所花费的时间，可能比预期的 33ms _ 多得多 _，即使拍摄速度设置为每秒 30 帧也是如此。 通过网络（特别是蜂窝网络）的传输，受需求变化的影响，也是动态变化的。 例如，更多的用户就意味着更多参与的通信者。 地理位置（特别是某些臭名昭著的低信号区）等其他因素也会增加丢包和延迟。 当你把数据包发送到网络接口（例如 WiFi 适配器或者 LTE）并请求传送时，会发生些什么呢？ 如果数据包无法被立即传送，它将被加入网络接口的队列中，队列越大，网络接口引入的延迟就越大。\n端到端延迟——手动测量 #  当我们谈论 端到端延迟时，指的是从 事件发生 到 事件被看到 (即视频帧播放在屏幕上) 的时间间隔。\nEndToEndLatency = T(observe) - T(happen) 一个想当然的方法是，记录事件发生的时间，再与事件被看到的时间相减即可得到。 但是，当精确度为毫秒级时，时间同步就成了难题。 想要在分布式系统中同步时钟基本是徒劳的，即使是时钟同步的一个小错误，也会让 延迟测量 不再可信。\n解决时间同步问题的一个简单方法，就是使用相同的时钟。 将发送方和接收方放在同一个参照系中。\n想象一下你有一个正常运行的毫秒级时钟（或者其他真实的可以表示时间的物体）。 你要测量一个系统的延迟，这个系统中，摄像头对准 时钟，采集的直播流显示到同一个地方的另一个屏幕上。 有一个直接的测量方式来 测量 时钟当前时间 (Thappen) 和这个时钟视频出现在屏幕上的时间 (Tobserve) 。步骤如下：\n 将你的摄像头对准这个时钟。 将视频帧发送给同一个地方的接收方，接收端在屏幕上进行播放。 （用你的手机）拍一张照片，将时钟和屏幕视频画面拍进同一个画面内。 将照片中的两个时间相减（时钟上的时间，和屏幕视频画面里时钟的时间）。  这是最真实的端到端延迟测量。 它考虑了所有组件（相机、编码器、网络、解码器）的延迟，并且不依赖任何时钟同步。\n. 在上面的照片中，测得的端到端延迟为 101 msec。事件发生的时间是 10:16:02.862 , 而 直播观看者看到的时间是 10:16:02.761。\n端到端延迟——自动测量 #  本文写作时（2021 年 5 月），WebRTC 标准中关于端到端延迟的话题正在被积极讨论中。 Firefox 实现了一套 API，让用户可以在标准 WebRTC API 之上，创建对延迟的自动测量。 不过，在本段落中，我们将讨论进行端到端延迟自动测量的最通用的方法。\nRoundtrip，即往返时间，简而言之就是： 我向你发送我的时间 tR1, 当我接收到 tR1 回来时，时间是 tR2 ，可得往返时间是 tR2 - tR1 。\n在给定发送方和接收方之间的通信通道（比如，DataChannel）后，接收方可以通过以下步骤来对发送方的单一时钟建模：\n 在时间 tR1，接收方发送一个消息，包含它本地单一时钟的时间戳 tR1。 在发送方一端的时间 tS1，发送方收到该消息，并发送响应消息，响应消息中包含三个时间：tR1 和 tS1，以及发送方的视频轨道时间 tSV1。 在接收方一端的时间 tR2，接收方收到消息，可以用消息的接收时间减去发送时间，计算出往返时间：RTT = tR2 - tR1。 有了往返时间 RTT 和发送方本地时间戳 tS1，就可以估算出发送方的单一时钟了。在 tR2 这个时间点，发送方的当前时间近似等于 tS1 加上往返时间 RTT 的一半。 根据发送方本地时钟的时间戳 tS1，以及视频轨道的时间戳 tSV1，加上往返时间 RTT，接收方就可以将自己这一端和发送方一端的视频轨道时间进行同步。  现在我们已经知道了从发送方发出最后一个视频帧时间 tSV1 之后所经过的时间，我们可以这样计算近似的时间延迟，即用 期待的视频时间（\u0026lsquo;expected_video_time\u0026rsquo;） 减去 当前播放的视频帧的时间（\u0026lsquo;actual_video_time\u0026rsquo;）：\nexpected_video_time = tSV1 + time_since(tSV1) latency = expected_video_time - actual_video_time 译者注：期待的视频时间指的是 没有时延的情况下应该播放到哪个时间，在 Sender 端，tSV1 时间采集 tSV1, 之后，过了 time_since(tSV1) 时间，Sender 端当前应该采集的是 tSV1 + time_since(tSV1)，无延迟情况下，期待的视频时间也就是 Sender 当前应该采集的时间。\n这种方法的缺陷是没有包含相机内部的延迟。 大多数视频系统一般将相机的帧传送到主内存的时间作为这一帧的拍摄时间戳，但拍摄实际发生的时间会略早于此时间。\n延迟测量示例 #  一个简单实现是在接收方开启一个 latency 数据通道，并定期将接收方的单一时钟时间戳发送到发送方。发送方响应一个 JSON 消息（消息中包含上面提到的三个时间），然后接收方根据这个消息来计算延迟。\n{ \u0026#34;received_time\u0026#34;: 64714, // Timestamp sent by receiver, sender reflects the timestamp. \u0026#34;delay_since_received\u0026#34;: 46, // Time elapsed since last `received_time` received on sender. \u0026#34;local_clock\u0026#34;: 1597366470336, // The sender\u0026#39;s current monotonic clock time. \u0026#34;track_times_msec\u0026#34;: { \u0026#34;myvideo_track1\u0026#34;: [ 13100, // Video frame RTP timestamp (in milliseconds). 1597366470289 // Video frame monotonic clock timestamp. ] } } 在接收方开启这个 latency 数据通道：\ndataChannel = peerConnection.createDataChannel(\u0026#39;latency\u0026#39;); 定期发送接收方的时间 tR1，示例中使用的周期是 2 秒：\nsetInterval(() =\u0026gt; { let tR1 = Math.trunc(performance.now()); dataChannel.send(\u0026#34;\u0026#34; + tR1); }, 2000); 发送方处理来自接收方的消息：\n// Assuming event.data is a string like \u0026#34;1234567\u0026#34;. tR1 = event.data now = Math.trunc(performance.now()); tSV1 = 42000; // Current frame RTP timestamp converted to millisecond timescale. tS1 = 1597366470289; // Current frame monotonic clock timestamp. msg = { \u0026#34;received_time\u0026#34;: tR1, \u0026#34;delay_since_received\u0026#34;: 0, \u0026#34;local_clock\u0026#34;: now, \u0026#34;track_times_msec\u0026#34;: { \u0026#34;myvideo_track1\u0026#34;: [tSV1, tS1] } } dataChannel.send(JSON.stringify(msg)); 接收方处理来自发送方的消息，并在控制台上打印估算的时延：\nlet tR2 = performance.now(); let fromSender = JSON.parse(event.data); let tR1 = fromSender[\u0026#39;received_time\u0026#39;]; let delay = fromSender[\u0026#39;delay_since_received\u0026#39;]; // How much time that has passed between the sender receiving and sending the response. let senderTimeFromResponse = fromSender[\u0026#39;local_clock\u0026#39;]; let rtt = tR2 - delay - tR1; let networkLatency = rtt / 2; let senderTime = (senderTimeFromResponse + delay + networkLatency); VIDEO.requestVideoFrameCallback((now, framemeta) =\u0026gt; { // Estimate current time of the sender.  let delaySinceVideoCallbackRequested = now - tR2; senderTime += delaySinceVideoCallbackRequested; let [tSV1, tS1] = Object.entries(fromSender[\u0026#39;track_times_msec\u0026#39;])[0][1] let timeSinceLastKnownFrame = senderTime - tS1; let expectedVideoTimeMsec = tSV1 + timeSinceLastKnownFrame; let actualVideoTimeMsec = Math.trunc(framemeta.rtpTimestamp / 90); // Convert RTP timebase (90000) to millisecond timebase.  let latency = expectedVideoTimeMsec - actualVideoTimeMsec; console.log(\u0026#39;latency\u0026#39;, latency, \u0026#39;msec\u0026#39;); }); 浏览器中的视频准确时间 #   \u0026lt;video\u0026gt;.requestVideoFrameCallback() 允许 web 开发者在视频帧可以被合成图像时收到通知。\n 直到最近（2020 年 5 月），我们还基本没有一个可靠的方式在浏览器中获取视频当前播放帧的时间戳 。虽然存在一个基于 video.currentTime 的变通方法，但得到的结果也不是特别精确。 Chrome 和 Mozilla 的浏览器开发者都支持引入新的 W3C 标准，HTMLVideoElement.requestVideoFrameCallback()，该标准添加了一个 API 回调来访问当前视频帧的时间。 尽管这个新 API 听起来微不足道，但它赋予了应用在 Web 上进行音视频同步的能力，并已经促进了多个 Web 上的高级的媒体应用的实现。 特别是对于 WebRTC，回调中将包含 rtpTimestamp 字段，即与当前视频帧的关联的 RTP 时间戳。 这个接口理应出现在 WebRTC 应用中，可惜目前还没有。\n延迟的调试技巧 #  由于调试很可能会影响测量到的延迟值，所以大体原则是：将你设置简化到能复现问题的最小程度。 移除越多的组件，就越容易找到造成延迟问题的组件。\n相机延迟 #  根据相机设置，相机延迟可能会有所不同。 检查自动曝光、自动对焦和自动白平衡等设置。 网络摄像头的所有 \u0026quot; 自动 \u0026quot; 功能都需要一些额外的时间来分析捕获的图像，然后才能将其提供给 WebRTC 协议栈。\n在 Linux 上，你可以使用 v4l2-ctl 命令行工具来控制相机设置：\n# Disable autofocus: v4l2-ctl -d /dev/video0 -c focus_auto=0 # Set focus to infinity: v4l2-ctl -d /dev/video0 -c focus_absolute=0 你也可以使用图形界面工具 guvcview 来快速检测和调整相机设置。\n编码延迟 #  大多数现代编码器会在输出已编码的帧之前，先缓存一些帧。 它们的首要任务是在生成的图片质量和比特率之间取得平衡。 多次编码器就是编码器忽略输出时延的一个极端例子。 在第一次编码过程中，编码器需要获取到完整的视频数据，然后才会开始输出视频帧。\n不过，通过适当的调整，我们可以减少 sub-frame 的延迟（译者注：这里应该是指 subsequent-frame, 避免对后续帧的依赖）。 请确保你的编码器不使用过多的参考帧或依赖于 B 帧。 每个编解码器的延迟调整设置都不同，但对于 x264 而言，我们建议使用 tune=zerolatency 和 profile=baseline 以获得最低的帧输出延迟。\n网络延迟 #  对于网络延迟，我们能做的不多，最好的方法就是升级到更好的网络连接。 网络延迟很像天气——你不能阻止下雨，但你可以查看天气预报然后打把雨伞。 WebRTC 以毫秒级精度测量网络状态。 重要的指标有：\n 往返时间 丢包与包重传  往返时间\nWebRTC 协议栈有内建的网络往返时间（round trip time, RTT）测量机制 。 网络延迟的一个很不错的近似值是 RTT/2。它假设发送和接收数据包需要同样长的时间，然而情况并非总是如此。 RTT 界定了端到端的时延的下限。 不管如何优化相机到编码器的处理管道，视频帧都无法在 RTT/2 的时间以内到达接收方。\n内建的 RTT 机制，基于特殊的 RTCP 包，也就是发送方 / 接收方报告。 发送方发送自己的时间戳给接收方，接收方再将这个时间戳回传给发送方。 这样，发送方就知道这个数据包从发往接收方到返回一共花了多长时间。 RTT 测量的更多内容，请参阅发送方和接收方报告章节。\n丢包与包重传\nRTP 和 RTCP 协议都是基于 UDP，对于数据的顺序、成功送达或者避免重复，UDP 不提供任何保障。 而上面所有这些在现实世界的 WebRTC 应用中都会发生，也总是在发生。 一个简单的解码器实现会期望一个视频帧的所有数据包都被完整送达，以便解码器能重新生成图像。 出现丢包问题时，如果丢失的是P 帧的数据包，则可能会解码出错误的图像。 如果丢失的是 I 帧的数据包，则所有依赖于此 I 帧的视频帧要么出现严重的解码错误，要么压根无法被解码。 这些都很可能会造成视频 \u0026quot; 卡住 \u0026quot; 一段时间。\n为了避免（当然只是尽量避免）视频卡住或者解码错误，WebRTC 使用 NACK（否定确认）。 当接收方没有收到一个期待的 RTP 包时，将返回 NACK 消息，让发送方再次发送这个丢失的包。 接收方 _ 等待 _ 数据包重传完成。 这样的重传会导致延迟增加。 NACK 包的发送和接收的数量会被记录在 WebRTC 内建的统计数据中，对应的字段是outbound stream nackCount和inbound stream nackCount 。\n在webrtc internals 页面中，你可以看到展示入站和出站的 nackCount 的漂亮的图表。 如果你看到 nackCount 正在增加，这意味着网络正处于大量丢包的状态，尽管如此，WebRTC 协议栈仍在努力创建流畅的音视频体验。\n当丢包率太高，解码器已经无法解码图像或者后续关联帧（例如 I 帧完全丢失的情况）的时候，所有后续的 P 帧都将无法解码。 在这种情况下，接收方将通过发送图片丢失指示（PLI）消息来尝试缓解问题。 一旦发送方接收到一个 PLI 消息，它将生成一个新的 I 帧来帮助接收方的解码器生成图像。 I 帧一般比 P 帧大，这也增加了需要传输的数据包数量。 和 NACK 消息一样，接收方需要等待新的 I 帧，这也引入了额外的延迟。\n你需要关注webrtc internals 页面中的 pliCount 指标，如果它增加了，你需要调整编码器以减少数据包的输出；或者启用容错度更高的模式。\n接收方一侧的延迟 #  延迟会受到数据包乱序到达的影响。 比如一张图片下半部分的数据包先到达了，那么必须等待上半部分的数据包到达后，才能开始解码。 关于这个问题的更详细内容，请参考解决抖动问题章节。\n你也可以参考内建的jitterBufferDelay指标，看一下一帧需要在接收缓冲区中存放多久，才能等到所有的数据包接收完成，并被释放到解码器。\n"});index.add({'id':9,'href':'/zh/docs/10-history-of-webrtc/','title':"历史",'section':"Docs",'content':"历史 #  在学习 WebRTC 时，开发人员经常对其复杂性感到沮丧，他们认为一些 WebRTC 功能与他们当前的项目无关，并希望 WebRTC 能够更简单一些。但问题是不同的开发者有迥然不同的应用场景。实时通信有着一段丰富的历史，人们在这个领域创造过很多不同的东西。\nWebRTC 是由一系列协议组成的，本章包含了对这些协议作者的采访。 这些采访可以让我们更深入的了解作者们在构建每个协议时所做的设计，并以关于 WebRTC 本身的采访结束。当你理解了软件的意图和设计，你可以用它构建出更有效率的系统。\nRTP #  RTP 和 RTCP 是处理 WebRTC 的所有媒体传输的协议。它是在 1996 年 1 月的RFC 1889中定义的。 我们很幸运地邀请到其中一位作者Ron Frederick自己来谈论这个问题。Ron 最近向 GitHub 上传了Network Video tool，这是一个展示了 RTP 的项目。\n用他自己的话讲 #  在 1992 年 10 月，我开始尝试使用 Sun VideoPix 帧采集卡，当时的想法是编写一个基于 IP 多播的网络视频会议工具。它是根据 \u0026ldquo;vat\u0026rdquo; 建模的，\u0026ldquo;vat\u0026rdquo; 是 LBL 开发的一个音频会议工具，它为参加会议的用户使用了类似的轻量级会话协议，你可以简单地使用此工具将数据发送到特定的多播组，并监听来自该组中其他小组成员的任何流量。\n为了使程序真正成功，它需要先压缩视频数据，然后再将其发布到网络上。我的目标是在大约 128 kbps 或标准家庭 ISDN 线路的带宽上生成可接受的可视数据流。我还希望在一半带宽下生成仍能被观看到的东西。这意味着我需要将特定图像尺寸和帧率的视频压缩到大约 20 分之一的大小。我实现了这种压缩，并申请了专利，专利是 US5485212A：用于电话会议的软件视频压缩。\n1992 年 11 月上旬，我向互联网社区发布了视频会议工具 \u0026ldquo;nv\u0026rdquo;（二进制形式）。经过一些初步测试后，它被用于在全球范围内对 11 月 Internet 工程任务组的部分进行视频广播。在 15 个国家 / 地区中，大约有 200 个子网能够接收此广播，并且一周中的某个时候，大约有 50-100 人使用 \u0026ldquo;nv\u0026rdquo; 接收了视频。\n在接下来的几个月中，另外三个研讨会和一些较小的会议使用 \u0026ldquo;nv\u0026rdquo; 向整个 Internet 进行广播，包括澳大利亚 NetWorkshop，MCNC 分组音频和视频研讨会以及瑞典的分布式虚拟现实 MultiG 研讨会。\n随后，在 1993 年 2 月，我发布了 \u0026ldquo;nv\u0026rdquo; 的源代码，并在 3 月发布了该工具的一个版本，在其中引入了新的基于小波的压缩方案。在 1993 年 5 月，我增加了对彩色视频的支持。\n用于 \u0026ldquo;nv\u0026rdquo; 和其他 Internet 会议工具的网络协议成为了实时传输协议（RTP）的基础，该协议通过 Internet 工程任务组（IETF）进行了标准化，该工作组首先在 RFCs 1889-1890 中发布，后来又与其他各种 RFC 一起，在 RFCs 3550-3551 中进行了修订，它们涵盖了用于传递特定音频和视频格式的配置文件。\n在接下来的几年中，关于 \u0026ldquo;nv\u0026rdquo; 的工作继续进行，该工具被移植到了许多其他硬件平台和视频捕获设备上。它仍然被用作当时在 Internet 上广播会议的主要工具之一，包括被 NASA 选中以在线直播的方式进行航天飞机飞行任务的实时报道。\n1994 年，我在 \u0026ldquo;nv\u0026rdquo; 中添加了对其他人开发的视频压缩算法的支持，其中包括一些硬件压缩方案，如 SunVideo 视频捕获卡支持的 CellB 格式。这也使得 \u0026ldquo;nv\u0026rdquo; 可以用 CUSeeMe 格式发送视频，并将视频发送给在 Mac 和 PC 上运行 CUSeeMe 的用户。\n最新的 \u0026ldquo;nv\u0026rdquo; 版本是 1994 年 7 月发布的 3.3beta 版本。当时我正在开发 \u0026ldquo;4.0alpha\u0026rdquo; 版本，该版本旨在将 \u0026ldquo;nv\u0026rdquo; 迁移到 RTP 协议 v2，但因为我转到了其他项目上，这项工作从未被完成。为了保持完整性，Network Video tool归档文件中包含 4.0 alpha 代码的副本，但它是未完成的，并且存在已知问题，尤其是在 RTPv2 支持不完整的情况下。\n\u0026ldquo;nv\u0026rdquo; 中提供的框架后来成为 Xerox PARC 的 \u0026ldquo;Jupiter multi-media MOO\u0026rdquo; 项目中视频会议的基础，该项目最终分拆为独立公司 \u0026ldquo;PlaceWare\u0026rdquo;，后来该公司被 Microsoft 收购。它也被用作许多硬件视频会议项目的基础，这些项目允许通过高带宽以太网和 ATM 网络发送完整的 NTSC 广播质量的视频。后来我还使用了其中一些代码作为 \u0026ldquo;Mediastore\u0026rdquo; 的基础，\u0026ldquo;Mediastore\u0026rdquo; 是基于网络的视频记录和回放服务。\n你还记得草案中其他人的动机 / 想法吗？ #  我们都是 IP 多播的研究人员，并且帮助创建了 Internet 多播主干网（又名 MBONE）。MBONE 由 Steve Deering（IP 多播的首位开发者），Van Jacobson 和 Steve Casner 创建。 我和 Steve Deering 在斯坦福大学有同一位顾问，Steve 离开斯坦福大学后就去了 Xerox PARC 工作，我作为 IP 多播相关项目的实习生在 Xerox PARC 呆了一个夏天，后来在斯坦福大学还继续为他们兼职工作，再后来转为全职。Van Jacobson 和 Steve Casner 是最初的 RTP RFC 的四位作者中的两位，还有 Henning Schulzrinne 和我本人。我们所有人都使用 MBONE 工具进行各种形式的在线协作，并且试图提炼出所有这些工具可以使用的通用基本协议，RTP 就是这样出现的。\n多播很棒，而 WebRTC 完全是单播的，可以说一下是为什么吗？ #  在前往斯坦福大学并学习 IP 多播之前，我花了很长时间致力于让计算机成为人们相互交流的方式。这是从 80 年代初期开始的，当时我运行了一个拨号公告板系统，人们可以登录并留下彼此的消息，既可以是私人的（相当于电子邮件），也可以是公共的（讨论小组）。大约在同一时间，我还了解了在线服务提供商 CompuServe。 CompuServe 的很酷的功能之一就是所谓的 \u0026ldquo;CB Simulator\u0026rdquo;，人们可以在其中进行实时交谈。这些都是基于文本的，但是它具有 \u0026quot; 频道 \u0026quot; 的概念，就像真正的 CB 广播一样，只要他们在同一个频道中，大家就可以看到其他人键入的内容。我构建了自己的 CB 版本，该版本在我可以访问的分时共享系统上运行，该系统可以让该系统上的用户实时向彼此发送消息，然后在接下来的几年中，我与朋友一起开发了更复杂的各种版本的实时通信工具，可以在几个不同的计算机系统和网络上运行。事实上，其中一个系统仍在运行，我每天都会用它与 30 多年前上大学的人们进行交流！\n所有这些工具都是基于文本的，因为当时的计算机通常没有任何音频 / 视频功能，但是当我到达斯坦福大学并学习了 IP 多播时，我产生了一个想法。做一个真正的 \u0026quot; 收音机 \u0026ldquo;，你可以将信号发送到网络上，该信号并不是特别发给任何人的，但是调谐到该 \u0026quot; 频道 \u0026quot; 的每个人都可以接收到它。碰巧的是，我正在为之移植 IP 多播代码的计算机是 Sun 的第一代 SPARC-station，而它实际上内置了电话级别的音频硬件！你可以将麦克风中的声音数字化，然后通过内置扬声器（或通过耳机输出）播放。因此，我的第一个想法是弄清楚如何使用 IP 多播将音频实时发送到网络上，然后看一下是否可以构建一个使用实际音频而不是文本的 \u0026ldquo;CB 收音机 \u0026ldquo;。\n这里有一些棘手的事情需要解决，例如计算机一次只能播放一个音频流，因此，如果有多个人在讲话，则需要在数学上将多个音频流 \u0026quot; 混合 \u0026quot; 为一个，然后才能播放。不过一旦你了解了音频采样的工作原理，这些工作就可以全部通过软件完成。该音频应用程序使我致力于 MBONE 的开发，并最终通过 \u0026ldquo;nv\u0026rdquo; 实现了到视频的转换。\n协议中遗漏了什么你原本希望添加的东西吗？有没有哪些让你后悔加入的内容？ #  我不觉得有什么后悔的，不过最终人们对 RTP 抱怨最多的其中一点就是 RTCP 实现的复杂性，RTCP 是与 RTP 主数据流量并行运行的控制协议。我认为，RTP 并未得到更广泛采用的主要原因就是太过复杂，尤其是在单播情况下，对 RTCP 的某些功能的需求不再那么大。由于网络带宽变得不再那么稀缺，而拥塞也不再是一个大问题，许多人最终只是通过纯 TCP（以及后来的 HTTP）流式传输音频和视频，一般来说，这就已经 \u0026quot; 足够好 \u0026quot; 了，以至于没有必要再去与 RTP 打交道。\n不幸的是，使用 TCP 或 HTTP 意味着多方音频和视频应用程序必须通过网络多次向需要接收数据的每个对等方发送相同的数据，从而从带宽的角度来看，效率被大大降低。有时，我希望我们之前能更加努力地推动 IP 多点广播的应用，使其不仅限于研究领域。我认为，如果我们这么做了的话，可能我们早就可以看到有线电视和广播电视过渡到基于 Internet 的音频和视频。\n有什么东西是你曾经想过使用 RTP 构建的呢？是不是有一些很酷的 RTP 项目 / 想法随时间流逝了呢？ #  我构建的其中一个有趣的项目是一个使用 IP 多播的经典游戏 \u0026ldquo;Spacewar\u0026rdquo; 版本。在没有任何类型的中央服务器的情况下，多个客户端可以各自运行 spacewar 的二进制文件，并开始广播其船舶的位置 / 速度 / 所面对的方向以及已发射的任何 \u0026quot; 子弹 \u0026quot; 的类似信息，所有其他客户端将收集这些信息并将其呈现在本地，从而使所有人都可以看到彼此的飞船和子弹，如果飞船撞向对方或被子弹击中，飞船就会 \u0026quot; 爆炸 \u0026ldquo;。我甚至将爆炸中的 \u0026quot; 碎片 \u0026quot; 也做成了可以击毁其他船只的活动物体，有时会引起有趣的连锁反应！\n本着原始游戏的精神，我使用模拟矢量图形对其进行了渲染，因此你可以执行诸如放大和缩小视图之类的操作，并且一切都会按比例放大 / 缩小。飞船本身是一堆矢量形式的线段，我在 PARC 的一些同事帮助我进行了设计，因此每个人的飞船都有独特的外观。\n基本上，如果一个东西需要实时数据流，又无需数据按照精确的时序传输，那么它就可以从 RTP 中受益。因此，除了音频和视频，我们还可以构建共享白板之类的东西。甚至使用 RTP 进行文件传输，尤其是与 IP 多播结合使用时。\n这就像 BitTorrent，但是你不需要在对等方之间点对点地传输所有数据。原始的做种者可以立即将多播流发送到所有接收者，并且通过成功接收数据的任何对等方的重发，就可以快速解决传输中数据包丢失的问题。接收者甚至可以确定重传请求的范围，以便附近的一些对等方能够传递数据的副本，重传请求也可以被多播到该区域中的其他节点，因为网络中间的数据包丢失往往意味着下游有很多客户端错过了相同的数据。\n为什么你必须实现自己的视频压缩协议？当时没有其他可用的东西了吗？ #  在我开始构建 \u0026ldquo;nv\u0026rdquo; 时，我所知道的唯一进行视频会议的系统是非常昂贵的专用硬件。例如，Steve Casner 可以从 BBN 访问一个名为 \u0026ldquo;DVC\u0026rdquo;（后来商品化为 \u0026ldquo;PictureWindow\u0026rdquo;）的系统。压缩需要专用硬件，但是解压缩可以通过软件完成。\u0026ldquo;nv\u0026rdquo; 之所以与众不同，是因为压缩和解压缩都是在软件中完成的，唯一的硬件要求是对输入的模拟视频信号进行数字化处理。\n当时，有关如何压缩视频的许多基本概念已经存在了，诸如 MPEG-1 标准之类的东西大约在 \u0026ldquo;nv\u0026rdquo; 出现的同时出现，但在当时绝对不可能使用 MPEG-1 进行实时编码。我所做的更改都是关于吸收这些基本概念并使用更便宜的算法对其进行近似模拟，其中我避免了余弦变换和浮点之类的事情，甚至避免了整数乘法，因为在 SPARC-stations 上这些运算速度非常慢。我尽量只进行加 / 减法、位屏蔽和移位，这样可以使速度足够快，并使结果看起来仍像是视频。\n在 \u0026ldquo;nv\u0026rdquo; 发布的一两年之内，不仅是在 MBONE 网络上，还有其他地方（如 Mac 上的 CU-SeeMe 工具），都出现了许多不同的音视频工具可供选择。很明显的，实时视频的时机成熟了。事实上，我最终使 \u0026ldquo;nv\u0026rdquo; 与许多这些工具互操作，还有某些工具甚至采用了 \u0026ldquo;nv\u0026rdquo; 编解码器，以便在使用压缩方案时它们可以互操作。\nWebRTC #  WebRTC 需要的标准化工作使得本章中描述的所有其他工作都相形见绌。它需要两个不同的标准机构（IETF 和 W3C），以及来自许多公司和国家的数以百计的人员合作。Serge Lachapelle会跟我们谈谈实现 WebRTC 的初始动机，以及在开发过程中所付出的巨大的努力。\nSerge 是 Google 的产品经理，目前担任 Google Workspace 的产品经理。下面是我总结后的采访内容。\n什么促使你参与 WebRTC ？ #  从大学开始，我就一直热衷于构建通信软件。在 90 年代，像nv这样的技术开始出现，但很难使用。我创建了一个项目，它允许你可以直接从浏览器加入视频通话。我也将它移植到了 Windows。\n我把这段经历带到了我共同创立的公司 Marratech。我们构建了用于群组视频会议的软件。从技术上来讲，当时的愿景与现在大不相同。当时的视频通信的前沿方向是使用多播网络。用户可以依靠网络将视频数据包传送给通话中的每一个人。这意味着我们的服务器可以非常简单。但这种做法存在一个巨大的缺点，必须设计网络以适配多播模式。后来，这个行业从多播转向了数据重组（packet shufflers），也就是现在大家都知道的 SFU。\nMarratech 于 2007 年被 Google 收购。然后我得以继续这个后来成为 WebRTC 的项目。\n在 Google 的第一个项目 #  WebRTC 前身团队（后来才有 WebRTC 项目）参与的第一个项目是 Gmail 语音和视频聊天。将音频和视频导入浏览器并不容易。我们需要从各个公司获得特定功能模块的许可。音频模块由 GIP 授权，视频模块由 Vidyo 授权，网络模块由 libjingle 授权。然后，我们要像变魔术一般让这些组件一起工作。\n每个子系统都有完全不同的 API，而且它们都是为了解决不同的问题而设计的。为了让它们协同工作，你需要同时具备多个领域的专业知识，例如：网络、密码学、媒体等等。 Justin Uberti是这项工作的负责人。他将这些组件组合在一起，开发了一个可用的产品。\n在浏览器中做实时渲染也非常困难。我们不得不使用 NPAPI（Netscape Plugin API），并做了很多创新性的工作，才使其最终得以实现。 从这个项目中，我们学到了很多经验教训，这极大地影响了 WebRTC。\nChrome #  与此同时，Chrome 项目在 Google 内部启动。Chrome 在项目之初就拥有远大的格局，带来了很多令人兴奋的东西，简单举几个例子，比如 WebGL、离线应用、数据库功能、游戏低延迟输入等等。\n是否摒弃 NPAPI 是当时的一个争论焦点。它是一个强大的 API，但也引入了诸多的安全性问题。Chrome 使用沙盒设计来确保用户安全。潜在的不安全操作被隔离在不同进程中运行。即使出现一些问题，攻击者也无法访问用户数据。\nWebRTC 诞生 #  我的个人理解是，多方面的因素和诉求，最终促成了 WebRTC 的诞生。\n构建实时通信软件不应该如此艰难。开发者们耗费了大量的精力来重新实现相同的东西。我们应该一次性解决这些令人沮丧的集成问题，然后就可以专注于其他事情。\n人际沟通应该是畅通无阻的，应该是开放的。为什么文本和 HTML 可以在浏览器里打开，而我的实时音视频却不能呢？\n安全是重中之重。使用 NPAPI 对用户来说并不是最好的。因此这也是一个机会，让我们可以创建一个默认就很安全的协议。\n为了实现 WebRTC，Google 收购并开源了很多我们用到过的组件，包括On2的视频技术和 Global IP Solution的 RTC 技术。我负责了其中 GIPS 的收购工作。我们必须将这些结合起来，让他们在浏览器内外都能够简单易用。\n标准化 #  WebRTC 的标准化是我们非常想要去做的一件事情，但我之前没有做过，当时的团队中也没有人有任何经验。这一点上，我们很幸运得到了 Google 的 Harald Alvestrand 的加盟。他此前已经在 IETF 做过很多工作，并且启动了 WebRTC 的标准化进程。\n2010 年的夏天，在 Maastricht 举办了一次非正式的午餐会。许多公司的开发人员们齐聚一堂，讨论 WebRTC 应该是什么样子的。餐桌上有来自 Google、Cisco、Ericsson、Skype、Mozilla、Linden Labs 等公司的工程师。你可以在rtc-web.alvestrand.com找到完整的出席人员和演示的幻灯片。\nSkype 当时已经在 IETF 完成了 Opus 的标准化工作，他们也提供了一些很好的指导意见。\n站在巨人的肩膀上 #  在 IETF 的工作实际是对过去人们工作的进一步扩展。 对 WebRTC 而言，我们非常幸运，因为已经有很多现有的技术可以使用。我们不需要负责所有的问题，因为很多问题（在现有的技术下）已经解决了。但如果你不喜欢现有的技术，这就可能成为一个麻烦的问题。我们一般不会选择重新造轮子，除非有特别必要的理由。\n我们也有意识地避免对某些东西重新标准化，比如信令（signaling）。信令的标准化已经通过 SIP 和其他非 IETF 组织的努力得到了解决，如果重新对它标准化，最终可能会演变成为政治问题。还有最本质的原因是，我们觉得（对其重新标准化）并不会创造什么有价值的贡献。\n我没有像 Justin 和 Harald 那样全程参与了标准化工作，不过我很享受参与其中的这段时光。当然，回来重新为用户创造产品是让我更兴奋的事。\n未来 #  WebRTC 如今正处于一个很好的位置。创新迭代在这个领域不断发生，而且这些创新并没有局限于我们曾经做过的一切。\n我最兴奋的是云计算将会如何影响通信技术。使用高级算法，我们可以从通话中去除背景噪音，这让我们在一些以前无法沟通的场景下通信成为可能。我们还看到 WebRTC 也不再局限于通信……谁能想到它已经被应用于云游戏 9 年之久了呢？如果没有 WebRTC 作为基础，这一切都是不可能实现的。\n"});index.add({'id':10,'href':'/zh/docs/11-faq/','title':"常见问题",'section':"Docs",'content':"常见问题 #   为什么 WebRTC 使用 UDP？ NAT 穿透需要 UDP。没有 NAT 穿透，就无法建立 P2P 连接。UDP 不像 TCP 那样 \u0026quot; 保证送达 \u0026ldquo;，因此 WebRTC 在用户级别提供这一特性。\n要了解更多信息，请参考 连接 章节。\n   数据通道最多可以有几个？ 因为流标识符有 16 位，所以最多有 65534 个通道。你可以随时关闭再创建一个新的。   WebRTC 是否有带宽限制？ 数据通道和 RTP 都使用拥塞控制。这意味着 WebRTC 会主动测量你的带宽并尝试使用最佳数值。这是一种平衡措施，这样可以尽量发送数据，而不会使网络连接过载。    我可以发送二进制数据吗？ 是的，你可以通过数据通道发送文本和二进制数据。   WebRTC 延迟怎么样？ 对于未作调整的媒体，估计不到 500 毫秒。如果你愿意为延迟调整或牺牲音质 / 画质，有开发人员将延迟降到了 100ms 以下。\n数据通道支持 \u0026quot; 部分可靠性 \u0026quot; 选项，该选项可以减少由于有损连接上的数据重传而引起的延迟。如果配置正确的话，速度可以超过 TCP TLS 连接。\n   什么情况下我会需要无序交付的数据通道？ 有时，新的信息会淘汰旧的信息（例如对象的位置信息）；或者，每个消息都是彼此独立的，并且你需要避免行头阻塞延迟。    我可以通过数据通道发送音频或视频吗？ 是的，你可以通过数据通道发送任何数据。如果是在浏览器中这样使用，你就需要自行对数据进行解码，然后将其传递给媒体播放器进行渲染；在使用媒体通道时，这部分是自动完成的。   "});index.add({'id':11,'href':'/zh/docs/12-glossary/','title':"术语",'section':"Docs",'content':"术语 #   ACK: Acknowledgment (确认报文) AVP: Audio and Video profile (音频视频描述) B-Frame: Bi-directional Predicted Frame. A partial picture, is a modification of previous and future pictures. (双向预测帧，存储图片的部分信息，存储的是相对前一张图片和后一张图片的差异信息) DCEP: Data Channel Establishment Protocol defined in RFC 8832 (DataChannel 建立协议) DeMux: Demultiplexer (解复用器) DLSR: delay since last sender report (从最近一个 Sender Report 开始的时间延迟) DTLS: Datagram Transport Layer Security defined in RFC 6347 E2E: end-to-end FEC: Forward Error Correction (前向纠错) FIR: Full INTRA-frame Request (完整 I 帧请求) G.711: A narrowband audio codec (一个窄带音频编码器) H.264: Advanced video coding for generic audiovisual services (面向通用视听服务的高级视频编码) H.265: Conformance specification for ITU-T H.265 high efficiency video coding. (ITU-T H.265 高效视频编码的一致性规范) HEVC: High Efficiency Video Coding (高效视频编码) HTTP: Hypertext Transfer Protocol (超文本传输协议) HTTPS: HTTP Over TLS defined in RFC 2818 (基于 TLS 的 HTTP) I-Frame: Intra-coded Frame. A complete picture, can be decoded without anything else. (内部编码帧，保存完整图片信息，自解码，不依赖外部数据) ICE: Interactive Connectivity Establishment defined in RFC 8445 (交互式连接建立协议) INIT: Initiate (初始化) IoT: Internet of Things (物联网) IPv4: Internet Protocol, Version 4 (第四代因特网协议) IPv6: Internet Protocol, Version 6 (第六代因特网协议) ITU-T: International Telecommunication Union Telecommunication Standardization Sector (国际电信联盟电信标准分局) JSEP: JavaScript Session Establishment Protocol defined in RFC 8829 (JavaScript 会话建立协议) MCU: Multi-point Conferencing Unit (多点会话单元) mDNS: Multicast DNS defined in RFC 6762 (组播 DNS) MITM: Man-In-The-Middle MTU: Maximum Transmission Unit (最大传输单元) MUX: Multiplexing (复用，一般指把不同格式的数据合并存储或传输) NACK: Negative Acknowledgment (逆确认报文，ACK 反馈收到报文 ,NACK 反馈未收到报文 ) NAT: Network Address Translation defined in RFC 4787 (网络地址转换，域名地址转换成 IP 地址) Opus: A totally open, royalty-free, highly versatile audio codec (一个完全开放、免版税、高度通用的音频编解码器) P-Frame: Predicted Frame. A partial picture, containing only changes from the previous picture. (前向预测帧，只保存相对于上一帧的差异信息) P2P: peer-to-peer PLI: Picture Loss Indication (图片丢失指示) PPID: Payload Protocol Identifier (Payload 协议标识) REMB: Receiver Estimated Maximum Bitrate (接收端估计的最大比特率) RFC: Request for Comments (征求意见) RMCAT: RTP Media Congestion Avoidance Techniques (RTP 媒体拥塞避免技术) RR: Receiver Report (RCTP 接收者报告) RTCP: RTP Control Protocol defined in RFC 3550 (RTP 控制协议) RTP: Real-time transport protocol defined in RFC 3550 (实时传输协议) RTT: Round-trip time (往返时间) SACK: Selective Acknowledgment (选择性确认) SCTP: Stream Control Transmission Protocol defined in RFC 4960 (流控传输协议) SDP: Session Description Protocol defined in RFC 8866 (会话描述协议) SFU: Selective Forwarding Unit (选择性转发单元) SR: Sender Report (RCTP 发送者报告) SRTP: Secure Real-time Transport Protocol defined in RFC 3711 (安全的 RTP) SSRC: Synchronization Source (同步源) STUN: Session Traversal Utilities for NAT defined in RFC 8489 (NAT 会话穿透) TCP: Transmission Control Protocol (传输控制协议) TLS: The Transport Layer Security defined in RFC 8446 (传输层安全) TMMBN: Temporary Maximum Media Stream Bit Rate Notification (临时最大媒体流比特率通知) TMMBR: Temporary Maximum Media Stream Bit Rate Request (临时最大媒体流比特率请求) TSN: Transmission Sequence Number (传输序列号) TURN: Traversal Using Relays around NAT defined in RFC 8656 (基于转发的 NAT 穿透) TWCC: Transport Wide Congestion Control (传输拥塞控制) UDP: User Datagram Protocol (数据报协议) VP8, VP9: Highly-efficient video compression technologies (video \u0026ldquo;codecs\u0026rdquo;) developed by the WebM Project. Anyone may use these codecs royalty-free. (WebM 项目开发的高效视频压缩技术 (视频编解码)，完全免费) WebM: An open media file format designed for the web. (一个开放的 Web 媒体文件格式) WebRTC: Web Real-Time Communications. W3C WebRTC 1.0: Real-Time Communication Between Browsers (Web 实时通信)  "});index.add({'id':12,'href':'/zh/docs/13-reference/','title':"Reference",'section':"Docs",'content':"Reference #  WebRTC(W3C) #   WebRTC 1.0: Real-Time Communication Between Browsers [26 January 2021] (Status: Recommendation) Web Real-Time Communications Working Group - Publications  WebRTC(RFC) #   RFC8825: Overview: Real-Time Protocols for Browser-Based Applications H. Alvestrand [January 2021] (Status: PROPOSED STANDARD) RFC8826: Security Considerations for WebRTC E. Rescorla [January 2021] (Status: PROPOSED STANDARD) RFC8836: Congestion Control Requirements for Interactive Real-Time Media R. Jesup, Z. Sarker [January 2021] (Status: INFORMATIONAL) RFC8854: WebRTC Forward Error Correction Requirements J. Uberti [January 2021] (Status: PROPOSED STANDARD)  DTLS #   RFC6347: Datagram Transport Layer Security Version 1.2 E. Rescorla, N. Modadugu [January 2012] (Obsoletes RFC4347) (Obsoleted-By RFC9147) (Updated-By RFC7507, RFC7905, RFC8996, RFC9146) (Status: PROPOSED STANDARD) RFC9147: The Datagram Transport Layer Security (DTLS) Protocol Version 1.3 E. Rescorla, H. Tschofenig, N. Modadugu [April 2022] (Obsoletes RFC6347) (Status: PROPOSED STANDARD) (See also: OpenSSL DTLS 1.3 status)  DataChannel #   RFC8831: WebRTC Data Channels R. Jesup, S. Loreto, M. Tüxen [January 2021] (Status: PROPOSED STANDARD) RFC8832: WebRTC Data Channel Establishment Protocol R. Jesup, S. Loreto, M. Tüxen [January 2021] (Status: PROPOSED STANDARD) RFC8864: Negotiation Data Channels Using the Session Description Protocol (SDP) K. Drage, M. Makaraju, R. Ejzak, J. Marcon, R. Even [January 2021] (Status: PROPOSED STANDARD)  MediaTransport #   RFC8834: Media Transport and Use of RTP in WebRTC C. Perkins, M. Westerlund, J. Ott [January 2021] (Status: PROPOSED STANDARD) RFC8837: Differentiated Services Code Point (DSCP) Packet Markings for WebRTC QoS P. Jones, S. Dhesikan, C. Jennings, D. Druta [January 2021] (Status: PROPOSED STANDARD)  SCTP #   RFC3758: Stream Control Transmission Protocol (SCTP) Partial Reliability Extension R. Stewart, M. Ramalho, Q. Xie, M. Tuexen, P. Conrad [May 2004] (Status: PROPOSED STANDARD) RFC5061: Stream Control Transmission Protocol (SCTP) Dynamic Address Reconfiguration R. Stewart, Q. Xie, M. Tuexen, S. Maruyama, M. Kozuka [September 2007] (Status: PROPOSED STANDARD) RFC5827: Early Retransmit for TCP and Stream Control Transmission Protocol (SCTP) M. Allman, K. Avrachenkov, U. Ayesta, J. Blanton, P. Hurtig [May 2010] (Status: EXPERIMENTAL) RFC6083: Datagram Transport Layer Security (DTLS) for Stream Control Transmission Protocol (SCTP) M. Tuexen, R. Seggelmann, E. Rescorla [January 2011] (Updated-By RFC8996) (Status: PROPOSED STANDARD) RFC6525: Stream Control Transmission Protocol (SCTP) Stream Reconfiguration R. Stewart, M. Tuexen, P. Lei [February 2012] (Status: PROPOSED STANDARD) RFC6951: UDP Encapsulation of Stream Control Transmission Protocol (SCTP) Packets for End-Host to End-Host Communication M. Tuexen, R. Stewart [May 2013] (Updated-By RFC8899) (Status: PROPOSED STANDARD) RFC7765: TCP and Stream Control Transmission Protocol (SCTP) RTO Restart P. Hurtig, A. Brunstrom, A. Petlund, M. Welzl [February 2016] (Status: EXPERIMENTAL) RFC8260: Stream Schedulers and User Message Interleaving for the Stream Control Transmission Protocol R. Stewart, M. Tuexen, S. Loreto, R. Seggelmann [November 2017] (Status: PROPOSED STANDARD) RFC8261: Datagram Transport Layer Security (DTLS) Encapsulation of SCTP Packets M. Tuexen, R. Stewart, R. Jesup, S. Loreto [November 2017] (Updated-By RFC8899, RFC8996) (Status: PROPOSED STANDARD) RFC8841: Session Description Protocol (SDP) Offer/Answer Procedures for Stream Control Transmission Protocol (SCTP) over Datagram Transport Layer Security (DTLS) Transport C. Holmberg, R. Shpount, S. Loreto, G. Camarillo [January 2021] (Status: PROPOSED STANDARD) RFC8899: Packetization Layer Path MTU Discovery for Datagram Transports G. Fairhurst, T. Jones, M. Tüxen, I. Rüngeler, T. Völker [September 2020] (Updates RFC4821, RFC4960, RFC6951, RFC8085, RFC8261) (Status: PROPOSED STANDARD) RFC9260: Stream Control Transmission Protocol R. Stewart, M. Tüxen, K. Nielsen [June 2022] (Obsoletes RFC4460, RFC4960, RFC6096, RFC7053, RFC8540) (Status: PROPOSED STANDARD)  SDP #   RFC8829: JavaScript Session Establishment Protocol (JSEP) J. Uberti, C. Jennings, E. Rescorla [January 2021] (Status: PROPOSED STANDARD) RFC8830: WebRTC MediaStream Identification in the Session Description Protocol H. Alvestrand [January 2021] (Status: PROPOSED STANDARD) RFC8839: Session Description Protocol (SDP) Offer/Answer Procedures for Interactive Connectivity Establishment (ICE) M. Petit-Huguenin, S. Nandakumar, C. Holmberg, A. Keränen, R. Shpount [January 2021] (Obsoletes RFC5245, RFC6336) (Status: PROPOSED STANDARD) RFC8841: Session Description Protocol (SDP) Offer/Answer Procedures for Stream Control Transmission Protocol (SCTP) over Datagram Transport Layer Security (DTLS) Transport C. Holmberg, R. Shpount, S. Loreto, G. Camarillo [January 2021] (Status: PROPOSED STANDARD) RFC8843: Negotiating Media Multiplexing Using the Session Description Protocol (SDP) C. Holmberg, H. Alvestrand, C. Jennings [January 2021] (Obsoleted-By RFC9143) (Updates RFC3264, RFC5888, RFC7941) (Status: PROPOSED STANDARD) RFC8844: Unknown Key-Share Attacks on Uses of TLS with the Session Description Protocol (SDP) M. Thomson, E. Rescorla [January 2021] (Updates RFC8122) (Status: PROPOSED STANDARD) RFC8851: RTP Payload Format Restrictions A.B. Roach [January 2021] (Updates RFC4855) (Status: PROPOSED STANDARD) RFC8852: RTP Stream Identifier Source Description (SDES) A.B. Roach, S. Nandakumar, P. Thatcher [January 2021] (Status: PROPOSED STANDARD) RFC8853: Using Simulcast in Session Description Protocol (SDP) and RTP Sessions B. Burman, M. Westerlund, S. Nandakumar, M. Zanaty [January 2021] (Status: PROPOSED STANDARD) RFC8866: SDP: Session Description Protocol A. Begen, P. Kyzivat, C. Perkins, M. Handley [January 2021] (Obsoletes RFC4566) (Status: PROPOSED STANDARD)  RTP #   RFC3550: RTP: A Transport Protocol for Real-Time Applications H. Schulzrinne, S. Casner, R. Frederick, V. Jacobson [July 2003] (Obsoletes RFC1889) (Updated-By RFC5506, RFC5761, RFC6051, RFC6222, RFC7022, RFC7160, RFC7164, RFC8083, RFC8108, RFC8860) (Also STD0064) (Status: INTERNET STANDARD) RFC3611: RTP Control Protocol Extended Reports (RTCP XR) T. Friedman, R. Caceres, A. Clark [November 2003] (Status: PROPOSED STANDARD) RFC3711: The Secure Real-time Transport Protocol (SRTP) M. Baugher, D. McGrew, M. Naslund, E. Carrara, K. Norrman [March 2004] (Updated-By RFC5506, RFC6904) (Status: PROPOSED STANDARD) RFC4585: Extended RTP Profile for Real-time Transport Control Protocol (RTCP)-Based Feedback (RTP/AVPF) J. Ott, S. Wenger, N. Sato, C. Burmeister, J. Rey [July 2006] (Updated-By RFC5506, RFC8108) (Status: PROPOSED STANDARD) RFC5104: Codec Control Messages in the RTP Audio-Visual Profile with Feedback (AVPF) S. Wenger, U. Chandra, M. Westerlund, B. Burman [February 2008] (Updated-By RFC7728, RFC8082) (Status: PROPOSED STANDARD) RFC5764: Datagram Transport Layer Security (DTLS) Extension to Establish Keys for the Secure Real-time Transport Protocol (SRTP) D. McGrew, E. Rescorla [May 2010] (Updated-By RFC7983) (Status: PROPOSED STANDARD) RFC6904: Encryption of Header Extensions in the Secure Real-time Transport Protocol (SRTP) J. Lennox [April 2013] (Updates RFC3711) (Status: PROPOSED STANDARD) RFC7741: RTP Payload Format for VP8 Video P. Westin, H. Lundin, M. Glover, J. Uberti, F. Galligan [March 2016] (Status: PROPOSED STANDARD) RFC8285: A General Mechanism for RTP Header Extensions D. Singer, H. Desineni, R. Even [October 2017] (Obsoletes RFC5285) (Status: PROPOSED STANDARD) RFC8852: RTP Stream Identifier Source Description (SDES) A.B. Roach, S. Nandakumar, P. Thatcher [January 2021] (Status: PROPOSED STANDARD) RFC8858: Indicating Exclusive Support of RTP and RTP Control Protocol (RTCP) Multiplexing Using the Session Description Protocol (SDP) C. Holmberg [January 2021] (Updates RFC5761) (Status: PROPOSED STANDARD) RFC8860: Sending Multiple Types of Media in a Single RTP Session M. Westerlund, C. Perkins, J. Lennox [January 2021] (Updates RFC3550, RFC3551) (Status: PROPOSED STANDARD) RFC8867: Test Cases for Evaluating Congestion Control for Interactive Real-Time Media Z. Sarker, V. Singh, X. Zhu, M. Ramalho [January 2021] (Status: INFORMATIONAL) RFC8868: Evaluating Congestion Control for Interactive Real-Time Media V. Singh, J. Ott, S. Holmer [January 2021] (Status: INFORMATIONAL) RFC8869: Evaluation Test Cases for Interactive Real-Time Media over Wireless Networks Z. Sarker, X. Zhu, J. Fu [January 2021] (Status: INFORMATIONAL) RFC8872: Guidelines for Using the Multiplexing Features of RTP to Support Multiple Media Streams M. Westerlund, B. Burman, C. Perkins, H. Alvestrand, R. Even [January 2021] (Status: INFORMATIONAL) RFC8888: RTP Control Protocol (RTCP) Feedback for Congestion Control Z. Sarker, C. Perkins, V. Singh, M. Ramalho [January 2021] (Status: PROPOSED STANDARD)  ICE, TURN and STUN #   RFC5780: NAT Behavior Discovery Using Session Traversal Utilities for NAT (STUN) D. MacDonald, B. Lowekamp [May 2010] (Updated-By RFC8553) (Status: EXPERIMENTAL) RFC8445: Interactive Connectivity Establishment (ICE): A Protocol for Network Address Translator (NAT) Traversal A. Keranen, C. Holmberg, J. Rosenberg [July 2018] (Obsoletes RFC5245) (Updated-By RFC8863) (Status: PROPOSED STANDARD) RFC8489: Session Traversal Utilities for NAT (STUN) M. Petit-Huguenin, G. Salgueiro, J. Rosenberg, D. Wing, R. Mahy, P. Matthews [February 2020] (Obsoletes RFC5389) (Status: PROPOSED STANDARD) RFC8656: Traversal Using Relays around NAT (TURN): Relay Extensions to Session Traversal Utilities for NAT (STUN) T. Reddy, A. Johnston, P. Matthews, J. Rosenberg [February 2020] (Obsoletes RFC5766, RFC6156) (Status: PROPOSED STANDARD) RFC8835: Transports for WebRTC H. Alvestrand [January 2021] (Status: PROPOSED STANDARD) RFC8838: Trickle ICE: Incremental Provisioning of Candidates for the Interactive Connectivity Establishment (ICE) Protocol E. Ivov, J. Uberti, P. Saint-Andre [January 2021] (Updated-By RFC8863) (Status: PROPOSED STANDARD) RFC8839: Session Description Protocol (SDP) Offer/Answer Procedures for Interactive Connectivity Establishment (ICE) M. Petit-Huguenin, S. Nandakumar, C. Holmberg, A. Keränen, R. Shpount [January 2021] (Obsoletes RFC5245, RFC6336) (Status: PROPOSED STANDARD) RFC8863: Interactive Connectivity Establishment Patiently Awaiting Connectivity (ICE PAC) C. Holmberg, J. Uberti [January 2021] (Updates RFC8445, RFC8838) (Status: PROPOSED STANDARD)  "});})();