[{"id":0,"href":"/ja/docs/01-what-why-and-how/","title":"何を、なぜ、どのように","section":"Docs","content":" 何を、なぜ、どのように # WebRTCとは？ # WebRTC とは、Web Real-Time Communication の略で、API であると同時にプロトコルでもあります。WebRTC プロトコルは、2 つの WebRTC エージェントが双方向の安全なリアルタイム通信をネゴシエートするための一連のルールです。WebRTC API は、開発者が WebRTC プロトコルを使用するためのものです。WebRTC API は、JavaScript のみで規定されています。\n似たような関係として、HTTP と fetch API があります。プロトコルとしての WebRTC が HTTP で、API としての WebRTC が fetch API となります。\nWebRTC プロトコルは、JavaScript 以外の API/言語でも利用可能です。また、WebRTC 用のサーバーやドメイン固有のツールもあります。これらの実装はすべて WebRTC プロトコルを使用しているため、相互にやりとりできます。\nWebRTC プロトコルは、IETF のrtcwebというワーキンググループで管理されています。WebRTC API は、W3C のwebrtcで文書化されています。\nなぜWebRTCを学ぶ必要があるのか？ # WebRTC を使うことで得られるものは以下の通りです。このリストはすべてを網羅しているわけではありませんが、あなたが旅をしている間に感謝することもあるでしょう。これらの用語のいくつかをまだ知らなくても、この本が教えてくれますのでご安心ください。\nオープンスタンダード 複数の実装 ブラウザで利用可能 必須の暗号化 NAT トラバーサル 既存技術の再利用 輻輳（ふくそう）制御 1秒未満のレイテンシー WebRTCプロトコルは他の技術の集合体である # これは、本 1 冊分の説明が必要なテーマです。しかし、ここでは 4 つのステップに分けて説明します。\nシグナリング 接続 セキュリティの確保 通信 この 4 つのステップは順番に行われます。前のステップが 100％成功しなければ、次のステップは始まりません。\nWebRTC の特徴の一つは、各ステップが実のところ他の多くのプロトコルによって構成されているということです。WebRTC を形作るために、多くの既存技術が組み合わされています。そういった意味で、WebRTC は 2000 年代初頭から存在する、よく理解された技術を組み合わせて構成したものと言えます。\nこれらのステップはそれぞれ専用の章を設けていますが、まずは大まかに理解しておくと便利です。これらの手順はお互いに依存しているため、それぞれの手順の目的をさらに説明する際に役立ちます。\nシグナリング: WebRTCでピアがお互いを見つける方法 # WebRTC エージェントが起動したとき、WebRTC エージェントは誰と何の通信をするのかを知りません。この問題を解決するのがシグナリングです。シグナリングは、2 つの WebRTC エージェントが通信を開始できるようにするために使用されます。\nシグナリングは、既存のプロトコルである SDP（Session Description Protocol）を使用します。SDP はプレーンテキストのプロトコルです。各 SDP メッセージは、キー／バリューペアで構成され、「メディアセクション」のリストを含んでいます。2 つの WebRTC エージェント間で交換する SDP には、以下のような詳細情報が含まれています。\nエージェントが到達可能な IP およびポート (候補) エージェントが送信しようとしているオーディオおよびビデオトラックの数 各エージェントがサポートするオーディオおよびビデオコーデック 接続時に使用される値 (uFrag/uPwd) セキュリティ確保時に使用される値 (証明書のフィンガープリント) シグナリングは通常 WebRTC プロトコルの与り知らないところで行われることに注意してください。つまり、アプリケーションは通常、WebRTC 自体を使用してシグナリングメッセージを交換することはありません。接続しようとしているピア間ではメッセージの送信に適するような任意のアーキテクチャを使用して SDP を中継することができ、多くのアプリケーションは既存のインフラストラクチャ (REST エンドポイント、WebSocket 接続、または認証プロキシなど) を使用して、適切なクライアント間で SDP を円滑に交換できるようにしています。\nSTUN/TURN による接続と NAT トラバーサル # これで、2 つの WebRTC Agent は、お互いに接続を試みるのに十分な詳細を知ることができました。WebRTC は ICE という別の確立された技術を使用します。\nICE（Interactive Connectivity Establishment）は、WebRTC よりも前のプロトコルです。ICE では、2 つの Agent 間で接続を確立できます。これらの Agent は、同じネットワーク上にある場合もあれば、地球の反対側にある場合もあります。ICE は、中央のサーバーを使わずに直接接続を確立するためのソリューションです。\nそれを可能にしているのは、「NAT トラバーサル」と「STUN/TURN サーバー」です。この 2 つの概念があれば、別のサブネットにいる ICE エージェントと通信できます。これらのトピックについては、後ほど詳しく説明します。\nICE が接続に成功すると、WebRTC は暗号化トランスポートの確立に進みます。このトランスポートは、音声、ビデオ、データに使用されます。\nDTLS と SRTP によるトランスポート層のセキュリティ確保 # ICE による双方向通信が可能になったところで、安全な通信を確立する必要があります。これには、WebRTC よりも古い 2 つのプロトコルを使用します。1 つ目のプロトコルは DTLS（Datagram Transport Layer Security）で、これは UDP 上の TLS に過ぎません。TLS は、HTTPS での通信を保護するために使用される暗号化プロトコルです。2 つ目のプロトコルは SRTP（Secure Real-time Transport Protocol）です。\nまず、WebRTC は ICE で確立された接続の上で DTLS ハンドシェイクを行って接続します。HTTPS とは異なり、WebRTC は証明書に中央機関を使用しません。代わりに、WebRTC は、DTLS を通じて交換された証明書が、シグナリングによって共有されたフィンガープリントと一致することを表明します。この DTLS 接続は、DataChannel メッセージに使用されます。\nWebRTC は、RTP と呼ばれるオーディオ／ビデオ伝送用の別のプロトコルを使用します。RTP パケットのセキュリティには SRTP を使用します。SRTP セッションは、ネゴシエートされた DTLS セッションからキーを抽出して初期化します。後の章では、メディア伝送に独自のプロトコルが必要な理由について説明します。\nこれで完了です。双方向の安全な通信が可能になりました。WebRTC エージェント間の接続が安定していれば、これ以上の複雑な作業は必要ありません。しかしながら、現実の世界ではパケットロスや帯域幅の制限があるため、WebRTC エージェントがそれらに対処する方法を次のセクションで説明します。\nRTP および SCTP によるピアとの通信 # これで 2 つの WebRTC Agent が安全な双方向通信を行うことができました。それでは早速、通信を開始しましょう。ここでも、既存の 2 つのプロトコルを使用します。RTP（Real-time Transport Protocol）と SCTP（Stream Control Transmission Protocol）です。SRTP で暗号化されたメディアのやり取りにはRTPを、DTLS で暗号化された DataChannel メッセージの送受信には SCTP を使用します。\nRTP は最小限の機能しか備えていませんが、リアルタイムストリーミングを実現するために必要な機能を備えています。重要なのは、RTP が開発者に柔軟性を与えていることで、開発者はレイテンシー、ロス、輻輳を思い通りに処理できます。この点については、「メディア」の章で詳しく説明します。\nスタックの最後のプロトコルは SCTP です。SCTP では、メッセージの配信オプションが多数用意されています。オプションで、信頼性のない、順番のない配信を選択できますので、リアルタイムシステムに必要なレイテンシーを得ることができます。\nプロトコルの集合体であるWebRTC # WebRTC は多くの問題を解決していて、一見過剰な技術とさえ思えるかもしれません。しかし、WebRTC のとてもすばらしいところは、実に謙虚だというところです。WebRTC は、自前ですべてをうまく解決できるとは考えませんでした。その代わり、多くの既存の単一目的の技術を採用し、それらを束ねることにしました。\nこれにより、私たちは圧倒されることなく、各部分を個別に検討し、学ぶことができるのです。「WebRTC エージェント」とは、実際には多くの異なるプロトコルを組み合わせたものに過ぎないということです。\nWebRTC (API) はどのように動作するか # このセクションでは、JavaScript の API がプロトコルにどのように対応するかを示します。これは、WebRTC API の広範なデモを意味するものではなく、すべてがどのように結びついているかのメンタルモデルを作成するためのものです。 どちらにも慣れていない方でも問題ありません。このセクションは、より多くのことを学ぶために戻ってくる楽しみがあるかもしれません。\nnew RTCPeerConnection # RTCPeerConnection は、トップレベルの「WebRTC セッション」です。これには上述のすべてのプロトコルが含まれています。サブシステムはすべて割り当てられていますが、まだ何も起こりません。\naddTrack # addTrack は新しい RTP ストリームを作成します。このストリームには、ランダムな同期ソース (SSRC) が生成されます。このストリームは、メディアセクション内の createOffer で生成された Session Description の中に入ります。 addTrack を呼び出すたびに、新しい SSRC とメディアセクションが作成されます。\nSRTP セッションが確立されるとすぐに、これらのメディアパケットは SRTP で暗号化された後、ICE 経由で送信され始めます。\ncreateDataChannel # createDataChannel は、SCTP アソシエーションが存在しない場合に、新しい SCTP ストリームを作成します。デフォルトでは、SCTP は有効ではなく、一方の側がデータチャネルを要求したときにのみ開始されます。\nDTLS セッションが確立された直後に、SCTP アソシエーションは ICE を経由して DTLS で暗号化されたパケットの送信を開始します。\ncreateOffer # createOffer は、リモートピアと共有するローカルステートの Session Description を生成します。\ncreateOffer を呼び出しても、ローカルピアは何も変わりません。\nsetLocalDescription # setLocalDescription は要求されたすべての変更をコミットします。addTrack, createDataChannel などの呼び出しは、この呼び出しまではすべて一時的なものです。 setLocalDescription は createOffer で生成された値で呼び出されます。\n通常、この呼び出しの後、リモートピアにオファーを送信し、リモートピアはそれを使って setRemoteDescription を呼び出します。\nsetRemoteDescription # setRemoteDescription は、リモート候補の状態をローカルエージェントに通知する方法です。これは、JavaScript の API で「シグナリング」をする方法です。\n双方で setRemoteDescription が呼び出されると、WebRTC エージェントは P2P 通信を開始するのに十分な情報を得ることができます!\naddIceCandidate # addIceCandidate を使うと、WebRTC エージェントはいつでも好きなときにリモートの ICE 候補を追加できます。この API は ICE サブシステムに ICE Candidate を直接送信し、大規模な WebRTC 接続には他の影響を与えません。\nontrack # ontrack は、リモートピアから RTP パケットを受信したときに起動されるコールバックです。受信パケットは、setRemoteDescription に渡された Session Description で宣言されているはずです。\nWebRTC は SSRC を使用して、関連する MediaStream と MediaStreamTrack を検索し、これらの詳細が入力された状態でこのコールバックを起動します。\noniceconnectionstatechange # oniceconnectionstatechange は、ICE エージェントの状態を反映して起動されるコールバックです。ネットワークに接続されたときや、切断されたときに、このように通知されます。\nonconnectionstatechange # onconnectionstatechange は、ICE エージェントと DTLS エージェントの状態を組み合わせたものです。これを見ることで、ICE と DTLS の両方が正常に完了したときに通知を受けることができます。\n"},{"id":1,"href":"/ja/docs/02-signaling/","title":"シグナリング","section":"Docs","content":" シグナリング # WebRTCシグナリングとは？ # WebRTC エージェントを作成したとき、エージェントは他のピアについて何も知りません。誰と接続しようとしているのか、何を送ろうとしているのか、全くわかりません。 シグナリングは、通話を可能にする最初のブートストラップです。これらの値が交換されると、WebRTC エージェントはお互いに直接通信できるようになります。\nシグナリングメッセージは単なるテキストです。WebRTC エージェントは、メッセージの転送方法を気にしません。一般的には WebSocket で共有されますが、これは必須ではありません。\nWebRTC のシグナリングはどのように動作しますか？ # WebRTC は、Session Description Protocol と呼ばれる既存のプロトコルを使用しています。このプロトコルにより、2 つの WebRTC エージェントは、接続を確立するために必要なすべての状態を共有します。このプロトコル自体は、読んで理解するのは簡単です。 複雑なのは、WebRTC がこのプロトコルに入力するすべての値を理解することです。\nこのプロトコルは WebRTC 固有のものではありません。WebRTC の話をしなくても、まず Session Description Protocol を学びます。WebRTC はこのプロトコルのサブセットを実際に利用するだけなので、ここでは必要なものだけを取り上げます。 プロトコルを理解した後は、WebRTC での応用的な使い方に進みます。\nSession Description Protocol (SDP)とは？ # SDP は、RFC 8866で定義されています。SDP はキーと値で構成されるプロトコルで、各値の後には改行が入ります。これは、INI ファイルに似ています。 Session Description は、0 個以上のメディア記述を含みます。頭の中では、Session Description にメディア記述の配列が含まれているようにモデル化できます。\nメディア記述は通常、メディアの 1 つのストリームに対応しています。つまり、3 つのビデオストリームと 2 つのオーディオトラックを持つ通話を記述したい場合、5 つのメディア記述が必要になります。\nSDPの読み方 # Session Description の各行は、1 つの文字で始まります。その後、等号が続きます。この等号以降が値となります。値が完了すると、改行されます。\nSDP では、有効なキーをすべて定義しています。プロトコルで定義されているキーには、文字しか使用できません。これらのキーにはすべて重要な意味がありますが、それについては後ほど説明します。\nSession Description の例を見てみましょう。\na=my-sdp-value a=second-value 2 つの行がありますね。それぞれがキー a を持っています。1 行目には my-sdp-value という値があり、2 行目には second-value という値があります。\nWebRTCは一部のSDPキーしか使用しない # WebRTC では、SDP で定義されているすべてのキー値を使用しているわけではありません。RFC 8829 JavaScriptセッション確立規約 (JavaScript Session Establishment Protocol (JSEP)) で定義されたキーのみが重要です。以下の 7 つのキーだけは、今すぐ理解しておく必要があります。\nv - バージョン(Version)、0 と同じでなければなりません。 o - オリジン(Origin)、再交渉に便利なユニークな ID を含む。 s - セッション名(Session Name)、- と同じでなければなりません。 t - タイミング(Timing)、0 0 と同じでなければなりません。 m - メディア記述(Media Description: m=\u0026lt;media\u0026gt; \u0026lt;port\u0026gt; \u0026lt;proto\u0026gt; \u0026lt;fmt\u0026gt; ...)、詳細は以下の通りです。 a - 属性(Attribute)、フリーテキストのフィールドです。これは WebRTC で最も一般的な行です。 c - 接続データ(Connection Data)、 IN IP4 0.0.0.0 と等しくなければなりません。 Session Description に含まれるメディアの説明文 # Session Description には、メディア記述を無制限に含めることができます。\nメディア記述の定義には、フォーマットのリストが含まれます。これらのフォーマットは RTP ペイロードタイプに対応しています。実際のコーデックは、メディア記述の中の rtpmap という値を持つ属性によって定義されます。 RTP と RTP Payload Type の重要性については、「メディア」の章で後述します。各メディア記述には、無制限の数の属性を含めることができます。\nSession Description を例に挙げてみましょう。\nv=0 m=audio 4000 RTP/AVP 111 a=rtpmap:111 OPUS/48000/2 m=video 4000 RTP/AVP 96 a=rtpmap:96 VP8/90000 a=my-sdp-value 2つのメディア記述があります。1つはfmt111のaudioタイプで、もう1つはfmt96のvideoタイプです。1つ目のメディア記述には1つの属性しかありません。この属性は、ペイロードタイプ 111 をOpusにマッピングします。 2つ目のメディア記述には2つの属性があります。1つ目の属性は、Payload Type 96 を VP8 にマップし、2つ目の属性は単なる my-sdp-value です。\nFull Example # 完全な例 # 次の例では、これまで説明してきたすべての概念をまとめています。これらはすべて、WebRTC が使用する SDP の機能です。 これが読めれば、どんな WebRTC の Session Description でも読めます。\nv=0 o=- 0 0 IN IP4 127.0.0.1 s=- c=IN IP4 127.0.0.1 t=0 0 m=audio 4000 RTP/AVP 111 a=rtpmap:111 OPUS/48000/2 m=video 4002 RTP/AVP 96 a=rtpmap:96 VP8/90000 v, o, s, c, t が定義されていますが、WebRTC セッションには影響しません。 2つのメディア記述があります。1つは audio タイプで、もう1つは video タイプです。 それぞれに1つの属性があります。この属性は RTP パイプラインの詳細を設定するもので、「メディアコミュニケーション」の章で説明します。 SDP(Session Description Protocol) と WebRTC の連携について # 次のパズルのピースは、WebRTC が SDP をどのように使用するかを理解することです。\nオファーとアンサーとは？ # WebRTCでは、オファー/アンサーモデルを採用しています。つまり、一方の WebRTC エージェントが「オファー」を出して通話を開始し、他方の WebRTC エージェントがオファーされた内容を受け入れるかどうかを「アンサー」します。\nこれにより、回答者はコーデックやメディア記述を拒否する機会が与えられます。このようにして、2つのピアが何を交換しようとしているのかを理解できます。\nトランシーバーは送受信用 # トランシーバーはWebRTC特有の概念で、APIの中にも出てきます。これは、「メディア記述」を JavaScript API に公開するものです。各メディア記述は、トランシーバーになります。 トランシーバーを作成するたびに、新しいメディア記述がローカルの Session Description に追加されます\nWebRTCの各メディア記述は、direction属性を持ちます。これにより、WebRTCエージェントは「このコーデックを送信するが、何も受信しない」と宣言できます。有効な値は4つあります。\nsend (送信) recv (受信) sendrecv (送受信) inactive (非アクティブ) WebRTC で使用される SDP の値 # ここでは、WebRTC エージェントの Session Description で見られる一般的な属性の一覧を示します。これらの値の多くは、これまで説明してこなかったサブシステムを制御するものです。\ngroup:BUNDLE # バンドルとは、複数の種類のトラフィックを1つの接続で実行することです。WebRTCの実装によっては、メディアストリームごとに専用の接続を使用するものもあります。バンドルが望ましいです。\nfingerprint:sha-256 # これは、ピアがDTLSに使用している証明書のハッシュ値です。DTLSのハンドシェイクが完了した後、これを実際の証明書と比較して、期待通りの相手と通信していることを確認します。\nsetup: # これは、DTLSエージェントの動作を制御します。ICEが接続した後に、クライアントとして実行するか、サーバーとして実行するかを決定します。設定可能な値は以下の通りです。\nsetup:active - DTLSクライアントとして動作します。 setup:passive - DTLSサーバーとして動作します。 setup:actpass - 他の WebRTC エージェントに選択を依頼します。 mid: # mid 属性は Session Description 内のメディアストリームを識別するために使われます。\nice-ufrag # ICEエージェントのユーザーフラグメント値です。ICEトラフィックの認証に使用されます。\nice-pwd # ICEエージェントのパスワードです。ICEトラフィックの認証に使用されます。\nrtpmap # この値は、特定のコーデックをRTPペイロードタイプにマッピングするために使用されます。ペイロードタイプは固定されていないので、通話ごとにオファー側が各コーデックのペイロードタイプを決定します。\nfmtp # 1つのPayload Typeに対して追加の値を定義します。これは、特定のビデオプロファイルやエンコーダの設定を伝えるのに便利です。\ncandidate (候補) # ICE エージェントから送られてくる ICE キャンディデートです。これは、WebRTCエージェントが利用可能なアドレスの1つです。これらについては、次の章で詳しく説明します。\nssrc # 同期ソース（SSRC）は、1つのメディアストリームトラックを定義します。\nlabel は、この個々のストリームの ID です。 mslabel は、内部に複数のストリームを持つことができるコンテナの ID です。\nWebRTC Session Description の例 # WebRTCクライアントが生成する Session Description の例を以下に示します。\nv=0 o=- 3546004397921447048 1596742744 IN IP4 0.0.0.0 s=- t=0 0 a=fingerprint:sha-256 0F:74:31:25:CB:A2:13:EC:28:6F:6D:2C:61:FF:5D:C2:BC:B9:DB:3D:98:14:8D:1A:BB:EA:33:0C:A4:60:A8:8E a=group:BUNDLE 0 1 m=audio 9 UDP/TLS/RTP/SAVPF 111 c=IN IP4 0.0.0.0 a=setup:active a=mid:0 a=ice-ufrag:CsxzEWmoKpJyscFj a=ice-pwd:mktpbhgREmjEwUFSIJyPINPUhgDqJlSd a=rtcp-mux a=rtcp-rsize a=rtpmap:111 opus/48000/2 a=fmtp:111 minptime=10;useinbandfec=1 a=ssrc:350842737 cname:yvKPspsHcYcwGFTw a=ssrc:350842737 msid:yvKPspsHcYcwGFTw DfQnKjQQuwceLFdV a=ssrc:350842737 mslabel:yvKPspsHcYcwGFTw a=ssrc:350842737 label:DfQnKjQQuwceLFdV a=msid:yvKPspsHcYcwGFTw DfQnKjQQuwceLFdV a=sendrecv a=candidate:foundation 1 udp 2130706431 192.168.1.1 53165 typ host generation 0 a=candidate:foundation 2 udp 2130706431 192.168.1.1 53165 typ host generation 0 a=candidate:foundation 1 udp 1694498815 1.2.3.4 57336 typ srflx raddr 0.0.0.0 rport 57336 generation 0 a=candidate:foundation 2 udp 1694498815 1.2.3.4 57336 typ srflx raddr 0.0.0.0 rport 57336 generation 0 a=end-of-candidates m=video 9 UDP/TLS/RTP/SAVPF 96 c=IN IP4 0.0.0.0 a=setup:active a=mid:1 a=ice-ufrag:CsxzEWmoKpJyscFj a=ice-pwd:mktpbhgREmjEwUFSIJyPINPUhgDqJlSd a=rtcp-mux a=rtcp-rsize a=rtpmap:96 VP8/90000 a=ssrc:2180035812 cname:XHbOTNRFnLtesHwJ a=ssrc:2180035812 msid:XHbOTNRFnLtesHwJ JgtwEhBWNEiOnhuW a=ssrc:2180035812 mslabel:XHbOTNRFnLtesHwJ a=ssrc:2180035812 label:JgtwEhBWNEiOnhuW a=msid:XHbOTNRFnLtesHwJ JgtwEhBWNEiOnhuW a=sendrecv このメッセージからわかったことは以下の通りです。\nオーディオとビデオの2つのメディアセクションがあります。 どちらも sendrecv トランシーバーです。2つのストリームを受信しているので、2つのストリームを送り返すことができます。 ICE CandidatesとAuthenticationの詳細があるので、接続を試みることができます。 証明書のフィンガープリントがあるので、安全な通話ができます。 その他のトピック # 本書の次のバージョンでは、以下のトピックについても説明します。疑問点があれば、Pull Request を提出してください。\nリネゴシエーション サイマルキャスト "},{"id":2,"href":"/ja/docs/03-connecting/","title":"接続","section":"Docs","content":" 接続 # なぜWebRTCには接続用の専用サブシステムが必要なのでしょうか？ # 現在導入されているほとんどのアプリケーションは、クライアント/サーバー接続を確立しています。クライアント/サーバー接続では、サーバーが安定した周知のトランスポートアドレスを持っている必要があります。クライアントはサーバーにコンタクトし、サーバーはそれに応答します。\nWebRTCは、クライアント/サーバーモデルを使用せず、ピアツーピア（P2P）接続を確立します。P2P接続では、接続を作成するタスクが両方のピアに均等に分配されます。これは、WebRTCのトランスポートアドレス（IPとポート）は想定できず、セッション中に変更される可能性もあるためです。WebRTCはできる限りの情報を収集し、2つのWebRTCエージェント間の双方向通信を実現するために多大な努力をします。\nしかし、ピアツーピアの接続を確立するのは難しいことです。これらのエージェントは、直接接続されていない異なるネットワークに存在する可能性があります。直接的な接続性が存在する場合でも、別の問題が発生することがあります。クライアントが異なるプロトコル (UDP \u0026lt;-\u0026gt; TCP) や、IPバージョン (IPv4 \u0026lt;-\u0026gt; IPv6) を利用している場合もあります。\nこのようにP2P接続の設定が難しいにもかかわらず、WebRTCには以下のような特徴があるため、従来のクライアント/サーバー技術よりも有利になります。\n帯域幅コストの削減 # メディアの通信はピア間で直接行われるため、メディアを中継するために別のサーバーを用意する必要がありません。\n遅延の低減 # 通信は直接行われる方が速いです。ユーザーが全ての通信をサーバーを経由して行うと、通信速度が低下します。\n安全なE2E通信 # 直接通信の方が安全です。ユーザーはサーバーを経由せずにデータを送信するので、ユーザーはサーバーがデータを解読しないことを信じる必要はありません。\nどうやって使うの？ # 上記のプロセスは、Interactive Connectivity Establishment (ICE)と呼ばれています。WebRTCよりも前のプロトコルです。\nICEは、2つのICE Agent間の通信に最適な方法を見つけようとするプロトコルです。各ICEエージェントは、到達可能な方法を公開しており、これを候補と呼びます。候補とは、基本的に、相手が到達できると考えられるエージェントのトランスポートアドレスです。ICEは、候補の中から最適な組み合わせを決定します。\nICEの実際のプロセスについては、本章の後半で詳しく説明します。WebRTC がネットワークにおけるどのような挙動を克服しようとしているかを理解すると、ICEが存在する理由を理解できます。\nネットワークの現実的な制約 # ICEは、実世界のネットワークの制約を克服するためのものです。解決策を探る前に、実際の問題点について説明します。\n同じネットワークにいない # ほとんどの場合、相手の WebRTC エージェントは同じネットワーク内にいるとは限りません。典型的な通話は、通常、直接接続されていない異なるネットワークにある2つのWebRTC Agent間で行われます。\n下の図は、公衆インターネットで接続された2つの異なるネットワークのグラフです。各ネットワークには2つのホストがあります。\n同一ネットワーク内のホストは、非常に簡単に接続できます。 192.168.0.1 -\u0026gt; 192.168.0.2 の間の通信は簡単にできます。これらの2つのホストは、外部の助けを借りずにお互いに接続できます。\nしかし、 ルーターB を使っているホストは、 ルーターA の後ろにあるものに直接アクセスする方法がありません。 ルーターA の後ろにある 192.168.0.1 と ルーターB の後ろにある同じIPの違いをどうやって見分けるのでしょうか？これらはプライベートIPです。 ルーターB を使用しているホストは、 ルーターA に直接トラフィックを送信できますが、リクエストはそこで終了します。ルーターAはどのホストにメッセージを転送すべきか、どうやって知るのでしょうか?\nプロトコルの制限 # ネットワークによっては、UDP トラフィックを全く許可していなかったり、TCP を許可していない場合があります。ネットワークによっては、MTU(Maximum Transmission Unit)が非常に低い場合があります。このように、ネットワーク管理者が変更できる変数はたくさんあり、それが通信を困難にしています。\nファイアウォール/IDSルール # また、「ディープ・パケット・インスペクション」やその他のインテリジェントなフィルタリングもあります。ネットワーク管理者の中には、すべてのパケットを処理しようとするソフトウェアを実行する人がいます。このようなソフトウェアはWebRTCを理解していないことが多く、WebRTCパケットをホワイトリストに載っていない任意のポートの不審なUDPパケットとして扱うなど、何をしていいかわからずブロックします。\nNATマッピング # NAT（Network Address Translation）マッピングは、WebRTCの接続性を実現する魔法です。これにより、WebRTCは全く異なるサブネットにいる2つのピアの通信を可能にし、上記の「同じネットワーク内にない」という問題に対処しています。新たな課題が生まれる一方で、そもそもNATマッピングがどのように機能するのかを説明しましょう。\nNATマッピングは、リレーやプロキシ、サーバーを使用しません。ここでも、「エージェント1」と「エージェント2」がいて、それぞれ別のネットワークにいます。しかし、トラフィックは完全に通過しています。視覚的には次のようになります。\nこの通信を実現するために、NATマッピングを確立します。エージェント1は、ポート7000を使用して、エージェント2とのWebRTC接続を確立します。これにより、 192.168.0.1:7000 から 5.0.0.1:7000 へのバインディングが作成されます。これにより、エージェント2は、 5.0.0.1:7000 にパケットを送信することで、エージェント1に到達できるようになります。この例のようにNATマッピングを作成することは、ルータでポートフォワーディングを行うことの自動化版のようなものです。\nNATマッピングの欠点は、マッピングの形式が一つではないこと（例：静的ポートフォワーディング）と、ネットワーク間で動作が一貫していないことです。ISPやハードウェアメーカーが異なる方法で行う場合もあります。場合によっては、ネットワーク管理者がこれを無効にしていることもあります。\nICEエージェントは、NATマッピングを作成したことと、そのマッピングの属性を確認できます。\nこれらの動作を説明したドキュメントは、RFC 4787です。\nマッピングの作成 # マッピングの作成は最も簡単な作業です。ネットワーク外のアドレスにパケットを送信すると、マッピングが作成されます。NAT マッピングは、NAT によって割り当てられた一時的なパブリック IP/Port に過ぎません。送信メッセージは、新たにマッピングされたアドレスを送信元アドレスとするように書き換えられます。マッピングにメッセージが送信されると、マッピングを作成したNAT内部のホストに自動的にルーティングされます。\nマッピングの詳細については、ここからが複雑になります。\nマッピング作成時の動作 # マッピングの作成は3つのカテゴリーに分類されます。\nエンドポイントに依存しないマッピング # NAT内の送信者ごとに1つのマッピングが作成されます。2つのパケットを2つの異なるリモートアドレスに送信した場合、NATマッピングは再利用されます。両方のリモートホストには、同じソースIP/ポートが表示されます。リモートホストが応答すれば、同じローカルリスナーに送り返されます。\nこれは、最良のシナリオです。通話が機能するためには、少なくとも片側がこのタイプでなければならない。\nアドレスに依存するマッピング # 新しいアドレスにパケットを送信するたびに、新しいマッピングが作成されます。2つのパケットを異なるホストに送信すると、2つのマッピングが作成されます。同じリモートホストに2つのパケットを送信し、宛先ポートが異なる場合、新しいマッピングは作成されません。\nアドレスとポートに依存するマッピング # リモートIPまたはポートが異なる場合、新しいマッピングが作成されます。同じリモートホストに2つのパケットを送信し、送信先のポートが異なる場合、新しいマッピングが作成されます。\nマッピングフィルタリングの動作 # マッピングのフィルタリングとは、マッピングの使用を許可する人に関するルールです。これらは3つの類似した分類に分類されます。\nエンドポイントに依存しないフィルタリング # 誰でもマッピングを使用できる。マッピングを他の複数のピアと共有し、それらがすべてトラフィックを送信できます。\nアドレスに依存したフィルタリング # マッピングが作成されたホストのみがマッピングを使用できます。ホスト A にパケットを送信すると、そのホストは好きなだけパケットを返してくることができます。ホストBがそのマッピングにパケットを送ろうとしても、それは無視されます。\nアドレスとポートに依存したフィルタリング # マッピングが作成されたホストとポートだけがそのマッピングを使用できます。ホスト A:5000 にパケットを送信すると、必要なだけのパケットを返信できます。ホスト A:5001 がそのマッピングにパケットを送ろうとしても、無視されます。\nマッピングの更新 # マッピングが 5 分間使用されない場合、破棄することを推奨します。これは、ISP やハードウェアメーカーの判断によります。\nSTUN # STUN (Session Traversal Utilities for NAT) は、NAT を利用するために作られたプロトコルです。これもWebRTC（とICE！）よりも前の技術です。このプロトコルはRFC 8489で定義されており、STUNのパケット構造も定義されています。STUNプロトコルはICE/TURNでも使用されています。\nSTUNが便利なのは、NATマッピングをプログラムで作成することができるからです。STUN以前は、NATマッピングを作成することはできましたが、そのIP/Portが何であるかはわかりませんでした。STUNでは、マッピングを作成できるだけでなく、詳細を知ることができるので、他の人とマッピングを共有して、作成したマッピング経由でトラフィックを送ることができます。\nまずは、STUNの基本的な説明から始めましょう。その後、TURNとICEの使い方について説明します。今のところ、マッピングを作成するためのリクエスト/レスポンスフローについてだけ説明します。その後、他の人と共有するためにその詳細を得る方法について話します。これは、WebRTC PeerConnectionのICEのURLに stun: サーバーがある場合に起こる処理です。簡単に言うと、STUNは、NATの外にあるSTUNサーバーに、観測された内容を報告してもらうことで、NATの後ろにいるエンドポイントが、どのようなマッピングが作成されたかを把握するのに役立ちます。\nProtocol Structure # STUNのパケットは以下のような構造になっています。\n0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ |0 0| STUN Message Type | Message Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Magic Cookie | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | | | Transaction ID (96 bits) | | | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Data | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ STUNメッセージのタイプ # 各STUNパケットにはタイプがあります。今のところ、以下のものについてのみ関心があります。\nバインディング・リクエスト - 0x0001 バインディングレスポンス - 0x0101 NATマッピングを作成するには、Binding Requestを行います。その後、サーバーは Binding Response で応答します。\nメッセージの長さ (Message Length) # これはDataセクションの長さです。このセクションには Message Type で定義された任意のデータが含まれます。\nマジッククッキー (Magic Cookie) # 固定値 0x2112A442 をネットワークのバイトオーダーで表したもので、STUN トラフィックを他のプロトコルと区別するのに役立ちます。\nトランザクションID (Transaction ID) # リクエスト/レスポンスを一意に識別する96ビットの識別子です。リクエストとレスポンスを組むのに役立ちます。\nデータ (Data) # データには、STUN属性のリストが含まれます。STUNアトリビュートは以下のような構造になっています。\n0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Type | Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Value (variable) .... +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ STUN Binding Request は属性を使用しません。これは、STUN Binding Request がヘッダーのみを含むことを意味します。\nSTUN Binding Response は XOR-MAPPED-ADDRESS (0x0020) という属性を使用します。この属性にはIP/Portが含まれる。これが、作成されるNATマッピングのIP/Portです!\nNAT マッピングの作成 # STUNを使ってNATマッピングを作成するには、リクエストを1回送るだけです。STUNサーバに STUN Binding Request を送信します。STUNサーバは、 STUN Binding Response を返信します。 この STUN Binding Response にはマップされたアドレスが含まれます。マップされたアドレスは、STUNサーバがあなたをどのように見るかであり、あなたのNATマッピングです。\nマップされたアドレスは、誰かにパケットを送ってもらいたいときに共有するものです。\nマップされたアドレスは、あなたの Public IP や Server Reflexive Candidate とも呼ばれています。\nNAT の種類の決定 # 残念ながら、「マップされたアドレス」はすべてのケースで使えるわけではありません。 「アドレス依存」の場合、STUNサーバーだけが自分にトラフィックを送り返すことができます。もしあなたがこのアドレスを共有していて、他の相手がメッセージを送ろうとすると、そのメッセージはドロップされます。これでは他の人との通信には使えません。もし、STUNサーバーがあなたの代わりにパケットを相手に転送することができれば、「アドレス依存」のケースは実際に解決可能であることがわかるかもしれません。これは、以下のTURNを使った解決策につながります。\nRFC 5780では、NATタイプを決定するためのテストを行う方法を定義しています。これは、直接接続が可能かどうかを事前に知ることができるので便利です。\nTURN # TURN(Traversal Using Relays around NAT)はRFC 8656で定義されており、直接接続ができない場合の解決策です。2つのNATタイプに互換性がない場合や、同じプロトコルを使用できない場合などに使用します。TURNは、プライバシー保護のためにも利用できます。すべての通信をTURN経由で行うことで、クライアントの実際のアドレスを見えなくできます。\nTURNは専用のサーバーを使います。このサーバーは、クライアントのプロキシとして機能します。クライアントは、TURNサーバーに接続し、アロケーションを作成します。アロケーションを作成することで、クライアントは一時的なIP/ポート/プロトコルを取得し、それを使ってクライアントにトラフィックを送り返すことができます。この新しいリスナーは中継トランスポートアドレスとして知られています。これは転送アドレスのようなもので、他の人がTURNを介してあなたにトラフィックを送れるように、このアドレスを提供します。中継トランスポートアドレスを渡した相手ごとに、自分との通信を許可するための新しいパーミッションを作成する必要があります。\nTURNを介してアウトバウンド・トラフィックを送信する際には、中継トランスポートアドレスを介して送信されます。リモートピアがトラフィックを取得する際には、TURNサーバーから送られてきていることがわかります。\nTURN ライフサイクル # 以下は、TURNのアロケーションを作成したいクライアントが行うべきことです。TURNを使っている相手との通信には、何の変更も必要ありません。相手はIP/Portを取得し、他のホストと同様に通信を行います。\nアロケーション # アロケーションは、TURNの中核をなすものです。アロケーション」とは、基本的に「TURNセッション」のことです。TURNのアロケーションを作成するには、TURNのサーバー・トランスポート・アドレス（通常はポート3478）と通信します。\nアロケーションを作成する際には、以下の項目を指定する必要があります。\nUsername/Password - TURNのアロケーションを作成するには認証が必要です。 アロケーション・トランスポート - サーバー(中継トランスポートアドレス)と通信相手間のトランスポートプロトコルにはUDPまたはTCPを指定できます。 偶数ポート - 複数のアロケーションに対して連続したポートを要求できますが、WebRTCには関係ありません。 リクエストが成功すると、TURNサーバーから、Dataセクションに以下のSTUN属性を持つレスポンスが得られます。\nXOR-MAPPED-ADDRESS - TURN クライアント のマップされたアドレスです。誰かがデータを中継トランスポートアドレスに送ると、ここに転送されます。 RELAYED-ADDRESS - これは他のクライアントに配るためのアドレスです。誰かがこのアドレスにパケットを送ると、TURNクライアントに中継されます。 LIFETIME - このTURNアロケーションが破棄されるまでの期間です。 リフレッシュ リクエストを送ることで、寿命を延長できます。 パーミッション # リモートホストは、あなたがパーミッションを作成するまで、あなたの中継トランスポートアドレスに送信できません。パーミッションを作成すると、TURNサーバーに「このIP/Portはインバウンドトラフィックの送信が許可されています」と伝えることになります。\nリモートホストは、TURNサーバーに表示されているIP/Portを伝える必要があります。つまり、TURNサーバーにSTUN Binding Requestを送る必要があります。よくあるエラーケースは、リモートホストが別のサーバーにSTUN Binding Requestを送信してしまうことです。そして、このIPに対してパーミッションを作成するように要求してきます。\n例えば、アドレスに依存したマッピングの背後にあるホストに対するパーミッションを作成したいとします。別のTURNサーバーからマップされたアドレスを生成すると、すべてのインバウンドトラフィックがドロップされます。異なるホストと通信するたびに新しいマッピングが生成されます。パーミッションはリフレッシュされないと5分後に失効します。\nSendIndication/ChannelData # これら2つのメッセージは、TURNクライアントがリモートピアにメッセージを送信するためのものです。\nSendIndicationは自己完結型のメッセージです。その中には、送りたいデータと、誰に送るかが書かれています。これは、リモート・ピアにたくさんのメッセージを送信する場合には無駄になります。1,000通のメッセージを送信すると、相手のIPアドレスを1,000回繰り返すことになります。\nChannelDataでは、データを送ることはできますが、IPアドレスを繰り返すことはできません。IP/Portを持つChannelを作成します。その後、ChannelIdを使って送信すると、IP/Portはサーバー側で入力されます。たくさんのメッセージを送信する場合は、この方法が適しています。\nRefreshing # 割り当てられたデータは自動的に破棄されます。TURNクライアントは、アロケーション作成時に指定したLIFETIMEよりも早くリフレッシュする必要があります。\nTURNの使い方 # TURNの使い方には2つの形態があります。通常は、片方のピアが「TURNクライアント」として動作し、もう片方が直接通信を行います。例えば、双方のクライアントがUDPをブロックしているネットワークにいるために、それぞれのTURNサーバーへの接続がTCP経由で行われるなど、双方にTURN Usageが存在する場合があります。\nこれらの図は、そのような場合を説明するのに役立ちます。\n通信のための1TURNの割り当て # コミュニケーションのための2つのTURNアロケーション # ICE # ICE（Interactive Connectivity Establishment）は、WebRTCが2つのAgentを接続する方法です。RFC 8445で定義されていますが、これもWebRTCよりも前の技術です。ICEは、接続性を確立するためのプロトコルです。ICEは、2つのピア間で可能なすべてのルートを決定し、接続を維持します。\nこれらのルートは候補ペアと呼ばれ、ローカルとリモートのトランスポートアドレスのペアとなっています。ICEでは、ここでSTUNとTURNが活躍します。これらのアドレスは、ローカルIPアドレスにポートを加えたものや、NATマッピング、中継トランスポートアドレスなどがあります。それぞれの側は、使用したいアドレスをすべて集めて交換し、接続を試みます。\n2つのICEエージェントは、ICE pingパケット（正式には接続性チェックと呼ばれる）を使って通信し、接続性を確立します。接続が確立した後は、好きなものを送ることができます。通常のソケットと同じように使用できます。これらのチェックには STUN プロトコルを使用しています。\nICE エージェントの作成 # ICE エージェントは、コントロールするまたはコントロールされるのいずれかです。コントロールするエージェントは、選択された候補者ペアを決定します。通常、オファーを送信している相手がコントロール側になります。\nそれぞれの側はユーザーフラグメントとパスワードを持たなければならない。接続性のチェックを開始する前に、この2つの値を交換する必要があります。ユーザーフラグメントはプレーンテキストで送信され、複数のICEセッションをデマックスするのに役立ちます。 パスワードはMESSAGE-INTEGRITY属性の生成に使用されます。各STUNパケットの最後には、パスワードをキーにしてパケット全体をハッシュ化した属性があります。これは、パケットを認証し、改ざんされていないことを確認するために使用されます。\nWebRTCでは、前章で説明したように、これらの値はすべて Session Description を介して配布されます。\n候補者の収集 # 次に、到達可能なすべてのアドレスを収集する必要があります。これらのアドレスを候補と呼びます。\nホスト # ホスト候補は、ローカルインターフェイス上で直接リッスンするものです。これはUDPでもTCPでも構いません。\nmDNS # mDNS候補は、ホスト候補と似ていますが、IPアドレスが見えません。相手に自分のIPアドレスを知らせるのではなく、UUIDをホスト名として与えます。そして、マルチキャストのリスナーを設定し、誰かがあなたの公開したUUIDを要求してきたら応答します。\nもしあなたがエージェントと同じネットワーク内にいれば、マルチキャストでお互いを見つけることができます。同じネットワーク内にいない場合は、（ネットワーク管理者がマルチキャストパケットの通過を許可するようにネットワークを明示的に設定していない限り）接続することができません。\nこれは、プライバシー保護のために役立ちます。ユーザーは、Host候補であれば、WebRTC経由であなたのローカルIPアドレスを（あなたに接続しようとしなくても）知ることができますが、mDNS候補では、ランダムなUUIDしか得られません。\nServer Reflexive # Server Reflexive 候補は、STUN サーバーに STUN Binding Request を行うことで生成されます。\nSTUN Binding Responseを取得すると、XOR-MAPPED-ADDRESSがサーバーリフレックス候補となる。\nPeer Reflexive # Peer Reflexive候補とは、自分が知らないアドレスからインバウンドリクエストを受け取った場合のことです。ICEは認証されたプロトコルであるため、そのトラフィックが有効であることがわかります。これは、リモートピアが、自分の知らないアドレスから通信しているということです。\nこれは、ホスト候補がサーバー反射候補と通信している場合によく起こります。サブネットの外で通信しているため、新しいNATマッピングが作成されました。接続性チェックは実際にはSTUNパケットであると言ったことを覚えていますか？STUNレスポンスのフォーマットでは、当然、相手は相手リフレックスアドレスを報告します。\nリレー # リレー候補は、TURNサーバーを使って生成されます。\nTURNサーバーとの最初のハンドシェイクの後、RELAYED-ADDRESSが与えられ、これがリレー候補となります。\n接続性のチェック # これで、リモートエージェントのユーザフラグメント、パスワード、候補者がわかりました。これで、接続を試みることができます。すべての候補者はお互いにペアになっています。つまり、片側3人の候補者がいる場合、9組の候補者がいることになります。\n視覚的には次のようになります。\n候補者選定 # コントロールするエージェントとコントロールされるエージェントは、それぞれのペアでトラフィックの送信を開始します。これは、一方のエージェントがAddress Dependent Mappingを使用している場合に必要となり、Peer Reflexive Candidateが作成されます。\nネットワークトラフィックを確認した各候補ペアは、有効な候補ペアに昇格します。コントロールエージェントは、有効な候補者のペアを1組選び、それを指名します。これがノミネートペアとなります。コントロール側とコントロールされる側のエージェントは、もう一回、双方向通信を試みます。これが成功すると，指名されたペアは選択された候補者ペアになります。このペアは、その後のセッションでも使用されます。\nリスタート # 選択された候補ペアが何らかの理由（NATマッピングの期限切れ、TURNサーバーのクラッシュなど）で動作しなくなった場合、ICEエージェントは失敗状態になります。どちらのエージェントも再起動することで、すべてのプロセスをやり直すことができます。\n"},{"id":3,"href":"/ja/docs/04-securing/","title":"セキュリティ対策","section":"Docs","content":" セキュリティ対策 # WebRTCにはどんなセキュリティがありますか？ # WebRTCの接続はすべて認証され、暗号化されています。第三者があなたの送信内容を見たり、偽のメッセージを挿入したりすることはないので安心です。また、Session Description を生成したWebRTCエージェントが、通信相手であることも確かです。\n誰もこれらのメッセージに手を加えないことが非常に重要です。第3者が転送中の Session Description を読んでも問題ありません。しかし、WebRTCには Session Description が変更されることに対する保護がありません。攻撃者は ICE Candidates を変更し、証明書フィンガープリントを更新することで、あなたに対して中間者攻撃を行うことができます。\nどのような仕組みになっているのですか？ # WebRTCは、Datagram Transport Layer Security (DTLS)とSecure Real-time Transport Protocol (SRTP)という2つの既存のプロトコルを使用しています。\nDTLSは、セッションをネゴシエートした後、2つのピア間で安全にデータを交換できます。DTLSは、HTTPSを実現する技術であるTLSと兄弟関係にありますが、DTLSはトランスポート層としてTCPではなくUDPを使用します。つまり、このプロトコルは、信頼性の低い配信を処理しなければならないということです。SRTPは、特にメディアを安全に交換するために設計されています。DTLSの代わりにSRTPを使用することで、いくつかの最適化が可能になります。\nDTLSは最初に使用されます。ICEが提供する接続に対してハンドシェイクを行います。DTLSはクライアント/サーバー型のプロトコルなので、ハンドシェイクはどちらか一方が開始する必要があります。クライアント／サーバーの役割は、シグナリング時に選択されます。DTLSのハンドシェイクでは、双方が証明書を提示します。 ハンドシェイクが完了すると、この証明書は Session Description にある証明書のハッシュ値と比較されます。これは、ハンドシェイクが期待していたWebRTCエージェントで行われたことを確認するためです。これで、DTLS 接続が DataChannel の通信に使用できるようになります。\nSRTPセッションを作成するには、DTLSで生成されたキーを使用してセッションを初期化します。SRTPにはハンドシェイク機構がないため、外部の鍵を使ってブートストラップを行う必要があります。これが完了すると、SRTP で暗号化されたメディアを交換できます。\nセキュリティ101 # 本章で紹介する技術を理解するには、まずこれらの用語を理解する必要があります。暗号は難しいテーマなので、他の資料も参考にしてください。\n暗号 # 暗号とは、平文を暗号文に変換する一連の手順のことです。その後、暗号を元に戻すことができるため、暗号文を平文に戻すことができます。暗号は通常、その動作を変えるための鍵を持っています。別の用語では、暗号化と復号化があります。\n簡単な暗号はROT13です。各文字が13文字分前に移動します。暗号を解除するには、13文字を後ろに移動します。平文のHELLOは暗号文のURYYBになります。この場合、暗号はROT、鍵は13となります。\n平文/暗号文 # 平文とは暗号の入力である。暗号文とは、暗号の出力である。\nハッシュ # ハッシュは、ダイジェストを生成する一方通行のプロセスです。入力があると、毎回同じ出力を生成します。出力が可逆的でないことが重要です。出力があれば、その入力を特定できないようにする必要があります。ハッシュ化は、メッセージが改ざんされていないことを確認したい場合に有効です。\n単純なハッシュは、1文字おきに取るだけのもので、HELLOはHLOになります。「HELLO」が入力であると仮定することはできませんが、「HELLO」が一致することは確認できます。\n公開鍵/秘密鍵暗号方式 # 公開鍵/秘密鍵暗号方式は、DTLS と SRTP が使用する暗号の種類を説明します。このシステムでは、公開鍵と秘密鍵の2つの鍵を持ちます。公開鍵は、メッセージを暗号化するためのもので、共有しても安全です。 秘密鍵は復号化のためのもので、決して共有してはいけません。公開鍵で暗号化されたメッセージを復号化できる唯一の鍵です。\nディフィー・ヘルマン交換 # ディフィー・ヘルマン交換は、初対面の2人のユーザがインターネット上で安全に共有秘密を作成できます。ユーザAは、盗聴の心配をすることなく、ユーザBに秘密を送ることができます。これは、離散対数問題を解く難しさによります。 この仕組みを完全に理解する必要はありませんが、これがDTLSのハンドシェイクを可能にしていることを知っておくと役立ちます。\nウィキペディアには、この動作の例があります リンク.\n擬似乱数関数 # 擬似乱数関数(PRF)とは、ランダムに見える値を生成するためにあらかじめ定義された関数です。複数の入力を受け取り、1つの出力を生成できます。\n鍵導出関数 # 鍵導出は、疑似乱数関数の一種です。 鍵導出は、鍵を強化するために使用される関数です。 一般的なパターンの1つは、キーストレッチです。\n例えば、8バイトの鍵が与えられたとします。KDFを使ってより強力なものにできます。\nノンス # ノンスとは、暗号機への追加入力です。これは、同じメッセージを複数回暗号化した場合でも、暗号から異なる出力を得ることができるようにするためです。\n同じメッセージを 10 回暗号化すると、暗号は同じ暗号文を 10 回生成します。ノンスを使用すれば、同じ鍵を使用しながら、異なる入力を得ることができます。メッセージごとに異なるノンスを使用することが重要です。そうしないと、その価値の多くが否定されてしまいます。\nメッセージ認証コード # メッセージ認証コード（Message Authentication Code）は、メッセージの最後に置かれるハッシュです。MACは、そのメッセージが期待したユーザーからのものであることを証明します。\nMACを使用しない場合、攻撃者は無効なメッセージを挿入できます。復号化しても、相手は鍵を知らないので、ただのゴミになってしまいます。\nキー・ローテーション # キーローテーションとは、一定期間ごとに鍵を交換することです。これにより、盗まれた鍵の影響を少なくできます。鍵が盗まれたり漏れたりした場合、復号できるデータの数は少なくなります。\nDTLS # DTLS(Datagram Transport Layer Security)は、2つのピアが既存の設定なしに安全な通信を確立できます。たとえ誰かが会話を盗み聞きしていたとしても、メッセージを解読することはできません。\nDTLSクライアントとサーバーが通信するためには、暗号と鍵に合意する必要があります。これらの値は、DTLSのハンドシェイクを行うことで決定されます。ハンドシェイクの間、メッセージは平文である。 DTLSクライアント/サーバーが暗号化を開始するのに十分な情報を交換したとき、Change Cipher Specを送信します。このメッセージの後、後続の各メッセージは暗号化されます。\nパケットフォーマット # 全てのDTLSパケットはヘッダーから始まります。\nコンテンツタイプ # 以下のようなタイプが想定されます。\nチェンジサイファースペック (Change Cipher Spec) - 20 ハンドシェイク (Handshake) - 22 アプリケーションデータ (Application Data) - 23 ハンドシェイク は、セッションを開始するための詳細情報を交換するために使用されます。チェンジサイファースペックは、相手にすべてのデータが暗号化されることを通知するために使用します。アプリケーションデータは、暗号化されたメッセージです。\nバージョン # バージョンは 0x0000feff (DTLS v1.0) または 0x0000fefd (DTLS v1.2) のいずれかで、v1.1 はありません。\nエポック # エポックは 0 から始まりますが、Change Cipher Spec を実行すると 1 になります。エポックが0でないメッセージはすべて暗号化されます。\nシーケンス番号 # シーケンス番号はメッセージを順番に並べるために使われます。メッセージを送信するたびに、シーケンス番号が増加します。エポックが増加すると、シーケンス番号は最初から始まる。\n長さとペイロード # ペイロードはコンテンツタイプごとに異なります。アプリケーションデータの場合、ペイロードは暗号化されたデータです。ハンドシェイクの場合は、メッセージによって異なります。\n長さはペイロードの大きさを表します。\nハンドシェイクのステートマシン # ハンドシェイクの間、クライアントとサーバーは一連のメッセージを交換します。これらのメッセージはフライトに分類されます。各フライトには複数のメッセージが含まれることがあります（1つだけの場合もあります）。 フライトは、そのフライトに含まれるすべてのメッセージを受信するまで完了しません。各メッセージの目的については、以下で詳しく説明します。\nClientHello # ClientHello は、クライアントが送信する最初のメッセージです。これは属性のリストを含んでいます。これらの属性は、クライアントがサポートしている暗号や機能をサーバーに伝えます。WebRTC の場合、これは SRTP Cipher を選択する方法でもあります。また、セッションの鍵を生成するために使用するランダムデータも含まれています。\nHelloVerifyRequest # HelloVerifyRequestは、サーバーからクライアントに送信されます。これは、クライアントがリクエストの送信を意図しているかどうかを確認するためです。その後、クライアントは、HelloVerifyRequestで指定されたトークンを使用して、ClientHelloを再送信します。\nServerHello # ServerHello は、このセッションの設定に対するサーバからの応答です。このセッションが終了したときに使用される暗号を含んでいます。また、サーバーのランダムデータも含まれています。\nCertificate # Certificate は、クライアントまたはサーバーの証明書を含みます。この証明書は、通信相手を一意に識別するために使用されます。ハンドシェイクが終わった後、この証明書をハッシュ化したものが Session Description のフィンガープリントと一致するかどうかを確認します。\nServerKeyExchange/ClientKeyExchange # これらのメッセージは、公開鍵を送信するために使用されます。起動時には、クライアントとサーバーの両方がキーペアを生成します。ハンドシェイクの後、これらの値は プレマスターシークレット の生成に使用されます。\nCertificateRequest # CertificateRequestは、サーバがクライアントに証明書が必要であることを通知するために送信されます。サーバは、証明書を要求することもできます。\nServerHelloDone # ServerHelloDone は、サーバーがハンドシェイクを終了したことをクライアントに通知します。\nCertificateVerify # CertificateVerify は、送信者が Certificate メッセージで送られたプライベートキーを持っていることを証明する方法です。\nChangeCipherSpec # ChangeCipherSpec は、このメッセージの後に送信されるすべてのものが暗号化されることを受信者に知らせます。\nFinished # Finished は暗号化され、すべてのメッセージのハッシュを含みます。これはハンドシェイクが改ざんされていないことを保証するためです。\n鍵の生成 # ハンドシェイクが完了すると、暗号化されたデータの送信が可能になります。暗号はサーバーが選択し、ServerHelloに入っています。では、その鍵はどのようにして選ばれたのでしょうか？\nまず、プレマスターシークレットを生成します。この値を得るために、ServerKeyExchangeとClientKeyExchangeで交換された鍵にDiffie-Hellmanを使用します。 詳細は選択した暗号によって異なります。\n次に、マスターシークレットが生成されます。DTLSの各バージョンには、定義された疑似乱数関数があります。DTLS 1.2では、この関数はプレマスターシークレットと、ClientHelloとServerHelloに含まれるランダムな値を受け取ります。 似乱数関数を実行した結果の出力はマスターシークレットです。マスターシークレットは、暗号に使用される値です。\nアプリケーションデータの交換 # DTLSの主力となるのがApplicationDataです。初期化されたCipherがあれば、暗号化して値を送信できます。\nApplicationDataメッセージは、前述のようにDTLSヘッダを使用します。Payload には暗号文が格納されています。これでDTLSセッションが動作し、安全に通信できるようになりました。\nDTLSには、再ネゴシエーションなど、さらに興味深い機能がたくさんあります。WebRTCでは使用されていないので、ここでは説明しません。\nSRTP # SRTP は、RTP パケットの暗号化に特化して設計されたプロトコルです。SRTP セッションを開始するには、鍵と暗号を指定します。DTLSとは異なり、ハンドシェイクの仕組みはない。すべての設定と鍵は、DTLSのハンドシェイク中に生成されます。\nDTLSでは、別のプロセスで使用するために鍵をエクスポートする専用のAPIを提供しています。これはRFC 5705で定義されています。\nセッションの作成 # SRTPでは、入力に使用される鍵導出関数を定義しています。SRTPセッションの作成時には、入力をこの関数に通して、SRTP暗号用の鍵を生成します。この後、メディアの処理に移ることができます。\nメディアの交換 # 各 RTP パケットには、16 ビットのシーケンス番号があります。このシーケンス番号は、主キーのように、パケットの順序を保つために使用されます。通話中、これらの番号はロールオーバーします。SRTPはそれを追跡し、これをロールオーバーカウンタと呼ぶ。\nSRTPは、パケットを暗号化する際に、ロールオーバーカウンタとシーケンス番号を nonceとして使用します。これは、同じデータを 2 回送信しても、暗号文が異なることを保証するためです。これは、攻撃者がパターンを特定したり、リプレイ攻撃を試みたりするのを防ぐために重要です。\n"},{"id":4,"href":"/ja/docs/05-real-time-networking/","title":"リアルタイム・ネットワーキング","section":"Docs","content":" リアルタイム・ネットワーキング # リアルタイム・コミュニケーションにおいて、なぜネットワークが重要なのか？ # ネットワークは、リアルタイム通信を制限する要素です。理想的な世界では、帯域幅が無限にあり、パケットは瞬時に到着します。しかし、実際にはそうではありません。ネットワークには限界があり、いつでも条件が変わる可能性があります。また、ネットワークの状態を測定・観察することも難しい問題です。ハードウェア、ソフトウェア、そしてその構成によって、さまざまな挙動を示すことがあります。\nまた、リアルタイムでの通信は、他の領域にはない問題です。Web制作者にとっては、ネットワークによってはWebサイトの表示が遅くなっても致命的ではありません。すべてのデータが届いていれば、ユーザーは満足です。WebRTCでは、データが遅れれば意味がありません。5秒前の電話会議の内容なんて誰も気にしません。そのため、リアルタイム通信システムを開発する際には、トレードオフの関係にならざるを得ません。制限時間は何秒か、どれだけ送れるか。\n本章では、データ通信とメディア通信の両方に適用される概念を説明します。後の章では、理論的な説明にとどまらず、WebRTCのメディアサブシステムとデータサブシステムがこれらの問題をどのように解決するのかを説明します。\n難しくしているネットワークの属性は何ですか？ # すべてのネットワークで効果的に機能するコードは複雑です。多くの異なる要因があり、それらがすべて微妙に影響し合います。開発者が遭遇する最も一般的な問題は以下の通りです。\n帯域幅 # 帯域幅とは、特定のパスで転送できるデータの最大レートのことです。これは固定された数値ではないことを覚えておく必要があります。帯域幅は、利用者の増加（または減少）に伴い、経路に沿って変化します。\n送信時間とラウンドトリップタイム # 送信時間とは、パケットが到着するまでの時間のことです。帯域幅と同様、これも一定ではありません。 送信時間は、いつでも変動する可能性があります。\n伝送時間を計算するには、送信側と受信側の時計がミリ秒単位で同期している必要があります。 少しでもずれがあると、信頼性の低い伝送時間の測定になってしまいます。 WebRTCは非常に異質な環境で運用されているため、ホスト間の完全な時刻同期に頼ることはほとんど不可能です。\nラウンドトリップタイムの測定は、不完全なクロック同期の回避策です。\nWebRTCのピアは、分散したクロックで動作する代わりに、自身のタイムスタンプ sendertime1 を含む特別なパケットを送信します。 協力しているピアがそのパケットを受信し、タイムスタンプを送信者に反映します。 オリジナルの送信者は、反映された時間を得ると、現在の時間 sendertime2 からタイムスタンプ sendertime1 を引きます。 この時間差を \u0026ldquo;往復伝搬遅延 \u0026ldquo;といい、より一般的にはラウンドトリップタイムといいます。\nrtt = sendertime2 - sendertime1\nラウンド・トリップ・タイムの半分は、送信時間の十分な近似値と考えられます。 この回避策には欠点がないわけではありません。 この方法では、パケットの送信と受信にかかる時間が同じであることを前提としています。 しかし、携帯電話ネットワークでは、送信と受信の動作が時間的に対称でない場合があります。 お使いの携帯電話のアップロード速度は、ほとんどの場合、ダウンロード速度よりも低いことにお気づきかもしれません。\ntransmission_time = rtt/2\nラウンドトリップタイムの測定に関する技術的な内容は、RTCP送信者と受信者のレポートの章で詳しく説明されています。\nジッター # ジッターとは、「伝送時間」がパケットごとに異なることです。パケットが遅延しても、すぐに到着する可能性があります。\nパケットロス # パケットロスとは、メッセージが送信中に失われることです。パケットロスは安定している場合もあれば、急激に発生する場合もあります。 これは、衛星やWi-Fiなどのネットワークの種類に起因します。衛星やWi-Fiなどのネットワークの種類に起因する場合もあれば、通信中のソフトウェアに起因する場合もあります。\n最大伝送単位 # 最大伝送容量とは、1つのパケットの大きさの制限のことです。ネットワークでは、1つの巨大なメッセージを送信することはできません。プロトコルレベルでは、メッセージを複数の小さなパケットに分割する必要があるかもしれません。\nMTUは、どのようなネットワーク経路をとるかによっても異なります。Path MTU Discoveryのようなプロトコルを使用して、送信可能な最大のパケットサイズを把握できます。\n輻輳 (ふくそう) # 輻輳（ふくそう）とは、ネットワークの限界に達した状態のことです。これは通常、現在のルートが処理できる帯域のピークに達したことが原因です。また、ISPが設定した1時間ごとの制限のように、オペレータが課すものもあります。\n輻輳は、さまざまな形で現れます。標準的な動作はありません。ほとんどの場合、輻輳状態になると、ネットワークは過剰なパケットをドロップします。他のケースでは、ネットワークはバッファリングします。これにより、パケットの送信時間が長くなります。また、ネットワークが輻輳すると、ジッターが増えることもあります。 この分野は急速に変化しており、輻輳検知のための新しいアルゴリズムはまだ開発中です。\nダイナミック # ネットワークは非常に動的で、状況は急速に変化します。一回の通話では、何十万ものパケットを送受信することがあります。 これらのパケットは、複数のホップを経由します。これらのホップは、何百万人もの他のユーザーによって共有されます。あなたのローカルネットワークでも、HDムービーがダウンロードされたり、デバイスがソフトウェアアップデートをダウンロードしたりすることがあります。\n良い通話ができるかどうかは、起動時にネットワークを測定するだけではわかりません。常に評価を行う必要があります。また、様々なネットワークのハードウェアやソフトウェアに起因する、あらゆる異なる動作に対応する必要があります。\nパケットロスの解決 # パケットロスの解決は、最も最初に解決すべき問題です。この問題を解決するには複数の方法があり、それぞれに利点があります。何を送信するのか、どの程度の遅延耐性があるのかによっても異なります。また、すべてのパケットロスが致命的なものではないことにも注意が必要です。ビデオの損失は問題にならないかもしれません、人間の目には認識できないかもしれません。しかし、ユーザーのテキストメッセージが失われることは致命的です。\n例えば、10個のパケットを送信して、5個目と6個目のパケットが失われたとします。この問題を解決する方法は以下の通りです。\n確認応答 (Acknowledgments) # 確認応答とは、受信者が受信したすべてのパケットを送信者に通知することです。送信者は、最終的ではないパケットに対する確認応答を2回受け取ると、パケットロスを認識します。送信者は、パケット4に対するACKを2回受け取ると、5がまだ見られていないことがわかります。\n選択的確認応答 (Selective Acknowledgments) # 選択的確認応答は、確認応答の改良版です。受信者は、複数のパケットを確認し、ギャップを送信者に通知するSACKを送信できます。 この場合、送信者は4と7に対してSACKを受け取ります。送信者は、5と6を再送する必要があることがわかります。\n否定確認応答 (Negative Acknowledgments) # 否定確認応答は、逆の方法で問題を解決します。受信者は、受信した内容を送信者に通知するのではなく、失われた内容を送信者に通知します。今回のケースでは、パケット5とパケット6に対して「NACK」が送信されます。 送信者は、受信者が再送信を希望するパケットだけを知ることができます。\n前方誤り訂正 (Forward Error Correction) # 前方誤り訂正は、パケットロスを先回りして修正する機能です。送信者は冗長なデータを送信するため、パケットロスがあっても最終的なストリームには影響しません。一般的なアルゴリズムとして リード・ソロモンエラー訂正があります。\nこれにより、アクノリッジの送信と処理のレイテンシーと複雑さが軽減されます。前方誤り訂正は、ネットワークの損失がゼロの場合、帯域幅の無駄になります。\nジッターの解決 # ジッターはほとんどのネットワークに存在します。LANの中でも、多くの機器が変動するレートでデータを送信しています。pingコマンドで他の機器にpingを打ち、ラウンドトリップレイテンシーの変動に気づくことで、ジッターを簡単に観察できます。\nジッターを解決するために、クライアントはジッターバッファーを使用します。ジッターバッファーはパケットの配信時間を安定させます。欠点は、ジッターバッファーが早く到着したパケットに若干の遅延を加えることです。 良い点は、遅く到着したパケットがジッターの原因にならないことです。 通話中に以下のようなパケット到着時間があるとします。\n* time=1.46 ms * time=1.93 ms * time=1.57 ms * time=1.55 ms * time=1.54 ms * time=1.72 ms * time=1.45 ms * time=1.73 ms * time=1.80 ms この場合は、～1.8msが良いでしょう。遅れて到着したパケットは、レイテンシーのウィンドウを使用します。早く到着したパケットは遅延し、遅く到着したパケットによって減少したウィンドウを埋めることができます。遅れて到着したパケットによって減少したウィンドウを埋めることができます。これにより、スタッタリングがなくなり、クライアントにスムーズな配信速度を提供できます。\n輻輳の検出 # 輻輳を解決する前に、輻輳を検出する必要があります。輻輳を検出するには、輻輳コントローラを使用します。これは複雑なテーマであり、今でも急速に変化しています。 新しいアルゴリズムは今でも発表され、テストされています。高いレベルでは、どれも同じように動作します。輻輳制御装置は、いくつかの入力が与えられると、帯域幅の推定値を提供します。 以下のような入力が考えられます。\nパケットロス - ネットワークが輻輳するとパケットが廃棄されます。 ジッター - ネットワーク機器がより過負荷になると、パケットがキューイングされ、時間が不安定になります。 ラウンド・トリップ・タイム - 輻輳するとパケットの到着に時間がかかります。ジッターとは異なり、ラウンド・トリップ・タイムは増加し続けます。 明示的輻輳通知 - 新しいネットワークでは、輻輳を緩和するためにパケットがドロップされる危険性があるとタグ付けされることがあります。 これらの値は、通話中に継続して測定する必要があります。ネットワークの利用率は増減するため、利用可能な帯域幅は常に変化します。\n輻輳の解消 # 推定帯域幅がわかったところで、送信するデータを調整する必要があります。どのように調整するかは、どのようなデータを送信するかによって異なります。\n送信速度を遅くする # データを送る速度を制限することは、輻輳を防ぐための最初の解決策です。輻輳制御装置が推定値を提示し、送信者の責任で速度制限を行います。\nこれは、ほとんどのデータ通信で使われている方法です。TCPのようなプロトコルでは、これはすべてオペレーティングシステムによって行われ、ユーザーや開発者にとっては完全に透過的です。\nより少ない情報を送る # 場合によっては、制限値を満たすために、より少ない情報を送ることができます。また、データの到着には期限がありますので、より遅く送ることはできません。このような制約がリアルタイムメディアにはあります。\n十分な帯域が確保できない場合は、送信するビデオの品質を下げることができます。そのためには、ビデオエンコーダーと輻輳制御装置の間で緊密なフィードバックループを構築する必要があります。\n"},{"id":5,"href":"/ja/docs/06-media-communication/","title":"メディア・コミュニケーション","section":"Docs","content":" メディア・コミュニケーション # WebRTCのメディア通信では何ができるのですか？ # WebRTCでは、オーディオやビデオのストリームを無制限に送受信できます。これらのストリームは、通話中にいつでも追加・削除できます。これらのストリームはすべて独立していることもあれば、まとめて送信することもできます。例えば、自分のデスクトップのビデオフィードを送信し、ウェブカムからのオーディオ／ビデオを含めることができます。\nWebRTCプロトコルは、コーデックに依存しません。基礎となるトランスポートは、まだ存在しないものも含めて、すべてをサポートしています。ただし、通信相手であるWebRTCエージェントが、それを受け入れるために必要なツールを持っていない場合もあります。\nまた、WebRTCは、動的なネットワーク状況に対応できるように設計されています。通話中に帯域が増えたり減ったりすることがあります。また、突然パケットロスが多発することもあります。WebRTCはこのような状況にも対応できるように設計されています。WebRTCはネットワークの状態に対応し、利用可能なリソースで最高の体験を提供しようとします。\nどのような仕組みになっているのですか？ # WebRTCは、RFC 3550で定義されている2つの既存のプロトコルRTPとRTCPを使用しています。\nRTP（Real-time Transport Protocol）は、メディアを伝送するプロトコルです。動画をリアルタイムに配信することを目的に設計されています。遅延や信頼性に関するルールは規定されていませんが、それらを実装するためのツールが提供されています。RTPはストリームを提供し、1つの接続で複数のメディアフィードを実行できます。また、メディアパイプラインに供給するために必要な、タイミングや順序の情報も提供します。\nRTCP（RTP Control Protocol）は、コールに関するメタデータを通信するためのプロトコルです。このフォーマットは非常に柔軟で、必要なメタデータを追加できます。通話に関する統計情報を通信するために使用されます。また、パケットロスの処理や輻輳制御の実装にも使用されます。これにより、変化するネットワークの状況に対応するために必要な双方向の通信が可能になります。\nレイテンシー vs クオリティ # リアルタイムメディアは、遅延と品質のトレードオフの関係にあります。遅延を許容すればするほど、高品質な映像が期待できます。\n現実の制約 # これらの制約は、すべて現実世界の制約に起因するもので、お客様が克服しなければならないネットワークの特性です。\nビデオは複雑 # 動画の転送は簡単ではありません。30分の非圧縮720 8bitビデオを保存するには、約110Gb必要です。この数字では、4人での電話会議は不可能です。もっと小さくする方法が必要ですが、その答えは映像の圧縮です。しかし、これにはデメリットもあります。\nビデオ101 # ここでは、動画圧縮について詳しく説明しませんが、RTPがなぜこのように設計されているのかを理解するには十分です。動画圧縮とは、動画を新しいフォーマットにエンコードすることで、同じ動画をより少ないビット数で表現することです。\n非可逆圧縮と可逆圧縮 # 動画のエンコードは、ロスレス（情報が失われない）とロッシー（情報が失われる可能性がある）の2種類があります。ロスレス圧縮の場合、相手に送るデータ量が多くなり、ストリームの遅延が大きくなったり、パケットの損失が多くなるため、RTPでは映像の品質が悪くなってもロッシー圧縮を行うのが一般的です。\nイントラフレームとインターフレームの圧縮 # 動画の圧縮には2種類あります。1つ目はイントラフレームです。フレーム内圧縮では、1つのビデオフレームを記述するためのビットを削減します。静止画の圧縮にも同じ手法が使われており、JPEG圧縮法などがあります。\n2つ目は、フレーム間圧縮です。動画は多くの画像で構成されているので、同じ情報を2度送らない方法を考えます。\nフレーム間の種類 # フレームには3つの種類があります。\nI-Frame - 完全な画像で、何もなくてもデコードできます。 P-Frame - 部分的な画像で、前の画像を修正したもの。 B-Frame - 部分的な画像で、以前の画像と未来の画像を組み合わせたもの。 3つのフレームタイプを視覚化すると以下のようになります。\n動画はデリケート # 動画の圧縮は非常にステートフルであり、インターネットでの転送は困難です。I-Frameの一部が失われるとどうなるのか？P-Frameはどうやって修正すべき箇所を知るのでしょうか？映像圧縮がより複雑になるにつれ、この問題はさらに深刻になっています。幸いなことに、RTPとRTCPには解決策があります。\nRTP # パケットフォーマット # すべてのRTPパケットは、以下のような構造になっています。\n0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ |V=2|P|X| CC |M| PT | Sequence Number | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Timestamp | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Synchronization Source (SSRC) identifier | +=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+ | Contributing Source (CSRC) identifiers | | .... | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Payload | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ バージョン (V) # バージョン は常に 2 です。\nパディング (P) # パディング はペイロードにパディングがあるかどうかを制御する bool です。\nペイロードの最後のバイトには、何バイトのパディングが追加されたかのカウントが入っています。\n拡張 (X) # セットされている場合、RTPヘッダーは拡張機能を持つことになります。これについては、以下で詳しく説明します。\nCSRC 数 (CC) # SSRCの後、ペイロードの前に続くCSRCの識別子の数です。\nマーカー (M) # マーカービットには事前に設定された意味はなく、ユーザーが好きなように使うことができます。\n場合によっては、ユーザーが話しているときに設定されることもあります。また、キーフレームのマークとしてもよく使われます。\nペイロードタイプ (PT) # ペイロードタイプ は、このパケットで伝送されるコーデックを示す一意の識別子です。\nWebRTCでは、ペイロードタイプは動的なものです。ある通話での VP8 は、別の通話では異なる可能性があります。通話中の提供者は、Session Description の中でペイロードタイプとコーデックのマッピングを決定します。\nシーケンス番号 # シーケンス番号は、ストリームのパケットの順序付けに使用されます。パケットが送信されるたびに、シーケンス番号は1ずつ増加します。\nRTPは、損失の多いネットワーク上で役立つように設計されています。これにより、受信者はパケットが失われたことを検出できます。\nタイムスタンプ # このパケットのサンプリング秒数です。これはグローバルクロックではなく、メディアストリームの中でどれだけ時間が経過したかを示します。複数のRTPパケットが同じタイムスタンプを持つこともあります(例: すべてのパケットが同じビデオフレームに含まれる場合)。\n同期ソース (SSRC) # SSRCは、このストリームの一意の識別子です。これにより、複数のメディアストリームを1つのストリーム上で実行できます。\nコントリビューションソース(CSRC) # どの SSRC がこのパケットに貢献したかを伝えるリストです。\nこれは一般的にトーキングインジケーターに使用されます。例えば、サーバー側で複数のオーディオフィードを1つのRTPストリームにまとめたとします。このフィールドを使用して、「入力ストリームAとCがこの瞬間に話していた」と言うことができます。\nペイロード # 実際のペイロードデータです。パディングフラグが設定されている場合は、何バイトのパディングが追加されたかが最後に表示されます。\n拡張機能 # RTCP # Packet Format # RTCPのパケットは、以下のような構造になっています。\n0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ |V=2|P| RC | PT | length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Payload | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ バージョン (V) # バージョン は常に 2 です。\nパディング (P) # パディング は bool で、ペイロードにパディングがあるかどうかを制御します。\nペイロードの最後のバイトには、何バイトのパディングが追加されたかのカウントが含まれています。\n受信レポート数 (RC) # このパケットに含まれるレポートの数です。1つのRTCPパケットに複数のイベントを含めることができます。\nパケットタイプ (PT) # この RTCP パケットがどのタイプであるかを示す一意の識別子です。WebRTCエージェントは、これらのタイプをすべてサポートする必要はなく、エージェントによってサポートが異なる場合があります。しかし、一般的に目にするのはこれらのタイプです。\nFull INTRA-frame Request (FIR) - 192 Negative ACKnowledgements (NACK) - 193 Sender Report - 200 Receiver Report - 201 Generic RTP Feedback - 205 Payload Specific Feedback - 206 これらのパケットタイプの意義については、以下で詳しく説明します。\nFull INTRA-frame Request (FIR)とPicture Loss Indication (PLI) # FIRとPLIの目的は似ています。これらのメッセージは、送信者にフルキーフレームを要求します。 PLIは、デコーダにパーシャルフレームが到着し、デコードできない場合に使用します。 これは、パケットロスが多い場合や、デコーダがクラッシュした場合などに起こります。\nRFC5104によると、パケットやフレームが失われたときには FIR を使用してはならないとされており、それは PLI の仕事です。FIR はパケットロス以外の理由でキーフレームを要求します。例えば、ビデオ会議に新しいメンバーが入ってきたときなどです。FIRはビデオストリームのデコードを開始するために完全なキーフレームを必要とし、デコーダはキーフレームが到着するまでフレームを破棄します。\nこれにより、接続してからユーザーの画面に画像が表示されるまでの遅延を最小限に抑えることができます。\nPLI パケットは、Payload Specific Feedback メッセージの一部です。\n実際には、PLI パケットと FIR パケットの両方を扱うことができるソフトウェアは、どちらの場合も同じように動作します。 エンコーダーに信号を送り、新しいフルキーフレームを生成します。\nNegative ACKnowledgements # NACKは、送信者に1つのRTPパケットの再送を要求するものです。これは通常、RTP パケットが失われたときに発生しますが、遅延した場合にも発生します。\nNACKは、フレーム全体の再送信を要求するよりも、はるかに帯域幅を効率的に利用できます。RTPはパケットを非常に小さなチャンクに分割するので、実際には1つの小さな欠落部分を要求しているに過ぎません。\n送信者/受信者レポート # これらのレポートは、エージェント間で統計情報を送信するために使用します。このレポートでは、実際に受信したパケット量やジッターを伝えます。\nこのレポートは、診断や輻輳制御に利用できます。\nRTP/RTCPが共に問題を解決する方法 # このように、RTPとRTCPが連携することで、ネットワークに起因するあらゆる問題を解決できます。これらの技術は今でも常に変化しています。\nNegative Acknowledgment # NACKとも呼ばれます。これは、RTPのパケットロスに対処する方法のひとつです。\nNACKは、再送信を要求するために送信者に送り返されるRTCPメッセージです。受信者は、SSRCとシーケンス番号を含むRTCPメッセージを作ります。送信者は、再送信可能なこのRTPパケットを持っていない場合、そのメッセージを無視します。\n前方誤り訂正 (Forward Error Correction) # FECとも呼ばれます。パケットロスに対処するもう一つの方法です。FEC は、同じデータを要求されてもいないのに複数回送信することです。これは、RTP レベルで行われ、さらに下位のコーデックでも行われます。\n通話中のパケットロスが安定している場合、FECはNACKよりもはるかに低遅延のソリューションです。NACKの場合は、パケットを要求してから再送信するまでの往復時間が大きくなります。\n適応型ビットレートと帯域幅の推定 (Adaptive Bitrate and Bandwidth Estimation) # リアルタイムネットワーキングで説明したように、ネットワークは予測不可能で信頼性がありません。帯域幅の利用可能性は、セッション中に何度も変化する可能性があります。 利用可能な帯域幅が1秒以内に劇的に（桁違いに）変化することも珍しくありません。\n主なアイデアは、予測される、現在および将来の利用可能なネットワーク帯域幅に基づいて、エンコーディングのビットレートを調整することです。 これにより、可能な限り最高の品質の映像・音声信号を伝送し、ネットワークの輻輳によって接続が切断されることがないようにします。 ネットワークの挙動をモデル化し、それを予測するヒューリスティックな手法を「帯域推定」といいます。\nこれには様々なニュアンスがありますので、詳しくご紹介しましょう。\nネットワーク状況の把握と伝達 # RTP/RTCPはあらゆる種類の異なるネットワーク上で動作するため、送信者から受信者への通信が途中で途切れることはよくあることです。UDPの上に構築されているため、輻輳制御の処理はもちろん、パケット再送のためのビルトインメカニズムは存在しません。\nユーザーに最高の体験を提供するために、WebRTC はネットワーク経路の品質を推定し、その品質が時間と共にどのように変化するかに適応する必要があります。監視すべき重要な特性には、利用可能な帯域幅（対称でない場合があるため各方向）、往復時間、ジッター（往復時間の変動）などがあります。また、パケットロスを考慮し、ネットワーク状況の変化に応じてこれらの特性の変化を伝える必要があります。\nこれらのプロトコルの主な目的は2つあります。\nネットワークがサポートする利用可能な帯域幅（各方向）を推定する。 送り手と受け手の間でネットワークの特性を伝達する RTP/RTCPは、この問題に対処するために3つの異なるアプローチを持っています。どれも長所と短所があり、一般に、各世代は前の世代よりも改善されています。どの実装を使用するかは、主にクライアントが使用できるソフトウェアスタックと、アプリケーションを構築するために使用できるライブラリに依存します。\nReceiver Reports / Sender Reports # 最初の実装は、Receiver Reportsとその補集合である Sender Reportsのペアです。これらのRTCPメッセージはRFC 3550で定義されており、エンドポイント間のネットワークステータスを通信する役割を担っています。受信者レポートは、ネットワークの品質(パケットロス、往復時間、ジッターなど)の通信に重点を置いており、これらのレポートに基づいて利用可能な帯域幅を推定する責任を負う他のアルゴリズムと対になっています。\n送信者レポートと受信者レポート（SRとRR）を合わせて、ネットワーク品質の全体像を描きます。これらは各SSRCのスケジュールに従って送信され、利用可能な帯域幅を推定する際に使用される入力となります。これらの推定は、以下のフィールドを含むRRデータを受信した後に送信者によって行われます。\nFraction Lost \u0026ndash; 前回のReceiver Report以降、何パーセントのパケットが失われたか。 Cumulative Number of Packets Lost \u0026ndash; 通話全体で失われたパケット数。 Extended Highest Sequence Number Received \u0026ndash; 最後に受信したシーケンス番号と、それが何回ロールオーバーしたかを示しています。 Interarrival Jitter \u0026ndash; 通話全体のローリングジッターです。 Last Sender Report Timestamp \u0026ndash; ラウンドトリップタイムの計算に使用される、送信者の最後の既知の時間。 SRとRRは連動して往復時間を計算します。\n送信者は、SRに自分のローカルタイム sendertime1 を含めます。受信者はSRパケットを受信すると、RRを送り返します。このとき、RRには送信者から受け取ったばかりの sendertime1 が含まれます。 SRを受信してからRRを送信するまでの間に遅延が発生します。そのため、RRは「最後の送信者レポートからの遅延」時間 - DLSR も含まれています。 DLSR は後の処理でラウンドトリップタイムの見積もりを調整するために使用されます。送信者はRRを受け取ると、現在の時刻 sendertime2 から sendertime1 と DLSR を差し引きます。この時間差をラウンドトリッププロパゲーションディレイまたはラウンドトリップタイムと呼びます。\nrtt = sendertime2 - sendertime1 - DLSR\n往復の時間をわかりやすく解説:\n私があなたにメッセージを送るとき、私の時計の現在の表示は「午後4時20分、42秒と420ミリ秒」です。 あなたはこの同じタイムスタンプを私に送り返します。 あなたはまた、私のメッセージを読んでからメッセージを送り返すまでの経過時間、例えば5ミリ秒を入れます。 このタイムスタンプを受け取った私は、再び時計を見ます。 今、私の時計は午後4時20分、42秒690ミリ秒と表示されています。 つまり、あなたに届いてから私に戻ってくるまでに265ミリ秒（690 - 420 - 5）かかったことになります。 したがって、往復の時間は265ミリ秒です。 TMMBR、TMMBN、REMB、TWCC、GCCと対になる # Google輻輳制御（GCC) # Google Congestion Control (GCC) アルゴリズム (概要は draft-ietf-rmcat-gcc-02) は、帯域幅の推定という難題に対処しています。GCCは、他のさまざまなプロトコルと組み合わせて、関連する通信要件を容易にします。その結果、受信側(TMMBR/TMMBNまたはREMBで実行する場合)または送信側 (TWCCで実行する場合)のどちらかで実行するのに適しています。\n利用可能な帯域幅の推定値を得るために、GCC は、パケット損失とフレーム到着時間の変動という 2 つの主要なメトリックスに着目しています。これらのメトリックは、ロスベース・コントローラと遅延ベース・コントローラという 2 つのリンクされたコントローラを介して実行されます。\nGCCの最初のコンポーネントであるロス・ベース・コントローラはシンプルなものです．\nパケットロスが 10%を超えると，推定帯域幅が縮小されます。 パケットロスが2～10％の場合、推定帯域は変わりません。 パケットロスが2%以下の場合、推定帯域を増加させます。 パケットロスの測定は頻繁に行われています。ペアとなる通信プロトコルによって、パケットロスは明示的に伝達される場合（TWCCなど）と推定される場合（TMMBR/TMBNやREMBなど）があります。これらの割合は、約1秒の間隔で評価されます。\n2 番目の機能は、損失ベースのコントローラと協力し、パケット到着時間の変動を見ます。この遅延ベースのコントローラーは、ネットワークリンクの混雑が深刻化するタイミングを特定することを目的としており、パケットロスが発生する前であっても帯域幅の見積もりを減らすことがあります。理論的には、パスに沿って最も忙しいネットワークインターフェイスは、そのバッファ内の容量を使い果たすまでパケットをキューに入れ続けることになります。そのインターフェイスが送信可能なトラフィックよりも多くのトラフィックを受信し続ける場合、そのバッファスペースに収まりきらないすべてのパケットをドロップすることを余儀なくされるでしょう。このようなパケットロスは、特に低遅延／リアルタイム通信において破壊的ですが、そのリンク上のすべての通信のスループットを低下させることもあり、理想的には避けるべきものです。したがって、GCC は、パケットロスが実際に発生する 前 に、ネットワークリンクがより大きく、より大きなキューの深さを増しているかどうかを把握しようとします。もし、時間の経過とともにキューの遅延が増加するのを観測したら、それは帯域幅の使用を減らすでしょう。\nこれを達成するために、GCC はラウンドトリップタイムの微妙な増加を測定することによって、 キューの深さの増加を推測しようとします。これは、フレームの「到着間時間」，t(i) - t(i-1) を記録するもので、パケットの 2 つのグループ（一般に，連続したビデオフレーム）の到着時間の差です．これらのパケット群は一定の時間間隔（例えば24fpsの映像の場合1/24秒間隔）で頻繁に創出します。その結果、到着間時間の測定は、最初のパケットグループ（すなわちフレーム）の開始と次のフレームの最初のフレームとの間の時間差を記録するのと同じくらい簡単です。\n下図では、パケット間遅延の増加の中央値は+20ミリ秒であり、ネットワーク輻輳の明確な指標となっています。\n到着間時間が時間とともに長くなる場合は、接続するネットワーク・インターフェイスのキューの深さが増している証拠と推定され、ネットワークの輻輳とみなされる。(注：GCCはフレームバイトサイズの変動に対して、これらの測定値を制御するのに十分な賢さを持っています)。GCCは輻輳にフラグを立てる前に、カルマンフィルターを使ってそのレイテンシー測定を改良し、ネットワークのラウンドトリップタイム（とその変動）の多くの測定を行います。GCCのカルマンフィルタを線形回帰の代わりと考えることができます：ジッターがタイミング測定にノイズを加えても正確な予測をするのに役立ちます。輻輳のフラグが立てられると、GCC は利用可能なビットレートを下げます。また、ネットワークが安定している場合は、帯域幅の推定値を徐々に増やして、より高い負荷の値をテストすることもできます。\nTMMBR、TMMBN、および REMB # TMMBR/TMMBNおよびREMBの場合、受信側はまず利用可能な受信帯域幅を推定し (GCCなどのプロトコルを使用)、次にその推定帯域幅をリモート送信側に伝達します。受信側で動作することにより、到着間時間やパケットロスを直接測定できるため、パケットロスやネットワークの混雑に関する他の品質に関する詳細を交換する必要はありません。その代わり、TMMBR、TMMBN、およびREMBは、帯域幅の推定値のみを交換します。\n一時的な最大メディアストリームビットレート要求(Temporary Maximum Media Stream Bit Rate Request) - 1つのSSRCに対する要求ビットレートの仮数/指数。 一時的な最大メディアストリームビットレート通知(Temporary Maximum Media Stream Bit Rate Notification) - TMMBRを受信したことを通知するためのメッセージ。 受信機推定最大ビットレート(Receiver Estimated Maximum Bitrate) - セッション全体の要求ビットレートの仮数/指数。 TMMBRとTMMBNが最初に登場し、RFC 5104で定義されています。REMBは後に登場し、draft-alvestrand-rmcat-rembでドラフトが提出されましたが、標準化されるには至りませんでした。\nREMBを使用するセッションの例は、以下のように動作します。\nこの方法は、理論的にはとてもうまくいきます。送信側は受信側から推定値を受け取り、エンコーダのビットレートを受け取った値に設定します。なんということでしょう！これでネットワークの状況に合わせた調整ができました。\nしかし実際には、REMB 方式には複数の欠点があります。\nエンコーダの非効率性が第一です。エンコーダーにビットレートを設定しても、必ずしも要求された通りのビットレートで出力されるとは限りません。エンコーダーの設定やエンコードされるフレームによって、出力されるビットが多くなったり少なくなったりすることがあります。\nたとえば、tune=zerolatency で x264 エンコーダーを使用すると、指定したターゲットビットレートから大きく外れることがあります。以下に考えられるシナリオを示します。\nまず、ビットレートを 1000kbps に設定したとします。 エンコーダーは 700kbps しか出力しない。（別名 - 壁を見つめる）。 また、受信機がパケットロスゼロで 700kbps の映像を受信した場合、REMB ルール 1 を適用して受信ビットレートを8％増加させたとします。 受信機は 756kbps の提案(700kbps * 1.08)をした REMB パケットを送信機に送ります。 送信者は、エンコーダのビットレートを 756kbps に設定します。 エンコーダーはさらに低いビットレートを出力します。 これを繰り返して、ビットレートを極限まで下げていきます。 これでは、エンコーダのパラメータ調整が大変になってしまい、素晴らしい接続環境であっても、ユーザーが見られない映像になってしまうことがわかります。\nトランスポートワイド輻輳制御 (Transport Wide Congestion Control) # トランスポートワイド輻輳制御は、RTCPのネットワーク状態通信における最新の開発です。draft-holmer-rmcat-transport-wide-cc-extensions-01で定義されていますが、標準化されたことはありません。\nTWCCは非常にシンプルな原理を使用しています。\nREMBでは、受信側が送信側にダウンロード可能なビットレートを指示します。また、パケットロスやパケット間到着時間などのデータを事前に測定しておく必要があります。\nTWCCは、SR/RRとREMB世代のプロトコルの間のハイブリッドアプローチに近いものです。帯域幅の推定を送信側に戻しますが (SR/RRと同様)、その帯域幅推定技法はREMB世代により近いものであるためです。\nTWCCでは、受信機から送信機に対して、各パケットの到着時刻が通知されます。これは送信側にとって、パケット間の到着遅延の変動を測定し、どのパケットがドロップされたか、あるいは到着が遅すぎてオーディオ／ビデオフィードに貢献しなかったかを特定するのに十分な情報です。このデータが頻繁に交換されることで、送信者はネットワークの状況の変化に迅速に対応し、GCCなどのアルゴリズムを使用して出力帯域幅を変化させることができます。\n送信者は、送信されたパケット、そのシーケンス番号、サイズ、およびタイムスタンプを追跡します。 送信側は受信側からRTCPメッセージを受信すると、送信パケット間遅延と受信遅延を比較します。 受信遅延が大きくなると、ネットワークの輻輳を意味し、送信者は是正措置を講じなければなりません。\nTWCCは、送信者に生データを提供することで、リアルタイムのネットワーク状況を把握することができます。\nパケットロスの挙動をほぼ瞬時に把握し、個々のパケットロスまで把握可能 正確な送信ビットレート 正確な受信ビットレート ジッター測定 送信パケット遅延と受信パケット遅延の違い ネットワークがバースト的または安定的な帯域幅の配信をどのように許容しているかの説明 TWCCの最も大きな貢献の一つは、WebRTCの開発者に柔軟性を与えることです。輻輳制御アルゴリズムを送信側に集約することで、広く使用できるシンプルなクライアントコードを実現し、時間の経過とともに必要な拡張を最小限に抑えることができます。複雑な輻輳制御アルゴリズムは、その後、それらが直接制御するハードウェア（セクション 8 で説明する選択的転送ユニットなど）上でより迅速に反復することができます。ブラウザとモバイルデバイスの場合、これは、これらのクライアントが標準化またはブラウザの更新（広く利用できるようになるまでかなり長い時間がかかる）を待つことなく、アルゴリズムの強化の恩恵を受けられることを意味します。\n帯域幅の推定の代替案 # 最も多く導入されているのは、draft-alvestrand-rmcat-congestionで定義されている「A Google Congestion Control Algorithm for Real-Time Communication」です。\nGCC に代わるものとして、NADA: A Unified Congestion Control Scheme for Real-Time Media や SCReAM - Self-Clocked Rate Adaptation for Multimedia などの実装があります。\n"},{"id":6,"href":"/ja/docs/07-data-communication/","title":"データ・コミュニケーション","section":"Docs","content":" データ・コミュニケーション # WebRTCのデータ通信で何が得られるのか？ # WebRTCは、データ通信のためのデータチャンネルを提供します。2つのピアの間では、65,534個のデータチャンネルを開くことができます。 データチャンネルはデータグラムをベースにしており、それぞれに耐久性の設定があります。デフォルトでは、各データチャネルには順序通りの配信が保証されています。\nメディアの観点からWebRTCにアプローチしている場合、データチャネルは無駄に思えるかもしれません。HTTP や WebSocket を使用することができるのに、なぜこのようなサブシステム全体が必要なのでしょうか？\nデータチャネルの本当の強みは、UDP のように順序のない、または損失のある配信を行うように設定できることです。 これは、低レイテンシーでハイパフォーマンスの場合に必要です。バックプレッシャーを測定し、ネットワークがサポートする量だけを送信できます。\nWebRTCはどのように動作するのですか？ # WebRTCは、RFC 4960で定義されているSCTP(Stream Control Transmission Protocol)を使用しています。SCTPはトランスポート層のプロトコルで、TCPやUDPの代替となることを目的としています。WebRTCでは、DTLS接続上で動作するアプリケーション層のプロトコルとして使用しています。\nSCTPはストリームを提供し、各ストリームは独立して設定できます。WebRTCのデータチャネルは、それらを薄く抽象化したものに過ぎません。耐久性や順序に関する設定は、そのままSCTPエージェントに渡されます。\nデータチャネルには、チャネルラベルなど、SCTPでは表現できない機能があります。この問題を解決するために、WebRTCはRFC 8832で定義されているDCEP（Data Channel Establishment Protocol）を使用します。DCEPでは、通信を行うためのメッセージを定義しています。\nDCEP # DCEPには、DATA_CHANNEL_OPENとDATA_CHANNEL_ACKの2つのメッセージしかありません。データチャネルが開かれるたびに、リモートはackで応答する必要があります。\nDATA_CHANNEL_OPEN # このメッセージは、チャネルを開くことを望む WebRTC エージェントによって送信されます。\nパケットフォーマット # 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Message Type | Channel Type | Priority | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Reliability Parameter | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Label Length | Protocol Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \\ \\ / Label / \\ \\ +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \\ \\ / Protocol / \\ \\ +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ メッセージタイプ # メッセージタイプは、0x03の静的な値です。\nチャンネルタイプ # Channel Type は、チャネルの耐久性や順序の属性を制御します。以下のような値があります。\nDATA_CHANNEL_RELIABLE (0x00) - メッセージが失われることはなく、順番に到着します。 DATA_CHANNEL_RELIABLE_UNORDERED (0x80) - メッセージは失われませんが、順不同に到着することがあります。 DATA_CHANNEL_PARTIAL_RELIABLE_REXMIT (0x01) - メッセージは要求された回数を試した後に失われる可能性がありますが、順番に到着します。 DATA_CHANNEL_PARTIAL_RELIABLE_REXMIT_UNORDERED (0x81) - メッセージは要求された回数だけ試行した後に失われる可能性があり、順不同に到着することがあります。 DATA_CHANNEL_PARTIAL_RELIABLE_TIMED (0x02) - メッセージは要求された時間内に到着しないと失われる可能性がありますが、順番に到着します。 DATA_CHANNEL_PARTIAL_RELIABLE_TIMED_UNORDERED (0x82) - メッセージは、要求された時間内に到着しなかった場合に失われる可能性があり、順不同に到着することがあります。 優先順位 # データチャネルの優先順位を指定します。優先度の高いデータチャネルが先にスケジュールされます。優先度の低い大きなユーザーメッセージがあっても、優先度の高いユーザーメッセージの送信を遅らせることはありません。\n信頼性パラメータ # データチャネルのタイプが DATA_CHANNEL_PARTIAL_RELIABLE の場合、サフィックスで動作を設定します。\nREXMIT - 送信者がメッセージをあきらめるまでに何回再送信するかを定義します。 TIMED - 送信者があきらめるまでに何回メッセージを再送信するかを時間（ms）で定義します。 ラベル # データチャネルの名前を、UTF-8でエンコードした文字列で指定します。これは空の文字列でもよい。\nプロトコル # これが空の文字列の場合、プロトコルは指定されていません。空でない文字列の場合は、 RFC 6455で定義されている \u0026ldquo;WebSocket Subprotocol Name Registry \u0026ldquo;に登録されているプロトコルを指定します。\nDATA_CHANNEL_ACK # このメッセージは、WebRTCエージェントが、このデータチャネルがオープンされたことを確認するために送信します。\nパケットフォーマット # 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Message Type | +-+-+-+-+-+-+-+-+ SCTP # SCTPは、WebRTCのデータチャネルを支える真の力です。SCTPは、データチャネルの以下の機能をすべて提供します。\n多重化 TCPライクな再送メカニズムによる信頼性の高い配信 パーシャル・リライアビリティ・オプション 輻輳回避 フロー制御 SCTPを理解するために、3つのパートに分けて説明します。目標は、この章の後、自分でデバッグしてSCTPの深い詳細を学ぶのに十分な知識を得ることです。\n概念 # SCTP は機能豊富なプロトコルです。このセクションでは、WebRTC で使用されている SCTP の部分のみを取り上げます。 WebRTC で使用されていない SCTP の機能には、マルチホーミングや経路選択があります。\n20年以上も開発されてきたSCTPを完全に理解するのは難しいかもしれません。\nアソシエーション # SCTP セッションのことをアソシエーションと言います。2つのSCTPエージェントが通信している間、2つのSCTPエージェント間で共有される状態です。\nストリーム # ストリームとは、ユーザーデータの1つの双方向シーケンスです。データチャネルを作成することは、実際には SCTP ストリームを作成することに他なりません。 SCTPストリームを作成しているに過ぎません。 各SCTPアソシエーションには、ストリームのリストが含まれます。 各ストリームには、異なる信頼性タイプを設定できます。\nWebRTCではストリーム作成時にしか設定できませんが、SCTPではいつでも設定を変更できます。\nデータグラムベース # SCTPはデータをバイトストリームではなく、データグラムとしてフレーム化します。データの送受信は、TCPではなくUDPを使っているような感覚です。 複数のファイルを1つのストリームで転送するために、余分なコードを追加する必要はありません。\nSCTPメッセージにはUDPのようなサイズ制限がありません。1つのSCTPメッセージのサイズは、複数のギガバイトになることもあります。\nチャンク # SCTP プロトコルはチャンクで構成されています。チャンクには様々な種類があります。これらのチャンクはすべての通信に使用されます。 ユーザーデータ、接続の初期化、輻輳制御など、すべてチャンクを介して行われます。\nSCTPの各パケットには、チャンクのリストが含まれています。そのため、1つのUDPパケットには、異なるストリームのメッセージを運ぶ複数のチャンクが含まれます。\nトランスミッションシーケンス番号 # TSN（Transmission Sequence Number）は、DATAチャンクのグローバルな一意の識別子です。 ユーザーが送信したいすべてのメッセージを伝えるものです。TSNは、受信者がパケットの紛失や順序の乱れを判断する上で重要な役割を果たします。\nTSNの欠落に気付いた受信者は、それが満たされるまでユーザーにデータを提供しません。\nストリームの識別子 # 各ストリームには固有の識別子があります。明示的なIDを持つデータチャネルを作成すると、実際にはそのIDがそのままSCTP にストリーム識別子として渡されます。ID を指定しない場合は、ストリーム識別子が選択されます。\nペイロードプロトコル識別子 # 各 DATA チャンクには、PPID（Payload Protocol Identifier）があります。これは、交換されるデータの種類を一意に識別するために使用されます。 SCTPには多くのPPIDがありますが、WebRTCでは以下の5つのPPIDのみを使用しています。\nWebRTC DCEP (50) - DCEP メッセージ WebRTC String (51) - データチャンネルの文字列メッセージ WebRTC Binary (53) - Datachannel のバイナリメッセージ WebRTC String Empty (56) - Datachannel の長さが 0 の文字列メッセージ WebRTC Binary Empty (57) - Datachannel の長さが 0 のバイナリメッセージ プロトコル # 以下は、SCTPプロトコルで使用されるチャンクの一部である。これは完全なデモンストレーションではありません。ステートマシンが意味をなすのに十分な構造を提供しています。\n各チャンクは、typeフィールドで始まります。チャンクのリストの前には、ヘッダーもあります。\nDATA チャンク # 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Type = 0 | Reserved|U|B|E| Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | TSN | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Stream Identifier | Stream Sequence Number | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Payload Protocol Identifier | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \\ \\ / User Data / \\ \\ +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ DATAチャンクは、すべてのユーザーデータが交換される方法です。データチャンネルで何かを送信するときは、このようにして交換されます。\n順不同のパケットであれば、Uビットが設定されます。ストリームシーケンス番号は無視できます。\nB と E は開始ビットと終了ビットです。1つのDATAチャンクでは大きすぎるメッセージを送信する場合は、複数のDATAチャンクに分割して別々のパケットで送信する必要があります。 B と E のビットとシーケンスナンバーで、SCTPはこれを表現することができます。\nB=1, E=0 - フラグメント化されたユーザメッセージの最初の部分 B=0, E=0 - フラグメント化されたユーザメッセージの中間部分 B=0, E=1 - フラグメント化されたユーザメッセージの最後の断片 B=1, E=1 - フラグメント化されていないメッセージ TSN は、Transmission Sequence Numberの略です。4,294,967,295個のチャンクの後、これは0に折り返されます。TSNは、断片化されたユーザーメッセージのチャンクごとにインクリメントされるので、他のユーザーは、完全なメッセージを得るために受信したチャンクをどのように順序付けるかを知ることができます。\nストリーム識別子 は、このデータが属するストリームの一意の識別子です。\nストリームシーケンス番号 は、ユーザメッセージごとにインクリメントされる16ビットの番号で、DATAメッセージのチャンクヘッダに含まれます。この番号は、 U が0に設定されている場合に、ユーザーに配信されるメッセージの順序を決定するために使用されます。ストリーム・シーケンス・ナンバーが各チャンクではなく、各メッセージ全体に対してのみインクリメントされるという点を除いては、TSNと同様です。\nペイロードプロトコル識別子は、このストリームに流れているデータの種類です。WebRTCでは、DCEP、String、Binaryのいずれかになります。\nユーザーデータとは、あなたが送信するデータのことです。WebRTCのデータチャンネルで送信するデータは、すべてDATAチャンクを介して送信されます。\nINIT チャンク # 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Type = 1 | Chunk Flags | Chunk Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Initiate Tag | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Advertised Receiver Window Credit (a_rwnd) | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Number of Outbound Streams | Number of Inbound Streams | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Initial TSN | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \\ \\ / Optional/Variable-Length Parameters / \\ \\ +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ INITチャンクは、アソシエーションを作成するプロセスを開始します。\n初期化タグはクッキーの生成に使われます。クッキーはMan-In-The-MiddleやDenial of Serviceの保護に使われます。これらについてはステートマシンのセクションで詳しく説明します。\nアドバタイズドレシーバーウィンドウクレジットはSCTPの輻輳制御に使用されます。これは、受信者がこのアソシエーションに割り当てたバッファの大きさを伝えるものです。\nアウトバウンド/インバウンドストリームの数は、このエージェントがサポートしているストリームの数をリモートに通知します。\n初期TSN は、ローカルのTSNを開始するためのランダムな uint32 です。\nオプションパラメータは、SCTPがプロトコルに新しい機能を導入することを可能にします。\nSACK チャンク # 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Type = 3 |Chunk Flags | Chunk Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Cumulative TSN Ack | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Advertised Receiver Window Credit (a_rwnd) | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Number of Gap Ack Blocks = N | Number of Duplicate TSNs = X | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Gap Ack Block #1 Start | Gap Ack Block #1 End | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ / / \\ ... \\ / / +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Gap Ack Block #N Start | Gap Ack Block #N End | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Duplicate TSN 1 | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ / / \\ ... \\ / / +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Duplicate TSN X | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ SACK（Selective Acknowledgment）チャンクは、受信者が送信者にパケットを受け取ったことを通知する方法です。送信者は、あるTSNに対するSACKを受け取るまで、問題のDATAチャンクを再送信します。SACKはTSNを更新するだけではありません。\n累積 TSN ACK 受信した最も高いTSNを示します。\nアドバタイズドレシーバーウィンドウクレジット レシーバーのバッファサイズです。受信者は、より多くのメモリが利用可能になった場合、セッション中にこれを変更できます。\n累積 TSN ACKの後に受信されたAckブロックTSN。 これは、配信されたパケットにギャップがある場合に使用されます。例えば、TSNが100、102、103、104のDATAチャンクが配信されたとします。累積 TSN ACKは100となりますが、102、103、104を再送する必要がないことを送信者に伝えるために、Ack Blocksを使用できます。\nDuplicate TSNは、送信者に以下のDATAチャンクを2回以上受信したことを通知します。\nHEARTBEAT チャンク # 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Type = 4 | Chunk Flags | Heartbeat Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \\ \\ / Heartbeat Information TLV (Variable-Length) / \\ \\ +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ HEARTBEAT チャンクは、リモートがまだ応答していることを確認するために使用されます。 DATAチャンクを送信しておらず、NATマッピングを開いておく必要がある場合に便利です。\nABORT チャンク # 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Type = 6 |Reserved |T| Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ / / \\ Zero or more Error Causes \\ / / +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ ABORT チャンクは、アソシエーションを突然シャットダウンします。片側がエラー状態になったときに使用します。優雅に接続を終了させるには、SHUTDOWNチャンクを使用します。\nSHUTDOWN チャンク # 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Type = 7 | Chunk Flags | Length = 8 | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Cumulative TSN Ack | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ SHUTDOWNチャンクは、SCTPアソシエーションのグレースフルシャットダウンを開始します。各エージェントは、最後に送信したTSNをリモートに通知します。これにより、パケットが失われることはありません。WebRTC は SCTP アソシエーションのグレースフルシャットダウンを行いません。潔く処理するためには、各データチャネルを自分で取り壊す必要があります。\nCumulative TSN ACKは、最後に送信されたTSNです。各サイドは、このTSNでDATAチャンクを受信するまで終了しないことを知っています。\nERROR チャンク # 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Type = 9 | Chunk Flags | Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \\ \\ / One or more Error Causes / \\ \\ +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ ERROR チャンクは、致命的ではないエラーが発生したことをリモートSCTPエージェントに通知するために使用されます。\nFORWARD TSN チャンク # 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Type = 192 | Flags = 0x00 | Length = Variable | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | New Cumulative TSN | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Stream-1 | Stream Sequence-1 | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \\ / / \\ +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Stream-N | Stream Sequence-N | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ FORWARD TSN チャンクは、グローバルTSNを前方に移動させます。SCTPがこれを行うことで、もう気にしないパケットをスキップできます。例えば、10 11 12 13 14 15と送ったとすると、これらのパケットはすべて到着した場合にのみ有効となります。また、このデータはリアルタイム性を重視しているので、到着が遅れると意味がありません。\nもし、12と13を失ったら、14と15を送る理由はありません! SCTPはFORWARD TSN Chunkを使ってこれを実現します。SCTPはFORWARD TSN Chunkを使ってこれを実現します。これは受信者に14と15がもう配信されないことを伝えます。\nNew Cumulative TSN これは接続の新しいTSNです。このTSNより前のパケットは保持されません。\nStreamおよびStream Sequenceは、Stream Sequence Numberの番号を先に進めるために使用されます。このフィールドの意味については、DATAチャンクを参照してください。\nステートマシン # これらはSCTPステートマシンの興味深い部分です。WebRTC は SCTP ステートマシンのすべての機能を使用していないので、これらの部分は除外しています。また、いくつかのコンポーネントは単独で理解できるように簡略化しました。\n接続確立の流れ # INITとINIT ACKのチャンクは、各ピアの能力と構成を交換するために使用されます。SCTPはハンドシェイクの際にクッキーを使用して、通信相手を検証します。 これは、ハンドシェイクが傍受されないようにするためと、DoS攻撃を防ぐためです。\nINIT ACKチャンクには、クッキーが含まれています。その後、クッキーは COOKIE ECHO を使って作成者に返されます。クッキーの検証に成功すると、COOKIE ACKが送信され、DATAチャンクの交換が可能になります。\nコネクション・ティアダウンの流れ # SCTPでは、SHUTDOWN Chunkを使用します。エージェントはSHUTDOWN Chunkを受信すると、要求されたCumulative TSN ACKを受信するまで待ちます。これにより、接続にロスがあっても、すべてのデータを確実に配信できます。\nキープアライブの仕組み # SCTPでは、接続を維持するために、HEARTBEAT REQUESTとHEARTBEAT ACKというチャンクを使用します。これらは設定可能な間隔で送信されます。また、SCTPはパケットが到着していない場合、指数関数的なバックオフを行います。\nHEARTBEATには時間の値も含まれています。これにより、2つのアソシエーションが2つのエージェント間のトリップタイムを計算できます。\n"},{"id":7,"href":"/ja/docs/08-applied-webrtc/","title":"応用WebRTC","section":"Docs","content":" WebRTCの応用 # WebRTCの仕組みがわかったところで、いよいよWebRTCを使って構築してみましょう。この章では、WebRTC を使って人々が何をどのように構築しているかを探り、WebRTC で起こっている興味深いことをすべて学びます。WebRTC のパワーにはコストがかかります。プロダクショングレードの WebRTC サービスを構築することは困難です。本章では、そのような課題にぶつかる前に、その課題を説明します。\nユースケース別 # WebRTCは、Webブラウザ上で会議を行うための技術に過ぎないと多くの人が考えています。しかし、それだけではありません。 WebRTCはさまざまなユースケースに利用されています。常に新しいユースケースが登場しています。この章では、一般的なユースケースをいくつか挙げ、WebRTC がそれらにどのような変革をもたらしているかを説明します。\n会議 # 会議は WebRTC の最初のユースケースです。このプロトコルには、他のプロトコルがブラウザで提供していないいくつかの必要な機能が含まれています。WebSocket で会議システムを構築しても、最適な条件であれば動作するかもしれません。現実のネットワーク環境で展開できるものを求めるのであれば、WebRTC が最適な選択です。\nWebRTCは、メディアの輻輳制御とアダプティブ・ビットレートを提供します。ネットワークの状況が変化しても、ユーザーは最高の体験を得ることができます。開発者は、これらの条件を測定するために追加のコードを書く必要もありません。\n参加者は、複数のストリームを送受信できます。また、それらのストリームはいつでも追加・削除できます。コーデックもネゴシエートされます。これらの機能はすべてブラウザが提供するもので、開発者がカスタムコードを書く必要はありません。\nまた、会議にはデータチャンネルの利点もあります。ユーザーはメタデータを送信したり、ドキュメントを共有できます。信頼性よりもパフォーマンスが必要な場合は、複数のストリームを作成して設定できます。\n放送 # 放送業界では、WebRTC を利用した新しいプロジェクトが数多く登場しています。このプロトコルは、メディアの発行者と消費者の両方にとって多くの利点があります。\nWebRTCはブラウザ上で動作するため、ユーザーは簡単に動画を公開できます。また、ユーザーが新しいクライアントをダウンロードする必要もありません。 ウェブブラウザがあれば、どんなプラットフォームでも動画を公開できます。パブリッシャーは、複数のトラックを送信し、いつでもそれらを修正／削除できます。これは、1つの接続につき1つのオーディオトラックと1つのビデオトラックしか許可されていなかった従来のプロトコルに比べて、大きな進歩です。\nWebRTCは、開発者が遅延と品質のトレードオフをより細かくコントロールできるようにします。遅延が一定の閾値を超えないことがより重要な可能性があり、多少のデコードアーチファクトは許容したいと思うでしょう。メディアが到着したらすぐに再生するようにビューアを設定できます。TCP上で動作する他のプロトコルでは、これは簡単ではありません。ブラウザでは、データを要求してそれで終わりです。\nリモートアクセス # リモートアクセスとは、WebRTC を使って他のコンピュータに遠隔でアクセスすることです。リモートホストを完全に制御することもできますし、単一のアプリケーションだけを制御することもできます。 これは、ローカルのハードウェアでは処理できないような、計算量の多いタスクを実行するのに適しています。例えば、新しいビデオゲームやCADソフトウェアの実行などです。WebRTCは、3つの方法でこの分野に革命をもたらしました。\nWebRTCは、世界的にルーティングされていないホストへのリモートアクセスに使用できます。NATトラバーサルを使えば、STUN経由でしか利用できないコンピュータにアクセスできます。これは、セキュリティやプライバシーの面でも優れています。ユーザーは、ビデオをインジェストや「ジャンプボックス」に通す必要がありません。また、NATトラバーサルは導入を容易にします。ポートフォワーディングや固定IPの設定を事前に心配する必要がありません。\nこのシナリオでは、データチャネルも非常に強力です。最新のデータだけを受け付けるように設定できます。TCPの場合、Head-of-lineブロッキングが発生する危険性があります。古いマウスクリックやキープレスが遅れて到着すると、後続のデータが受け入れられなくなります。 WebRTCのデータチャネルはこの問題に対処するように設計されており、失われたパケットの再試行を行わないように設定できます。また、バックプレッシャを測定して、ネットワークがサポートする以上のデータを送信していないことを確認することもできます。\nWebRTCがブラウザで利用できるようになったことで、生活の質が大きく向上しました。セッションを開始するために、専用のクライアントをダウンロードする必要はありません。WebRTCを搭載したクライアントはますます増えており、スマートテレビには完全なウェブブラウザが搭載されています。\nファイル共有と検閲回避 # ファイル共有と検閲回避は全く異なる問題です。しかし、WebRTCはこの2つの問題を同じように解決します。それは、どちらも簡単に利用でき、ブロックするのが難しくなるということです。\nWebRTCが解決する最初の問題は、クライアントの獲得です。ファイル共有ネットワークに参加するには、クライアントをダウンロードする必要があります。ネットワークが分散されていても、まずクライアントを入手する必要があります。 制限されたネットワークでは、ダウンロードはしばしばブロックされます。ダウンロードできたとしても、ユーザーがクライアントをインストール/実行できない場合もあります。WebRTCはすべてのWebブラウザで利用可能なので、すぐに利用できます。\nWebRTCが解決する2つ目の問題は、トラフィックがブロックされることです。ファイル共有や検閲回避を目的としたプロトコルを使用している場合、それをブロックするのは非常に簡単です。 WebRTCは汎用プロトコルなので、これをブロックするとすべての人に影響が及びます。WebRTCをブロックすると、ネットワークの他のユーザーが電話会議に参加できなくなる可能性があります。\nIoT # IoTにはいくつかの異なるユースケースがあります。多くの人にとって、これはネットワークに接続されたセキュリティカメラを意味します。WebRTC を使用して、携帯電話やブラウザなどの他の WebRTC ピアにビデオをストリーミングできます。また、デバイスを接続してセンサーデータを交換するというユースケースもあります。LANに接続された2つのデバイスで、気候、騒音、光の測定値を交換できます。\nWebRTCは、従来のビデオストリームプロトコルに比べて、プライバシーの面で非常に優れています。WebRTCはP2P接続をサポートしているので、カメラはビデオを直接ブラウザに送信できます。ビデオがサードパーティのサーバーに送られる必要はありません。ビデオが暗号化されていても、攻撃者は通話のメタデータから推測できます。\n相互運用性は、IoT分野でのもう一つの利点です。WebRTCは、C#、C++、C、Go、Java、Python、Rust、TypeScriptなど、たくさんの異なる言語で利用できます。つまり、自分に最適な言語を使うことができるのです。また、2つの異なるクライアントを接続するために、独自のプロトコルやフォーマットを使用する必要もありません。\nメディアプロトコルブリッジング # 既存のハードウェアとソフトウェアで動画を作成しているが、まだアップグレードできない。ユーザーが動画を見るために独自のクライアントをダウンロードすることを期待するのは不満です。そこで、WebRTC ブリッジを導入します。ブリッジは2つのプロトコルを変換するので、ユーザーは従来のセットアップでブラウザを使用できます。\n開発者がブリッジするフォーマットの多くは、WebRTCと同じプロトコルを使用しています。SIPは一般的にWebRTCで公開されており、ユーザーはブラウザから電話をかけることができます。RTSPは、多くのレガシーセキュリティカメラで使用されています。どちらも同じ基本プロトコル（RTPとSDP）を使用しているので、計算コストをかけずに実行できます。ブリッジが必要なのは、WebRTC固有の機能を追加したり削除したりする場合だけです。\nデータプロトコルブリッジング # Web ブラウザは、限られたプロトコルしか使用できません。使えるのは、HTTP、WebSocket、WebRTC、QUIC です。それ以外のプロトコルに接続するには、プロトコルブリッジを使用する必要があります。プロトコルブリッジとは、外国のトラフィックをブラウザがアクセスできるものに変換するサーバーのことです。よくある例は、ブラウザからSSHを使ってサーバーにアクセスすることです。WebRTCのデータチャネルには、競合製品と比べて2つの利点があります。\nWebRTCのデータチャネルでは、信頼性の低い、順序のない配信が可能です。低レイテンシーが重要なケースでは、これが必要です。これはヘッドオブラインブロッキングと呼ばれるもので、新しいデータが古いデータによってブロックされてしまうことを避けるためです。例えば、マルチプレイヤーの一人称視点のシューティングゲームをプレイしているとします。プレイヤーが2秒前にどこにいたかなんて、本当に気になりますか？もしそのデータが間に合わなかったとしたら、何度も送信しようとしても意味がありません。信頼性のない、順序立てられていない配信では、データが到着したらすぐに受け取ることができます。\nまた、データチャネルにはフィードバック・プレッシャーがあります。これは、接続がサポートする以上の速度でデータを送信しているかどうかを教えてくれます。このような場合、2つの選択肢があります。 データチャネルをバッファリングして遅れてデータを配信するように設定するか、リアルタイムに到着していないデータをドロップするかです。\n遠隔操作 # 遠隔操作とは、WebRTC のデータチャネルを使ってデバイスを遠隔操作し、そのカメラを RTP で送り返すことです。現在、開発者は WebRTC を介して遠隔地で車を運転しています。建設現場でロボットを操作したり、荷物を配達したりするのにも使われています。このような問題にWebRTCを使用するのは、2つの理由から理にかなっています。\nWebRTCのユビキタス性により、ユーザーにコントロールを与えることが容易になります。ユーザーに必要なのは、Webブラウザと入力デバイスだけです。ブラウザは、ジョイスティックやゲームパッドからの入力にも対応しています。WebRTCは、ユーザーのデバイスに追加のクライアントをインストールする必要性を完全に排除します。\n分散型CDN # 分散型CDNは、ファイル共有のサブセットです。分散型CDNはファイル共有のサブセットで、配信されるファイルはCDNの運営者が代わりに設定します。ユーザーはCDNネットワークに参加すると、許可されたファイルをダウンロードして共有できます。ユーザーは、ファイル共有と同様のメリットを得ることができます。\nこのようなCDNは、外部との接続性は悪いが、LANの接続性は良いというオフィスでの使用に適しています。一人のユーザーがビデオをダウンロードし、それを他のユーザーと共有できます。誰もが外部ネットワーク経由で同じファイルを取得しようとしないので、転送がより速く完了します。\nWebRTCトポロジー # WebRTCは2つのエージェントを接続するためのプロトコルですが、開発者はどのようにして数百人を一度に接続しているのでしょうか？これにはいくつかの方法があり、それぞれに長所と短所があります。これらのソリューションは大きく分けて、「ピアツーピア」と「クライアント／サーバー」の2つのカテゴリーに分類されます。WebRTC の柔軟性により、その両方を実現できます。\n1 対 1 # 1 対 1 は WebRTC で使用する最初の接続形態です。2 つの WebRTC Agent を直接接続して、双方向のメディアやデータを送信できます。 接続は以下のようになります。\nフルメッシュ # カンファレンスコールやマルチプレイヤーゲームを構築する場合は、フルメッシュが最適です。このトポロジーでは、各ユーザーが他のすべてのユーザーと直接接続を確立します。これにより、アプリケーションを構築できますが、いくつかのデメリットがあります。\nフルメッシュトポロジーでは、各ユーザーが直接接続されます。そのため、通話相手ごとにビデオのエンコードやアップロードを行う必要があります。 各接続間のネットワーク状況は異なるため、同じ映像を再利用することはできません。また、このような環境では、エラー処理も難しくなります。完全な接続性が失われたのか、それとも1つのリモートピアとの接続性だけが失われたのかを慎重に検討する必要があります。\nこのような問題があるため、フルメッシュは少人数のグループに使用するのが最適です。それ以上の規模の場合は、クライアント/サーバー型のトポロジーが最適です。\nハイブリッドメッシュ # ハイブリッドメッシュは、フルメッシュの問題点を軽減することができるフルメッシュの代替手段です。ハイブリッドメッシュでは、すべてのユーザー間で接続を確立しません。ハイブリッドメッシュでは、すべてのユーザー間で接続するのではなく、ネットワーク内のピアを介してメディアを中継します。これにより、メディアの作成者は、メディアを配信するために多くの帯域を使用する必要がありません。\nしかし、これにはいくつかのデメリットがあります。この設定では、メディアのオリジナル作成者は、自分のビデオが誰に送られているのか、そしてそれが正常に到着したのかを知ることができません。また、ハイブリッド・メッシュ・ネットワークでは、ホップごとにレイテンシーが増加してしまいます。\n選択的フォワーディングユニット (Selective Forwarding Unit) # SFU(Selective Forwarding Unit)もフルメッシュの問題点を解決しますが、方法は全く異なります。SFUは、P2Pではなく、クライアント/サーバー型のトポロジーを実装しています。 各WebRTCピアはSFUに接続し、メディアをアップロードします。SFUはこのメディアを、接続された各クライアントに転送します。\nSFUでは、各WebRTCエージェントがビデオをエンコードしてアップロードするのは一度だけです。すべての視聴者に配信する負担はSFUにあります。 SFUの接続はP2Pよりもはるかに簡単です。SFUはワールドルーティング可能なアドレスで動作させることができるので、クライアントの接続が非常に容易になります。 NATマッピングを気にする必要もありません。ただし、SFUがTCP経由で利用可能であることを確認する必要があります（ICE-TCPまたはTURN経由）。\nシンプルなSFUの構築は、週末にでもできます。すべてのタイプのクライアントを処理できる優れたSFUを構築するには、終わりがありません。輻輳制御、エラー訂正、パフォーマンスのチューニングは終わりのない作業です。\nMCU # MCU (Multi-point Conferencing Unit) は、SFU と同様のクライアント/サーバー型のトポロジーですが、出力ストリームを合成します。MCU (Multi-point Conferencing Unit)はSFUと同様のクライアント/サーバー型トポロジーですが、出力ストリームを合成します。\n"},{"id":8,"href":"/ja/docs/09-debugging/","title":"デバッグ","section":"Docs","content":" デバッグ # WebRTCのデバッグは、非常に困難な作業です。たくさんの可動部品があり、それらがすべて独立して壊れる可能性があります。注意していないと、間違ったものを探すために何週間もの時間を費やすことになります。やっと壊れた部品を見つけても、その原因を理解するためには、少し勉強する必要があります。\n本章では、WebRTC をデバッグするための心構えを身につけます。問題をどのように分解するかを説明します。問題を把握した後は、一般的なデバッグツールを簡単にご紹介します。\n問題の切り分け # デバッグの際には、問題がどこから発生しているのかを切り分ける必要があります。問題の始まりから始めてみましょう。\nシグナリングの失敗 # ネットワーキングの失敗 # netcatを使ってSTUNサーバーをテストします。\n20バイトのバインディングリクエストパケットを準備します。\necho -ne \u0026#34;\\x00\\x01\\x00\\x00\\x21\\x12\\xA4\\x42TESTTESTTEST\u0026#34; | hexdump -C 00000000 00 01 00 00 21 12 a4 42 54 45 53 54 54 45 53 54 |....!..BTESTTEST| 00000010 54 45 53 54 |TEST| 00000014 の解釈を行います。\n0001 はメッセージタイプ\n00 00 はデータセクションの長さです。\n21 12 a4 42 はマジック・クッキーです。\n54 45 53 54 54 45 53 54 54 45 53 54 (ASCIIでは TESTTESTTEST とデコードされます)は12バイトのトランザクションIDです。\nリクエストを送信し、32バイトのレスポンスを待ちます。\nstunserver=stun1.l.google.com;stunport=19302;listenport=20000;echo -ne \u0026#34;\\x00\\x01\\x00\\x00\\x21\\x12\\xA4\\x42TESTTESTTEST\u0026#34; | nc -u -p $listenport $stunserver $stunport -w 1 | hexdump -C 00000000 01 01 00 0c 21 12 a4 42 54 45 53 54 54 45 53 54 |....!..BTESTTEST| 00000010 54 45 53 54 00 20 00 08 00 01 6f 32 7f 36 de 89 |TEST. ....o2.6..| 00000020 の解釈を行います:\n01 01 はメッセージタイプ\n00 0c はデータセクションの長さで、10進数では12にデコードされます。\n21 12 a4 42 は、マジッククッキーです。\nそして、54 45 53 54 54 45 53 54 54 45 53 54（ASCIIではTESTTESTTESTとデコードされる）は、12バイトのトランザクションIDです。\n00 20 00 08 00 01 6f 32 7f 36 de 89 は 12 バイトのデータで解釈は次のようになります:\n00 20 はタイプ: xor-mapped-address です。\n00 08 は値の部分の長さで、10進数では8にデコードされます。\n00 01 6f 32 7f 36 de 89 はデータの値で、以下のように解釈します:\n00 01 はアドレスタイプ(IPv4)です\n6f 32 は XOR マップされたポートです\n7f 36 de 89 はXORマップされたIPアドレスです\nXORマップされた部分を解読するのは面倒ですが、00 00 00 00に設定された(無効な)ダミーのマジッククッキーを与えることで、stunサーバを騙してダミーのXORマップを実行させることができます。\nstunserver=stun1.l.google.com;stunport=19302;listenport=20000;echo -ne \u0026#34;\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00TESTTESTTEST\u0026#34; | nc -u -p $listenport $stunserver $stunport -w 1 | hexdump -C 00000000 01 01 00 0c 00 00 00 00 54 45 53 54 54 45 53 54 |........TESTTEST| 00000010 54 45 53 54 00 01 00 08 00 01 4e 20 5e 24 7a cb |TEST......N ^$z.| 00000020 ダミーのマジッククッキーとのXORは冪等であるため、ポートとアドレスはレスポンスに明確に表示されます（IPアドレスをごまかして通過するパケットを操作するルータもあるため、すべての状況でこれが機能するわけではありません）。\n00 01 4e 20 5e 24 7a cb がデータ値で、解釈は次のようになります:\n00 01 はアドレスタイプ（IPv4）です\n4e 20 はマップされたポートで，10進数で 20000 にデコードされます\n5e 24 7a cb は IP アドレスで，ドット 10 進表記では 94.36.122.203 となります\nセキュリティの失敗 # メディアの障害 # データの障害 # Tools of the trade # netcat (nc) # netcatは、TCP や UDP を使ったネットワーク接続を読み書きするためのコマンドラインネットワークユーティリティです。主に nc コマンドとして利用できます。\ntcpdump # tcpdump は、コマンドラインのデータネットワークパケットアナライザです。\n一般的なコマンドです。\n19302 番ポートとの間の UDP パケットをキャプチャし、パケットの内容を 16 進数で表示します。\nsudo tcpdump 'udp port 19302' -xx\n同じくパケットをPCAP(packet capture)ファイルに保存して後で確認する。\nsudo tcpdump 'udp port 19302' -w stun.pcap\nPCAPファイルは、wiresharkのGUIで開くことができます。wireshark stun.pcap です。\nWireshark # Wireshark は世界中で利用されているプロトコルアナライザーです。\nwebrtc-internals # Chromeには、chrome://webrtc-internalsで利用できる WebRTC の統計ページが組み込まれています。\nレイテンシー # レイテンシーが高いことをどうやって知ることができますか？\n映像が遅れていることに気づいているかもしれませんが、どれくらい遅れているか正確に知っていますか？遅延を減らすためには、まず遅延を測定することから始めなければなりません。\n本当の意味での遅延は、エンドツーエンドで測定することになっています。\nつまり、送信者と受信者の間のネットワークパスのレイテンシーだけでなく、カメラのキャプチャ、フレームのエンコード、送信、受信、デコード、表示などの複合的なレイテンシーや、これらのステップ間のキューイングの可能性も含めて測定します。\nエンド・ツー・エンドのレイテンシーは、各コンポーネントのレイテンシーの単純な合計ではありません。\n理論的には、ライブビデオ伝送パイプラインの各コンポーネントのレイテンシーを個別に測定し、それらを合計することができますが、実際には、少なくともいくつかのコンポーネントは計測のためにアクセスできないか、パイプラインの外で測定すると大きく異なる結果になります。パイプラインステージ間のキューデプスの変化、ネットワークトポロジー、カメラの露出変化などは、エンドツーエンドのレイテンシーに影響を与えるコンポーネントのほんの一例です。\nライブストリーミングシステムの各コンポーネントの固有のレイテンシーが変化し、下流のコンポーネントに影響を与える可能性があります。キャプチャーしたビデオの内容も、レイテンシーに影響を与えます。例えば、木の枝などの高周波数の特徴には、低周波数の澄んだ青空に比べて多くのビットが必要となります。また、自動露出をオンにしたカメラでは、キャプチャレートを毎秒30フレームに設定しても、1フレームをキャプチャするのに予想される33ミリ秒よりもはるかに長い時間がかかることがあります。また、ネットワーク（特に携帯電話）での通信は、需要の変化に応じて非常にダイナミックに変化します。ユーザーが増えれば増えるほど、放送中のおしゃべりも増えます。また、ユーザーの物理的な位置（悪名高い低信号ゾーン）やその他の要因により、パケットロスやレイテンシーが増加します。無線LANアダプターやLTEモデムなどのネットワークインターフェースにパケットを送信するとどうなるでしょうか。すぐに配送できない場合は、インターフェース上でキューに入れられます。キューが大きいほど、そのネットワークインターフェースがもたらす遅延も大きくなります。\n手動によるエンド・ツー・エンドのレイテンシー測定 # エンド・ツー・エンドのレイテンシーとは、ある事象が発生してから、それが観測されるまでの時間、つまりビデオのフレームが画面に表示されるまでの時間を意味します。\nEndToEndLatency = T(observe) - T(happen) 素朴なアプローチとしては、イベント発生時の時間を記録し、それを観測時の時間から差し引くという方法があります。 しかし、精度がミリ秒単位になると、時間の同期が問題になります。 分散したシステム間で時計を同期させようとしても、ほとんどの場合は無駄であり、時間同期のわずかな誤差でさえ、信頼性の低い遅延測定になってしまいます。\nクロック同期の問題を回避する簡単な方法は、同じクロックを使用することです。 送信者と受信者を同じ基準のフレームに入れます。\n時を刻むミリ秒クロックやその他のイベントソースがあるとします。 カメラをリモートスクリーンに向けて、クロックをライブストリーミングするシステムのレイテンシーを測定したいとします。 ミリ秒のタイマーがカチカチと音を立ててから (Thappen)、時計のビデオフレームが画面に表示される (Tobserve) までの時間を計測するには、次のような方法があります。\nミリ秒の時計にカメラを向ける。 物理的に同じ場所にある受信機にビデオフレームを送る。 ミリ秒のタイマーと受信した映像を画面上で撮影する（携帯電話を使用）。 2回分を引く。 これが最も正確なエンド・ツー・エンドのレイテンシー測定法です。 これはすべてのコンポーネント（カメラ、エンコーダー、ネットワーク、デコーダー）のレイテンシーを考慮しており、クロック同期に依存していません。 を参照してください。 上の写真では、測定されたエンドツーエンドのレイテンシーは101ミリ秒です。現在発生しているイベントは10:16:02.862ですが、ライブストリーミングシステムのオブザーバーは10:16:02.761を見ています。\nエンドツーエンドの遅延の自動測定 # 執筆時点(2021年5月)では、エンドツーエンドの遅延に関するWebRTC規格が活発に議論されています。 Firefoxは、標準的なWebRTC APIの上に、ユーザーが自動遅延測定を作成できるようにするための一連のAPIを実装しました。 しかし、この段落では、遅延を自動的に測定する最も互換性のある方法について説明します。\nラウンドトリップタイムを簡単に説明すると 私はあなたに私の時間 tR1 を送り、私の tR1 を時間 tR2 で受け取ると、ラウンドトリップタイムは tR2 - tR1 であることがわかります。\n送信者と受信者の間に通信チャネル（例：DataChannel）が与えられた場合、受信者は以下のプロトコルに従って送信者のモノトニッククロックをモデル化することができます。\n時刻 tR1 に、受信者はそのローカル・モノトニック・クロックのタイムスタンプをメッセージとして送信します。 送信者のローカル時間 tS1 に受信すると、送信者は tR1 のコピーに加えて、送信者の tS1 と送信者のビデオトラック時間 tSV1 を返信します。 送信者のビデオトラックの時間 tSV1 を含む。 受信側の時刻tR2において，メッセージの送信時間と受信時間を差し引くことでラウンド・トリップ・タイムを計算する。RTT = tR2 - tR1 となります。 ラウンド・トリップ・タイム RTT と送信者のローカル・タイムスタンプ tS1 を合わせれば、送信者のモノトニック・クロックの推定値が得られます。時刻 tR2 における送信者の現在の時刻は、tS1 にラウンド・トリップ・タイムの半分を加えたものになります。 送信者のローカルクロックのタイムスタンプ tS1 とビデオトラックのタイムスタンプ tSV1 のペア、およびラウンドトリップタイム RTT は、受信者のビデオトラックの時間を送信者のビデオトラックに同期させるのに十分です。 最後に確認した送信側ビデオフレームの時間 tSV1 からどれだけの時間が経過したかがわかったので、現在表示されているビデオフレームの時間と tSV1 からの経過時間を比較することで、遅延を概算することができます。\nexpected_video_time = tSV1 + time_since(tSV1) latency = expected_video_time - actual_video_time この方法の欠点は、カメラの固有のレイテンシーが含まれていないことです。 ほとんどのビデオシステムでは，フレームキャプチャのタイムスタンプを，カメラからのフレームがメインメモリに送られた時刻とみなしていますが，これは記録されるイベントが実際に起こってから数秒後になります。\nレイテンシー推定の例 # サンプルの実装では、受信機で latency データチャネルを開き、受信機の単調なタイマーのタイムスタンプを送信機に定期的に送信します。 送信者は、JSONメッセージで応答を返します。 受信機はこのメッセージに基づいてレイテンシーを計算します。\n{ \u0026#34;received_time\u0026#34;: 64714, // 受信者が送信したタイムスタンプ、送信者はそのタイムスタンプを反映する \u0026#34;delay_since_received\u0026#34;: 46, // 送信者が最後に受信した `received_time` から経過した時間 \u0026#34;local_clock\u0026#34;: 1597366470336, // 送信者の現在の単調なクロック時間 \u0026#34;track_times_msec\u0026#34;: { \u0026#34;myvideo_track1\u0026#34;: [ 13100, // ビデオフレームのrtpタイムスタンプ (ミリ秒のタイムスケール) 1597366470289 // ビデオフレームのモノトニッククロックのタイムスタンプ ] } } 受信機でデータチャンネルを開く\ndataChannel = peerConnection.createDataChannel(\u0026#39;latency\u0026#39;); 受信機の時間 tR1 を定期的に送信する。この例では特に理由なく2秒を使用している。\nsetInterval(() =\u0026gt; { let tR1 = Math.trunc(performance.now()); dataChannel.send(\u0026#34;\u0026#34; + tR1); }, 2000); 受信者から送信者に届くメッセージを処理する\n//イベントデータが以下のような文字列であると仮定します。\u0026#34;1234567\u0026#34; tR1 = event.data now = Math.trunc(performance.now()); tSV1 = 42000; //現在のフレームのrtpのタイムスタンプをミリ秒のタイムスケールに変換 tS1 = 1597366470289; //カレントフレームのモノトニッククロックのタイムスタンプ msg = { \u0026#34;received_time\u0026#34;: tR1, \u0026#34;delay_since_received\u0026#34;: 0, \u0026#34;local_clock\u0026#34;: now, \u0026#34;track_times_msec\u0026#34;: { \u0026#34;myvideo_track1\u0026#34;: [tSV1, tS1]. } } dataChannel.send(JSON.stringify(msg)); 送信者からの受信メッセージを処理し、推定レイテンシーを コンソール に表示する\nlet tR2 = performance.now(); let fromSender = JSON.parse(event.data); let tR1 = fromSender[\u0026#39;received_time\u0026#39;]; let delay = fromSender[\u0026#39;delay_since_received\u0026#39;]; // 送信者がレスポンスを受信してから送信するまでに経過した時間 let senderTimeFromResponse = fromSender[\u0026#39;local_clock\u0026#39;]; let rtt = tR2 - delay - tR1; let networkLatency = rtt / 2; let senderTime = (senderTimeFromResponse + delay + networkLatency); VIDEO.requestVideoFrameCallback((now, framemeta) =\u0026gt; {。 // 送信者の現在時刻を推定 let delaySinceVideoCallbackRequested = now - tR2; senderTime += delaySinceVideoCallbackRequested; let [tSV1, tS1] = Object.entries(fromSender[\u0026#39;track_times_msec\u0026#39;])[0][1]. let timeSinceLastKnownFrame = senderTime - tS1; let expectedVideoTimeMsec = tSV1 + timeSinceLastKnownFrame; let actualVideoTimeMsec = Math.trunc(framemeta.rtpTimestamp / 90); // rtpのタイムベース(90000)をミリ秒のタイムベースに変換する let latency = expectedVideoTimeMsec - actualVideoTimeMsec; console.log(\u0026#39;latency\u0026#39;, latency, \u0026#39;msec\u0026#39;); }); ブラウザでの実際のビデオ時間 # \u0026lt;video\u0026gt;.requestVideoFrameCallback()を使うと、ウェブ制作者は合成用のフレームが提示されたときに通知を受けることができます。\nごく最近（2020年5月）まで、ブラウザで現在表示されているビデオフレームのタイムスタンプを確実に取得することは不可能に近かった。video.currentTime に基づく回避方法は存在していましたが、特に正確ではありませんでした。\nChrome と Mozilla の両ブラウザ開発者は、新しい W3C 標準である HTMLVideoElement.requestVideoFrameCallback() の導入を サポート しており、現在のビデオフレーム時間にアクセスするための API コールバックが追加されています。 この追加は些細なことのようですが、オーディオとビデオの同期を必要とするウェブ上の複数の高度なメディアアプリケーションを可能にしました。 特にWebRTCの場合、コールバックには、現在のビデオフレームに関連するRTPタイムスタンプであるrtpTimestampフィールドが含まれます。 これは、WebRTCアプリケーションでは存在すべきですが、それ以外では存在しません。\nレイテンシーのデバッグのヒント # まず第一に、デバッグは測定されたレイテンシーに影響を与える可能性が高いため、一般的なルールとして、問題を再現できる最小のセットアップに簡略化することが挙げられます。 より多くのコンポーネントを取り除くことができれば、どのコンポーネントがレイテンシーの問題を引き起こしているのかを簡単に把握することができます。\nカメラのレイテンシー # カメラの設定により、カメラの待ち時間が異なる場合があります。 自動露出、自動フォーカス、自動ホワイトバランスの設定を確認してください。 Webカメラの「自動」機能はすべて、撮影した画像を分析してからWebRTCスタックで利用できるようにするまでに時間がかかります。\nLinux をお使いの場合は、カメラの設定を制御するために v4l2-ctl コマンドラインツールを使用してください。\n# オートフォーカスの無効化 v4l2-ctl -d /dev/video0 -c focus_auto=0 # フォーカスを無限大にする v4l2-ctl -d /dev/video0 -c focus_absolute=0 また、カメラの設定を素早く確認したり調整したりするために、UIツールのguvcviewを使用しています。\nエンコーダーのレイテンシー # 最近のエンコーダーは、エンコードされたフレームを出力する前に、いくつかのフレームをバッファリングします。 画質とビットレートのバランスを第一に考えています。 マルチパスエンコーディングは、エンコーダーが出力レイテンシーを無視した極端な例です。 エンコーダーは、最初のパスで映像全体を取り込み、その後、フレームの出力を開始します。\nしかし、適切な調整を行えば、サブフレームのレイテンシーを達成した人もいます。 エンコーダが過剰な参照フレームを使用したり、B-フレームに依存していないことを確認してください。 コーデックごとにレイテンシーチューニングの設定は異なりますが、x264 の場合、フレーム出力のレイテンシーを最小にするために、tune=zerolatency と profile=baseline を使用することをお勧めします。\nネットワークのレイテンシー # ネットワークの遅延は、より良いネットワーク接続にアップグレードする以外には、ほとんど何もできないと言っても過言ではありません。 ネットワークの遅延は天気とよく似ています。雨を止めることはできませんが、天気予報をチェックして傘を持つことはできます。 WebRTCでは、ネットワークの状態をミリ秒単位で測定しています。\n重要な測定基準は\nラウンド・トリップ・タイム パケットロスとパケット再送 ラウンド・トリップ・タイム（Round-Trip Time）\nWebRTC スタックには、ネットワークのラウンドトリップタイム（RTT）の測定メカニズムが組み込まれています。 遅延の適切な近似値はRTTの半分です。RTT は、パケットの送信と受信に同じ時間がかかることを前提としていますが、必ずしもそうではありません。 RTTはエンドツーエンドのレイテンシーの下限を設定します。 カメラからエンコーダーまでのパイプラインがどれだけ最適化されていても、ビデオフレームはRTT/2よりも早く受信機に到達することはできません。\n組み込みのRTTメカニズムは、送信者/受信者レポートと呼ばれる特別なRTCPパケットに基づいています。 送信者は受信者にタイムリーディングを送信し、受信者は同じタイムスタンプを送信者に反映させます。 これにより、送信者は、パケットが受信者まで移動して戻ってくるまでにかかった時間を知ることができます。 RTT測定の詳細については、送受信レポートの章を参照してください。\nパケットロスとパケット再送について\nRTPとRTCPの両プロトコルはUDPをベースにしていますが、UDPには順序付け、配送の成功、重複しないことなどの保証はありません。 上記のようなことは、実際のWebRTCアプリケーションでも起こり得ますし、実際に起こっています。 素朴なデコーダの実装では、デコーダが画像を正常に再構成するために、フレームのすべてのパケットが配信されることを期待します。 P-フレームのパケットが失われた場合、パケットロスがあると、デコーディングアーチファクトが発生する可能性があります。 I-フレームのパケットが失われると、それに依存するすべてのフレームに重いアーティファクトが発生するか、まったくデコードされません。 これは、ビデオが「フリーズ」しているように見えます。\nビデオのフリーズやデコードの不具合を避けるために（少なくとも避けようとするために）、WebRTCはネガティブアクノレッジメントメッセージ（NACK）を使用しています。 受信者が期待したRTPパケットを取得できなかった場合、送信者に不足しているパケットを再度送信するようにNACKメッセージを返します。 受信者は、パケットの再送を_待つことになります。 このような再送は明らかにレイテンシーの増加を引き起こします。 送受信された NACK パケットの数は、WebRTC の組み込み統計フィールド outbound stream nackCount および inbound stream nackCount に記録されます。\nwebrtc internals pageでは、インバウンドとアウトバウンドの nackCount の美しいグラフを見ることができます。 nackCountが増加している場合は、ネットワークで高いパケットロスが発生していることを意味し、WebRTCスタックはそれにもかかわらず、スムーズなビデオ/オーディオ体験を実現するために最善を尽くしています。\nパケットロスが非常に大きく、デコーダーが画像を生成できない場合、または完全に失われたIフレームの場合のように後続の依存画像を生成できない場合、以降のすべてのPフレームがデコードされません。 受信側は、特別なピクチャ・ロス・インジケーション・メッセージ(PLI)を送信することで、その影響を軽減しようとします。 送信者はPLIを受信すると、受信者のデコーダを助けるために新しいIフレームを生成します。 I-フレームは通常、P-フレームよりもサイズが大きくなります。これにより、送信しなければならないパケットの数が増えます。 NACKメッセージと同様に、受信者は新しいI-フレームを待つ必要があり、追加のレイテンシーが発生します。\nwebrtc internals pageのpliCountを見て、もし増えていたら、パケット数が少なくなるようにエンコーダを調整するか、error resilient modeを有効にしてください。\n受信側のレイテンシー # パケットが順番通りに来ないと、レイテンシーに影響します。 イメージパケットの下半分が上半分より先に来た場合、デコードする前に上半分を待たなければなりません。 これについては、ジッターの解決の章で詳しく説明しています。\nまた、jitterBufferDelayというビルトインメトリックで、フレームがデコーダに解放されるまで受信バッファで全てのパケットを待っていた時間を確認することができます。\n"},{"id":9,"href":"/ja/docs/10-history-of-webrtc/","title":"歴史","section":"Docs","content":" 歴史 # WebRTC を学ぶ際、開発者はその複雑さに苛立ちを覚えることがあります。WebRTC の機能が現在のプロジェクトとは無関係であることを知り、WebRTC がもっとシンプルであればと思うのです。問題は、使用例が人によって異なることです。リアルタイム通信には豊かな歴史があり、さまざまな人がさまざまなものを作ってきました。\n本章では、WebRTC を構成するプロトコルの開発者へのインタビューを掲載しています。 それぞれのプロトコルを構築する際の設計について洞察し、最後に WebRTC そのものについてのインタビューを行います。ソフトウェアの意図や設計を理解すれば、そのソフトウェアを使ってより効果的なシステムを構築することができます。\nRTP # RTP および RTCP は、WebRTC のすべてのメディア伝送を担当するプロトコルです。1996年1月にRFC 1889で定義されました。 著者の一人であるRon Frederickが自ら語ってくれるというのはとてもラッキーなことです。Ron は最近、RTPに影響を与えたプロジェクトであるNetwork Video toolを GitHub にアップロードしました。\n彼自身の言葉です。\n1992年10月、私はIPマルチキャストをベースにしたネットワークビデオ会議ツールを書こうと思い、Sun VideoPixフレームグラバーカードの実験を始めました。このプログラムは、LBLで開発されたオーディオ会議ツール「vat」をモデルにしたもので、会議に参加するユーザーに同様の軽量なセッションプロトコルを使用し、特定のマルチキャストグループにデータを送り、他のグループメンバーからのトラフィックを監視するだけのものでした。\nこのプログラムを成功させるためには、ネットワークに出す前にビデオデータを圧縮する必要がありました。私の目標は、家庭用ISDN回線の帯域幅である128kbps程度に収まる、見た目にも美しいデータストリームを作ることでした。さらに、その半分の帯域で見られるようなものを作りたかった。そのためには、画像サイズとフレームレートに応じて、約20倍の圧縮が必要でした。私はこの圧縮を実現し、使用した技術の特許を申請しました。これは後に特許US5485212Aとして認められました: 電話会議のためのソフトウェアビデオ圧縮。\n1992年11月初旬、私はビデオ会議ツール「nv」を（バイナリ形式で）インターネットコミュニティに公開しました。初期テストの後、 このツールを使って、 11月のインターネット技術タスクフォースの一部を世界中にビデオキャストしました。15カ国の約200のサブネットでこの放送を受信することができ、1週間のうちに約50～100人が「nv」を使ってビデオを受信しました。\nその後、オーストラリアの「NetWorkshop」、MCNCの「Packet Audio and Video」、スウェーデンの「MultiG Workshop on Distributed Virtual Realities」など、他の3つのワークショップやいくつかの小規模な会議でも「nv」を使ってインターネット全体に向けた放送が行われました。\n1993年2月には「nv」のソースコードを公開し、3月にはウェーブレットベースの圧縮方式を導入したバージョンを公開しました。1993年5月には、カラービデオにも対応しました。\n「nv」をはじめとするインターネット会議ツールのネットワークプロトコルは、インターネット技術タスクフォース（IETF）で標準化されたリアルタイム・トランスポート・プロトコル（RTP）をベースにしています。RFC 1889-1890で最初に発表され、その後RFC 3550-3551で改訂され、音声やビデオの特定フォーマットを伝送するためのプロファイルをカバーするさまざまな他のRFCも追加されました。\nその後、数年にわたって「nv」の開発が続けられ、多くのハードウェアプラットフォームやビデオキャプチャーデバイスにツールが移植されました。当時、インターネット上で会議を中継するための主要なツールの一つとして使われ続け、NASAからシャトルミッションのライブ中継に選ばれたこともある。\n1994年には、他社が開発したビデオ圧縮アルゴリズムを「nv」でサポートするようにした。これには、SunVideoビデオキャプチャカードがサポートするCellBフォーマットなどのハードウェア圧縮方式も含まれる。これにより、「nv」はCUSeeMeフォーマットでビデオを送信できるようになり、MacやPCでCUSeeMeを実行しているユーザーにビデオを送信できるようになりました。\n「nv」が最後に公開されたのは、1994年7月にリリースされた「3.3beta」だった。私は「nv」をRTPプロトコルのバージョン2に移行させることを目的とした「4.0alpha」のリリースに取り組んでいましたが、私が他のプロジェクトに移ったため、この作業は完了しませんでした。4.0αのコードは、Network Video toolのアーカイブに含まれていますが、未完成であり、特にRTPv2のサポートが不完全であるなど、既知の問題があります。\n「nv」で提供されたフレームワークは、後にXerox PARCの「Jupiter multi-media MOO」プロジェクトにおけるビデオ会議の基礎となり、後にMicrosoftに買収されたスピンオフ企業「PlaceWare」の基礎となりました。また、このコードは、高帯域幅のイーサネットやATMネットワーク上でNTSC放送品質のビデオを送ることができる多くのハードウェアビデオ会議プロジェクトの基礎としても使われました。 また、このコードの一部は、ネットワークベースのビデオ録画・再生サービスである「Mediastore」のベースとしても使用しました。\nドラフトに参加していた他のメンバーの動機やアイデアは覚えていますか？\n私たちは皆、IPマルチキャストの研究者で、インターネット・マルチキャスト・バックボーン（通称MBONE）の構築に携わっていました。MBONEは、IPマルチキャストを最初に開発したスティーブ・デアリング、ヴァン・ジェイコブソン、スティーブ・キャスナーの3人によって作られました。スティーブ・デアリングと私はスタンフォード大学で同じ指導教官でしたが、スティーブはスタンフォード大学を辞めてXerox PARCで働くことになりました。私はインターンとしてXerox PARCでIPマルチキャスト関連のプロジェクトにひと夏を過ごし、スタンフォード大学在学中はパートタイムで、その後はフルタイムで働き続けました。ヴァン・ジェイコブソンとスティーブ・キャスナーは、ヘニング・シュルツリンと私と一緒に、初期のRTP RFCの4人の著者のうちの2人でした。私たちは皆、様々な形のオンラインコラボレーションを可能にするMBONEツールを開発していましたが、これらのツールが使用できる共通のベースプロトコルを作ろうとしたことがRTPにつながったのです。\nマルチキャストはとても魅力的です。WebRTCは完全にユニキャストですが、その点について説明していただけますか？\nスタンフォード大学に入学してIPマルチキャストについて学ぶ前、私はコンピュータを使って人々が互いにコミュニケーションを取る方法について長い間研究してきました。私は80年代初頭にダイアルアップの掲示板システムを運営していましたが、そこでは人々がログオンしてお互いにメッセージを残すことができ、プライベートなもの（電子メールに相当するもの）とパブリックなもの（ディスカッショングループ）がありました。同じ頃、CompuServeというオンラインサービスの存在も知りました。CompuServeの優れた機能の一つに「CB Simulator」というものがあり、人々がリアルタイムで会話をすることができました。すべてテキストベースでしたが、本物のCBラジオのように「チャンネル」という概念があり、同じチャンネルにいる限り、複数の人が他の人の入力した内容を見ることができました。 私は、タイムシェアリングシステム上で動作する自作のCBを作り、そのシステム上のユーザーがリアルタイムにメッセージを送れるようにしました。実は、そのうちの1つのシステムは今でも稼働していて、30数年前に大学で一緒だった人たちと毎日のように会話をしているんですよ。\nしかし、スタンフォード大学でIPマルチキャストについて学んだとき、マルチキャストを使って真の「ラジオ」のようなものを手に入れることができるという考えに興味を持ちました。偶然にも、私がIPマルチキャストのコードを移植していたコンピュータは、サンの第一世代のSPARCステーションで、実は電話品質のオーディオハードウェアを内蔵していたのです。 マイクからの音をデジタル化して、内蔵スピーカー（またはヘッドフォン出力）で再生できるのです。そこで私が最初に考えたのは、IPマルチキャストを使ってその音声をリアルタイムでネットワーク上に送る方法を見つけ出し、テキストの代わりに実際の音声を使って「CBラジオ」に相当するものを作れないかということでした。\nコンピュータは一度に1つのオーディオストリームしか再生できないので、複数の人が話している場合には、再生する前に複数のオーディオストリームを数学的に1つに「ミックス」する必要があるなど、いくつか厄介な点がありましたが、オーディオサンプリングの仕組みを理解すれば、ソフトウェアですべて解決することができました。このオーディオアプリケーションがきっかけで、私はMBONEに取り組み、最終的には「nv」でオーディオからビデオへと移行しました。\nプロトコルに含まれていないもので、追加しておけばよかったと思うものはありますか？ プロトコルの中で後悔していることはありますか？\n後悔しているとまでは言いませんが、RTPに対する大きな不満のひとつは、RTPのデータトラフィックと並行して走る制御プロトコルであるRTCPの実装が複雑だったことです。RTPが広く採用されなかったのは、この複雑さが大きく影響していると思います。特にユニキャストの場合は、RTCPの機能の一部がそれほど必要ではありませんでした。 ネットワークの帯域幅が希少ではなくなり、輻輳がそれほど大きな問題ではなくなったため、多くの人がオーディオやビデオを普通のTCP（後にはHTTP）でストリーミングするようになり、一般的には「十分に」機能するのでRTPを扱う価値はありませんでした。\n残念なことに、TCPやHTTPを使用すると、マルチパーティのオーディオやビデオのアプリケーションは、同じデータをネットワーク上で何度も送信しなければならず、それを受信する必要のある各ピアに送信しなければならず、帯域幅の観点からは効率が非常に悪くなります。私は、IPマルチキャストの採用を研究機関だけでなく、もっと推進していればよかったと思うことがあります。 そうすれば、ケーブルテレビや放送テレビからインターネットベースのオーディオやビデオへの移行を、もっと早く実現できたと思います。\nRTPでどんなものが作られると想像していましたか？RTPを使ってどんなものが作られると想像していましたか？また、失われてしまったクールなRTPプロジェクトやアイデアはありますか？\n私が作って面白かったのは、IPマルチキャストを使った古典的な「Space War」ゲームのバージョンでした。セントラルサーバを持たずに、複数のクライアントがそれぞれspacewarバイナリを実行し、自機の位置、速度、向いている方向、発射した「弾」の同様の情報をブロードキャストし始めると、他のすべてのインスタンスがその情報を拾ってローカルにレンダリングし、ユーザーはお互いの自機や弾を見ることができ、自機がお互いに衝突したり、弾が当たったりすると「爆発」します。爆発の際に発生する「破片」は、他の船を破壊できる生きたオブジェクトにして、時には連鎖反応を起こすようにしました。\nオリジナルのゲームの精神に則り、シミュレートされたベクターグラフィックスを使ってレンダリングしました。船自体は、PARCの同僚にデザインを手伝ってもらったベクター形式の線分の束で、みんなの船がユニークな外観になっています。\n基本的にRTPは、完全なインオーダー・デリバリーを必要としないリアルタイム・データ・ストリームの恩恵を受けられるものであれば、何でも利用できる。つまり、オーディオやビデオに加えて、共有のホワイトボードのようなものを構築できます。ファイル転送でも、特にIPマルチキャストとの組み合わせでは、RTPの恩恵を受けることができます。\nBitTorrentのようなものを想像してみてください。ただし、ピア間でポイント・ツー・ポイントでデータをやり取りする必要はありません。オリジナルのシーダーは、マルチキャストストリームをすべてのリーチャーに一度に送信することができ、途中でパケットロスがあっても、データの受信に成功したピアからの再送ですぐに解決できます。ネットワークの真ん中でパケットロスが発生すると、その地点から下流にいるたくさんのクライアントが同じデータを逃してしまうことになるからです。\nなぜ独自の動画圧縮を行う必要があったのですか？当時は他になかったのでしょうか？\n私が「nv」を作り始めた当時、ビデオ会議を行うシステムは非常に高価な専用ハードウェアしかありませんでした。例えば、スティーブ・カスナーはBBN社の「DVC」（後に「PictureWindow」として商品化）というシステムを利用していました。圧縮には専用のハードウェアが必要だが、解凍はソフトウェアで行うことができた。「nv」がユニークなのは、圧縮と解凍の両方をソフトウェアで行い、必要なハードウェアは入力されたアナログビデオ信号をデジタル化するものだけだということです。\n映像を圧縮するための基本的なコンセプトは、「nv」と同時期に登場したMPEG-1規格などによってすでに確立されていましたが、MPEG-1を使ったリアルタイムのエンコーディングは、当時は絶対にできませんでした。私が行った変更は、これらの基本的な概念を、より安価なアルゴリズムで近似することでした。コサイン変換や浮動小数点などは避け、SPARCステーションでは非常に遅いため、整数の乗算も避けました。加減算とビットマスク、シフトだけでできる限りのことをしようとしました。そうすることで、ビデオのような感覚を維持するのに十分なスピードを取り戻すことができました。\n「nv」がリリースされてから1〜2年も経たないうちに、MBONEだけでなく、Macに搭載されたCU-SeeMeツールなど、さまざまなオーディオ・ビデオツールが登場しました。そのため、明らかに時代に合ったアイデアだと思いました。実際、私は「nv」をこれらのツールの多くと相互運用できるようにしましたし、いくつかのケースでは、他のツールが私の「nv」コーデックをピックアップして、私の圧縮スキームを使用する際に相互運用できるようにしました。\nWebRTC # WebRTCの標準化には、この章で紹介した他のすべての取り組みに比べて、非常に大きな努力が必要でした。2つの異なる標準化団体（IETFとW3C）と、多くの企業や国の何百人もの人々の協力が必要でした。WebRTCを実現するために必要な動機と途方もない努力の内側を見るために、Serge Lachapelleに来てもらいました。\nSergeはGoogleのプロダクトマネージャーで、現在はGoogle Workspaceのプロダクトマネージャーを務めています。インタビューの内容をまとめてみました。\nWebRTCに取り組むことになったきっかけは？ # 私は、大学時代からコミュニケーションソフトウェアの構築に情熱を注いできました。90年代にはnvのような技術が登場し始めましたが、使いこなすのは困難でした。 私は、ブラウザからすぐにビデオ通話に参加できるプロジェクトを作りました。それをWindowsに移植したのです。\nこの経験を生かして、共同設立したMarratechという会社で、グループビデオ会議のソフトウェアを作りました。私たちはグループビデオ会議用のソフトウェアを開発しました。 技術的には、当時の状況は大きく異なっていました。ビデオの最先端は、マルチキャスト・ネットワークに基づいていました。 ユーザーはネットワークに依存して、通話中の全員にビデオパケットを配信することができました。そのため、サーバーも非常にシンプルなものでした。しかし、これには大きな欠点があり、ネットワークをそれに合わせて設計しなければなりませんでした。業界では、マルチキャストからパケットシャッフル（一般的にはSFUと呼ばれる）へと移行していきました。\nMarratechは2007年にGoogleに買収されました。私はその後、WebRTCを伝えるプロジェクトに参加することになりました。\nGoogleの最初のプロジェクト # 未来のWebRTCチームが最初に取り組んだプロジェクトは、Gmailの音声・ビデオチャットでした。音声や動画をブラウザに取り込むのは簡単なことではありませんでした。そのためには、さまざまな企業からライセンスを取得する必要がありました。 音声はGIPsから、ビデオはVidyoから、ネットワークはlibjingleからライセンスを受けました。そして、それらすべてを一緒に動作させるのがマジックでした。\nそれぞれのサブシステムはまったく異なるAPIを持っており、異なる問題を解決することを前提としていました。すべてを一緒に動作させるには、ネットワーク、暗号、メディアなどの知識が必要です。Justin Ubertiは、この作業を引き受けてくれた人です。 彼は、これらのコンポーネントをまとめて、使いやすい製品を作りました。\nブラウザでリアルタイムにレンダリングすることも、とても大変でした。NPAPI（Netscape Plugin API）を使ったり、巧妙なことをたくさんしないとうまくいきませんでした。 このプロジェクトで得た教訓は、WebRTCに大きな影響を与えました。\nChrome # 同時期に Google 社内で Chrome プロジェクトが始まりました。このプロジェクトには大きな目標があり、非常に興奮していました。WebGL、オフライン、データベース機能、ゲーム用の低遅延入力などの話がありました。\nNPAPIからの脱却が大きな焦点となりました。NPAPIは強力なAPIですが、大きなセキュリティ上の問題があります。Chromeでは、ユーザーの安全を守るためにサンドボックス方式を採用しています。 安全でない可能性のある操作は、別のプロセスで実行されます。 何か問題が発生しても、攻撃者はユーザーのデータにアクセスできません。\nWebRTCの誕生 # 私にとってWebRTCは、いくつかの動機から生まれました。それらが相まって、努力が生まれました。\nRTC 体験を構築するのは、こんなに難しいことではないはずです。同じものを異なる開発者が再実装することで、多くの努力が無駄になっています。このようなイライラするような統合問題を一度解決して、他のことに集中すべきです。\n人間のコミュニケーションは妨げられることなく、オープンであるべきです。テキストやHTMLはオープンでいいのに、リアルタイムでの自分の声や映像がオープンでないのはなぜでしょうか？\nセキュリティは最優先事項です。NPAPIを使うことは、ユーザーにとってベストではありませんでした。これは、デフォルトで安全なプロトコルを作るチャンスでもありました。\nWebRTCを実現するために、Googleはそれまで使っていたコンポーネントを買収し、オープンソース化しました。ビデオ技術ではOn2を、RTC技術ではGlobal IP Solutionsを買収しました。 私はGIPSの買収を担当していました。 これらを組み合わせて、ブラウザ内外で使いやすくする作業に取り掛かりました。\n標準化 # WebRTCの標準化は、私たちが本当にやりたいと思っていたことでしたが、私もチームのメンバーもやったことがありませんでした。この点については、GoogleのHarald Alvestrand氏に大変お世話になりました。彼はすでにIETFで幅広い活動を行っており、WebRTCの標準化プロセスを開始しました。\n2010年の夏、マーストリヒトで非公式の昼食会が開かれました。多くの企業から開発者が集まり、WebRTCがどうあるべきかを議論しました。昼食会には、Google、Cisco、Ericsson、Skype、Mozilla、Linden Labsなどのエンジニアが参加しました。 全出席者と発表者のスライドはrtc-web.alvestrand.comでご覧いただけます。\nまた、SkypeはIETFでOpusと一緒に仕事をしていたこともあり、いくつかの素晴らしいガイダンスを提供してくれました。\n巨人の肩の上に立つ # IETF で作業をするということは、それまでの作業の延長線上にあるということです。 WebRTCでは、多くのものが存在していたことが幸いしました。すでに解決されていたので、すべての問題に取り組む必要はありませんでした。もし既存の技術が気に入らなければ、イライラするかもしれませんが。既存のものを無視するにはよほどの理由が必要で、自分で作るという選択肢はありません。\nまた、シグナリングなどの再標準化も意識的に行いませんでした。 これはすでにSIPやその他のIETF以外の取り組みで解決されており、非常に政治的な問題になりかねないと考えたからです。最終的には、この空間に加えるべき価値があまりないと感じたのです。\n私は、Justin や Harald ほどは標準化に関与しませんでしたが、標準化を楽しんでいました。それよりも、ユーザーのためのモノづくりに戻りたいという気持ちの方が強かったですね。\n今後の展望 # WebRTC は現在、素晴らしい状態にあります。多くの反復的な変更が行われていますが、特に私が取り組んでいるものはありません。\n私が最も期待しているのは、クラウド・コンピューティングがコミュニケーションに何をもたらすかということです。高度なアルゴリズムを用いることで、通話中のバックグラウンドノイズを除去し、これまで不可能だったコミュニケーションを可能にすることができます。 また、WebRTCは通信にとどまらず、9年後にはクラウドベースのゲームにも使われるようになるとは、誰が予想したでしょうか。これらはすべて、WebRTCという基盤がなければ実現しません。\n"},{"id":10,"href":"/ja/docs/11-faq/","title":"FAQ","section":"Docs","content":" FAQ # なぜWebRTCはUDPを使うのですか？ NATトラバーサルにはUDPが必要です。NATトラバーサルがなければ、P2P接続の確立をすることはできません。 UDPはTCPのような「配信保証」を提供していないので、WebRTCではユーザーレベルで提供しています。\n詳しくは 接続 をご覧ください\nデータチャンネルはいくつまで持てますか？ ストリームの識別子が16ビットなので、65534チャンネルです。いつでも新しいものを閉じたり開いたりできます。 WebRTCは帯域幅の制限がありますか？ DataChannels と RTP は共に輻輳制御を使用します。これは、WebRTC が帯域幅を積極的に測定し、最適な量を使用しようとすることを意味します。これは、接続を圧迫することなく、可能な限り多くのデータを送信するためのバランスです。 バイナリデータの送信は可能ですか？ はい、DataChannelsでは、テキストとバイナリの両方のデータを送信できます。 WebRTCのレイテンシーはどのくらいですか？ チューニングされていないメディアでは、500ミリ秒以下が期待できます。もし、レイテンシーのために品質を犠牲にしても構わないのであれば、開発者は100ミリ秒以下を実現しています。\nDataChannelsは、\u0026ldquo;Partial-reliability \u0026ldquo;オプションをサポートしています。適切に設定されていれば、TCP TLS 接続よりも優れていることが示されています。\nなぜDataChannelsに順序付けされていない配信が必要なのでしょうか？ 物体の位置情報など、新しい情報が古い情報を駆逐する場合や、各メッセージが他のメッセージから独立しており、回線の先頭でのブロック遅延を回避する必要がある場合などです。 DataChannelでオーディオやビデオを送信できますか？ どんなデータでもDataChannelで送ることができます。ブラウザの場合、データをデコードしてメディアプレーヤーに渡してレンダリングするのはあなたの責任ですが、メディアチャンネルを使用する場合は自動的に行われます。 "},{"id":11,"href":"/ja/docs/12-glossary/","title":"用語集","section":"Docs","content":" 用語集 # ACK: Acknowledgment AVP: Audio and Video profile B-Frame: Bi-directional Predicted Frame. 部分的な画像で,以前の画像と未来の画像を組み合わせたもの DCEP: Data Channel Establishment Protocol 策定文書 RFC 8832 DeMux: Demultiplexer DLSR: delay since last sender report DTLS: Datagram Transport Layer Security 策定文書 RFC 6347 E2E: end-to-end FEC: Forward Error Correction FIR: Full INTRA-frame Request G.711: A narrowband audio codec GCC: Google Congestion Control 策定文書 draft-ietf-rmcat-gcc-02 H.264: Advanced video coding for generic audiovisual services H.265: Conformance specification for ITU-T H.265 high efficiency video coding HEVC: High Efficiency Video Coding HTTP: Hypertext Transfer Protocol HTTPS: HTTP Over TLS 策定文書 RFC 2818 I-Frame: Intra-coded Frame. 完全な画像で,何もなくてもデコードできる ICE: Interactive Connectivity Establishment 策定文書 RFC 8445 INIT: Initiate IoT: Internet of Things IPv4: Internet Protocol, Version 4 IPv6: Internet Protocol, Version 6 ITU-T: International Telecommunication Union Telecommunication Standardization Sector JSEP: JavaScript Session Establishment Protocol 策定文書 RFC 8829 MCU: Multi-point Conferencing Unit mDNS: Multicast DNS 策定文書 RFC 6762 MITM: Man-In-The-Middle MTU: Maximum Transmission Unit MUX: Multiplexing NACK: Negative Acknowledgment NADA: network-assisted dynamic adaptation 策定文書 draft-zhu-rmcat-nada-04 NAT: Network Address Translation 策定文書 RFC 4787 Opus: A totally open, royalty-free, highly versatile audio codec P-Frame: Predicted Frame. 部分的な画像で,前の画像を修正したもの P2P: peer-to-peer PLI: Picture Loss Indication PPID: Payload Protocol Identifier REMB: Receiver Estimated Maximum Bitrate RFC: Request for Comments RMCAT: RTP Media Congestion Avoidance Techniques RR: Receiver Report RTCP: RTP Control Protocol 策定文書 RFC 3550 RTP: Real-time transport protocol 策定文書 RFC 3550 RTT: Round-trip time SACK: Selective Acknowledgment SCReAM: Self-Clocked Rate Adaptation for Multimedia defined 策定文書 draft-johansson-rmcat-scream-cc-05 SCTP: Stream Control Transmission Protocol 策定文書 RFC 4960 SDP: Session Description Protocol 策定文書 RFC 8866 SFU: Selective Forwarding Unit SR: Sender Report SRTP: Secure Real-time Transport Protocol 策定文書 RFC 3711 SSRC: Synchronization Source STUN: Session Traversal Utilities for NAT 策定文書 RFC 8489 TCP: Transmission Control Protocol TLS: The Transport Layer Security 策定文書 RFC 8446 TMMBN: Temporary Maximum Media Stream Bit Rate Notification TMMBR: Temporary Maximum Media Stream Bit Rate Request TSN: Transmission Sequence Number TURN: Traversal Using Relays around NAT 策定文書 RFC 8656 TWCC: Transport Wide Congestion Control UDP: User Datagram Protocol VP8, VP9: Highly-efficient video compression technologies (video \u0026ldquo;codecs\u0026rdquo;) developed by the WebM Project. 誰もが利用可能なロイヤリティフリーのコーデック WebM: An open media file format designed for the web. WebRTC: Web Real-Time Communications. W3C WebRTC 1.0: Real-Time Communication Between Browsers "},{"id":12,"href":"/ja/docs/13-reference/","title":"参考文献","section":"Docs","content":" 参考文献 # WebRTC(W3C) # WebRTC 1.0: Real-Time Communication Between Browsers [26 January 2021] (Status: Recommendation) Web Real-Time Communications Working Group - Publications WebRTC(RFC) # RFC8825: Overview: Real-Time Protocols for Browser-Based Applications H. Alvestrand [January 2021] (Status: PROPOSED STANDARD) RFC8826: Security Considerations for WebRTC E. Rescorla [January 2021] (Status: PROPOSED STANDARD) RFC8836: Congestion Control Requirements for Interactive Real-Time Media R. Jesup, Z. Sarker [January 2021] (Status: INFORMATIONAL) RFC8854: WebRTC Forward Error Correction Requirements J. Uberti [January 2021] (Status: PROPOSED STANDARD) DTLS # RFC6347: Datagram Transport Layer Security Version 1.2 E. Rescorla, N. Modadugu [January 2012] (Obsoletes RFC4347) (Obsoleted-By RFC9147) (Updated-By RFC7507, RFC7905, RFC8996, RFC9146) (Status: PROPOSED STANDARD) RFC9147: The Datagram Transport Layer Security (DTLS) Protocol Version 1.3 E. Rescorla, H. Tschofenig, N. Modadugu [April 2022] (Obsoletes RFC6347) (Status: PROPOSED STANDARD) (See also: OpenSSL DTLS 1.3 status) DataChannel # RFC8831: WebRTC Data Channels R. Jesup, S. Loreto, M. Tüxen [January 2021] (Status: PROPOSED STANDARD) RFC8832: WebRTC Data Channel Establishment Protocol R. Jesup, S. Loreto, M. Tüxen [January 2021] (Status: PROPOSED STANDARD) RFC8864: Negotiation Data Channels Using the Session Description Protocol (SDP) K. Drage, M. Makaraju, R. Ejzak, J. Marcon, R. Even [January 2021] (Status: PROPOSED STANDARD) MediaTransport # RFC8834: Media Transport and Use of RTP in WebRTC C. Perkins, M. Westerlund, J. Ott [January 2021] (Status: PROPOSED STANDARD) RFC8837: Differentiated Services Code Point (DSCP) Packet Markings for WebRTC QoS P. Jones, S. Dhesikan, C. Jennings, D. Druta [January 2021] (Status: PROPOSED STANDARD) SCTP # RFC3758: Stream Control Transmission Protocol (SCTP) Partial Reliability Extension R. Stewart, M. Ramalho, Q. Xie, M. Tuexen, P. Conrad [May 2004] (Status: PROPOSED STANDARD) RFC5061: Stream Control Transmission Protocol (SCTP) Dynamic Address Reconfiguration R. Stewart, Q. Xie, M. Tuexen, S. Maruyama, M. Kozuka [September 2007] (Status: PROPOSED STANDARD) RFC5827: Early Retransmit for TCP and Stream Control Transmission Protocol (SCTP) M. Allman, K. Avrachenkov, U. Ayesta, J. Blanton, P. Hurtig [May 2010] (Status: EXPERIMENTAL) RFC6083: Datagram Transport Layer Security (DTLS) for Stream Control Transmission Protocol (SCTP) M. Tuexen, R. Seggelmann, E. Rescorla [January 2011] (Updated-By RFC8996) (Status: PROPOSED STANDARD) RFC6525: Stream Control Transmission Protocol (SCTP) Stream Reconfiguration R. Stewart, M. Tuexen, P. Lei [February 2012] (Status: PROPOSED STANDARD) RFC6951: UDP Encapsulation of Stream Control Transmission Protocol (SCTP) Packets for End-Host to End-Host Communication M. Tuexen, R. Stewart [May 2013] (Updated-By RFC8899) (Status: PROPOSED STANDARD) RFC7765: TCP and Stream Control Transmission Protocol (SCTP) RTO Restart P. Hurtig, A. Brunstrom, A. Petlund, M. Welzl [February 2016] (Status: EXPERIMENTAL) RFC8260: Stream Schedulers and User Message Interleaving for the Stream Control Transmission Protocol R. Stewart, M. Tuexen, S. Loreto, R. Seggelmann [November 2017] (Status: PROPOSED STANDARD) RFC8261: Datagram Transport Layer Security (DTLS) Encapsulation of SCTP Packets M. Tuexen, R. Stewart, R. Jesup, S. Loreto [November 2017] (Updated-By RFC8899, RFC8996) (Status: PROPOSED STANDARD) RFC8841: Session Description Protocol (SDP) Offer/Answer Procedures for Stream Control Transmission Protocol (SCTP) over Datagram Transport Layer Security (DTLS) Transport C. Holmberg, R. Shpount, S. Loreto, G. Camarillo [January 2021] (Status: PROPOSED STANDARD) RFC8899: Packetization Layer Path MTU Discovery for Datagram Transports G. Fairhurst, T. Jones, M. Tüxen, I. Rüngeler, T. Völker [September 2020] (Updates RFC4821, RFC4960, RFC6951, RFC8085, RFC8261) (Status: PROPOSED STANDARD) RFC9260: Stream Control Transmission Protocol R. Stewart, M. Tüxen, K. Nielsen [June 2022] (Obsoletes RFC4460, RFC4960, RFC6096, RFC7053, RFC8540) (Status: PROPOSED STANDARD) SDP # RFC8829: JavaScript Session Establishment Protocol (JSEP) J. Uberti, C. Jennings, E. Rescorla [January 2021] (Status: PROPOSED STANDARD) RFC8830: WebRTC MediaStream Identification in the Session Description Protocol H. Alvestrand [January 2021] (Status: PROPOSED STANDARD) RFC8839: Session Description Protocol (SDP) Offer/Answer Procedures for Interactive Connectivity Establishment (ICE) M. Petit-Huguenin, S. Nandakumar, C. Holmberg, A. Keränen, R. Shpount [January 2021] (Obsoletes RFC5245, RFC6336) (Status: PROPOSED STANDARD) RFC8841: Session Description Protocol (SDP) Offer/Answer Procedures for Stream Control Transmission Protocol (SCTP) over Datagram Transport Layer Security (DTLS) Transport C. Holmberg, R. Shpount, S. Loreto, G. Camarillo [January 2021] (Status: PROPOSED STANDARD) RFC8843: Negotiating Media Multiplexing Using the Session Description Protocol (SDP) C. Holmberg, H. Alvestrand, C. Jennings [January 2021] (Obsoleted-By RFC9143) (Updates RFC3264, RFC5888, RFC7941) (Status: PROPOSED STANDARD) RFC8844: Unknown Key-Share Attacks on Uses of TLS with the Session Description Protocol (SDP) M. Thomson, E. Rescorla [January 2021] (Updates RFC8122) (Status: PROPOSED STANDARD) RFC8851: RTP Payload Format Restrictions A.B. Roach [January 2021] (Updates RFC4855) (Status: PROPOSED STANDARD) RFC8852: RTP Stream Identifier Source Description (SDES) A.B. Roach, S. Nandakumar, P. Thatcher [January 2021] (Status: PROPOSED STANDARD) RFC8853: Using Simulcast in Session Description Protocol (SDP) and RTP Sessions B. Burman, M. Westerlund, S. Nandakumar, M. Zanaty [January 2021] (Status: PROPOSED STANDARD) RFC8866: SDP: Session Description Protocol A. Begen, P. Kyzivat, C. Perkins, M. Handley [January 2021] (Obsoletes RFC4566) (Status: PROPOSED STANDARD) RTP # RFC3550: RTP: A Transport Protocol for Real-Time Applications H. Schulzrinne, S. Casner, R. Frederick, V. Jacobson [July 2003] (Obsoletes RFC1889) (Updated-By RFC5506, RFC5761, RFC6051, RFC6222, RFC7022, RFC7160, RFC7164, RFC8083, RFC8108, RFC8860) (Also STD0064) (Status: INTERNET STANDARD) RFC3611: RTP Control Protocol Extended Reports (RTCP XR) T. Friedman, R. Caceres, A. Clark [November 2003] (Status: PROPOSED STANDARD) RFC3711: The Secure Real-time Transport Protocol (SRTP) M. Baugher, D. McGrew, M. Naslund, E. Carrara, K. Norrman [March 2004] (Updated-By RFC5506, RFC6904) (Status: PROPOSED STANDARD) RFC4585: Extended RTP Profile for Real-time Transport Control Protocol (RTCP)-Based Feedback (RTP/AVPF) J. Ott, S. Wenger, N. Sato, C. Burmeister, J. Rey [July 2006] (Updated-By RFC5506, RFC8108) (Status: PROPOSED STANDARD) RFC5104: Codec Control Messages in the RTP Audio-Visual Profile with Feedback (AVPF) S. Wenger, U. Chandra, M. Westerlund, B. Burman [February 2008] (Updated-By RFC7728, RFC8082) (Status: PROPOSED STANDARD) RFC5764: Datagram Transport Layer Security (DTLS) Extension to Establish Keys for the Secure Real-time Transport Protocol (SRTP) D. McGrew, E. Rescorla [May 2010] (Updated-By RFC7983) (Status: PROPOSED STANDARD) RFC6904: Encryption of Header Extensions in the Secure Real-time Transport Protocol (SRTP) J. Lennox [April 2013] (Updates RFC3711) (Status: PROPOSED STANDARD) RFC7741: RTP Payload Format for VP8 Video P. Westin, H. Lundin, M. Glover, J. Uberti, F. Galligan [March 2016] (Status: PROPOSED STANDARD) RFC8285: A General Mechanism for RTP Header Extensions D. Singer, H. Desineni, R. Even [October 2017] (Obsoletes RFC5285) (Status: PROPOSED STANDARD) RFC8852: RTP Stream Identifier Source Description (SDES) A.B. Roach, S. Nandakumar, P. Thatcher [January 2021] (Status: PROPOSED STANDARD) RFC8858: Indicating Exclusive Support of RTP and RTP Control Protocol (RTCP) Multiplexing Using the Session Description Protocol (SDP) C. Holmberg [January 2021] (Updates RFC5761) (Status: PROPOSED STANDARD) RFC8860: Sending Multiple Types of Media in a Single RTP Session M. Westerlund, C. Perkins, J. Lennox [January 2021] (Updates RFC3550, RFC3551) (Status: PROPOSED STANDARD) RFC8867: Test Cases for Evaluating Congestion Control for Interactive Real-Time Media Z. Sarker, V. Singh, X. Zhu, M. Ramalho [January 2021] (Status: INFORMATIONAL) RFC8868: Evaluating Congestion Control for Interactive Real-Time Media V. Singh, J. Ott, S. Holmer [January 2021] (Status: INFORMATIONAL) RFC8869: Evaluation Test Cases for Interactive Real-Time Media over Wireless Networks Z. Sarker, X. Zhu, J. Fu [January 2021] (Status: INFORMATIONAL) RFC8872: Guidelines for Using the Multiplexing Features of RTP to Support Multiple Media Streams M. Westerlund, B. Burman, C. Perkins, H. Alvestrand, R. Even [January 2021] (Status: INFORMATIONAL) RFC8888: RTP Control Protocol (RTCP) Feedback for Congestion Control Z. Sarker, C. Perkins, V. Singh, M. Ramalho [January 2021] (Status: PROPOSED STANDARD) ICE, TURN and STUN # RFC5780: NAT Behavior Discovery Using Session Traversal Utilities for NAT (STUN) D. MacDonald, B. Lowekamp [May 2010] (Updated-By RFC8553) (Status: EXPERIMENTAL) RFC8445: Interactive Connectivity Establishment (ICE): A Protocol for Network Address Translator (NAT) Traversal A. Keranen, C. Holmberg, J. Rosenberg [July 2018] (Obsoletes RFC5245) (Updated-By RFC8863) (Status: PROPOSED STANDARD) RFC8489: Session Traversal Utilities for NAT (STUN) M. Petit-Huguenin, G. Salgueiro, J. Rosenberg, D. Wing, R. Mahy, P. Matthews [February 2020] (Obsoletes RFC5389) (Status: PROPOSED STANDARD) RFC8656: Traversal Using Relays around NAT (TURN): Relay Extensions to Session Traversal Utilities for NAT (STUN) T. Reddy, A. Johnston, P. Matthews, J. Rosenberg [February 2020] (Obsoletes RFC5766, RFC6156) (Status: PROPOSED STANDARD) RFC8835: Transports for WebRTC H. Alvestrand [January 2021] (Status: PROPOSED STANDARD) RFC8838: Trickle ICE: Incremental Provisioning of Candidates for the Interactive Connectivity Establishment (ICE) Protocol E. Ivov, J. Uberti, P. Saint-Andre [January 2021] (Updated-By RFC8863) (Status: PROPOSED STANDARD) RFC8839: Session Description Protocol (SDP) Offer/Answer Procedures for Interactive Connectivity Establishment (ICE) M. Petit-Huguenin, S. Nandakumar, C. Holmberg, A. Keränen, R. Shpount [January 2021] (Obsoletes RFC5245, RFC6336) (Status: PROPOSED STANDARD) RFC8863: Interactive Connectivity Establishment Patiently Awaiting Connectivity (ICE PAC) C. Holmberg, J. Uberti [January 2021] (Updates RFC8445, RFC8838) (Status: PROPOSED STANDARD) "}]