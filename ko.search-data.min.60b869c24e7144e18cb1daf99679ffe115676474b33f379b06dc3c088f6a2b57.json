[{"id":0,"href":"/ko/docs/01-what-why-and-how/","title":"무엇, 왜, 어떻게?","section":"Docs","content":" 무엇, 왜, 어떻게? # WebRTC란 무엇인가? # WebRTC(Web Real-Time Communication)는 API이자 프로토콜입니다. WebRTC 프로토콜은 두 WebRTC 에이전트가 실시간 양방향 안전 통신을 협상하기 위한 규칙 집합입니다. WebRTC API는 개발자가 이 WebRTC 프로토콜을 사용할 수 있게 합니다. WebRTC API는 JavaScript를 대상으로 합니다.\nHTTP와 Fetch API의 관계에 비유할 수 있습니다. WebRTC 프로토콜이 HTTP라면, WebRTC API는 Fetch API에 해당합니다.\nWebRTC 프로토콜은 JavaScript 외의 언어로도 구현되어 있습니다. 서버와 도메인 특화 도구들도 존재합니다. 이 모든 구현은 WebRTC 프로토콜을 사용하므로 상호 운용이 가능합니다.\nWebRTC 프로토콜은 IETF(Internet Engineering Task Force)의 rtcweb 작업 그룹에서 관리되며, WebRTC API는 W3C에 문서화되어 있습니다.\n왜 WebRTC를 배워야 하나요? # WebRTC는 다음과 같은 이점을 제공합니다.\n개방형 표준 다중 구현체 웹 브라우저 지원 의무적 암호화 NAT 우회 기존 기술 재사용 혼잡 제어 1초 미만 지연 이 목록은 전부가 아니라 예시에 불과합니다. 아직 익숙하지 않은 용어가 있더라도 걱정하지 마세요. 이 책을 읽는 동안 자연스럽게 의미를 배우게 됩니다.\nWebRTC 프로토콜은 여러 기술의 집합 # WebRTC 프로토콜은 방대하여 책 한 권이 필요할 주제입니다. 시작을 위해 네 단계로 나누어 보겠습니다.\n시그널링(Signaling) 연결(Connecting) 보안(Securing) 통신(Communication) 이 단계들은 순차적입니다. 앞 단계를 충분히 이해해야 다음 단계로 넘어갈 수 있습니다.\nWebRTC의 흥미로운 점은 각 단계가 다시 많은 프로토콜로 이루어져 있다는 것입니다! WebRTC는 이미 존재하는 다양한 기술을 조합해 만듭니다. 즉, WebRTC는 완전히 새로운 발명이라기보다 2000년대 초반부터 잘 이해된 기술들의 조합과 구성으로 볼 수 있습니다.\n각 단계는 별도 장에서 자세히 다루지만, 먼저 높은 수준에서 개념을 잡아두면 도움이 됩니다. 단계들이 서로 의존하므로, 각 단계의 목적을 염두에 두면 세부 설명을 이해하기 쉬워집니다.\n시그널링: WebRTC에서 단말들은 어떻게 서로를 찾을까? # WebRTC 에이전트는 시작 시점에 누구와 무엇을 통신할지 알지 못합니다. 바로 이 문제를 시그널링이 해결합니다! 시그널링은 두 독립적인 WebRTC 에이전트가 통신을 시작할 수 있도록 호출을 개시합니다.\n시그널링에는 SDP(Session Description Protocol)라는 평문 텍스트 프로토콜을 사용합니다. 각 SDP 메시지는 키-값으로 이뤄지며, 여러 개의 “미디어 섹션”을 포함합니다. 두 WebRTC 에이전트가 교환하는 SDP에는 다음과 같은 정보가 들어갑니다.\n에이전트가 접근 가능한 IP와 포트(ICE 후보) 전송하려는 오디오/비디오 트랙의 개수 각 에이전트가 지원하는 오디오/비디오 코덱 연결 과정에서 사용하는 값들(uFrag/uPwd) 보안 설정에 사용하는 값(인증서 지문) 중요한 점은, 시그널링은 대개 “대역 외(out-of-band)”로 이뤄진다는 것입니다. 즉, 애플리케이션은 보통 WebRTC 자체가 아닌 적절한 메시징 수단을 사용해 시그널링 메시지를 교환합니다. SDPs를 주고받기 위해 적합한 어떤 아키텍처도 사용할 수 있으며 많은 애플리케이션은 기존 인프라(예: REST API, WebSocket 연결, 인증 프록시 서버 등)를 그대로 활용합니다.\n연결과 NAT 우회: STUN/TURN # 두 WebRTC 에이전트가 SDP를 교환하면 서로 연결을 시도할 수 있을 만큼의 정보를 갖추게 됩니다. 이를 위해 WebRTC는 ICE(Interactive Connectivity Establishment)라는 확립된 기술을 사용합니다.\nICE는 WebRTC보다 오래된 프로토콜로, 중앙 서버 없이 두 에이전트 간 직접 연결을 수립할 수 있게 해 줍니다. 두 에이전트는 같은 네트워크에 있을 수도, 지구 반대편에 있을 수도 있습니다.\nICE는 직접 연결을 가능하게 하지만, 진정한 마법은 ‘NAT 우회’와 STUN/TURN 서버의 사용에 있습니다. 이 두 개념은 다른 서브넷에 있는 ICE 에이전트와 통신하기 위해 필요한 모든 것입니다. 자세한 내용은 뒤에서 다룹니다.\n연결이 성립되면 두 에이전트는 미디어와 데이터 전송을 위한 기반을 얻게 됩니다. 이 과정 전반은 연결성 검사, 후보 수집과 우선순위화, 그리고 최종 후보 쌍 선정 등으로 구성됩니다.\n보안: 어떻게 안전하게 만들까? # 연결이 수립된 뒤에는 보안이 중요합니다. WebRTC는 DTLS를 통해 키 교환과 상호 인증을 수행하고, SRTP로 미디어를 암호화합니다. 데이터 채널은 DTLS 위의 SCTP를 통해 보호됩니다. 이렇게 해서 전송 중 콘텐츠가 도청되거나 변조되는 것을 방지합니다.\n통신: 무엇을 어떻게 주고받을까? # 보안 채널이 준비되면 실제 통신이 시작됩니다. 미디어는 RTP/SRTP로, 데이터는 SCTP(DataChannel)로 전송됩니다. 코덱, 전송률 제어, 패킷 손실 대응, 지터 버퍼 등 실시간 전송 품질을 좌우하는 요소들이 여기에 포함됩니다.\nWebRTC API는 어떻게 동작하나? # 이 절은 앞서 설명한 WebRTC 프로토콜이 JavaScript API와 어떻게 대응되는지 설명합니다. API의 모든 기능을 다루는 광범위한 데모가 아니라, 전체를 묶어 이해할 수 있는 사고 모델을 제시합니다. 프로토콜이나 API가 익숙하지 않다면 걱정하지 마세요. 더 배우고 돌아와도 좋습니다!\nnew RTCPeerConnection # RTCPeerConnection은 최상위 수준의 ‘WebRTC 세션’입니다. 앞서 언급한 모든 하위 시스템을 포함하지만, 아직 이 시점에는 구체적인 동작이 일어나지 않습니다.\naddTrack # addTrack은 새로운 RTP 스트림을 만듭니다. 이 스트림에는 무작위 동기화 소스(SSRC)가 할당됩니다. 이 스트림은 createOffer가 생성하는 세션 설명의 미디어 섹션에 포함됩니다. addTrack을 호출할 때마다 새 미디어 섹션과 SSRC가 추가됩니다.\nSRTP 세션이 성립되는 즉시, 이 미디어 패킷들은 SRTP로 암호화되어 ICE를 통해 전송됩니다.\ncreateDataChannel # createDataChannel은 기존에 SCTP 연결이 없다면 새로운 SCTP 연결을 만듭니다. SCTP는 기본적으로 활성화되어 있지 않으며, 한쪽에서 데이터 채널을 요청할 때 시작됩니다.\nDTLS 세션이 수립되면, SCTP 연결은 DTLS로 암호화된 패킷을 ICE를 통해 전송하기 시작합니다.\ncreateOffer # createOffer는 원격 단말과 공유할 로컬 상태의 세션 설명을 생성합니다.\ncreateOffer 자체는 로컬 단말의 상태를 바꾸지 않습니다.\nsetLocalDescription # setLocalDescription은 요청된 변경을 확정합니다. addTrack, createDataChannel 등은 이 호출 전까지는 일시적인 상태이며, 보통 createOffer가 만든 값을 setLocalDescription에 전달합니다.\n대개 이 다음 단계로, 생성된 오퍼를 원격 단말에 전송하고, 원격 단말은 이를 받아 setRemoteDescription을 호출합니다.\nsetRemoteDescription # setRemoteDescription은 원격 후보의 상태를 로컬 에이전트에 알립니다. JavaScript API 관점에서 시그널링을 수행하는 단계입니다.\n양쪽에서 setRemoteDescription 호출이 끝나면, 이제 WebRTC 에이전트들은 P2P 통신을 시작하기에 충분한 정보를 갖춘 것입니다!\naddIceCandidate # addIceCandidate는 언제든지 원격 ICE 후보를 추가할 수 있게 합니다. 이 API는 후보를 ICE 하위 시스템에 직접 전달하며, 그 외 WebRTC 연결 전반에는 영향을 주지 않습니다.\nontrack # ontrack은 원격 단말에서 RTP 패킷을 수신했을 때 발생합니다. 들어오는 패킷은 setRemoteDescription에 전달된 세션 설명에 기재되어 있습니다.\nWebRTC는 SSRC를 바탕으로 연결된 MediaStream과 MediaStreamTrack을 찾아, 이 정보를 담아 콜백을 호출합니다.\noniceconnectionstatechange # oniceconnectionstatechange는 ICE 에이전트의 상태 변화가 있을 때 반영됩니다. 네트워크 연결성에 변화가 생기면 이를 통해 알림을 받습니다.\nonconnectionstatechange # onconnectionstatechange는 ICE와 DTLS 상태를 조합해 보여줍니다. ICE와 DTLS가 성공적으로 완료되었을 때 등을 확인할 수 있습니다.\n"},{"id":1,"href":"/ko/docs/02-signaling/","title":"시그널링","section":"Docs","content":" 시그널링 # WebRTC 시그널링이란? # WebRTC 에이전트를 생성했을 때, 상대 피어에 대해 아는 것은 없습니다. 누구와 연결할지, 무엇을 보낼지 전혀 모릅니다! 시그널링은 통화를 가능하게 만드는 초기 부트스트랩 단계입니다. 이 값들을 교환한 뒤에는 WebRTC 에이전트끼리 직접 통신할 수 있습니다.\n시그널링 메시지는 단지 텍스트일 뿐입니다. WebRTC 에이전트는 어떤 전송 수단을 쓰는지 신경 쓰지 않습니다. 보통 WebSocket으로 주고받지만, 필수는 아닙니다.\nWebRTC 시그널링은 어떻게 동작하나? # WebRTC는 Session Description Protocol(SDP)이라는 기존 프로토콜을 사용합니다. 이 프로토콜을 통해 두 WebRTC 에이전트는 연결 수립에 필요한 모든 상태를 공유합니다. 프로토콜 자체는 읽고 이해하기 쉽습니다. 복잡함은 WebRTC가 채워 넣는 값들을 이해하는 데서 옵니다.\n이 프로토콜은 WebRTC 전용이 아닙니다. 먼저 WebRTC와 무관하게 SDP를 학습합니다. WebRTC는 이 프로토콜의 일부만 사용하므로 필요한 부분만 다룹니다. 프로토콜을 이해한 다음, WebRTC에서의 실제 사용 방법을 살펴보겠습니다.\nSession Description Protocol(SDP)이란? # SDP는 RFC 8866에 정의되어 있습니다. 각 줄이 키/값 형태이며, 값 뒤에 개행이 옵니다. INI 파일과 비슷한 느낌입니다. 세션 설명(Session Description)은 0개 이상의 미디어 설명(Media Description)을 포함합니다. 즉, 세션 설명은 미디어 설명의 배열로 모델링할 수 있습니다.\n하나의 미디어 설명은 보통 하나의 미디어 스트림에 대응합니다. 예를 들어 비디오 3개와 오디오 2개로 이루어진 통화를 설명하려면 5개의 미디어 설명이 필요합니다.\nSDP 읽는 법 # 세션 설명의 모든 줄은 한 글자의 키로 시작합니다. 그 뒤에 등호가 오며, 등호 뒤가 값입니다. 값이 끝나면 개행으로 마무리합니다.\nSDP는 사용할 수 있는 키를 정의합니다. 키는 알파벳 문자만 사용할 수 있으며 각 키는 중요한 의미를 갖습니다(뒤에서 설명).\n다음은 SDP 일부 예시입니다.\na=my-sdp-value a=second-value 두 줄이 있으며, 둘 다 키는 a입니다. 첫 줄의 값은 my-sdp-value, 둘째 줄의 값은 second-value입니다.\nWebRTC가 사용하는 SDP 키 # SDP에 정의된 모든 키를 WebRTC가 사용하는 것은 아닙니다. RFC 8829에 정의된 JSEP(JavaScript Session Establishment Protocol)에서 사용하는 키만 중요합니다. 지금 이해해야 할 핵심 키는 다음 일곱 가지입니다.\nv - 버전, 항상 0이어야 합니다. o - 오리진, 재협상 시 유용한 고유 ID를 담습니다. s - 세션 이름, - 여야 합니다. t - 타이밍, 0 0 여야 합니다. m - 미디어 설명(m=\u0026lt;media\u0026gt; \u0026lt;port\u0026gt; \u0026lt;proto\u0026gt; \u0026lt;fmt\u0026gt; ...), 아래에서 자세히 설명합니다. a - 속성(Attribute), 자유 텍스트 필드. WebRTC에서 가장 흔한 줄입니다. c - 연결 정보, IN IP4 0.0.0.0이어야 합니다. 세션 설명의 미디어 설명 # 하나의 세션 설명은 제한 없이 많은 미디어 설명을 담을 수 있습니다.\n미디어 설명은 여러 포맷 목록을 포함하며, 각 포맷은 RTP Payload Type에 매핑됩니다. 실제 코덱은 미디어 설명 내부의 rtpmap 속성으로 정의합니다. RTP와 Payload Type의 중요성은 미디어 장에서 자세히 다룹니다. 각 미디어 설명에는 제한 없이 많은 속성을 가질 수 있습니다.\n다음 예시를 봅시다.\nv=0 m=audio 4000 RTP/AVP 111 a=rtpmap:111 OPUS/48000/2 m=video 4000 RTP/AVP 96 a=rtpmap:96 VP8/90000 a=my-sdp-value 두 개의 미디어 설명이 있습니다. 오디오 타입의 111 포맷 하나, 비디오 타입의 96 포맷 하나입니다. 첫 번째 미디어 설명에는 하나의 속성이 있으며, Payload Type 111을 Opus에 매핑합니다. 두 번째 미디어 설명에는 두 개의 속성이 있으며, 첫 번째는 96을 VP8에 매핑하고 두 번째는 단순 속성 my-sdp-value입니다.\n전체 예시 # 앞서 설명한 개념을 모두 합친 예시입니다. WebRTC가 사용하는 SDP의 모든 요소가 들어 있습니다. 이 예시를 읽을 수 있다면 어떤 WebRTC SDP든 읽을 수 있습니다!\nv=0 o=- 0 0 IN IP4 127.0.0.1 s=- c=IN IP4 127.0.0.1 t=0 0 m=audio 4000 RTP/AVP 111 a=rtpmap:111 OPUS/48000/2 m=video 4002 RTP/AVP 96 a=rtpmap:96 VP8/90000 v, o, s, c, t는 정의되지만 WebRTC 세션 자체에는 영향을 주지 않습니다. audio와 video 두 개의 미디어 설명이 있습니다. 각 미디어 설명에는 하나의 속성이 있으며, 이는 RTP 파이프라인의 세부를 구성합니다(“미디어 통신” 장에서 설명). SDP와 WebRTC의 결합 방식 # 다음으로 WebRTC가 SDP를 ‘어떻게’ 사용하는지 이해해야 합니다.\n오퍼와 앤서 # WebRTC는 Offer/Answer 모델을 사용합니다. 한쪽 WebRTC 에이전트가 통화를 시작하겠다는 “오퍼(Offer)”를 제안하고, 상대 에이전트가 이를 수락하면 “앤서(Answer)”를 반환합니다.\n이 과정에서 응답자는 미디어 설명에서 지원하지 않는 코덱을 거부할 수 있습니다. 이렇게 두 피어는 서로 교환 가능한 포맷을 합의합니다.\n트랜시버: 송수신의 단위 # 트랜시버(Transceiver)는 API에서 보게 되는 WebRTC 고유 개념으로, 본질적으로 미디어 설명을 JavaScript API로 노출한 것입니다. 트랜시버를 만들 때마다 로컬 SDP에 새 미디어 설명이 추가됩니다.\nWebRTC의 각 미디어 설명에는 방향 속성이 있습니다. 예를 들어 “나는 이 코덱을 보낼 수 있지만, 받지는 않겠다”와 같이 선언할 수 있습니다. 가능한 값은 다음 네 가지입니다.\nsend recv sendrecv inactive WebRTC가 쓰는 SDP 값들 # 다음은 WebRTC 에이전트의 SDP에서 자주 보게 되는 속성들입니다. 많은 값은 아직 다루지 않은 하위 시스템을 제어합니다.\ngroup:BUNDLE # 번들은 여러 종류의 트래픽을 하나의 연결로 다루는 방식입니다. 일부 구현은 미디어 스트림마다 전용 연결을 사용하지만, 번들을 사용하는 것이 바람직합니다.\nfingerprint:sha-256 # DTLS에 사용하는 인증서의 해시입니다. DTLS 핸드셰이크가 끝나면 실제 인증서와 비교해 예상한 피어와 통신 중인지 확인합니다.\nsetup: # ICE 연결 이후 DTLS 에이전트의 동작(클라이언트/서버 역할)을 제어합니다. 가능한 값은 다음과 같습니다.\nsetup:active - DTLS 클라이언트로 동작 setup:passive - DTLS 서버로 동작 setup:actpass - 상대 에이전트가 선택하도록 요청 mid # 세션 설명 내에서 미디어 스트림을 식별하는 데 사용하는 값입니다.\nice-ufrag # ICE 에이전트의 user fragment 값으로, ICE 트래픽 인증에 사용됩니다.\nice-pwd # ICE 에이전트의 비밀번호로, ICE 트래픽 인증에 사용됩니다.\nrtpmap # 특정 코덱을 RTP Payload Type에 매핑합니다. Payload Type은 고정이 아니므로, 오퍼 측이 통화마다 코덱별 타입을 정합니다.\nfmtp # 특정 Payload Type의 추가 매개변수를 정의합니다. 예를 들어 특정 비디오 프로파일이나 인코더 설정을 전달할 때 유용합니다.\ncandidate # ICE 에이전트가 제공하는 ICE 후보입니다. WebRTC 에이전트가 사용 가능한 하나의 주소를 나타냅니다. 자세한 내용은 다음 장에서 다룹니다.\nssrc # SSRC(Synchronization Source)는 하나의 미디어 스트림 트랙을 정의합니다.\nlabel은 개별 스트림의 ID이고, mslabel은 여러 스트림을 담을 수 있는 컨테이너 ID입니다.\nWebRTC 세션 설명 예시 # 다음은 WebRTC 클라이언트가 생성한 완전한 SDP입니다.\nv=0 o=- 3546004397921447048 1596742744 IN IP4 0.0.0.0 s=- t=0 0 a=fingerprint:sha-256 0F:74:31:25:CB:A2:13:EC:28:6F:6D:2C:61:FF:5D:C2:BC:B9:DB:3D:98:14:8D:1A:BB:EA:33:0C:A4:60:A8:8E a=group:BUNDLE 0 1 m=audio 9 UDP/TLS/RTP/SAVPF 111 c=IN IP4 0.0.0.0 a=setup:active a=mid:0 a=ice-ufrag:CsxzEWmoKpJyscFj a=ice-pwd:mktpbhgREmjEwUFSIJyPINPUhgDqJlSd a=rtcp-mux a=rtcp-rsize a=rtpmap:111 opus/48000/2 a=fmtp:111 minptime=10;useinbandfec=1 a=ssrc:350842737 cname:yvKPspsHcYcwGFTw a=ssrc:350842737 msid:yvKPspsHcYcwGFTw DfQnKjQQuwceLFdV a=ssrc:350842737 msid:yvKPspsHcYcwGFTw DfQnKjQQuwceLFdV a=ssrc:350842737 mslabel:yvKPspsHcYcwGFTw a=ssrc:350842737 label:DfQnKjQQuwceLFdV a=msid:yvKPspsHcYcwGFTw DfQnKjQQuwceLFdV a=sendrecv a=candidate:foundation 1 udp 2130706431 192.168.1.1 53165 typ host generation 0 a=candidate:foundation 2 udp 2130706431 192.168.1.1 53165 typ host generation 0 a=candidate:foundation 1 udp 1694498815 1.2.3.4 57336 typ srflx raddr 0.0.0.0 rport 57336 generation 0 a=candidate:foundation 2 udp 1694498815 1.2.3.4 57336 typ srflx raddr 0.0.0.0 rport 57336 generation 0 a=end-of-candidates m=video 9 UDP/TLS/RTP/SAVPF 96 c=IN IP4 0.0.0.0 a=setup:active a=mid:1 a=ice-ufrag:CsxzEWmoKpJyscFj a=ice-pwd:mktpbhgREmjEwUFSIJyPINPUhgDqJlSd a=rtcp-mux a=rtcp-rsize a=rtpmap:96 VP8/90000 a=ssrc:2180035812 cname:XHbOTNRFnLtesHwJ a=ssrc:2180035812 msid:XHbOTNRFnLtesHwJ JgtwEhBWNEiOnhuW a=ssrc:2180035812 mslabel:XHbOTNRFnLtesHwJ a=ssrc:2180035812 label:JgtwEhBWNEiOnhuW a=msid:XHbOTNRFnLtesHwJ JgtwEhBWNEiOnhuW a=sendrecv 이 메시지로부터 알 수 있는 점은 다음과 같습니다.\n오디오와 비디오, 두 개의 미디어 섹션이 있습니다. 둘 다 sendrecv 트랜시버입니다. 두 스트림을 받고, 두 스트림을 보낼 수 있습니다. ICE 후보와 인증 세부 정보가 있어 연결을 시도할 수 있습니다. 인증서 지문이 있어 안전한 통화를 설정할 수 있습니다. 추가 주제 # 이후 버전에서 다음 주제도 다룰 예정입니다.\n재협상(Renegotiation) 시뮬캐스트(Simulcast) "},{"id":2,"href":"/ko/docs/03-connecting/","title":"연결","section":"Docs","content":" 연결 # 왜 WebRTC에는 전용 ‘연결’ 하위 시스템이 필요한가요? # 대부분의 애플리케이션은 클라이언트/서버 연결을 사용합니다. 이 모델에서는 서버가 안정적인 전송 주소(IP/포트)를 가져야 하며, 클라이언트가 서버에 요청하면 서버가 응답합니다.\nWebRTC는 클라이언트/서버 모델이 아니라 P2P(Peer-to-Peer) 연결을 수립합니다. P2P에서는 연결 수립의 책임이 양쪽 피어에 균등하게 분산됩니다. 이는 WebRTC에서의 전송 주소(IP/포트)를 미리 가정할 수 없고, 심지어 세션 중에도 바뀔 수 있기 때문입니다. WebRTC는 가능한 모든 정보를 수집해 두 WebRTC 에이전트 간 양방향 통신을 성사시키기 위해 많은 과정을 수행합니다.\n그러나 P2P 연결을 수립하는 일은 쉽지 않습니다. 서로 다른 네트워크에 있어서 직접 연결이 불가능할 수 있습니다. 직접 연결이 가능한 상황에서도 문제가 생길 수 있습니다. 어떤 경우에는 두 클라이언트가 같은 네트워크 프로토콜(UDP \u0026lt;-\u0026gt; TCP)을 쓰지 않거나, 서로 다른 IP 버전(IPv4 \u0026lt;-\u0026gt; IPv6)을 사용할 수 있습니다.\n이러한 어려움에도 불구하고, WebRTC가 제공하는 특성 덕분에 전통적인 클라이언트/서버 기술 대비 다음과 같은 장점을 얻게 됩니다.\n대역폭 비용 절감 # 미디어가 피어 간에 직접 전달되므로, 미디어를 중계하는 별도 서버를 운영하거나 비용을 지불할 필요가 없습니다.\n더 낮은 지연 # 직접 통신이 더 빠릅니다! 모든 트래픽을 서버를 경유해 보내야 하면 전송이 느려집니다.\n안전한 종단 간(E2E) 통신 # 직접 통신은 더 안전합니다. 데이터가 서버를 경유하지 않으므로, 심지어 서버 운영자를 신뢰할 필요도 줄어듭니다.\n어떻게 동작하나요? # 위 과정을 표준화한 것이 ICE(Interactive Connectivity Establishment, RFC 8445)입니다. WebRTC 이전부터 존재하던 프로토콜입니다.\nICE는 두 ICE 에이전트가 통신하기에 최적의 경로를 찾는 프로토콜입니다. 각 ICE 에이전트는 자신에 도달 가능한 방법들을 공개하는데, 이를 후보(candidate)라 부릅니다. 후보는 다른 피어가 접근할 수 있다고 예상하는 전송 주소입니다. ICE는 이 후보들 중 최적의 쌍을 선택합니다.\n구체적인 ICE 동작은 이 장 후반에서 다룹니다. 먼저 ICE가 왜 필요한지, 극복해야 하는 네트워크 행태를 이해하는 것이 도움이 됩니다.\n실제 네트워크의 제약 # ICE는 현실 세계 네트워크의 제약을 극복하는 데 초점을 둡니다. 해결책을 보기 전에 문제를 먼저 짚어봅시다.\n같은 네트워크가 아님 # 대부분의 경우 상대 WebRTC 에이전트는 같은 네트워크에 있지 않습니다. 일반적인 통화는 서로 다른 네트워크에 있는 두 에이전트 간에 이뤄지며, 직접 연결이 없습니다.\n아래는 공용 인터넷으로 연결된 두 개의 서로 다른 네트워크를 보여줍니다. 각 네트워크에는 두 개의 호스트가 있습니다.\n같은 네트워크 내 호스트끼리는 연결이 쉽습니다. 192.168.0.1 -\u0026gt; 192.168.0.2 간 통신은 어렵지 않습니다! 외부 도움 없이도 가능합니다.\n하지만 Router B 뒤의 호스트는 Router A 뒤의 대상에 직접 접근할 방법이 없습니다. Router A 뒤의 192.168.0.1과 Router B 뒤의 동일한 IP를 어떻게 구분할까요? 둘 다 사설 IP이기 때문입니다! Router B의 호스트가 Router A로 트래픽을 보낼 수는 있지만, 요청은 라우터에서 끝납니다. Router A는 어떤 호스트로 전달해야 할지 알 수 없습니다.\n프로토콜 제한 # 어떤 네트워크는 UDP를 전혀 허용하지 않거나, TCP를 허용하지 않을 수 있습니다. MTU(최대 전송 단위)가 매우 낮을 수도 있습니다. 네트워크 관리자가 바꿀 수 있는 변수가 많아 통신을 어렵게 만들 수 있습니다.\n방화벽/IDS 규칙 # 깊은 패킷 검사(DPI) 등 지능형 필터링을 수행하는 경우도 있습니다. 일부 관리자는 모든 패킷을 해석하려는 소프트웨어를 사용합니다. 이 소프트웨어가 WebRTC를 이해하지 못하면, 화이트리스트에 없는 임의 포트의 UDP 패킷처럼 보인다는 이유로 차단할 수 있습니다.\nNAT 매핑 # NAT(Network Address Translation) 매핑은 WebRTC 연결을 가능케 하는 핵심 요소입니다. 이는 앞서 언급한 “같은 네트워크가 아님” 문제를 해결하여, 완전히 다른 서브넷의 두 피어가 통신하도록 합니다. 새로운 과제를 만들기도 하지만, 먼저 NAT 매핑이 어떻게 동작하는지 살펴봅시다.\n릴레이나 프록시, 서버를 사용하지 않습니다. Agent 1과 Agent 2가 서로 다른 네트워크에 있지만, 트래픽은 완전히 통과합니다. 시각화하면 다음과 같습니다.\n이 통신을 가능하게 하려면 NAT 매핑을 수립합니다. Agent 1이 포트 7000을 사용해 Agent 2와 WebRTC 연결을 수립하면, 192.168.0.1:7000 ↔ 5.0.0.1:7000 바인딩이 생성됩니다. 이렇게 되면 Agent 2는 이 매핑으로 Agent 1에 트래픽을 보낼 수 있습니다. NAT의 동작은 매핑 정책에 따라 달라질 수 있으며, 주소/포트 의존적일 수도 있습니다. 이로 인해 직접 통신이 항상 가능한 것은 아니며, 이후에 설명할 TURN이 필요할 수 있습니다.\nSTUN # STUN(Session Traversal Utilities for NAT, RFC 8489)은 NAT 매핑을 알아내는 표준 프로토콜입니다. STUN 패킷은 고정 크기 헤더와 속성 목록으로 구성되며, 핵심 메시지 타입은 다음과 같습니다.\nBinding Request - 0x0001 Binding Response - 0x0101 Binding Request를 STUN 서버로 보내면, 응답으로 Binding Response를 받습니다. 이 응답에 포함된 XOR-MAPPED-ADDRESS(0x0020) 속성이 바로 생성된 NAT 매핑의 공인 IP/포트입니다. 이를 ‘Server Reflexive 후보’라고도 부릅니다.\nNAT 유형 판별 # 안타깝게도 매핑이 항상 유용한 것은 아닙니다. 매핑이 주소 의존적(Address Dependent)인 경우, STUN 서버만 응답을 보낼 수 있고 다른 피어의 트래픽은 드롭될 수 있습니다. 이 경우 직접 통신에는 쓸모가 없습니다. RFC 5780은 NAT 유형을 판별하는 시험 방법을 정의합니다. 미리 직접 연결 가능성을 판단하는 데 유용합니다. 직접이 어렵다면 아래의 TURN을 사용합니다.\nTURN # TURN(Traversal Using Relays around NAT, RFC 8656)은 직접 연결이 불가능할 때의 해결책입니다. 서로 호환되지 않는 NAT 유형이거나, 동일한 프로토콜을 사용할 수 없는 경우에도 사용할 수 있습니다. 프라이버시를 위해서도 TURN을 쓸 수 있습니다. 모든 통신을 TURN을 통해 보내면 클라이언트의 실제 주소를 숨길 수 있습니다.\nTURN은 전용 서버를 사용합니다. 클라이언트는 TURN 서버에 연결해 ‘할당(Allocation)’을 생성합니다. 그러면 임시 IP/포트/프로토콜인 RELAYED-ADDRESS를 부여받고, 여기에 들어오는 트래픽은 클라이언트로 포워딩됩니다. 각 원격 피어에 대해 통신을 허용하려면 ‘Permission’을 생성해야 합니다.\nTURN 수명주기 # TURN 할당을 만들려면 다음을 수행합니다.\n사용자 이름/비밀번호: TURN 할당에는 인증이 필요합니다. 할당 전송 방식: 릴레이와 피어 간 전송 프로토콜(UDP 또는 TCP) Even-Port: 연속 포트를 요청(일반 WebRTC에는 크게 중요하지 않음) 성공 시 응답의 속성에는 다음이 포함됩니다.\nXOR-MAPPED-ADDRESS: TURN 클라이언트의 매핑 주소. 릴레이 주소로 들어온 트래픽의 포워딩 대상 RELAYED-ADDRESS: 다른 클라이언트에게 제공할 주소(이 주소로 오면 클라이언트로 릴레이) LIFETIME: 할당 만료 시간. Refresh 요청으로 연장 가능 ICE # ICE(Interactive Connectivity Establishment)는 WebRTC가 두 에이전트를 연결하는 방법입니다(RFC 8445). 두 피어 사이의 가능한 모든 경로를 파악하고, 연결 유지까지 책임지는 프로토콜입니다. 후보쌍(candidate pair)은 로컬/원격 전송 주소의 쌍이며, 여기서 STUN과 TURN이 사용됩니다. 각 측은 사용할 주소들을 수집해 교환하고, 연결을 시도합니다.\nICE 에이전트 간에는 연결성 검사(connectivity checks)라 불리는 ICE 핑(STUN 기반)을 주고받아 연결을 수립합니다. 연결이 성립하면 일반 소켓처럼 임의의 데이터를 보낼 수 있습니다.\nICE 에이전트 생성 # ICE 에이전트는 Controlling 또는 Controlled 역할 중 하나입니다. Controlling 에이전트가 최종 선택된 후보쌍을 결정합니다. 일반적으로 오퍼를 보내는 쪽이 Controlling입니다.\n양쪽 모두 user fragment와 password를 가져야 하며, 연결성 검사를 시작하기 전에 교환되어야 합니다. user fragment는 평문으로 전송되어 여러 ICE 세션을 디멕스하는 데 유용합니다. password는 MESSAGE-INTEGRITY 계산에 사용됩니다. 각 STUN 패킷 끝에는 패킷 전체의 해시가 포함되며, 키로 password를 사용합니다. 이는 패킷 인증과 변조 방지에 쓰입니다. WebRTC에서는 이 값들을 앞 장에서 설명한 세션 설명을 통해 교환합니다.\n후보 수집 # 이제 도달 가능한 모든 주소(후보)를 수집합니다.\nHost # 로컬 인터페이스에서 직접 수신하는 후보입니다(UDP 또는 TCP).\nmDNS # Host 후보와 유사하지만 IP를 가리지 않고 UUID 호스트명을 제공합니다. 멀티캐스트 리스너를 띄우고, 공개한 UUID 질의에 응답합니다. 같은 네트워크면 멀티캐스트로 서로를 찾을 수 있지만, 네트워크가 다르면 일반적으로 연결되지 않습니다(관리자가 멀티캐스트 트래버설을 허용하지 않는 한). 로컬 IP 노출을 막아 프라이버시를 향상할 수 있습니다.\nServer Reflexive # STUN Binding Request/Response를 통해 얻은 XOR-MAPPED-ADDRESS로 생성되는 후보입니다.\nPeer Reflexive # 알려지지 않은 주소에서 유효한(인증된) 트래픽을 받은 경우 생성되는 후보입니다. 예컨대 Host 후보 ↔ Server Reflexive 후보 간 통신에서 서브넷 외부와 통신하며 새 NAT 매핑이 생기는 경우가 이에 해당합니다. STUN 응답 형식은 피어 반사 주소를 자연스럽게 보고할 수 있습니다.\nRelay # TURN 서버에서 핸드셰이크 후 부여되는 RELAYED-ADDRESS로 생성되는 후보입니다.\n연결성 검사 # 이제 원격 에이전트의 user fragment, password, 후보를 모두 알게 되었으니 연결을 시도합니다! 모든 후보는 서로 페어링됩니다. 각 측에 후보가 3개라면 9개의 후보쌍이 만들어집니다.\n시각화하면 다음과 같습니다.\n후보 선택 # Controlling/Controlled 에이전트는 모든 후보쌍에 트래픽을 시도합니다. 한 에이전트가 주소 의존 매핑 뒤에 있는 경우, 이 과정에서 Peer Reflexive 후보가 생길 수 있기 때문입니다.\n트래픽이 오간 후보쌍은 Valid Candidate로 승격됩니다. Controlling 에이전트는 Valid 후보쌍 중 하나를 지명(nominate)하고, 이 쌍을 대상으로 양방향 통신을 한 번 더 시도합니다. 성공하면 Selected Candidate Pair가 되며, 세션 내내 이 쌍이 사용됩니다.\n재시작 # 선택된 후보쌍이 어떤 이유로든 동작을 멈추면(NAT 매핑 만료, TURN 장애 등) ICE 에이전트는 Failed 상태로 전이합니다. 양측 모두 재시작하여 전체 과정을 다시 수행할 수 있습니다.\n"},{"id":3,"href":"/ko/docs/04-securing/","title":"보안","section":"Docs","content":" 보안 # WebRTC는 어떤 보안을 제공하나요? # 모든 WebRTC 연결은 인증되고 암호화됩니다. 제3자가 당신이 보내는 내용을 엿보거나 가짜 메시지를 삽입할 수 없습니다. 또한 세션 설명(Session Description)을 생성한 바로 그 WebRTC 에이전트와 통신하고 있음을 보장할 수 있습니다.\n이 메시지들이 변조되지 않는 것이 매우 중요합니다. 전송 중 세션 설명을 제3자가 읽는 것은 괜찮지만, WebRTC는 그 내용이 수정되는 것에 대해 자체 보호 장치가 없습니다. 공격자는 ICE 후보를 바꾸고 인증서 지문을 바꿔 중간자 공격을 시도할 수 있습니다.\n어떻게 동작하나요? # WebRTC는 두 가지 기성 프로토콜을 사용합니다. Datagram Transport Layer Security(DTLS)와 Secure Real-time Transport Protocol(SRTP)입니다.\nDTLS는 두 피어 간에 세션을 협상하고 데이터를 안전하게 교환할 수 있게 합니다. HTTPS에 쓰이는 TLS의 형제 격 기술이지만, DTLS는 전송 계층으로 TCP 대신 UDP를 사용하므로 비신뢰성 전달을 자체적으로 처리해야 합니다. SRTP는 미디어를 안전하게 교환하도록 특화된 프로토콜로, DTLS 대신 사용할 때 가능한 최적화가 있습니다.\nDTLS가 먼저 사용됩니다. ICE로 마련된 연결 위에서 핸드셰이크를 수행합니다. DTLS는 클라이언트/서버 프로토콜이므로 한쪽이 핸드셰이크를 시작해야 합니다. 이 역할은 시그널링 단계에서 결정됩니다. DTLS 핸드셰이크 중 양쪽은 인증서를 제시합니다. 핸드셰이크가 끝나면 이 인증서를 세션 설명에 있는 인증서 해시와 비교합니다. 기대한 WebRTC 에이전트와 핸드셰이크가 이루어졌는지 확인하기 위함입니다. 이후 이 DTLS 연결은 DataChannel 통신에 사용됩니다.\nSRTP 세션을 만들 때는 DTLS가 생성한 키로 초기화합니다. SRTP는 핸드셰이크 메커니즘이 없으므로 외부 키로 부트스트랩해야 합니다. 준비가 끝나면 SRTP로 암호화된 미디어 교환이 시작됩니다!\n보안 101 # 이 장의 기술을 이해하려면 먼저 다음 용어를 알아야 합니다. 암호학은 까다로운 주제이므로 다른 자료도 함께 참고하길 권합니다.\n평문과 암호문 # 평문(plaintext)은 암호화기의 입력, 암호문(ciphertext)은 출력입니다.\n암호(Cipher) # 암호는 평문을 암호문으로 변환하는 절차입니다. 이 절차는 역으로 적용 가능하여 암호문을 평문으로 되돌릴 수 있습니다. 대부분의 암호는 동작을 바꾸는 ‘키’를 사용합니다. 흔히 말하는 암호화/복호화입니다.\n간단한 예로 ROT13이 있습니다. 각 문자를 13글자씩 밀어내는 방식입니다. 되돌릴 때는 13글자 뒤로 이동합니다. 평문 HELLO는 암호문 URYYB가 됩니다. 이 경우 암호는 ROT, 키는 13입니다.\n해시 함수 # 해시 함수는 일방향으로 동작하여 다이제스트를 생성합니다. 같은 입력에 대해 항상 같은 출력이 나오며, 출력으로부터 입력을 역으로 알아낼 수 없어야 합니다. 해시는 메시지가 변조되지 않았음을 확인할 때 유용합니다.\n아주 단순한 해시 예로 ‘한 글자 건너뛰기’를 생각해볼 수 있습니다. HELLO → HLO. 이 값만으로 입력이 HELLO였다고 단정할 수는 없지만, HELLO가 이 해시와 일치하는지는 확인할 수 있습니다.\n공개키/개인키 암호 # DTLS와 SRTP가 사용하는 암호 방식입니다. 공개키와 개인키 두 개의 키를 사용합니다. 공개키는 메시지 암호화에 쓰이며 공유해도 안전합니다. 개인키는 복호화에 사용하며 절대 공유하면 안 됩니다. 공개키로 암호화된 메시지는 개인키로만 복호화할 수 있습니다.\n디피-헬먼 교환 # 디피-헬먼 교환은 서로 처음 만난 두 사용자가 인터넷을 통해 안전하게 공유 비밀을 만드는 방법입니다. 이는 이산 로그 문제의 난이도에 기댑니다. 이 메커니즘이 DTLS 핸드셰이크를 가능하게 한다는 점만 알아두면 충분합니다.\n자세한 설명은 위키피디아를 참고하세요.\n의사난수 함수(PRF) # 의사난수 함수는 겉보기엔 무작위처럼 보이는 값을 생성하는 정해진 함수로, 여러 입력을 받아 단일 출력을 만듭니다.\n키 유도 함수(KDF) # 키 유도는 PRF의 한 형태입니다. 더 강한 키를 만들기 위해 사용하는 함수로, 대표적으로 키 스트레칭이 있습니다.\n예를 들어 8바이트 길이의 키를 더 강하게 만들고 싶을 때 KDF를 사용할 수 있습니다.\n논스(Nonce) # 논스는 암호에 추가로 제공하는 입력입니다. 같은 메시지를 여러 번 암호화하더라도 서로 다른 출력을 얻게 해 줍니다.\n같은 메시지를 10번 암호화해도, 논스를 다르게 주면 각기 다른 암호문이 생성됩니다. 이는 패턴 식별이나 재전송 공격을 어렵게 합니다.\nDTLS # DTLS는 TLS와 유사하지만 UDP 위에서 동작합니다. WebRTC에서는 ICE가 만들어 준 연결 위에서 DTLS 핸드셰이크가 진행됩니다. 핸드셰이크를 위해 여러 메시지가 오가며, 성공하면 애플리케이션 데이터 교환이 시작됩니다.\n핸드셰이크 절차 # DTLS 핸드셰이크는 다음과 같은 메시지로 구성됩니다(주요 항목만 요약).\nHelloVerifyRequest # 서버가 클라이언트의 출처를 확인하기 위한 응답으로, 재전송 공격 방지에 도움이 됩니다.\nClientHello / ServerHello # 지원하는 프로토콜 버전과 암호군 목록, 랜덤 값 등을 교환합니다. 서버는 선택된 암호군을 통지합니다.\nCertificate # 상대에게 자신의 공개키 인증서를 보냅니다.\nServerKeyExchange / ClientKeyExchange # 공개키 교환에 사용됩니다. 핸드셰이크 이후 두 값으로 Pre-Master Secret을 생성합니다.\nCertificateRequest # 서버가 클라이언트에게 인증서를 요구할 때 전송합니다(요청 또는 필수).\nServerHelloDone # 서버 측 핸드셰이크 단계가 끝났음을 알립니다.\nCertificateVerify # 인증서에 대응하는 개인키를 소유하고 있음을 증명합니다.\nChangeCipherSpec # 이 메시지 이후로는 암호화가 적용됨을 알립니다.\nFinished # 암호화된 상태로 전송되며, 지금까지의 모든 메시지 해시를 포함합니다. 핸드셰이크 변조 여부를 검증합니다.\n키 생성 # 핸드셰이크가 끝나면 암호화된 데이터 전송을 시작할 수 있습니다. 구체적인 암호군은 ServerHello에서 결정됩니다.\n먼저 Pre-Master Secret을 생성합니다. ServerKeyExchange와 ClientKeyExchange에서 교환한 키로 디피-헬먼 과정을 수행해 얻습니다.\n다음으로 Master Secret을 생성합니다. DTLS 버전마다 정의된 의사난수 함수가 있으며, DTLS 1.2에서는 Pre-Master Secret과 ClientHello/ServerHello의 랜덤 값을 입력으로 사용합니다. 이 함수의 출력이 Master Secret이며, 실제 암호에 쓰이는 키가 됩니다.\n애플리케이션 데이터 교환 # DTLS의 주력 메시지는 ApplicationData입니다. 초기화된 암호로 페이로드를 암호화해 송수신하면, 보안 채널이 완성됩니다.\nDTLS에는 재협상 등 흥미로운 기능이 더 있지만, WebRTC에서는 사용하지 않으므로 여기서는 다루지 않습니다.\nSRTP # SRTP는 RTP 패킷 암호화를 위해 설계된 프로토콜입니다. 세션을 시작하려면 키와 암호를 지정해야 합니다. DTLS와 달리 자체 핸드셰이크가 없으므로, 필요한 키와 설정은 DTLS 핸드셰이크 과정에서 생성한 것을 사용합니다. DTLS는 다른 프로세스가 사용할 키를 내보내는 API를 제공하며, RFC 5705에 정의되어 있습니다.\n세션 생성 # SRTP는 입력 값에 키 유도 함수를 적용해 실제로 사용할 키를 생성합니다. 세션 생성이 끝나면 미디어 처리를 시작할 수 있습니다.\n미디어 교환 # 각 RTP 패킷에는 16비트 SequenceNumber가 있습니다. 이는 패킷 순서를 유지하는 데 사용되며, 통화 중에는 값이 순환합니다. SRTP는 이 순환을 추적하며 롤오버 카운터라고 부릅니다. 패킷을 암호화할 때 SRTP는 롤오버 카운터와 시퀀스 번호를 논스로 사용하여, 같은 데이터를 두 번 보내더라도 암호문이 달라지게 합니다. 이는 패턴 식별 및 재전송 공격을 방지하는 데 중요합니다.\n"},{"id":4,"href":"/ko/docs/05-real-time-networking/","title":"실시간 네트워킹","section":"Docs","content":" 실시간 네트워킹 # 왜 실시간 통신에서 네트워킹이 중요한가요? # 네트워크는 실시간 통신의 한계 요소입니다. 이상적으로는 무한 대역폭과 즉시 도착하는 패킷이 있으면 좋겠지만, 현실은 다릅니다. 네트워크는 제한적이며 언제든 조건이 변할 수 있습니다. 네트워크 상태를 측정/관찰하는 일도 어렵습니다. 하드웨어, 소프트웨어, 설정에 따라 행동이 달라질 수 있습니다.\n실시간 통신에는 다른 영역에 없는 문제가 있습니다. 웹사이트가 어떤 네트워크에서 좀 느려도, 데이터만 모두 도착하면 사용자는 괜찮습니다. 하지만 WebRTC에서는 데이터가 늦으면 무용지물입니다. 5초 전에 회의에서 한 말을 지금 받는 건 의미가 없습니다. 따라서 실시간 시스템을 만들 때는 타협이 필요합니다. 시간 제한은 얼마이며, 그 안에 얼마나 보낼 수 있을까요?\n이 장은 데이터와 미디어 모두에 적용되는 개념을 다룹니다. 이후 장에서는 이론을 넘어서 WebRTC의 미디어/데이터 하위 시스템이 이 문제들을 어떻게 해결하는지 살펴봅니다.\n네트워크를 어렵게 만드는 속성은 무엇인가요? # 모든 네트워크에서 잘 동작하는 코드를 만드는 일은 어렵습니다. 많은 요소가 있으며 서로 미묘하게 영향을 주고받습니다. 다음은 흔한 이슈들입니다.\n대역폭(Bandwidth) # 대역폭은 경로를 따라 전송할 수 있는 최대 속도입니다. 정적 값이 아니라는 점이 중요합니다. 경로를 사용하는 사람이 늘거나 줄면 달라집니다.\n전송 시간과 왕복 시간(RTT) # 전송 시간은 패킷이 목적지에 도착하는 데 걸리는 시간입니다. 대역폭처럼 일정하지 않습니다. 언제든 변동할 수 있습니다.\ntransmission_time = receive_time - send_time\n전송 시간을 계산하려면 송신측과 수신측의 시계를 밀리초 수준으로 동기화해야 합니다. 작은 오차도 신뢰할 수 없는 측정을 만듭니다. WebRTC는 이기종 환경에서 동작하므로 완벽한 동기화에 의존하기 어렵습니다.\n이를 우회하는 방법이 왕복 시간(RTT) 측정입니다.\n분산 시계 대신, WebRTC 피어가 자체 타임스탬프 sendertime1이 담긴 특수 패킷을 보냅니다. 협력 피어는 이를 받아 타임스탬프를 반사해 돌려줍니다. 원 송신자가 반사된 패킷을 받으면 현재 시각 sendertime2에서 sendertime1을 뺍니다. 이 시간 차이가 RTT입니다.\nrtt = sendertime2 - sendertime1\nRTT의 절반을 전송 시간의 근사치로 사용합니다. 단, 이 방법은 전송/수신 시간이 대칭이라는 가정을 합니다. 셀룰러 네트워크에서는 대칭이 아닐 수 있습니다. 휴대폰 업로드가 다운로드보다 느린 것을 떠올리면 됩니다.\ntransmission_time = rtt/2\n왕복 시간 측정의 자세한 내용은 RTCP 송신/수신 리포트 절을 참고하세요.\n지터(Jitter) # 각 패킷의 전송 시간이 달라질 수 있다는 사실입니다. 지연되다 한꺼번에 도착하는 등 변동이 큽니다.\n패킷 손실(Packet Loss) # 전송 중 메시지가 유실되는 것입니다. 꾸준히 손실될 수도, 스파이크로 나타날 수도 있습니다. 위성/와이파이 같은 매체 특성이나, 경로상의 소프트웨어가 원인일 수 있습니다.\n최대 전송 단위(MTU) # 단일 패킷의 최대 크기 제한입니다. 하나의 거대한 메시지를 보낼 수 없고, 프로토콜 수준에서 여러 패킷으로 쪼개야 할 수 있습니다. 경로에 따라 MTU도 달라집니다. Path MTU Discovery로 전송 가능한 최대 크기를 파악할 수 있습니다.\n혼잡(Congestion) # 네트워크 한계에 도달한 상태입니다. 현재 경로가 처리할 수 있는 최대 대역폭을 넘겼거나, 사업자가 설정한 시간대 제약 등일 수 있습니다.\n혼잡의 모습은 다양하며 표준화되어 있지 않습니다. 보통 혼잡 시 초과 패킷을 드롭합니다. 어떤 경우에는 버퍼링이 발생해 전송 시간이 늘어납니다. 혼잡해질수록 지터가 증가할 수도 있습니다. 이 영역은 변화가 빠르며, 혼잡 감지를 위한 새로운 알고리즘이 계속 제안됩니다.\n동적(Dynamic) # 네트워크는 매우 동적이며, 조건이 빠르게 바뀝니다. 따라서 측정도 지속적이어야 합니다.\n지터 버퍼(Jitter Buffer) # 네트워크로 인한 변동을 흡수하려면 재생 전에 약간 지연을 두고 패킷을 재정렬해야 합니다. 이를 지터 버퍼가 담당합니다.\n간단한 예로, 다음과 같은 전송 시간을 관측했다고 합시다.\ntime=1.00 ms time=1.45 ms time=1.73 ms time=1.80 ms 이 경우 약 1.8ms 정도가 적절합니다. 늦게 도착한 패킷은 지연 창을 소모해 제시간에 재생하도록 하고, 일찍 도착한 패킷은 잠시 보류해 늦은 패킷으로 인해 고갈된 창을 채웁니다. 이렇게 하면 어긋남 없이 부드럽게 전달할 수 있습니다.\n지터 버퍼 동작 # 모든 패킷은 수신 즉시 지터 버퍼에 추가됩니다. 프레임을 재구성하기 충분한 패킷이 모이면 해당 패킷들이 버퍼에서 방출되어 디코더로 전달됩니다. 디코더는 이를 디코드해 화면에 표시합니다. 버퍼 용량은 한정되어 있으므로, 너무 오래 머무는 패킷은 폐기됩니다.\n비디오 프레임이 RTP 패킷으로 바뀌는 과정과 재구성이 필요한 이유는 미디어 통신 장을 참고하세요.\njitterBufferDelay는 네트워크 성능과 재생 매끄러움에 대한 좋은 인사이트를 제공합니다. 이는 수신 스트림과 관련된 WebRTC 통계 API의 일부입니다. 디코딩 전 프레임이 버퍼에서 대기한 시간을 의미하며, 값이 길수록 네트워크 혼잡이 심함을 나타냅니다.\n혼잡 감지 # 혼잡을 해결하기 전에 먼저 감지해야 합니다. 혼잡 컨트롤러가 이를 담당하며, 빠르게 발전하는 주제입니다. 높은 수준에서는 모두 비슷하게 동작합니다. 일부 입력을 받아 가용 대역폭을 추정합니다. 예시는 다음과 같습니다.\n패킷 손실: 혼잡해질수록 드롭이 늘어납니다. 지터: 장비가 과부하되면 큐잉으로 시간 변동이 커집니다. RTT: 혼잡 시 패킷 도착 시간이 늘어나며, 지터와 달리 계속 증가하는 경향이 있습니다. ECN: 최신 네트워크는 드롭 위험 패킷을 태깅할 수 있습니다. 이 값들은 통화 내내 계속 측정되어야 합니다. 네트워크 사용량이 변하므로 가용 대역폭도 계속 변할 수 있습니다.\n혼잡 해결 # 대역폭 추정치를 얻었으면 전송 방식을 조정해야 합니다. 무엇을 보낼지에 따라 방법이 달라집니다.\n더 느리게 보내기 # 전송 속도를 제한하는 것이 첫 번째 방법입니다. 혼잡 컨트롤러가 추정치를 제공하면, 송신자가 레이트 리밋을 적용합니다. 대부분의 데이터 통신이 이 방식을 씁니다. TCP 같은 프로토콜에서는 운영체제가 이를 처리하므로 사용자/개발자에게 투명합니다.\n더 적게 보내기 # 실시간 미디어처럼 도착 시간에 마감이 있는 경우 느리게 보낼 수 없습니다. 대신 전송 정보를 줄여 제한을 맞출 수 있습니다. 예컨대 사용 가능한 대역폭이 부족하면 비디오 화질을 낮출 수 있습니다. 이를 위해서는 비디오 인코더와 혼잡 컨트롤러 간 긴밀한 피드백 루프가 필요합니다.\n"},{"id":5,"href":"/ko/docs/06-media-communication/","title":"미디어 통신","section":"Docs","content":" 미디어 통신 # WebRTC 미디어 통신으로 무엇을 할 수 있나요? # WebRTC는 무제한의 오디오/비디오 트랙을 보낼 수 있고 받을 수 있습니다. 통화 중에도 언제든 스트림을 추가/제거할 수 있으며, 서로 독립적으로 보낼 수도, 하나의 연결로 번들링할 수도 있습니다. 예를 들어 데스크톱 화면 비디오에 웹캠의 오디오/비디오를 함께 보낼 수 있습니다.\nWebRTC 프로토콜은 코덱에 중립적입니다. 기저 전송은 존재하지 않는 형식까지도 이론상 지원할 수 있습니다. 다만 상대 에이전트가 해당 코덱을 처리할 수 있어야 합니다.\n또한 WebRTC는 동적인 네트워크 상태에 대응하도록 설계되었습니다. 통화 중 대역폭이 늘거나 줄 수 있고, 갑작스런 패킷 손실도 생길 수 있습니다. 프로토콜은 이러한 상황에 반응해 가능한 최선의 경험을 제공하려고 합니다.\n어떻게 동작하나요? # WebRTC는 RTP와 RTCP를 사용합니다(둘 다 RFC 1889).\nRTP(Real-time Transport Protocol)는 실제 미디어를 운반합니다. 지연/신뢰성 규칙은 강제하지 않지만, 이를 구현할 도구를 제공합니다. 하나의 연결에서 여러 미디어 스트림을 운반할 수 있도록 스트림 모델과, 미디어 파이프라인에 필요한 타이밍/정렬 정보를 제공합니다.\nRTCP(RTP Control Protocol)는 통화에 대한 메타데이터를 교환합니다. 포맷이 유연해 원하는 메타데이터를 넣을 수 있습니다. 통화 통계를 전달하고, 패킷 손실 처리, 혼잡 제어 구현에 사용됩니다. 네트워크 변화에 대응하기 위한 양방향 통신을 제공합니다.\n지연과 품질의 균형 # 실시간 미디어는 지연과 화질 사이에서 절충이 필요합니다. 더 큰 지연을 허용할수록 더 높은 화질을 기대할 수 있습니다.\n현실적 제약 # 모든 제약은 현실 세계 네트워크의 한계에서 옵니다. 극복해야 할 네트워크 특성입니다.\n비디오는 복잡하다 # 비디오 전송은 쉽지 않습니다. 예컨대 30분 분량의 무압축 720p 8비트 비디오는 약 110GB가 필요합니다. 4인 회의를 생각하면 불가능합니다. 해법은 압축이며, 당연히 대가가 따릅니다.\n비디오 101 # 비디오 압축의 모든 것을 다루지는 않고, RTP가 왜 그렇게 설계되었는지를 이해할 만큼만 설명합니다. 압축은 더 적은 비트로 같은 영상을 표현합니다.\n손실/무손실 압축 # 무손실(정보 손실 없음)과 손실(일부 손실 허용) 방식이 있습니다. 무손실은 더 많은 데이터를 전송해야 하므로 지연이 늘고 손실이 늘어납니다. RTP에서는 보통 손실 압축을 사용합니다.\n인트라/인터 프레임 압축 # 인트라 프레임은 단일 프레임 내부에서 중복을 줄입니다(JPEG과 유사). 인터 프레임은 연속된 프레임 간 중복을 줄입니다.\n인터 프레임 종류 # I-프레임: 완전한 그림, 단독 디코딩 가능 P-프레임: 이전 그림 대비 변경분만 포함 B-프레임: 이전/이후 그림을 모두 참조해 변경분만 포함 비디오는 섬세하다 # 비디오 압축은 강한 상태성을 갖습니다. I-프레임의 일부를 잃으면? P-프레임은 무엇을 수정해야 하는지 어떻게 알까요? 복잡해질수록 문제는 커집니다. 다행히 RTP/RTCP가 해법을 가지고 있습니다.\nRTP # 패킷 형식(요점) # RTP 헤더에는 버전, 페이로드 타입(코덱 식별), 시퀀스 번호(손실/재정렬 판단), 타임스탬프(동기화), SSRC(스트림 식별) 등이 포함됩니다. 시퀀스 번호는 패킷 손실/순서 판단에, 타임스탬프는 디코딩/재생 타이밍에 쓰입니다.\nRTCP # RTCP 패킷은 다양한 타입이 있습니다. 공통 헤더에는 버전, 패딩, 리포트 개수, 패킷 타입, 길이, 페이로드가 옵니다.\n자주 보는 타입은 다음과 같습니다.\n192: FIR(Full INTRA-frame Request) 193: NACK(Negative ACKnowledgement) 200: Sender Report 201: Receiver Report 205: Generic RTP Feedback 206: Payload Specific Feedback FIR와 PLI # FIR/PLI는 모두 키프레임(I-프레임) 재전송을 요청합니다. RFC 5104에 따르면 손실 상황에는 PLI를, 그 외(예: 새 참가자 입장)에는 FIR을 사용합니다. 실무에서는 두 경우 모두 인코더에 키프레임 생성을 요청합니다.\nNACK # NACK은 특정 RTP 패킷 하나의 재전송을 요청합니다. RTP가 작은 조각으로 나뉘어 있어, 프레임 전체 재전송보다 대역폭 효율이 좋습니다. 송신자가 해당 패킷을 보유하지 않으면 무시됩니다.\n송신/수신 리포트(SR/RR) # 엔드포인트 간 통계(손실률, 누적 손실, 최고 시퀀스, 지터, 송신 시각 등)를 주고받습니다. RTT 계산과 혼잡 제어에 사용됩니다.\nRTT 계산은 다음과 같습니다.\nrtt = sendertime2 - sendertime1 - DLSR\n함께 문제를 푸는 방식 # 순방향 오류 정정(FEC) # 요청을 기다리지 않고 여분 데이터를 함께 보내 손실에 대비합니다. 손실이 지속적이면 NACK보다 지연이 적습니다.\n적응형 비트레이트와 대역폭 추정 # 세션 중 가용 대역폭은 크게 변할 수 있습니다. 인코딩 비트레이트를 예측/현재/미래 대역폭에 맞춰 조정합니다. 이를 위해 대역폭 추정 알고리즘과 네트워크 특성 교환이 필요합니다.\n네트워크 상태의 식별과 교환 # WebRTC는 양방향으로 대역폭, RTT, 지터, 손실을 관측/전달해야 합니다. 대표적인 접근은 다음과 같습니다.\nReceiver/Sender Reports(RR/SR) # RFC 3550 정의. RR이 네트워크 품질(손실, RTT, 지터)을 보고하고, 송신자는 이를 바탕으로 비트레이트를 추정/조정합니다. 필드에는 Fraction Lost, Cumulative Lost, Extended Highest Seq, Interarrival Jitter, Last SR Timestamp 등이 포함됩니다.\nTMMBR/TMMBN, REMB, TWCC와 GCC # GCC(Google Congestion Control) # 손실 기반 컨트롤러와 지연 기반 컨트롤러를 결합해 대역폭을 추정합니다(draft-ietf-rmcat-gcc-02). 수신측 피드백(TMMBR/TMMBN/REMB) 또는 송신측 피드백(TWCC)과 함께 동작합니다.\nTMMBR/TMMBN, REMB # 수신측이 허용 비트레이트를 알려 송신자가 인코더 비트레이트를 조정합니다. 인코더 편차, 규격화 미흡 등 한계가 있어 실무에서는 세심한 튜닝이 필요합니다. TWCC(Transport-Wide Congestion Control) # 패킷 도착 시간을 송신자에 상세히 제공해, 송신자가 직접 지연 변동/손실을 추정하고 빠르게 조정합니다. SR/RR의 송신자 중심성과 REMB의 정밀 측정을 절충한 방식입니다. 송신자는 보낸 패킷의 크기/타임스탬프/시퀀스를 추적하고, 수신 리포트의 도착 간격과 비교해 혼잡을 감지합니다.\n대역폭 추정의 대안 # 가장 널리 쓰이는 구현은 \u0026ldquo;Google Congestion Control\u0026quot;입니다. 대안으로 NADA, SCReAM 등이 있습니다.\n"},{"id":6,"href":"/ko/docs/07-data-communication/","title":"데이터 통신","section":"Docs","content":" 데이터 통신 # WebRTC 데이터 통신으로 무엇을 할 수 있나요? # WebRTC는 데이터 채널을 제공합니다. 두 피어 사이에 최대 65,534개의 채널을 열 수 있습니다. 데이터 채널은 데이터그램 기반이며, 채널마다 내구성(재전송/시간 제한/순서 보장)을 독립적으로 설정할 수 있습니다. 기본은 보장된 순서 전달입니다.\n미디어 관점에서 보면 데이터 채널은 과해 보일 수 있습니다. HTTP/WebSocket으로도 보낼 수 있지 않나? 하지만 데이터 채널의 힘은 무질서/손실 허용(UDP 유사) 동작으로 구성할 수 있다는 데 있습니다. 낮은 지연/고성능에 필수적이며, 백프레셔를 측정해 네트워크 용량을 넘지 않도록 보낼 수 있습니다.\n어떻게 동작하나요? # WebRTC는 RFC 4960의 SCTP(Stream Control Transmission Protocol)를 사용합니다. 원래 전송 계층용이지만, WebRTC에서는 DTLS 위의 응용 계층 프로토콜로 사용합니다. SCTP는 ‘스트림’을 제공하며 각 스트림을 독립적으로 구성할 수 있습니다. 데이터 채널은 이에 대한 얇은 추상화로, 내구성/순서 옵션은 SCTP 에이전트에 그대로 전달됩니다.\n또한 채널 라벨처럼 SCTP가 직접 표현하지 못하는 정보는 RFC 8832의 DCEP(Data Channel Establishment Protocol)로 교환합니다.\nDCEP # DCEP에는 DATA_CHANNEL_OPEN과 DATA_CHANNEL_ACK 두 메시지만 있습니다. 채널을 열면 상대는 ACK로 응답해야 합니다.\nDATA_CHANNEL_OPEN # 채널을 열고자 하는 에이전트가 전송합니다. 필드는 다음 의미를 갖습니다.\nMessage Type: 0x03 Channel Type: 내구성/순서 속성 RELIABLE(0x00): 손실 없음, 순서 보장 RELIABLE_UNORDERED(0x80): 손실 없음, 무질서 허용 PARTIAL_RELIABLE_REXMIT(0x01): 제한 횟수 재전송 후 손실 허용, 순서 보장 PARTIAL_RELIABLE_REXMIT_UNORDERED(0x81): 위와 동일, 무질서 허용 PARTIAL_RELIABLE_TIMED(0x02): 제한 시간 내 도착하지 않으면 손실 허용, 순서 보장 PARTIAL_RELIABLE_TIMED_UNORDERED(0x82): 위와 동일, 무질서 허용 Priority: 높은 우선순위가 먼저 스케줄됨 Reliability Parameter: REXMIT(재전송 횟수) 또는 TIMED(재전송 시간, ms) Label: 채널 이름(UTF-8) Protocol: 비어 있지 않다면 [RFC 6455]의 WebSocket 서브프로토콜 레지스트리 값을 권장 DATA_CHANNEL_ACK # 원격이 채널 오픈을 수락했음을 알립니다.\nSCTP 핵심 개념 # 전송 시퀀스 번호(TSN) # 모든 DATA 청크의 전역 고유 번호입니다. 손실/무질서 판단에 사용합니다.\n스트림 식별자/시퀀스 번호 # 각 스트림에는 ID가 있고, 메시지 단위의 시퀀스 번호가 있습니다(U=0일 때 순서 판단에 사용).\nPPID(Payload Protocol Identifier) # 전송 데이터의 타입을 나타냅니다. WebRTC는 DCEP(50), String(51), Binary(53), String Empty(56), Binary Empty(57)를 사용합니다.\n주요 청크 # DATA # 사용자 데이터 전달에 사용합니다. U(무질서), B/E(분할 메시지의 시작/끝), TSN, Stream ID, Stream Seq, PPID 등을 포함합니다.\nINIT # 연결(Association) 생성 시작. 쿠키용 Initiate Tag, 수신 윈도 크기(a_rwnd), 송/수신 스트림 수, 초기 TSN, 선택 매개변수 등을 담습니다.\nSACK # 수신 확인(Selective ACK). 누적 TSN ACK, 수신 윈도 크기, 갭 ACK 블록, 중복 TSN 등을 보고합니다.\nHEARTBEAT / ABORT / SHUTDOWN / ERROR # 연결 상태 확인, 비정상 종료, 정상 종료, 비치명적 오류 보고 등에 사용됩니다.\nFORWARD TSN # 더 이상 필요 없는 오래된 데이터 구간을 건너뛰도록 누적 TSN을 앞으로 당깁니다(실시간 무용 데이터 스킵).\n상태 머신 # 연결 수립 흐름 # INIT/INIT ACK로 능력/설정을 교환합니다. SCTP는 핸드셰이크 중 쿠키를 사용해 상대를 검증하고(DOS/MITM 방지), COOKIE ECHO/COOKIE ACK로 완료합니다. 이후 DATA 교환이 시작됩니다.\n연결 종료 흐름 # SHUTDOWN으로 우아한 종료를 시작합니다. 각 측은 마지막 전송 TSN을 공유해 데이터 손실 없이 종료합니다.\nKeep-Alive # HEARTBEAT REQUEST/ACK를 주기적으로 교환해 연결을 유지하고, 왕복 시간을 추정합니다.\n"},{"id":7,"href":"/ko/docs/08-applied-webrtc/","title":"적용 WebRTC","section":"Docs","content":" 적용 WebRTC # 이제 WebRTC가 어떻게 동작하는지 알았으니, 실제로 만들어볼 차례입니다! 이 장에서는 사람들이 WebRTC로 무엇을 만들고, 어떻게 만들고 있는지 살펴봅니다. WebRTC로 벌어지는 흥미로운 일들을 배우게 될 것입니다. 다만 강력함에는 대가가 있습니다. 프로덕션급 WebRTC 서비스를 구축하는 일은 도전적입니다. 이 장에서는 여러분이 마주치기 전에 그런 도전 과제를 미리 설명합니다.\n사용 사례별 # 많은 이들이 WebRTC를 브라우저 화상회의 기술로만 생각하지만, 그 이상입니다! WebRTC는 매우 다양한 애플리케이션에 쓰입니다. 새로운 사용 사례도 계속 등장하고 있습니다. 여기서는 대표적인 사례와, WebRTC가 어떻게 변화를 이끄는지 소개합니다.\n콘퍼런싱 # 콘퍼런싱은 WebRTC의 원조 사용 사례입니다. 브라우저에서 다른 프로토콜이 제공하지 못하는 핵심 기능을 갖추고 있습니다. WebSockets만으로도 이상적 환경에서는 회의 시스템을 만들 수 있겠지만, 실제 네트워크에서 배포하려면 WebRTC가 최선입니다.\nWebRTC는 미디어를 위한 혼잡 제어와 적응형 비트레이트를 제공합니다. 네트워크 조건이 변해도 사용자는 가능한 최선의 경험을 얻게 됩니다. 개발자가 별도 측정 코드를 작성할 필요도 없습니다.\n참가자는 여러 스트림을 보내고 받을 수 있으며, 통화 중 언제든 스트림을 추가/제거할 수 있습니다. 코덱 협상도 자동으로 이뤄집니다. 이 모든 기능은 브라우저가 제공하므로 개발자가 별도 코드를 작성할 필요가 없습니다.\n콘퍼런싱은 데이터 채널에서도 이점을 얻습니다. 메타데이터를 보내거나 문서를 공유할 수 있습니다. 여러 데이터 스트림을 만들고, 신뢰성보다 성능을 우선하도록 구성할 수도 있습니다.\n방송 # 방송 영역에서도 WebRTC를 사용하는 프로젝트가 빠르게 늘고 있습니다. 이 프로토콜은 발행자와 소비자 모두에게 장점이 있습니다.\n브라우저에 내장되어 있어 사용자가 영상을 쉽게 발행할 수 있습니다. 별도 프로그램을 설치할 필요가 없습니다. 브라우저가 있는 플랫폼이면 어디서든 발행이 가능하며, 여러 트랙을 보내고 필요할 때 수정/제거할 수 있습니다. 연결당 오디오/비디오 한 개만 허용하던 레거시 프로토콜 대비 큰 진전입니다.\nWebRTC는 지연 대 화질의 트레이드오프를 더 세밀하게 제어할 수 있습니다. 지연이 특정 임계치를 넘지 않는 것이 더 중요하고, 약간의 디코딩 아티팩트를 감수할 수 있다면, 도착 즉시 재생하도록 뷰어를 구성할 수 있습니다. TCP 위에서 동작하는 다른 프로토콜로는 쉽지 않습니다.\n원격 접속 # 원격 접속은 WebRTC로 다른 컴퓨터를 원격으로 제어하는 것을 말합니다. 전체 시스템을 제어할 수도, 특정 애플리케이션만 제어할 수도 있습니다. 로컬 하드웨어로 수행하기 어려운 연산 집약 작업(최신 게임 실행, CAD 등)에 유용합니다. WebRTC는 세 가지 측면에서 이 영역을 혁신했습니다.\n첫째, 전 세계 라우팅이 되지 않는 호스트에도 접속할 수 있습니다. NAT 우회를 통해 STUN만으로 접근 가능한 컴퓨터에 연결할 수 있습니다. 이는 보안과 프라이버시 측면에서 좋습니다. 비디오를 인제스트 서버나 점프 박스에 경유시킬 필요가 없습니다. 또한 포트 포워딩이나 고정 IP 준비 없이도 배포가 쉬워집니다.\n둘째, 데이터 채널이 강력합니다. 최신 데이터만 수용하도록 설정할 수 있습니다. TCP에서는 HOL(Head-of-Line) 블로킹이 발생할 수 있어 오래된 마우스 클릭이나 키 입력이 늦게 도착해 이후 입력을 막을 수 있습니다. WebRTC 데이터 채널은 손실 패킷을 재전송하지 않도록 설정할 수 있고, 백프레셔를 측정해 네트워크 용량을 초과해 보내지 않도록 제어할 수 있습니다.\n셋째, 브라우저에서 바로 사용할 수 있어 사용자 경험이 좋아졌습니다. 전용 클라이언트를 설치하지 않아도 세션을 시작할 수 있고, 스마트 TV 등 더 많은 클라이언트가 WebRTC를 내장하고 있습니다.\n파일 공유와 검열 우회 # 파일 공유와 검열 우회는 전혀 다른 문제처럼 보이지만, WebRTC는 두 경우 모두에서 같은 문제를 해결합니다. 접근성을 높이고 차단을 어렵게 만듭니다.\n첫째 문제는 ‘클라이언트 얻기’입니다. 파일 공유 네트워크에 참여하려면 클라이언트를 내려받아야 합니다. 네트워크가 분산되어 있어도 마찬가지입니다. 제약된 네트워크에서는 이 다운로드가 차단되기 쉽고, 다운로드하더라도 설치/실행을 못 할 수 있습니다. WebRTC는 이미 모든 브라우저에 있으므로 즉시 사용할 수 있습니다.\n둘째 문제는 트래픽 차단입니다. 파일 공유에만 쓰이는 프로토콜을 사용하면 트래픽 특성만으로 차단되기 쉽습니다. 반면 WebRTC 트래픽은 일반 웹 트래픽과 구분하기 어렵고, UDP/TCP 조합과 포트도 다양해 차단이 쉽지 않습니다.\n토폴로지별 # WebRTC 애플리케이션을 설계할 때 사용할 수 있는 대표적인 연결 토폴로지는 다음과 같습니다.\n1:1 # 가장 단순한 모델입니다. 한 사용자가 다른 사용자와 직접 연결합니다. 데이터 채널과 미디어 트랙을 원하는 대로 추가할 수 있습니다.\n연결 형태는 다음과 같습니다.\n풀 메시(Full Mesh) # 소규모 회의나 멀티플레이어 게임에 적합합니다. 모든 사용자가 서로에게 직접 연결합니다. 애플리케이션을 구축할 수 있지만 단점도 있습니다.\n각 사용자가 통화 참여자마다 독립적으로 인코딩하여 업로드해야 합니다. 연결마다 네트워크 상태가 달라 같은 비디오를 재사용할 수 없습니다. 오류 처리도 어렵습니다. 전체 연결이 끊긴 것인지, 특정 피어와의 연결만 끊긴 것인지 신중히 판단해야 합니다.\n이런 이유로 풀 메시 토폴로지는 소규모 그룹에 적합하며, 더 큰 규모에는 클라이언트/서버 토폴로지가 좋습니다.\n하이브리드 메시 # 풀 메시의 문제를 일부 완화하는 대안입니다. 모든 사용자 사이에 직접 연결을 만들지 않고, 네트워크 내 다른 피어를 통해 미디어를 릴레이합니다. 원본 발행자가 미디어 배포에 쓰는 대역폭을 줄일 수 있습니다.\n다만 단점도 있습니다. 원본 발행자는 자신의 비디오가 누구에게 전달되는지, 성공적으로 도착했는지 알기 어렵습니다. 또한 홉이 늘어날수록 지연이 증가합니다.\nSFU(Selective Forwarding Unit) # SFU는 풀 메시의 문제를 전혀 다른 방식으로 해결합니다. P2P 대신 클라이언트/서버 토폴로지를 구현합니다. 각 WebRTC 피어는 SFU에 연결해 자신의 미디어를 업로드하고, SFU는 이를 각 클라이언트로 전달합니다.\n이 방식에서는 각 에이전트가 비디오를 한 번만 인코딩/업로드하면 됩니다. 시청자에게 배포하는 부담은 SFU가 집니다. 또한 SFU를 공인 주소에서 운영할 수 있어 연결성이 P2P보다 쉽습니다. NAT 매핑 걱정도 줄어듭니다. 다만 TCP 경로(ICE-TCP 또는 TURN) 노출은 여전히 필요합니다.\n간단한 SFU는 주말 동안에도 만들 수 있지만, 모든 유형의 클라이언트를 잘 다루는 ‘좋은’ SFU를 만드는 일은 끝이 없습니다. 혼잡 제어, 오류 정정, 성능 튜닝은 지속적인 과제입니다.\nMCU # MCU(Multi-point Conferencing Unit)는 SFU처럼 클라이언트/서버 토폴로지이지만, 출력 스트림을 합성합니다. 개별 스트림을 그대로 배포하는 대신 하나의 피드로 다시 인코딩해 전달합니다.\n"},{"id":8,"href":"/ko/docs/09-debugging/","title":"디버깅","section":"Docs","content":" 디버깅 # WebRTC 디버깅은 만만치 않습니다. 구성요소가 많고, 각자 독립적으로 실패할 수 있습니다. 잘못된 부분을 오래 들여다보느라 시간을 낭비하기 쉽습니다. 이 장은 문제를 분해하고, 인기 있는 도구로 진단하는 방법을 안내합니다.\n문제를 격리하라 # 어디에서 문제가 비롯되는지 초기에 구분하세요.\n시그널링 실패 # 시그널링 채널이 연결되고, SDP/ICE 후보가 정상적으로 교환되는지부터 확인합니다.\n네트워킹 실패 # STUN 서버를 netcat으로 점검할 수 있습니다.\n20바이트 바인딩 요청 패킷 준비 echo -ne \u0026#34;\\x00\\x01\\x00\\x00\\x21\\x12\\xA4\\x42TESTTESTTEST\u0026#34; | hexdump -C 요청 전송 후 32바이트 응답 확인 stunserver=stun1.l.google.com;stunport=19302;listenport=20000;echo -ne \u0026#34;\\x00\\x01\\x00\\x00\\x21\\x12\\xA4\\x42TESTTESTTEST\u0026#34; | nc -u -p $listenport $stunserver $stunport -w 1 | hexdump -C XOR 계산을 단순화하려면 매직 쿠키를 0으로 둔 더미 요청을 보낼 수 있습니다.\nstunserver=stun1.l.google.com;stunport=19302;listenport=20000;echo -ne \u0026#34;\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00TESTTESTTEST\u0026#34; | nc -u -p $listenport $stunserver $stunport -w 1 | hexdump -C 보안 실패 # DTLS 핸드셰이크가 완료되는지, 인증서 지문이 SDP와 일치하는지 확인합니다.\n미디어 실패 # 코덱/포맷 호환, 카메라/마이크 권한, 트랙 추가 상태(addTrack)와 수신(ontrack) 발생 여부를 확인합니다.\n데이터 실패 # 데이터 채널 오픈(DCEP 교환)과 메시지 송수신, 백프레셔/버퍼 상태를 점검합니다.\n흔히 쓰는 도구 # netcat (nc) # TCP/UDP 연결로 송수신을 수행하는 네트워크 유틸리티입니다.\ntcpdump # 패킷 캡처/헥사덤프 도구입니다.\nUDP 19302 포트 캡처: sudo tcpdump 'udp port 19302' -xx PCAP 저장: sudo tcpdump 'udp port 19302' -w stun.pcap (Wireshark로 열기) Wireshark # GUI 기반의 강력한 패킷 분석기입니다.\nwebrtc-internals # Chrome의 통계 페이지: chrome://webrtc-internals\n지연 측정 # 지연을 줄이려면 먼저 정확히 측정해야 합니다. 이상적인 방법은 종단 간 지연을 측정하는 것입니다(카메라 캡처, 인코딩, 전송, 수신, 디코딩, 디스플레이, 큐잉 포함).\nDIY 측정(수동) # 카메라를 밀리초 단위 시계를 향하게 합니다. 같은 장소의 수신기로 영상을 보냅니다. 휴대폰으로 시계와 수신 화면을 동시에 찍습니다. 두 시각의 차이를 구합니다. . 자동 측정(호환 방식) # NTP 스타일로 DataChannel을 이용해 송신자/수신자 단조 시계를 동기화하고, 비디오 트랙 시간과 대조해 지연을 추정합니다.\n핵심 개념:\nexpected_video_time = tSV1 + time_since(tSV1) latency = expected_video_time - actual_video_time 샘플 메시지 포맷(송신자 응답):\n{ \u0026#34;received_time\u0026#34;: 64714, \u0026#34;delay_since_received\u0026#34;: 46, \u0026#34;local_clock\u0026#34;: 1597366470336, \u0026#34;track_times_msec\u0026#34;: { \u0026#34;myvideo_track1\u0026#34;: [13100, 1597366470289] } } 수신기에서 데이터채널 열기:\ndataChannel = peerConnection.createDataChannel(\u0026#39;latency\u0026#39;); 주기적으로 수신기 시간 전송:\nsetInterval(() =\u0026gt; { let tR1 = Math.trunc(performance.now()); dataChannel.send(String(tR1)); }, 2000); 송신기 처리 및 응답:\n// event.data 예: \u0026#34;1234567\u0026#34; const tR1 = Number(event.data); const now = Math.trunc(performance.now()); const tSV1 = 42000; // 현재 프레임 RTP 타임스탬프(ms) const tS1 = 1597366470289; // 현재 프레임 단조 시계 const msg = { received_time: tR1, delay_since_received: 0, local_clock: now, track_times_msec: { myvideo_track1: [tSV1, tS1] } }; dataChannel.send(JSON.stringify(msg)); 수신기에서 지연 추정:\nlet tR2 = performance.now(); let fromSender = JSON.parse(event.data); let tR1 = fromSender.received_time; let delay = fromSender.delay_since_received; let senderTimeFromResponse = fromSender.local_clock; let rtt = tR2 - delay - tR1; let networkLatency = rtt / 2; let senderTime = senderTimeFromResponse + delay + networkLatency; VIDEO.requestVideoFrameCallback((now, framemeta) =\u0026gt; { senderTime += (now - tR2); let [tSV1, tS1] = Object.entries(fromSender.track_times_msec)[0][1]; let timeSinceLastKnownFrame = senderTime - tS1; let expectedVideoTimeMsec = tSV1 + timeSinceLastKnownFrame; let actualVideoTimeMsec = Math.trunc(framemeta.rtpTimestamp / 90); let latency = expectedVideoTimeMsec - actualVideoTimeMsec; console.log(\u0026#39;latency\u0026#39;, latency, \u0026#39;msec\u0026#39;); }); 브라우저에서 실제 비디오 시간 # HTMLVideoElement.requestVideoFrameCallback()으로 현재 표시된 비디오 프레임의 시간(및 WebRTC의 경우 rtpTimestamp)에 접근할 수 있습니다.\n지연 디버깅 팁 # 설정을 단순화해 문제 재현 최소 구성을 만드세요. 카메라: 자동 노출/초점/화이트밸런스가 지연을 늘릴 수 있습니다(Linux: v4l2-ctl). 인코더: B-프레임/레퍼런스 프레임이 지연을 늘립니다(x264: tune=zerolatency, profile=baseline 권장). 네트워크: RTT는 지연의 하한입니다. NACK/PLI가 늘면 지연 증가 요인입니다(webrtc-internals의 nackCount, pliCount 확인). 수신측: 패킷 무질서/재조립 대기 시간이 지연을 늘립니다(jitterBufferDelay 확인). "},{"id":9,"href":"/ko/docs/10-history-of-webrtc/","title":"역사","section":"Docs","content":" 역사 # WebRTC는 기능이 많고 복잡해 보일 수 있습니다. 그러나 이런 복잡성은 다양한 실시간 통신 요구를 포괄하려는 과정에서 생겨났습니다. 이 장은 WebRTC를 구성하는 주요 프로토콜들의 역사와 설계 의도를 간략히 소개합니다. 배경을 이해하면 더 효과적인 시스템을 설계할 수 있습니다.\nRTP # RTP/RTCP는 WebRTC의 미디어 전송을 담당하며, 1996년 RFC 1889로 공개되었습니다. 초기 인터넷 멀티캐스트 실험과 화상회의 도구에서 출발해, 오늘날까지도 실시간 미디어 전송의 표준으로 자리 잡았습니다.\n맥락과 의도 # 당시 목표는 제한된 대역폭(예: ISDN 128kbps)에서도 수용 가능한 화질을 제공하는 것이었습니다. 이를 위해 소프트웨어 기반 비디오 압축과 멀티캐스트 전송이 탐구되었고, 경험이 RTP 설계로 이어졌습니다. RTCP의 통계/제어 채널은 혼잡과 품질 문제를 다루기 위한 도구로 도입되었습니다.\n교훈 # RTCP의 복잡성이 단일 유니캐스트 스트리밍에서 채택을 어렵게 만들기도 했습니다. 반면 멀티파티/멀티캐스트 시나리오에서는 대역폭 효율과 확장성의 이점을 제공했습니다.\nSRTP/DTLS와 보안 # WebRTC는 DTLS로 키 합의/인증을 수행하고, SRTP로 미디어를 암호화합니다. 표준 웹 기술과 친화적인 신뢰 모델을 바탕으로 P2P 환경에서도 종단 간 보안을 확보하는 데 초점을 맞추었습니다.\nNAT 우회와 ICE의 등장 # 현실 세계 네트워크는 NAT/방화벽/프로토콜 제약이 상시 존재합니다. STUN/TURN/ICE는 이런 제약을 넘기 위한 표준화된 해법으로 발전했고, WebRTC는 이를 조합해 다양한 네트워크에서도 연결성을 최대화합니다.\n데이터 통신의 진화 # HTTP/TCP만으로는 지연/성능의 제약이 큽니다. WebRTC는 DTLS 위의 SCTP(DataChannel)로, 무질서/부분 신뢰성/프래그먼테이션 등 실시간 데이터에 필요한 세밀한 제어를 제공합니다.\n오늘과 내일 # 브라우저, 모바일, 임베디드까지 생태계가 확장되며 WebRTC는 계속 진화하고 있습니다. 혼잡 제어(TWCC/GCC), 코덱(AV1 등), 전송 최적화는 여전히 활발한 연구/개발 주제입니다. 개방 표준/상호운용성이라는 철학은 그대로 유지됩니다.\n참고: 이 장의 원문에는 초기 구현자들의 상세 인터뷰가 포함됩니다. 본 한국어판에서는 핵심 맥락 위주로 요약했습니다. 원문 인터뷰와 세부 일화는 영문판을 참고하세요.\n"},{"id":10,"href":"/ko/docs/11-faq/","title":"자주 묻는 질문(FAQ)","section":"Docs","content":" FAQ # 왜 WebRTC는 UDP를 쓰나요? NAT 우회에는 UDP가 필요합니다. NAT 우회가 없다면 P2P 연결을 수립할 수 없습니다. UDP는 TCP처럼 “보장 전달”이 없으므로, WebRTC가 상위 레이어에서 이를 처리합니다.\n연결 장을 참고하세요.\nDataChannel은 몇 개까지 만들 수 있나요? 식별자(스트림 ID)가 16비트이므로 최대 65,534개입니다. 필요할 때 닫았다가 새로 열 수 있습니다. WebRTC에 대역폭 제한이 있나요? DataChannel과 RTP 모두 혼잡 제어를 사용합니다. 즉, WebRTC가 대역폭을 지속적으로 측정해 최적 사용량을 시도합니다. 가능한 많이 보내되, 연결을 과부하시키지 않는 선에서 균형을 맞춥니다. 바이너리 데이터를 보낼 수 있나요? 네, DataChannel을 통해 텍스트와 바이너리 모두 보낼 수 있습니다. WebRTC의 지연은 어느 정도 기대할 수 있나요? 튜닝하지 않은 미디어의 경우 500ms 미만을 기대할 수 있습니다. 튜닝을 하거나 품질을 희생해 지연을 더 낮추면 100ms 미만도 가능합니다.\nDataChannel은 “부분 신뢰성(Partial Reliability)” 옵션을 지원해 손실 재전송으로 인한 지연을 줄일 수 있습니다. 이 옵션을 설정하면 TCP/TLS 연결보다 더 좋은 지연 특성을 보이기도 합니다.\n왜 DataChannel에서 무질서(Out-of-order) 전달을 원하나요? 새로운 정보가 오래된 정보를 곧바로 무의미하게 만드는 경우(예: 객체의 위치), 또는 각 메시지가 서로 독립적이며 HOL 블로킹으로 인한 지연을 피해야 하는 경우에 유용합니다. DataChannel로 오디오/비디오를 보낼 수 있나요? 네, 어떤 데이터든 보낼 수 있습니다. 다만 브라우저에서는 데이터를 직접 디코드해 미디어 플레이어에 전달해 렌더링해야 합니다. 미디어 트랙을 사용하면 이러한 처리가 자동으로 이루어집니다. "},{"id":11,"href":"/ko/docs/12-glossary/","title":"용어집","section":"Docs","content":" 용어집 # ACK: Acknowledgment(확인 응답) AVP: Audio and Video profile B-Frame: 양방향 예측 프레임. 이전/이후 그림을 참고해 부분만 담는 프레임 DCEP: Data Channel Establishment Protocol, RFC 8832 DeMux: Demultiplexer(역다중화) DLSR: Delay since last sender report DTLS: Datagram Transport Layer Security, RFC 6347 E2E: End-to-End(종단 간) FEC: Forward Error Correction FIR: Full INTRA-frame Request G.711: 협대역 오디오 코덱 GCC: Google Congestion Control, draft-ietf-rmcat-gcc-02 H.264: 범용 오디오비주얼 인코딩 규격 H.265: ITU-T H.265 고효율 비디오 코딩 적합성 규격 HEVC: High Efficiency Video Coding HTTP: Hypertext Transfer Protocol HTTPS: TLS 위의 HTTP, RFC 2818 I-Frame: 인트라 프레임. 완전한 그림으로 단독 디코딩 가능 ICE: Interactive Connectivity Establishment, RFC 8445 INIT: Initiate IoT: Internet of Things(사물인터넷) IPv4: Internet Protocol, Version 4 IPv6: Internet Protocol, Version 6 ITU-T: International Telecommunication Union Telecommunication Standardization Sector JSEP: JavaScript Session Establishment Protocol, RFC 8829 MCU: Multi-point Conferencing Unit mDNS: Multicast DNS, RFC 6762 MITM: Man-In-The-Middle(중간자) MTU: Maximum Transmission Unit, 패킷 최대 크기 MUX: Multiplexing(다중화) NACK: Negative Acknowledgment NADA: network-assisted dynamic adaptation, draft-zhu-rmcat-nada-04 NAT: Network Address Translation, RFC 4787 Opus: 완전 개방형, 로열티 프리, 다목적 오디오 코덱 P-Frame: 예측 프레임. 이전 그림 대비 변경분만 포함 P2P: Peer-to-Peer PLI: Picture Loss Indication PPID: Payload Protocol Identifier REMB: Receiver Estimated Maximum Bitrate RFC: Request for Comments RMCAT: RTP Media Congestion Avoidance Techniques RR: Receiver Report RTCP: RTP Control Protocol, RFC 3550 RTP: Real-time transport protocol, RFC 3550 RTT: Round-Trip Time(왕복 시간) SACK: Selective Acknowledgment SCReAM: Self-Clocked Rate Adaptation for Multimedia, draft-johansson-rmcat-scream-cc-05 SCTP: Stream Control Transmission Protocol, RFC 4960 SDP: Session Description Protocol, RFC 8866 SFU: Selective Forwarding Unit SR: Sender Report SRTP: Secure Real-time Transport Protocol, RFC 3711 SSRC: Synchronization Source STUN: Session Traversal Utilities for NAT, RFC 8489 TCP: Transmission Control Protocol TLS: Transport Layer Security, RFC 8446 TMMBN: Temporary Maximum Media Stream Bit Rate Notification TMMBR: Temporary Maximum Media Stream Bit Rate Request TSN: Transmission Sequence Number TURN: Traversal Using Relays around NAT, RFC 8656 TWCC: Transport Wide Congestion Control UDP: User Datagram Protocol VP8, VP9: WebM 프로젝트에서 개발한 고효율 비디오 코덱. 누구나 로열티 없이 사용 가능 WebM: 웹을 위한 개방형 미디어 파일 포맷 WebRTC: Web Real-Time Communications. W3C WebRTC 1.0: Real-Time Communication Between Browsers "},{"id":12,"href":"/ko/docs/13-reference/","title":"참고 자료","section":"Docs","content":" 참고 자료 # WebRTC(W3C) # WebRTC 1.0: Real-Time Communication Between Browsers [2021-01-26] (Status: Recommendation) Web Real-Time Communications Working Group - Publications WebRTC(RFC) # RFC8825: Overview: Real-Time Protocols for Browser-Based Applications H. Alvestrand [2021-01] (Status: PROPOSED STANDARD) RFC8826: Security Considerations for WebRTC E. Rescorla [2021-01] (Status: PROPOSED STANDARD) RFC8836: Congestion Control Requirements for Interactive Real-Time Media R. Jesup, Z. Sarker [2021-01] (Status: INFORMATIONAL) RFC8854: WebRTC Forward Error Correction Requirements J. Uberti [2021-01] (Status: PROPOSED STANDARD) DTLS # RFC6347: Datagram Transport Layer Security Version 1.2 E. Rescorla, N. Modadugu [2012-01] (Obsoletes RFC4347) (Obsoleted-By RFC9147) (Updated-By RFC7507, RFC7905, RFC8996, RFC9146) (Status: PROPOSED STANDARD) RFC9147: The Datagram Transport Layer Security (DTLS) Protocol Version 1.3 E. Rescorla, H. Tschofenig, N. Modadugu [2022-04] (Obsoletes RFC6347) (Status: PROPOSED STANDARD) (See also: OpenSSL DTLS 1.3 status) DataChannel # RFC8831: WebRTC Data Channels R. Jesup, S. Loreto, M. Tüxen [2021-01] (Status: PROPOSED STANDARD) RFC8832: WebRTC Data Channel Establishment Protocol R. Jesup, S. Loreto, M. Tüxen [2021-01] (Status: PROPOSED STANDARD) RFC8864: Negotiation Data Channels Using the Session Description Protocol (SDP) K. Drage, M. Makaraju, R. Ejzak, J. Marcon, R. Even [2021-01] (Status: PROPOSED STANDARD) MediaTransport # RFC8834: Media Transport and Use of RTP in WebRTC C. Perkins, M. Westerlund, J. Ott [2021-01] (Status: PROPOSED STANDARD) RFC8837: Differentiated Services Code Point (DSCP) Packet Markings for WebRTC QoS P. Jones, S. Dhesikan, C. Jennings, D. Druta [2021-01] (Status: PROPOSED STANDARD) SCTP # RFC3758: Stream Control Transmission Protocol (SCTP) Partial Reliability Extension R. Stewart, M. Ramalho, Q. Xie, M. Tuexen, P. Conrad [2004-05] (Status: PROPOSED STANDARD) RFC5061: Stream Control Transmission Protocol (SCTP) Dynamic Address Reconfiguration R. Stewart, Q. Xie, M. Tuexen, S. Maruyama, M. Kozuka [2007-09] (Status: PROPOSED STANDARD) RFC5827: Early Retransmit for TCP and Stream Control Transmission Protocol (SCTP) M. Allman, K. Avrachenkov, U. Ayesta, J. Blanton, P. Hurtig [2010-05] (Status: EXPERIMENTAL) RFC6083: Datagram Transport Layer Security (DTLS) for Stream Control Transmission Protocol (SCTP) M. Tuexen, R. Seggelmann, E. Rescorla [2011-01] (Updated-By RFC8996) (Status: PROPOSED STANDARD) RFC6525: Stream Control Transmission Protocol (SCTP) Stream Reconfiguration R. Stewart, M. Tuexen, P. Lei [2012-02] (Status: PROPOSED STANDARD) RFC6951: UDP Encapsulation of Stream Control Transmission Protocol (SCTP) Packets for End-Host to End-Host Communication M. Tuexen, R. Stewart [2013-05] (Updated-By RFC8899) (Status: PROPOSED STANDARD) RFC7765: TCP and Stream Control Transmission Protocol (SCTP) RTO Restart P. Hurtig, A. Brunstrom, A. Petlund, M. Welzl [2016-02] (Status: EXPERIMENTAL) RFC8260: Stream Schedulers and User Message Interleaving for the Stream Control Transmission Protocol R. Stewart, M. Tuexen, S. Loreto, R. Seggelmann [2017-11] (Status: PROPOSED STANDARD) RFC8261: Datagram Transport Layer Security (DTLS) Encapsulation of SCTP Packets M. Tuexen, R. Stewart, R. Jesup, S. Loreto [2017-11] (Updated-By RFC8899, RFC8996) (Status: PROPOSED STANDARD) RFC8841: Session Description Protocol (SDP) Offer/Answer "}]