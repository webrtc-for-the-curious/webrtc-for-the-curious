[{"id":0,"href":"/es/docs/01-what-why-and-how/","title":"¿Qué, Por qué y Cómo?","section":"Docs","content":" ¿Qué, Por qué y Cómo? # ¿Qué es WebRTC? # WebRTC, es la abreviatura de Web Real-Time Communication, es una API como un Protocolo. El protocolo WebRTC es un conjunto de reglas para que dos Agentes WebRTC negocien una comunicación bidireccional segura en tiempo real. Mientras que la WebRTC API permite a los desarrolladores usar el protocolo WebRTC. La WebRTC API es solo para JavaScript.\nUna relación similar sería entre HTTP y la Fetch API. El protocolo WebRTC sería HTTP, y la WebRTC API sería la Fetch API.\nEl protocolo WebRTC está disponible en otros lenguajes además de JavaScript. Puedes encontrar servidores y herramientas de dominio específico para WebRTC. Todas estas implementaciones usan el protocolo WebRTC, así que pueden interactuar entre ellos.\nEl protocolo WebRTC es mantenido en el IETF (Grupo de Trabajo de Ingeniería de Internet) en el grupo de trabajo rtcweb. La WebRTC API es documentada en W3C.\n¿Por qué debería aprender WebRTC? # Estas son algunas cosas que WebRTC te proporcionará:\nEstándar abierto Implementaciones Múltiples Disponibilidad en navegadores web Cifrado obligatorio NAT transversal Reuso de tecnología existente Control de congestión Latencia de menos de un segundo Esta lista no es exhaustiva, solo un ejemplo de algunas de las cosas que podrás apreciar durante el recorrido. No te preocupes si no sabes todos estos términos aún, este libro te enseñará su significado con el tiempo.\nEl protocolo WebRTC es una colección de otras tecnologías # El protocolo WebRTC es un tema inmenso que tomaría un libro entero para explicarlo. Sin embargo, para empezar lo dividiremos en cuatro pasos.\nSeñalización (Signaling) Conexión (Connecting) Seguridad (Securing) Comunicación (Communication) Estos pasos son secuenciales, lo que significa que el paso anterior debe haber sido entendido al 100% para dar comienzo con el siguiente paso.\nUn hecho peculiar de WebRTC es que cada uno de los pasos ¡está hecho de muchos otros protocolos! Para crear WebRTC, nosotros juntamos varias tecnologías ya existentes. En ese sentido, puedes pensar en WebRTC como una combinación y configuración de tecnología bien entendida, que se remonta a principios de la década del 2000 que como un proceso completamente nuevo por derecho propio.\nCada uno de estos pasos tiene un capítulo dedicado, pero ayuda mucho el primero entenderlos a un alto nivel. Ya que dependen del uno al otro, ayudará cuando se explique más el propósito de cada uno de estos pasos.\nSeñalización: ¿Cómo se encuentran los puntos de conexión entre ellos en WebRTC? # Cuando un agente de WebRTC es iniciado, no tiene ni idea de con quién se va a comunicar o que es lo que van a comunicar. ¡La Señalización resuelve este problema! La señalización es usada para arrancar la llamada, permitiendo dos Agentes independientes de WebRTC empezar a comunicarse.\nLa señalización usa un protocolo de texto plano, llamado SDP (Protocolo de descripción de Sesión). Cada mensaje SDP está hecho de una llave y un valor, y contiene una lista de \u0026ldquo;sección de medios\u0026rdquo;. El SDP que intercambian los dos Agentes WebRTC contiene detalles como:\nLas IPs y Puertos que el agente es accesible (es candidato). El número de pistas de audio y vídeo que el agente desea mandar. Los códecs de audio y vídeo que cada agente soporta. Los valores usados mientras se conectaban (uFrag/uPwd). Los valores usados mientras se aseguraban (certificado de huella digital). Es importante tener en cuenta que, la señalización típicamente pasa \u0026ldquo;fuera de banda\u0026rdquo;, lo que significa, aplicaciones que generalmente no usan WebRTC por si mismos para intercambiar mensajes de señalización. Cualquier arquitectura apropiada para mandar mensajes puede transmitir los SDPs entre los puntos de conexión, y muchas aplicaciones simplemente usarán infraestructura existente (ej. REST API, conexiones WebSocket, o servidores proxy de autenticación) para facilitar el comercio de SDPs entre los clientes apropiados.\nConexión y NAT Transversal con STUN/TURN # Una vez, dos Agentes WebRTC han intercambiado SDPs, tendrán la información suficiente para intentar conectarse entre ellos. Para que esto pase, WebRTC usa otra tecnología establecida llamada ICE (Establecimiento de Conectividad Interactiva).\nICE es un protocolo que es más antiguo que WebRTC y permite el establecimiento de una conexión directa entre dos Agentes sin un servidor central. Estos dos Agentes podrían estar en la misma red o en la otra parte del mundo.\nICE permite conexiones directas, pero lo realmente mágico del proceso de conexión, implica un concepto llamado \u0026lsquo;NAT Transversal\u0026rsquo; y el uso de servidores STUN/TURN. Estos dos conceptos, los cuales los exploraremos con más detalle luego, son todo lo que se necesita para comunicarse con un Agente ICE en otra Subred.\nUna vez, los dos Agentes han establecido una conexión ICE satisfactoriamente, WebRTC se mueve al siguiente paso: establecer un transporte cifrado para compartir audio, vídeo y datos entre ellos.\nAsegurando la capa de transporte con DTLS y SRTP # Ahora que tenemos una comunicación bidireccional (vía ICE), ¡necesitamos hacer nuestra comunicación segura! Esto se hace mediante dos o más protocolos que también son más antiguos que WebRTC; DTLS (Seguridad de la capa de transporte de datagramas) y SRTP (Protocolo de Transporte Seguro en Tiempo Real). El primer protocolo, DTLS, es simplemente TSL sobre UDP (TLS es el protocolo de cifrado que se usa para asegurar una comunicación segura vía HTTP). El segundo protocolo, SRTP, se utiliza para garantizar el cifrado de paquetes de datos RTP (Protocolo en Tiempo Real)\nPrimero, WebRTC se conecta haciendo uso de DTLS sobre la conexión establecida por ICE. Diferente a HTTPS, WebRTC no usa una autoridad central para certificados. Simplemente afirma que el certificado intercambiado vía DTLS coincide con la huella digital, compartida por medio de la señalización. Esta conexión DTLS se usa luego para los mensajes de DataChannel.\nDespués, WebRTC usa el protocolo RTP, asegurado usando SRTP, para la transmisión de audio/vídeo. Nosotros inicializamos nuestra sesión SRTP, extrayendo la llave desde la sesión DTLS negociada.\nDiscutiremos por qué los medios y la transmisión de datos tienen sus propios protocolos en los siguientes capítulos, pero por ahora es suficiente para saber que se manejan por separado.\n¡Todo listo! Hemos establecido una comunicación bidireccional y segura exitosamente. Si tienes una conexión estable entre tus agentes WebRTC, esta es toda la complejidad que necesitas. En la siguiente sección, hablaremos sobre como WebRTC trata con los desafortunados problemas del mundo real: la perdida de paquetes y los límites de banda ancha.\nComunicándose con los puntos de conexión vía RTP y SCTP # Ahora que tenemos dos Agentes WebRTC conectados y asegurados y con una comunicación bidireccional establecida, ¡Vamos a comenzar a comunicarnos! Para esto, WebRTC usará dos protocolos ya existentes: RTP (Protocolo de Transport de Tiempo Real), y SCTP (Protocolo de Transmisión de Control de Flujo). Usamos RTP para intercambiar multimedia cifrada con SRTP, y usamos SCTP para mandar y recibir mensajes de DataChannel cifrados con DTLS.\nRTP es casi un protocolo pequeño, pero provee las herramientas necesarias para implementar transmisión en tiempo real. Lo más importante acerca de RTP es que le da flexibilidad a el desarrollador, permitiéndoles manejar la latencia, la perdida de paquetes, y la congestión como ellos gusten. Discutiremos acerca de esto en el capítulo de multimedia.\nEl protocolo final en el conjunto es SCTP. Lo importante acerca de este, es que permite la entrega de mensajes no confiables y fuera de servicio (entre muchas diferentes opciones). Esto permite a los desarrolladores asegurar la latencia necesaria para sistemas de tiempo real.\nWebRTC, una colección de protocolos # WebRTC resuelve muchos problemas. A primera vista, la tecnología puede parecer sobre-diseñada, pero la genialidad de WebRTC es su humildad. No fue creado bajo la suposición de que podría resolver todo mejor. En cambio, abarcó muchas tecnologías existentes de un solo propósito y las reunió en un paquete simplificado y ampliamente aplicable.\nEsto nos permite examinar y aprender cada parte individualmente sin abrumarse. Una buena manera de visualizarlo es que un \u0026lsquo;Agente WebRTC\u0026rsquo; es solamente un intermediario de muchos protocolos diferentes.\n¿Cómo funciona WebRTC (la API)? # Esta sección describe como la API JavaScript de WebRTC se asigna al protocolo WebRTC descrito anteriormente. No pretende ser una demostración extensa de la API de WebRTC, pero si crear un modelo mental de como todo se une. Si no estás familiarizado con ningún protocolo o la API, no te preocupes. ¡Esta podría ser una sección divertida a la que regresar cuando aprendas más!\nnew RTCPeerConnection # La RTCPeerConnection es la \u0026ldquo;Sesión WebRTC\u0026rdquo; de nivel superior. Esta contiene todos los protocolos mencionados anteriormente. Los subsistemas están asignados pero todavía no pasa nada.\naddTrack # addTrack crea un nuevo secuencia RTP. Una Fuente de Sincronización Aleatoria (SSRC) será generada para esta secuencia. Esta secuencia estará dentro de la Descripción de la Sesión, generada por createOffer dentro de la sección de multimedia. Cada llamada a addTrack creará una nueva sección multimedia y SSRC.\nInmediatamente después de que una sesión SRTP es establecida, estos paquetes multimedia comenzarán a ser cifrados usando SRTP y enviados vía ICE.\ncreateDataChannel # createDataChannel crea una nueva secuencia SCTP si no existe ninguna asociación SCTP. SCTP no está activado por defecto. Solo se inicia cuando un lado solicita un canal de datos.\nInmediatamente después de que una sesión DTLS es establecida, la asociación SCTP comenzará a enviar paquetes cifrados con DTLS vía ICE.\ncreateOffer # createOffer genera una Descripción de la Sesión del estado local para ser compartido con el punto de conexión remoto.\nEl acto de llamar createOffer no cambia nada para el punto de conexión local.\nsetLocalDescription # setLocalDescription confirma cualquier cambio de solicitud. Las llamadas a addTrack, createDataChannel, y similares, son temporales hasta esta convocatoria. setLocalDescription es llamada con el valor generado por createOffer.\nUsualmente, después de esta convocatoria, tu enviarás la oferta a el punto de conexión remoto, el cual lo usará para llamar a setRemoteDescription.\nsetRemoteDescription # setRemoteDescription es la forma con la que informamos al agente local acerca del estado del candidato remoto. Asi es como se hace el acto de \u0026lsquo;Señalización\u0026rsquo; con la API de JavaScript.\nCuando setRemoteDescription fue llamado en ambos lados, ¡los Agentes WebRTC ahora tienen la suficiente información para comenzar una comunicación Peer-To-Peer (P2P)!\naddIceCandidate # addIceCandidate permite a el agente WebRTC añadir más Candidatos remotos ICE en cualquier momento. Esta API envía el Candidato ICE directamente al subsistema ICE y no tiene ningún otro efecto en la conexión WebRTC mayor.\nontrack # ontrack es una llamada que se activa cuando se recibe un paquete RTP del punto de conexión remoto. Los paquetes entrantes habría sido declarado en la descripción de la sesión que se pasó a setRemoteDescription.\nWebRTC usa el SSRC y busca MediaStream y MediaStreamTrack asociados y activa esta llamada con estos detalles completados.\noniceconnectionstatechange # oniceconnectionstatechange es una llamada que refleja un cambio en el estado de un agente ICE. Cuando tiene un cambio en la conectividad de la red, así es como se le notifica.\nonconnectionstatechange # onconnectionstatechange es una combinación de los estados de los agentes ICE y DTLS. Puedes ver esto para recibir una notificación cuando ICE y DTLS se hayan completado con éxito.\n"},{"id":1,"href":"/es/docs/02-signaling/","title":"Señalización","section":"Docs","content":" Señalización # ¿Qué es la Señalización de WebRTC? # Cuando creas un agente WebRTC, no sabe nada sobre el otro par. ¡No tiene idea de con quién se va a conectar o qué van a enviar! La señalización es el proceso inicial de arranque que hace posible una llamada. Después de que estos valores se intercambian, los agentes WebRTC pueden comunicarse directamente entre sí.\nLos mensajes de señalización son simplemente texto. A los agentes WebRTC no les importa cómo se transportan. Comúnmente se comparten a través de Websockets, pero eso no es un requisito.\n¿Cómo funciona la señalización de WebRTC? # WebRTC utiliza un protocolo existente llamado Protocolo de Descripción de Sesión (Session Description Protocol). A través de este protocolo, los dos agentes WebRTC compartirán todo el estado requerido para establecer una conexión. El protocolo en sí es simple de leer y entender. La complejidad proviene de comprender todos los valores con los que WebRTC lo completa.\nEste protocolo no es específico de WebRTC. Primero aprenderemos el Protocolo de Descripción de Sesión sin siquiera hablar de WebRTC. WebRTC realmente solo aprovecha un subconjunto del protocolo, por lo que solo vamos a cubrir lo que necesitamos. Después de que entendamos el protocolo, pasaremos a su uso aplicado en WebRTC.\n¿Qué es el Protocolo de Descripción de Sesión (SDP)? # El Protocolo de Descripción de Sesión está definido en RFC 8866. Es un protocolo de clave/valor con una nueva línea después de cada valor. Se sentirá similar a un archivo INI. Una Descripción de Sesión contiene cero o más Descripciones de Medios. Mentalmente puedes modelarlo como una Descripción de Sesión que contiene un array de Descripciones de Medios.\nUna Descripción de Medios generalmente se mapea a un solo flujo de medios. Así que si quisieras describir una llamada con tres flujos de video y dos pistas de audio tendrías cinco Descripciones de Medios.\nCómo leer el SDP # Cada línea en una Descripción de Sesión comenzará con un solo carácter, esta es tu clave. Luego será seguida por un signo igual. Todo después de ese signo igual es el valor. Después de que el valor esté completo, tendrás una nueva línea.\nEl Protocolo de Descripción de Sesión define todas las claves que son válidas. Solo puedes usar letras para claves como se define en el protocolo. Estas claves tienen un significado importante, que se explicará más adelante.\nToma este extracto de Descripción de Sesión:\na=my-sdp-value a=second-value Tienes dos líneas. Cada una con la clave a. La primera línea tiene el valor my-sdp-value, la segunda línea tiene el valor second-value.\nWebRTC solo usa algunas claves SDP # No todos los valores de clave definidos por el Protocolo de Descripción de Sesión son utilizados por WebRTC. Solo las claves usadas en el Protocolo de Establecimiento de Sesión de JavaScript (JSEP), definido en RFC 8829, son importantes. Las siguientes siete claves son las únicas que necesitas entender ahora mismo:\nv - Versión, debería ser igual a 0. o - Origen, contiene un ID único útil para renegociaciones. s - Nombre de Sesión, debería ser igual a -. t - Temporización, debería ser igual a 0 0. m - Descripción de Medios (m=\u0026lt;media\u0026gt; \u0026lt;port\u0026gt; \u0026lt;proto\u0026gt; \u0026lt;fmt\u0026gt; ...), descrito en detalle más abajo. a - Atributo, un campo de texto libre. Esta es la línea más común en WebRTC. c - Datos de Conexión, debería ser igual a IN IP4 0.0.0.0. Descripciones de Medios en una Descripción de Sesión # Una Descripción de Sesión puede contener un número ilimitado de Descripciones de Medios.\nUna definición de Descripción de Medios contiene una lista de formatos. Estos formatos se mapean a Tipos de Carga Útil RTP. El códec real se define luego por un Atributo con el valor rtpmap en la Descripción de Medios. La importancia de RTP y los Tipos de Carga Útil RTP se discute más adelante en el capítulo de Medios. Cada Descripción de Medios puede contener un número ilimitado de atributos.\nToma este extracto de Descripción de Sesión como ejemplo:\nv=0 m=audio 4000 RTP/AVP 111 a=rtpmap:111 OPUS/48000/2 m=video 4000 RTP/AVP 96 a=rtpmap:96 VP8/90000 a=my-sdp-value Tienes dos Descripciones de Medios, una de tipo audio con fmt 111 y una de tipo video con el formato 96. La primera Descripción de Medios tiene solo un atributo. Este atributo mapea el Tipo de Carga Útil 111 a Opus. La segunda Descripción de Medios tiene dos atributos. El primer atributo mapea el Tipo de Carga Útil 96 a VP8, y el segundo atributo es solo my-sdp-value.\nEjemplo Completo # Lo siguiente reúne todos los conceptos de los que hemos hablado. Estas son todas las características del Protocolo de Descripción de Sesión que WebRTC utiliza. ¡Si puedes leer esto, puedes leer cualquier Descripción de Sesión de WebRTC!\nv=0 o=- 0 0 IN IP4 127.0.0.1 s=- c=IN IP4 127.0.0.1 t=0 0 m=audio 4000 RTP/AVP 111 a=rtpmap:111 OPUS/48000/2 m=video 4002 RTP/AVP 96 a=rtpmap:96 VP8/90000 v, o, s, c, t están definidos, pero no afectan la sesión WebRTC. Tienes dos Descripciones de Medios. Una de tipo audio y una de tipo video. Cada una de esas tiene un atributo. Este atributo configura detalles del pipeline RTP, que se discute en el capítulo \u0026ldquo;Comunicación de Medios\u0026rdquo;. Cómo funcionan juntos el Protocolo de Descripción de Sesión y WebRTC # La siguiente pieza del rompecabezas es entender cómo WebRTC usa el Protocolo de Descripción de Sesión.\n¿Qué son las Ofertas y Respuestas? # WebRTC usa un modelo de oferta/respuesta. Todo esto significa que un agente WebRTC hace una \u0026ldquo;Oferta\u0026rdquo; para iniciar una llamada, y el otro agente WebRTC \u0026ldquo;Responde\u0026rdquo; si está dispuesto a aceptar lo que se ha ofrecido.\nEsto le da al que responde la oportunidad de rechazar códecs no soportados en las Descripciones de Medios. Así es como dos pares pueden entender qué formatos están dispuestos a intercambiar.\nLos Transceivers son para enviar y recibir # Transceivers es un concepto específico de WebRTC que verás en la API. Lo que está haciendo es exponer la \u0026ldquo;Descripción de Medios\u0026rdquo; a la API de JavaScript. Cada Descripción de Medios se convierte en un Transceiver. Cada vez que creas un Transceiver se agrega una nueva Descripción de Medios a la Descripción de Sesión local.\nCada Descripción de Medios en WebRTC tendrá un atributo de dirección. Esto permite que un agente WebRTC declare \u0026ldquo;Voy a enviarte este códec, pero no estoy dispuesto a aceptar nada de vuelta\u0026rdquo;. Hay cuatro valores válidos:\nsend recv sendrecv inactive Valores SDP utilizados por WebRTC # Esta es una lista de algunos atributos comunes que verás en una Descripción de Sesión de un agente WebRTC. Muchos de estos valores controlan los subsistemas que aún no hemos discutido.\ngroup:BUNDLE # El empaquetamiento (Bundling) es el acto de ejecutar múltiples tipos de tráfico sobre una conexión. Algunas implementaciones de WebRTC usan una conexión dedicada por flujo de medios. El empaquetamiento debería ser preferido.\nfingerprint:sha-256 # Este es un hash del certificado que un par está usando para DTLS. Después de que se completa el handshake DTLS, comparas esto con el certificado real para confirmar que te estás comunicando con quien esperas.\nsetup: # Esto controla el comportamiento del agente DTLS. Esto determina si se ejecuta como un cliente o servidor después de que ICE se haya conectado. Los valores posibles son:\nsetup:active - Ejecutar como Cliente DTLS. setup:passive - Ejecutar como Servidor DTLS. setup:actpass - Pedir al otro agente WebRTC que elija. mid # El atributo \u0026ldquo;mid\u0026rdquo; se usa para identificar flujos de medios dentro de una descripción de sesión.\nice-ufrag # Este es el valor de fragmento de usuario para el agente ICE. Usado para la autenticación del tráfico ICE.\nice-pwd # Esta es la contraseña para el agente ICE. Usado para la autenticación del tráfico ICE.\nrtpmap # Este valor se usa para mapear un códec específico a un Tipo de Carga Útil RTP. Los tipos de carga útil no son estáticos, así que para cada llamada el oferente decide los tipos de carga útil para cada códec.\nfmtp # Define valores adicionales para un Tipo de Carga Útil. Esto es útil para comunicar un perfil de video específico o configuración de codificador.\ncandidate # Este es un Candidato ICE que proviene del agente ICE. Esta es una posible dirección en la que el agente WebRTC está disponible. Estos se explican completamente en el siguiente capítulo.\nssrc # Una Fuente de Sincronización (SSRC) define una única pista de flujo de medios.\nlabel es el ID para este flujo individual. mslabel es el ID para un contenedor que puede tener múltiples flujos dentro de él.\nEjemplo de una Descripción de Sesión de WebRTC # Lo siguiente es una Descripción de Sesión completa generada por un cliente WebRTC:\nv=0 o=- 3546004397921447048 1596742744 IN IP4 0.0.0.0 s=- t=0 0 a=fingerprint:sha-256 0F:74:31:25:CB:A2:13:EC:28:6F:6D:2C:61:FF:5D:C2:BC:B9:DB:3D:98:14:8D:1A:BB:EA:33:0C:A4:60:A8:8E a=group:BUNDLE 0 1 m=audio 9 UDP/TLS/RTP/SAVPF 111 c=IN IP4 0.0.0.0 a=setup:active a=mid:0 a=ice-ufrag:CsxzEWmoKpJyscFj a=ice-pwd:mktpbhgREmjEwUFSIJyPINPUhgDqJlSd a=rtcp-mux a=rtcp-rsize a=rtpmap:111 opus/48000/2 a=fmtp:111 minptime=10;useinbandfec=1 a=ssrc:350842737 cname:yvKPspsHcYcwGFTw a=ssrc:350842737 msid:yvKPspsHcYcwGFTw DfQnKjQQuwceLFdV a=ssrc:350842737 mslabel:yvKPspsHcYcwGFTw a=ssrc:350842737 label:DfQnKjQQuwceLFdV a=msid:yvKPspsHcYcwGFTw DfQnKjQQuwceLFdV a=sendrecv a=candidate:foundation 1 udp 2130706431 192.168.1.1 53165 typ host generation 0 a=candidate:foundation 2 udp 2130706431 192.168.1.1 53165 typ host generation 0 a=candidate:foundation 1 udp 1694498815 1.2.3.4 57336 typ srflx raddr 0.0.0.0 rport 57336 generation 0 a=candidate:foundation 2 udp 1694498815 1.2.3.4 57336 typ srflx raddr 0.0.0.0 rport 57336 generation 0 a=end-of-candidates m=video 9 UDP/TLS/RTP/SAVPF 96 c=IN IP4 0.0.0.0 a=setup:active a=mid:1 a=ice-ufrag:CsxzEWmoKpJyscFj a=ice-pwd:mktpbhgREmjEwUFSIJyPINPUhgDqJlSd a=rtcp-mux a=rtcp-rsize a=rtpmap:96 VP8/90000 a=ssrc:2180035812 cname:XHbOTNRFnLtesHwJ a=ssrc:2180035812 msid:XHbOTNRFnLtesHwJ JgtwEhBWNEiOnhuW a=ssrc:2180035812 mslabel:XHbOTNRFnLtesHwJ a=ssrc:2180035812 label:JgtwEhBWNEiOnhuW a=msid:XHbOTNRFnLtesHwJ JgtwEhBWNEiOnhuW a=sendrecv Esto es lo que sabemos de este mensaje:\nTenemos dos secciones de medios, una de audio y una de video. Ambas son transceivers sendrecv. Estamos recibiendo dos flujos, y podemos enviar dos de vuelta. Tenemos Candidatos ICE y detalles de Autenticación, así que podemos intentar conectarnos. Tenemos una huella digital de certificado, así que podemos tener una llamada segura. Temas Adicionales # En versiones posteriores de este libro, también se abordarán los siguientes temas:\nRenegociación Simulcast "},{"id":2,"href":"/es/docs/03-connecting/","title":"Conexión","section":"Docs","content":" Conexión # ¿Por qué WebRTC necesita un subsistema dedicado para conectarse? # La mayoría de las aplicaciones implementadas hoy en día establecen conexiones cliente/servidor. Una conexión cliente/servidor requiere que el servidor tenga una dirección de transporte estable y bien conocida. Un cliente contacta a un servidor, y el servidor responde.\nWebRTC no usa un modelo cliente/servidor, establece conexiones peer-to-peer (P2P). En una conexión P2P, la tarea de crear una conexión se distribuye equitativamente entre ambos pares. Esto se debe a que una dirección de transporte (IP y puerto) en WebRTC no se puede asumir, e incluso puede cambiar durante la sesión. WebRTC recopilará toda la información que pueda e irá a grandes esfuerzos para lograr comunicación bidireccional entre dos Agentes WebRTC.\nSin embargo, establecer conectividad peer-to-peer puede ser difícil. Estos agentes podrían estar en diferentes redes sin conectividad directa. En situaciones donde existe conectividad directa, aún puedes tener otros problemas. En algunos casos, tus clientes no hablan los mismos protocolos de red (UDP \u0026lt;-\u0026gt; TCP) o tal vez usan diferentes versiones de IP (IPv4 \u0026lt;-\u0026gt; IPv6).\nA pesar de estas dificultades para establecer una conexión P2P, obtienes ventajas sobre la tecnología cliente/servidor tradicional debido a los siguientes atributos que WebRTC ofrece.\nCostos de Ancho de Banda Reducidos # Dado que la comunicación de medios ocurre directamente entre pares, no tienes que pagar por, u hospedar un servidor separado para transmitir medios.\nMenor Latencia # La comunicación es más rápida cuando es directa. Cuando un usuario tiene que ejecutar todo a través de tu servidor, hace que las transmisiones sean más lentas.\nComunicación E2E Segura # La comunicación directa es más segura. Dado que los usuarios no están enrutando datos a través de tu servidor, ni siquiera necesitan confiar en que no los descifrarás.\n¿Cómo funciona? # El proceso descrito anteriormente se llama Establecimiento de Conectividad Interactiva (ICE). Otro protocolo que es anterior a WebRTC.\nICE es un protocolo que intenta encontrar la mejor manera de comunicarse entre dos Agentes ICE. Cada Agente ICE publica las formas en que es accesible, estas se conocen como candidatos. Un candidato es esencialmente una dirección de transporte del agente que cree que el otro par puede alcanzar. ICE entonces determina el mejor emparejamiento de candidatos.\nEl proceso ICE real se describe con mayor detalle más adelante en este capítulo. Para entender por qué existe ICE, es útil entender qué comportamientos de red estamos superando.\nRestricciones de redes del mundo real # ICE se trata de superar las restricciones de las redes del mundo real. Antes de explorar la solución, hablemos de los problemas reales.\nNo en la misma red # La mayor parte del tiempo el otro Agente WebRTC ni siquiera estará en la misma red. Una llamada típica suele ser entre dos Agentes WebRTC en diferentes redes sin conectividad directa.\nA continuación se muestra un gráfico de dos redes distintas, conectadas a través de Internet público. En cada red tienes dos hosts.\nPara los hosts en la misma red es muy fácil conectarse. ¡La comunicación entre 192.168.0.1 -\u0026gt; 192.168.0.2 es fácil de hacer! Estos dos hosts pueden conectarse entre sí sin ninguna ayuda externa.\nSin embargo, un host usando Router B no tiene forma de acceder directamente a nada detrás de Router A. ¿Cómo distinguirías entre 192.168.0.1 detrás de Router A y la misma IP detrás de Router B? ¡Son IPs privadas! Un host usando Router B podría enviar tráfico directamente a Router A, pero la solicitud terminaría ahí. ¿Cómo sabe Router A a qué host debe reenviar el mensaje?\nRestricciones de Protocolo # Algunas redes no permiten tráfico UDP en absoluto, o tal vez no permiten TCP. Algunas redes pueden tener un MTU (Unidad Máxima de Transmisión) muy bajo. Hay muchas variables que los administradores de red pueden cambiar que pueden dificultar la comunicación.\nReglas de Firewall/IDS # Otra es la \u0026ldquo;Inspección Profunda de Paquetes\u0026rdquo; y otro filtrado inteligente. Algunos administradores de red ejecutarán software que intenta procesar cada paquete. Muchas veces este software no entiende WebRTC, por lo que lo bloquea porque no sabe qué hacer, por ejemplo, tratando los paquetes WebRTC como paquetes UDP sospechosos en un puerto arbitrario que no está en la lista blanca.\nMapeo NAT # El mapeo NAT (Traducción de Direcciones de Red) es la magia que hace posible la conectividad de WebRTC. Así es como WebRTC permite que dos pares en subredes completamente diferentes se comuniquen, abordando el problema de \u0026ldquo;no en la misma red\u0026rdquo; anterior. Si bien crea nuevos desafíos, expliquemos cómo funciona el mapeo NAT en primer lugar.\nNo utiliza un relé, proxy o servidor. Nuevamente tenemos Agente 1 y Agente 2 y están en diferentes redes. Sin embargo, el tráfico fluye completamente. Visualizado se ve así:\nPara que esta comunicación suceda, estableces un mapeo NAT. El Agente 1 usa el puerto 7000 para establecer una conexión WebRTC con el Agente 2. Esto crea un enlace de 192.168.0.1:7000 a 5.0.0.1:7000. Esto permite que el Agente 2 alcance al Agente 1 enviando paquetes a 5.0.0.1:7000. Crear un mapeo NAT como en este ejemplo es como una versión automatizada de hacer reenvío de puertos en tu enrutador.\nLa desventaja del mapeo NAT es que no hay una sola forma de mapeo (por ejemplo, reenvío de puertos estático), y el comportamiento es inconsistente entre redes. Los ISP y fabricantes de hardware pueden hacerlo de diferentes maneras. En algunos casos, los administradores de red pueden incluso deshabilitarlo.\nLa buena noticia es que se entiende y observa el rango completo de comportamientos, por lo que un Agente ICE puede confirmar que creó un mapeo NAT y los atributos del mapeo.\nEl documento que describe estos comportamientos es RFC 4787.\nCrear un mapeo # Crear un mapeo es la parte más fácil. ¡Cuando envías un paquete a una dirección fuera de tu red, se crea un mapeo! Un mapeo NAT es solo una IP pública temporal y un puerto que es asignado por tu NAT. El mensaje saliente se reescribirá para tener su dirección de origen dada por la dirección de mapeo recién creada. Si se envía un mensaje al mapeo, se enrutará automáticamente de vuelta al host dentro del NAT que lo creó. Los detalles sobre los mapeos es donde se vuelve complicado.\nComportamientos de Creación de Mapeos # La creación de mapeos se divide en tres categorías diferentes:\nMapeo Independiente del Punto Final # Se crea un mapeo para cada remitente dentro del NAT. Si envías dos paquetes a dos direcciones remotas diferentes, el mapeo NAT se reutilizará. Ambos hosts remotos verían la misma IP y puerto de origen. Si los hosts remotos responden, se enviaría de vuelta al mismo oyente local.\nEste es el mejor escenario posible. Para que una llamada funcione, al menos un lado DEBE ser de este tipo.\nMapeo Dependiente de la Dirección # Se crea un nuevo mapeo cada vez que envías un paquete a una nueva dirección. Si envías dos paquetes a diferentes hosts, se crearán dos mapeos. Si envías dos paquetes al mismo host remoto pero diferentes puertos de destino, NO se creará un nuevo mapeo.\nMapeo Dependiente de Dirección y Puerto # Se crea un nuevo mapeo si la IP o el puerto remoto es diferente. Si envías dos paquetes al mismo host remoto, pero diferentes puertos de destino, se creará un nuevo mapeo.\nComportamientos de Filtrado de Mapeos # El filtrado de mapeos son las reglas sobre quién puede usar el mapeo. Se dividen en tres clasificaciones similares:\nFiltrado Independiente del Punto Final # Cualquiera puede usar el mapeo. Puedes compartir el mapeo con múltiples otros pares, y todos podrían enviar tráfico a él.\nFiltrado Dependiente de la Dirección # Solo el host para el que se creó el mapeo puede usar el mapeo. Si envías un paquete al host A solo puedes obtener una respuesta de ese mismo host. Si el host B intenta enviar un paquete a ese mapeo, será ignorado.\nFiltrado Dependiente de Dirección y Puerto # Solo el host y puerto para el que se creó el mapeo pueden usar ese mapeo. Si envías un paquete a A:5000 solo puedes obtener una respuesta de ese mismo host y puerto. Si A:5001 intenta enviar un paquete a ese mapeo, será ignorado.\nActualización de Mapeos # Se recomienda que si un mapeo no se usa durante 5 minutos, debe ser destruido. Esto depende completamente del ISP o fabricante de hardware.\nSTUN # STUN (Utilidades de Traversal de Sesión para NAT) es un protocolo que fue creado solo para trabajar con NATs. Esta es otra tecnología que es anterior a WebRTC (¡y a ICE!). Está definido por RFC 8489, que también define la estructura del paquete STUN. El protocolo STUN también es utilizado por ICE/TURN.\nSTUN es útil porque permite la creación programática de Mapeos NAT. Antes de STUN, podíamos crear un mapeo NAT, ¡pero no teníamos idea de cuál era la IP y el puerto! STUN no solo te da la capacidad de crear un mapeo, sino que también te da los detalles para que puedas compartirlos con otros, para que puedan enviarte tráfico de vuelta a través del mapeo que acabas de crear.\nComencemos con una descripción básica de STUN. Más tarde, ampliaremos el uso de TURN e ICE. Por ahora, solo vamos a describir el flujo de Solicitud/Respuesta para crear un mapeo. Luego hablaremos sobre cómo obtener los detalles para compartir con otros. Este es el proceso que ocurre cuando tienes un servidor stun: en tus URLs ICE para una PeerConnection de WebRTC. En pocas palabras, STUN ayuda a un punto final detrás de un NAT a descubrir qué mapeo fue creado al pedirle a un servidor STUN fuera del NAT que informe lo que observa.\nEstructura del Protocolo # Cada paquete STUN tiene la siguiente estructura:\n0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ |0 0| STUN Message Type | Message Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Magic Cookie | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | | | Transaction ID (96 bits) | | | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Data | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ Tipo de Mensaje STUN # Cada paquete STUN tiene un tipo. Por ahora, solo nos importan los siguientes:\nSolicitud de Enlace (Binding Request) - 0x0001 Respuesta de Enlace (Binding Response) - 0x0101 Para crear un mapeo NAT hacemos una Solicitud de Enlace. Luego el servidor responde con una Respuesta de Enlace.\nLongitud del Mensaje # Esto es cuán larga es la sección Data. Esta sección contiene datos arbitrarios que son definidos por el Tipo de Mensaje.\nMagic Cookie # El valor fijo 0x2112A442 en orden de bytes de red, ayuda a distinguir el tráfico STUN de otros protocolos.\nID de Transacción # Un identificador de 96 bits que identifica únicamente una solicitud/respuesta. Esto te ayuda a emparejar tus solicitudes y respuestas.\nData # Data contendrá una lista de atributos STUN. Un Atributo STUN tiene la siguiente estructura:\n0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Type | Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Value (variable) .... +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ La Solicitud de Enlace STUN no usa atributos. Esto significa que una Solicitud de Enlace STUN contiene solo el encabezado.\nLa Respuesta de Enlace STUN usa un XOR-MAPPED-ADDRESS (0x0020). Este atributo contiene una IP y puerto. ¡Esta es la IP y el puerto del mapeo NAT que se crea!\nCrear un Mapeo NAT # ¡Crear un mapeo NAT usando STUN solo requiere enviar una solicitud! Envías una Solicitud de Enlace STUN al Servidor STUN. El Servidor STUN entonces responde con una Respuesta de Enlace STUN. Esta Respuesta de Enlace STUN contendrá la Dirección Mapeada. La Dirección Mapeada es cómo el Servidor STUN te ve y es tu mapeo NAT. La Dirección Mapeada es lo que compartirías si quisieras que alguien te envíe paquetes.\nLa gente también llamará a la Dirección Mapeada tu IP Pública o Candidato Reflexivo del Servidor.\nDeterminar el Tipo de NAT # Desafortunadamente, la Dirección Mapeada puede no ser útil en todos los casos. Si es Dependiente de la Dirección, solo el servidor STUN puede enviarte tráfico de vuelta. Si la compartes y otro par intenta enviar mensajes, serán descartados. Esto lo hace inútil para comunicarse con otros. Puedes encontrar que el caso Dependiente de la Dirección es de hecho solucionable, ¡si el host que ejecuta el servidor STUN también puede reenviar paquetes para ti al par! Esto nos lleva a la solución usando TURN a continuación.\nRFC 5780 define un método para ejecutar una prueba para determinar tu Tipo de NAT. Esto es útil porque sabrías de antemano si la conectividad directa es posible.\nTURN # TURN (Traversal Usando Relés alrededor de NAT) está definido en RFC 8656 y es la solución cuando la conectividad directa no es posible. Puede ser porque tienes dos Tipos de NAT que son incompatibles, ¡o tal vez no pueden hablar el mismo protocolo! TURN también se puede usar para propósitos de privacidad. Al ejecutar toda tu comunicación a través de TURN, ocultas la dirección real del cliente.\nTURN usa un servidor dedicado. Este servidor actúa como un proxy para un cliente. El cliente se conecta a un Servidor TURN y crea una Asignación. Al crear una asignación, un cliente obtiene un IP/Puerto/Protocolo temporal que se puede usar para enviar tráfico de vuelta al cliente. Este nuevo oyente se conoce como la Dirección de Transporte Retransmitida. ¡Piensa en ella como una dirección de reenvío, la das para que otros puedan enviarte tráfico a través de TURN! Para cada par al que le das la Dirección de Transporte de Relé, debes crear un nuevo Permiso para permitir la comunicación contigo.\nCuando envías tráfico saliente a través de TURN, se envía a través de la Dirección de Transporte Retransmitida. Cuando un par remoto recibe tráfico, lo ve venir del Servidor TURN.\nCiclo de Vida de TURN # Lo siguiente es todo lo que un cliente que desea crear una asignación TURN tiene que hacer. Comunicarse con alguien que está usando TURN no requiere cambios. El otro par obtiene una IP y puerto, y se comunica con ella como cualquier otro host.\nAsignaciones # Las asignaciones están en el núcleo de TURN. Una asignación es básicamente una \u0026ldquo;Sesión TURN\u0026rdquo;. Para crear una asignación TURN, te comunicas con la Dirección de Transporte del Servidor TURN (generalmente puerto 3478).\nAl crear una asignación, necesitas proporcionar lo siguiente:\nNombre de Usuario/Contraseña - Crear asignaciones TURN requiere autenticación. Transporte de Asignación - El protocolo de transporte entre el servidor (Dirección de Transporte Retransmitida) y los pares, puede ser UDP o TCP. Even-Port - Puedes solicitar puertos secuenciales para múltiples asignaciones, no relevante para WebRTC. Si la solicitud tuvo éxito, obtienes una respuesta del Servidor TURN con los siguientes Atributos STUN en la sección Data:\nXOR-MAPPED-ADDRESS - Dirección Mapeada del Cliente TURN. Cuando alguien envía datos a la Dirección de Transporte Retransmitida, aquí es donde se reenvía. RELAYED-ADDRESS - Esta es la dirección que das a otros clientes. Si alguien envía un paquete a esta dirección, se retransmite al cliente TURN. LIFETIME - Cuánto tiempo hasta que esta Asignación TURN sea destruida. Puedes extender el tiempo de vida enviando una solicitud Refresh. Permisos # Un host remoto no puede enviar a tu Dirección de Transporte Retransmitida hasta que crees un permiso para ellos. Cuando creas un permiso, le estás diciendo al servidor TURN que esta IP y puerto pueden enviar tráfico entrante.\nEl host remoto necesita darte la IP y el puerto tal como aparece en el servidor TURN. Esto significa que debe enviar una Solicitud de Enlace STUN al Servidor TURN. Un caso de error común es que un host remoto enviará una Solicitud de Enlace STUN a un servidor diferente. Luego te pedirán que crees un permiso para esta IP.\nDigamos que quieres crear un permiso para un host detrás de un Mapeo Dependiente de la Dirección. Si generas la Dirección Mapeada desde un servidor TURN diferente, todo el tráfico entrante será descartado. Cada vez que se comunican con un host diferente, genera un nuevo mapeo. Los permisos expiran después de 5 minutos si no se actualizan.\nSendIndication/ChannelData # Estos dos mensajes son para que el Cliente TURN envíe mensajes a un par remoto.\nSendIndication es un mensaje autocontenido. Dentro está los datos que deseas enviar, y a quién deseas enviarlo. Esto es derrochador si estás enviando muchos mensajes a un par remoto. Si envías 1,000 mensajes repetirás su Dirección IP 1,000 veces.\nChannelData te permite enviar datos, pero sin repetir una Dirección IP. Creas un Canal con una IP y puerto. Luego envías con el ChannelId, y la IP y puerto se completarán del lado del servidor. Esta es la mejor opción si estás enviando muchos mensajes.\nActualización # Las asignaciones se destruirán automáticamente. El Cliente TURN debe actualizarlas antes del LIFETIME dado al crear la asignación.\nUso de TURN # El uso de TURN existe en dos formas. Usualmente, tienes un par actuando como un \u0026ldquo;Cliente TURN\u0026rdquo; y el otro lado comunicándose directamente. En algunos casos, puedes tener uso de TURN en ambos lados, por ejemplo, porque ambos clientes están en redes que bloquean UDP y, por lo tanto, la conexión a los respectivos servidores TURN ocurre a través de TCP.\nEstos diagramas ayudan a ilustrar cómo se vería eso.\nUna Asignación TURN para Comunicación # Dos Asignaciones TURN para Comunicación # ICE # ICE (Establecimiento de Conectividad Interactiva) es cómo WebRTC conecta dos Agentes. Definido en RFC 8445, ¡esta es otra tecnología que es anterior a WebRTC! ICE es un protocolo para establecer conectividad. Determina todas las rutas posibles entre los dos pares y luego asegura que te mantengas conectado.\nEstas rutas se conocen como Pares de Candidatos, que es un emparejamiento de una dirección de transporte local y remota. Aquí es donde STUN y TURN entran en juego con ICE. Estas direcciones pueden ser tu Dirección IP local más un puerto, mapeo NAT, o Dirección de Transporte Retransmitida. Cada lado recopila todas las direcciones que quieren usar, las intercambian, ¡y luego intentan conectarse!\nDos Agentes ICE se comunican usando paquetes de ping ICE (o formalmente llamados verificaciones de conectividad) para establecer conectividad. Después de que se establece la conectividad, pueden enviar los datos que quieran. Será como usar un socket normal. Estas verificaciones usan el protocolo STUN.\nCrear un Agente ICE # Un Agente ICE es Controlador o Controlado. El Agente Controlador es el que decide el Par de Candidatos seleccionado. Generalmente, el par que envía la oferta es el lado controlador.\nCada lado debe tener un fragmento de usuario y una contraseña. Estos dos valores deben intercambiarse antes de que puedan comenzar las verificaciones de conectividad. El fragmento de usuario se envía en texto plano y es útil para demultiplexar múltiples Sesiones ICE. La contraseña se usa para generar un atributo MESSAGE-INTEGRITY. Al final de cada paquete STUN, hay un atributo que es un hash de todo el paquete usando la contraseña como clave. Esto se usa para autenticar el paquete y asegurar que no haya sido manipulado.\nPara WebRTC, todos estos valores se distribuyen a través de la Descripción de Sesión como se describe en el capítulo anterior.\nRecopilación de Candidatos # Ahora necesitamos recopilar todas las direcciones posibles en las que somos accesibles. Estas direcciones se conocen como candidatos.\nHost # Un candidato Host está escuchando directamente en una interfaz local. Esto puede ser UDP o TCP.\nmDNS # Un candidato mDNS es similar a un candidato host, pero la dirección IP está oculta. En lugar de informar al otro lado sobre tu dirección IP, le das un UUID como nombre de host. Luego configuras un oyente de multidifusión y respondes si alguien solicita el UUID que publicaste.\nSi estás en la misma red que el agente, pueden encontrarse entre sí a través de Multidifusión. Si no estás en la misma red, no podrás conectarte (a menos que el administrador de red configuró explícitamente la red para permitir que los paquetes de Multidifusión atraviesen).\nEsto es útil para propósitos de privacidad. Un usuario podría descubrir tu dirección IP local a través de WebRTC con un candidato Host (sin siquiera intentar conectarse a ti), pero con un candidato mDNS, ahora solo obtienen un UUID aleatorio.\nReflexivo del Servidor # Un candidato Reflexivo del Servidor se genera haciendo una Solicitud de Enlace STUN a un Servidor STUN.\nCuando obtienes la Respuesta de Enlace STUN, el XOR-MAPPED-ADDRESS es tu Candidato Reflexivo del Servidor.\nReflexivo del Par # Un candidato Reflexivo del Par se crea cuando el par remoto recibe tu solicitud desde una dirección previamente desconocida para el par. Al recibir, el par informa (refleja) dicha dirección de vuelta a ti. El par sabe que la solicitud fue enviada por ti y no por alguien más porque ICE es un protocolo autenticado.\nEsto comúnmente ocurre cuando un Candidato Host se comunica con un Candidato Reflexivo del Servidor que está en una subred diferente, lo que resulta en la creación de un nuevo mapeo NAT. Recuerda que dijimos que las verificaciones de conectividad son de hecho paquetes STUN. El formato de la respuesta STUN naturalmente permite que un par informe de vuelta la dirección reflexiva del par.\nRelé # Un Candidato de Relé se genera usando un Servidor TURN.\nDespués del handshake inicial con el Servidor TURN, se te da una RELAYED-ADDRESS, este es tu Candidato de Relé.\nVerificaciones de Conectividad # ¡Ahora conocemos el fragmento de usuario, contraseña y candidatos del agente remoto. Ahora podemos intentar conectar! Cada candidato se empareja entre sí. Así que si tienes 3 candidatos en cada lado, ahora tienes 9 pares de candidatos.\nVisualmente se ve así:\nSelección de Candidatos # El Agente Controlador y Controlado comienzan a enviar tráfico en cada par. Esto es necesario si un Agente está detrás de un Mapeo Dependiente de la Dirección, esto causará que se cree un Candidato Reflexivo del Par.\nCada Par de Candidatos que vio tráfico de red es entonces promovido a un par Candidato Válido. El Agente Controlador luego toma un par Candidato Válido y lo nomina. Este se convierte en el Par Nominado. El Agente Controlador y Controlado luego intentan una ronda más de comunicación bidireccional. Si eso tiene éxito, ¡el Par Nominado se convierte en el Par de Candidatos Seleccionado! Este par se usa luego para el resto de la sesión.\nReinicios # Si el Par de Candidatos Seleccionado deja de funcionar por cualquier razón (el mapeo NAT expira, el Servidor TURN falla), el Agente ICE pasará al estado Failed. Ambos agentes pueden reiniciarse y harán todo el proceso de nuevo.\n"},{"id":3,"href":"/es/docs/04-securing/","title":"Seguridad","section":"Docs","content":" Seguridad # ¿Qué seguridad tiene WebRTC? # Cada conexión WebRTC está autenticada y cifrada. Puedes estar seguro de que un tercero no puede ver lo que estás enviando ni insertar mensajes falsos. También puedes estar seguro de que el Agente WebRTC que generó la Descripción de Sesión es con quien te estás comunicando.\nEs muy importante que nadie manipule esos mensajes. Está bien si un tercero lee la Descripción de Sesión en tránsito. Sin embargo, WebRTC no tiene protección contra su modificación. Un atacante podría realizar un ataque de intermediario (man-in-the-middle) cambiando los Candidatos ICE y actualizando la Huella Digital del Certificado.\n¿Cómo funciona? # WebRTC usa dos protocolos preexistentes, Seguridad de la Capa de Transporte de Datagramas (DTLS) y el Protocolo de Transporte en Tiempo Real Seguro (SRTP).\nDTLS te permite negociar una sesión y luego intercambiar datos de forma segura entre dos pares. Es un hermano de TLS, la misma tecnología que impulsa HTTPS, pero DTLS usa UDP en lugar de TCP como capa de transporte. Eso significa que el protocolo tiene que manejar entregas no confiables. SRTP está específicamente diseñado para intercambiar medios de forma segura. Hay algunas optimizaciones que podemos hacer al usarlo en lugar de DTLS.\nDTLS se usa primero. Hace un handshake sobre la conexión proporcionada por ICE. DTLS es un protocolo cliente/servidor, por lo que un lado necesita iniciar el handshake. Los roles de Cliente/Servidor se eligen durante la señalización. Durante el handshake DTLS, ambos lados ofrecen un certificado. Después de que se completa el handshake, este certificado se compara con el hash del certificado en la Descripción de Sesión. Esto es para asegurar que el handshake ocurrió con el Agente WebRTC que esperabas. La conexión DTLS está entonces disponible para ser utilizada para la comunicación DataChannel.\nPara crear una sesión SRTP la inicializamos usando las claves generadas por DTLS. SRTP no tiene un mecanismo de handshake, por lo que tiene que ser iniciado con claves externas. Una vez que esto se hace, ¡los medios pueden ser intercambiados cifrados usando SRTP!\nSeguridad 101 # Para entender la tecnología presentada en este capítulo necesitarás entender estos términos primero. La criptografía es un tema complicado, ¡así que valdría la pena consultar otras fuentes también!\nTexto Plano y Texto Cifrado # El texto plano es la entrada a un cifrador. El texto cifrado es la salida de un cifrador.\nCifrador # Un cifrador es una serie de pasos que lleva el texto plano a texto cifrado. El cifrador puede ser revertido, para que puedas llevar tu texto cifrado de vuelta a texto plano. Un cifrador generalmente tiene una clave para cambiar su comportamiento. Otro término para esto es cifrar y descifrar.\nUn cifrador simple es ROT13. Cada letra se mueve 13 caracteres hacia adelante. Para deshacer el cifrador mueves 13 caracteres hacia atrás. El texto plano HELLO se convertiría en el texto cifrado URYYB. En este caso, el Cifrador es ROT, y la clave es 13.\nFunciones Hash # Una función hash criptográfica es un proceso unidireccional que genera un resumen. Dado una entrada, genera la misma salida cada vez. Es importante que la salida no sea reversible. Si tienes una salida, no deberías poder determinar su entrada. El hash es útil cuando quieres confirmar que un mensaje no ha sido manipulado.\nUna función hash simple (aunque ciertamente no adecuada para criptografía real) sería tomar solo cada dos letras. HELLO se convertiría en HLO. No puedes asumir que HELLO fue la entrada, pero puedes confirmar que HELLO coincidiría con el resumen hash.\nCriptografía de Clave Pública/Privada # La Criptografía de Clave Pública/Privada describe el tipo de cifradores que DTLS y SRTP usan. En este sistema, tienes dos claves, una clave pública y una privada. La clave pública es para cifrar mensajes y es seguro compartirla. La clave privada es para descifrar, y nunca debe ser compartida. Es la única clave que puede descifrar los mensajes cifrados con la clave pública.\nIntercambio Diffie–Hellman # El intercambio Diffie–Hellman permite que dos usuarios que nunca se han conocido antes creen un secreto compartido de forma segura a través de Internet. El Usuario A puede enviar un secreto al Usuario B sin preocuparse por escuchas indiscretas. Esto depende de la dificultad de romper el problema del logaritmo discreto. No necesitas entender completamente cómo funciona esto, pero ayuda saber que esto es lo que hace posible el handshake DTLS.\nWikipedia tiene un ejemplo de esto en acción aquí.\nFunción Pseudoaleatoria # Una Función Pseudoaleatoria (PRF) es una función predefinida para generar un valor que aparece aleatorio. Puede tomar múltiples entradas y generar una única salida.\nFunción de Derivación de Clave # La Derivación de Clave es un tipo de Función Pseudoaleatoria. La Derivación de Clave es una función que se usa para hacer una clave más fuerte. Un patrón común es el estiramiento de claves.\nDigamos que te dan una clave de 8 bytes. Podrías usar una KDF para hacerla más fuerte.\nNonce # Un nonce es una entrada adicional a un cifrador. Esto se usa para que puedas obtener una salida diferente del cifrador, incluso si estás cifrando el mismo mensaje varias veces.\nSi cifras el mismo mensaje 10 veces, el cifrador te dará el mismo texto cifrado 10 veces. Al usar un nonce puedes obtener una salida diferente, mientras sigues usando la misma clave. ¡Es importante que uses un nonce diferente para cada mensaje! De lo contrario, niega gran parte del valor.\nCódigo de Autenticación de Mensajes # Un Código de Autenticación de Mensajes es un hash que se coloca al final de un mensaje. Un MAC prueba que el mensaje proviene del usuario que esperabas.\nSi no usas un MAC, un atacante podría insertar mensajes inválidos. Después de descifrar solo tendrías basura porque no conocen la clave.\nRotación de Claves # La Rotación de Claves es la práctica de cambiar tu clave en un intervalo. Esto hace que una clave robada tenga menos impacto. Si una clave es robada o filtrada, se pueden descifrar menos datos.\nDTLS # DTLS (Seguridad de la Capa de Transporte de Datagramas) permite que dos pares establezcan comunicación segura sin configuración preexistente. Incluso si alguien está escuchando la conversación, no podrán descifrar los mensajes.\nPara que un Cliente DTLS y un Servidor se comuniquen, necesitan acordar un cifrador y la clave. Determinan estos valores haciendo un handshake DTLS. Durante el handshake, los mensajes están en texto plano. Cuando un Cliente/Servidor DTLS ha intercambiado suficientes detalles para comenzar a cifrar, envía un Change Cipher Spec. ¡Después de este mensaje, cada mensaje subsiguiente será cifrado!\nFormato de Paquete # Cada paquete DTLS comienza con un encabezado.\nTipo de Contenido # Puedes esperar los siguientes tipos:\n20 - Change Cipher Spec 22 - Handshake 23 - Application Data Handshake se usa para intercambiar los detalles para iniciar la sesión. Change Cipher Spec se usa para notificar al otro lado que todo será cifrado. Application Data son los mensajes cifrados.\nVersión # La versión puede ser 0x0000feff (DTLS v1.0) o 0x0000fefd (DTLS v1.2), no hay v1.1.\nÉpoca # La época comienza en 0, pero se convierte en 1 después de un Change Cipher Spec. Cualquier mensaje con una época distinta de cero está cifrado.\nNúmero de Secuencia # El Número de Secuencia se usa para mantener los mensajes en orden. Cada mensaje incrementa el Número de Secuencia. Cuando la época se incrementa, el Número de Secuencia comienza de nuevo.\nLongitud y Carga Útil # La Carga Útil es específica del Tipo de Contenido. Para un Application Data la Carga Útil son los datos cifrados. Para Handshake será diferente dependiendo del mensaje. La longitud es para qué tan grande es la Carga Útil.\nMáquina de Estados del Handshake # Durante el handshake, el Cliente/Servidor intercambian una serie de mensajes. Estos mensajes se agrupan en vuelos. Cada vuelo puede tener múltiples mensajes (o solo uno). Un Vuelo no está completo hasta que se han recibido todos los mensajes en el vuelo. Describiremos el propósito de cada mensaje con mayor detalle a continuación.\nClientHello # ClientHello es el mensaje inicial enviado por el cliente. Contiene una lista de atributos. Estos atributos le dicen al servidor los cifradores y características que el cliente soporta. Para WebRTC así es como elegimos el Cifrador SRTP también. También contiene datos aleatorios que se usarán para generar las claves para la sesión.\nHelloVerifyRequest # HelloVerifyRequest es enviado por el servidor al cliente. Es para asegurarse de que el cliente tenía la intención de enviar la solicitud. El Cliente luego reenvía el ClientHello, pero con un token proporcionado en el HelloVerifyRequest.\nServerHello # ServerHello es la respuesta del servidor para la configuración de esta sesión. Contiene qué cifrador se usará cuando esta sesión termine. También contiene los datos aleatorios del servidor.\nCertificate # Certificate contiene el certificado para el Cliente o Servidor. Esto se usa para identificar únicamente con quién nos estábamos comunicando. Después de que termine el handshake nos aseguraremos de que este certificado cuando se hashea coincida con la huella digital en la SessionDescription.\nServerKeyExchange/ClientKeyExchange # Estos mensajes se usan para transmitir la clave pública. Al inicio, el cliente y el servidor generan un par de claves. Después del handshake estos valores se usarán para generar el Pre-Master Secret.\nCertificateRequest # Un CertificateRequest es enviado por el servidor notificando al cliente que quiere un certificado. El servidor puede Solicitar o Requerir un certificado.\nServerHelloDone # ServerHelloDone notifica al cliente que el servidor ha terminado con el handshake.\nCertificateVerify # CertificateVerify es cómo el remitente prueba que tiene la clave privada enviada en el mensaje Certificate.\nChangeCipherSpec # ChangeCipherSpec informa al receptor que todo lo enviado después de este mensaje será cifrado.\nFinished # Finished está cifrado y contiene un hash de todos los mensajes. Esto es para afirmar que el handshake no fue manipulado.\nGeneración de Claves # Después de que el Handshake está completo, puedes comenzar a enviar datos cifrados. El Cifrador fue elegido por el servidor y está en el ServerHello. ¿Cómo se eligió la clave entonces?\nPrimero generamos el Pre-Master Secret. Para obtener este valor se usa Diffie–Hellman en las claves intercambiadas por el ServerKeyExchange y ClientKeyExchange. Los detalles difieren dependiendo del Cifrador elegido.\nA continuación se genera el Master Secret. Cada versión de DTLS tiene una Función Pseudoaleatoria definida. Para DTLS 1.2 la función toma el Pre-Master Secret y valores aleatorios en el ClientHello y ServerHello. La salida de ejecutar la Función Pseudoaleatoria es el Master Secret. El Master Secret es el valor que se usa para el Cifrador.\nIntercambio de ApplicationData # El caballo de batalla de DTLS es ApplicationData. Ahora que tenemos un cifrador inicializado, podemos comenzar a cifrar y enviar valores.\nLos mensajes ApplicationData usan un encabezado DTLS como se describió anteriormente. La Carga Útil se rellena con texto cifrado. Ahora tienes una Sesión DTLS funcionando y puedes comunicarte de forma segura.\nDTLS tiene muchas más características interesantes como la renegociación. No son usadas por WebRTC, por lo que no se cubrirán aquí.\nSRTP # SRTP es un protocolo diseñado específicamente para cifrar paquetes RTP. Para iniciar una sesión SRTP especificas tus claves y cifrador. A diferencia de DTLS no tiene mecanismo de handshake. Toda la configuración y claves fueron generadas durante el handshake DTLS.\nDTLS proporciona una API dedicada para exportar las claves para ser utilizadas por otro proceso. Esto está definido en RFC 5705.\nCreación de Sesión # SRTP define una Función de Derivación de Clave que se usa en las entradas. Al crear una Sesión SRTP, las entradas se ejecutan a través de esto para generar nuestras claves para nuestro Cifrador SRTP. Después de esto puedes pasar al procesamiento de medios.\nIntercambio de Medios # Cada paquete RTP tiene un SequenceNumber de 16 bits. Estos Números de Secuencia se usan para mantener los paquetes en orden, como una Clave Primaria. Durante una llamada estos se reiniciarán. SRTP rastrea esto y lo llama el contador de reinicio (rollover counter).\nAl cifrar un paquete, SRTP usa el contador de reinicio y el número de secuencia como un nonce. Esto es para asegurar que incluso si envías los mismos datos dos veces, el texto cifrado será diferente. Esto es importante para evitar que un atacante identifique patrones o intente un ataque de repetición.\n"},{"id":4,"href":"/es/docs/05-real-time-networking/","title":"Redes en Tiempo Real","section":"Docs","content":" Redes en Tiempo Real # ¿Por qué las redes son tan importantes en la comunicación en tiempo real? # Las redes son el factor limitante en la comunicación en tiempo real. En un mundo ideal tendríamos ancho de banda ilimitado y los paquetes llegarían instantáneamente. Sin embargo, este no es el caso. Las redes son limitadas, y las condiciones pueden cambiar en cualquier momento. Medir y observar las condiciones de la red también es un problema difícil. Puedes obtener diferentes comportamientos dependiendo del hardware, software y su configuración.\nLa comunicación en tiempo real también plantea un problema que no existe en la mayoría de los otros dominios. Para un desarrollador web no es fatal si tu sitio web es más lento en algunas redes. Mientras todos los datos lleguen, los usuarios están felices. Con WebRTC, si tus datos llegan tarde son inútiles. A nadie le importa lo que se dijo en una llamada de conferencia hace 5 segundos. Así que cuando desarrollas un sistema de comunicación en tiempo real, tienes que hacer un compromiso. ¿Cuál es mi límite de tiempo, y cuántos datos puedo enviar?\nEste capítulo cubre los conceptos que se aplican tanto a la comunicación de datos como de medios. En capítulos posteriores vamos más allá de lo teórico y discutimos cómo los subsistemas de medios y datos de WebRTC resuelven estos problemas.\n¿Cuáles son los atributos de la red que la hacen difícil? # El código que funciona efectivamente en todas las redes es complicado. Tienes muchos factores diferentes, y todos pueden afectarse sutilmente entre sí. Estos son los problemas más comunes que los desarrolladores encontrarán.\nAncho de Banda # El ancho de banda es la tasa máxima de datos que se pueden transferir a través de una ruta dada. Es importante recordar que este tampoco es un número estático. El ancho de banda cambiará a lo largo de la ruta a medida que más (o menos) personas lo usen.\nTiempo de Transmisión y Tiempo de Ida y Vuelta # El Tiempo de Transmisión es cuánto tiempo tarda un paquete en llegar a su destino. Como el Ancho de Banda, esto no es constante. El Tiempo de Transmisión puede fluctuar en cualquier momento.\ntransmission_time = receive_time - send_time\nPara calcular el tiempo de transmisión, necesitas relojes en el remitente y el receptor sincronizados con precisión de milisegundos. Incluso una pequeña desviación produciría una medición poco confiable del tiempo de transmisión. Dado que WebRTC está operando en entornos altamente heterogéneos, es casi imposible confiar en una sincronización de tiempo perfecta entre hosts.\nLa medición del tiempo de ida y vuelta es una solución alternativa para la sincronización imperfecta del reloj.\nEn lugar de operar con relojes distribuidos, un par WebRTC envía un paquete especial con su propia marca de tiempo sendertime1. Un par cooperante recibe el paquete y refleja la marca de tiempo de vuelta al remitente. Una vez que el remitente original obtiene el tiempo reflejado, resta la marca de tiempo sendertime1 del tiempo actual sendertime2. Este delta de tiempo se llama \u0026ldquo;retardo de propagación de ida y vuelta\u0026rdquo; o más comúnmente tiempo de ida y vuelta.\nrtt = sendertime2 - sendertime1\nLa mitad del tiempo de ida y vuelta se considera una aproximación suficientemente buena del tiempo de transmisión. Esta solución alternativa no está exenta de inconvenientes. Asume que toma la misma cantidad de tiempo enviar y recibir paquetes. Sin embargo, en redes celulares, las operaciones de envío y recepción pueden no ser simétricas en tiempo. Es posible que hayas notado que las velocidades de carga en tu teléfono son casi siempre más bajas que las velocidades de descarga.\ntransmission_time = rtt/2\nLos tecnicismos de la medición del tiempo de ida y vuelta se describen con mayor detalle en el capítulo de Informes de Remitente y Receptor RTCP.\nJitter # El jitter es el hecho de que el Tiempo de Transmisión puede variar para cada paquete. Tus paquetes podrían retrasarse, pero luego llegar en ráfagas.\nPérdida de Paquetes # La Pérdida de Paquetes es cuando los mensajes se pierden en la transmisión. La pérdida podría ser constante, o podría venir en picos. Esto podría ser por el tipo de red como satélite o Wi-Fi. O podría ser introducido por el software en el camino.\nUnidad Máxima de Transmisión # La Unidad Máxima de Transmisión es el límite de qué tan grande puede ser un solo paquete. Las redes no te permiten enviar un mensaje gigante. A nivel de protocolo, los mensajes pueden tener que dividirse en múltiples paquetes más pequeños.\nLa MTU también diferirá dependiendo de qué ruta de red tomes. Puedes usar un protocolo como Path MTU Discovery para averiguar el tamaño de paquete más grande que puedes enviar.\nCongestión # La congestión es cuando se han alcanzado los límites de la red. Esto generalmente es porque has alcanzado el ancho de banda máximo que la ruta actual puede manejar. O podría ser impuesto por el operador como límites horarios que tu ISP configura.\nLa congestión se manifiesta de muchas maneras diferentes. No hay un comportamiento estandarizado. En la mayoría de los casos, cuando se alcanza la congestión la red descartará paquetes en exceso. En otros casos, la red almacenará en búfer. Esto causará que el Tiempo de Transmisión de tus paquetes aumente. También podrías ver más jitter a medida que tu red se congestiona. Esta es un área que cambia rápidamente y aún se están escribiendo nuevos algoritmos para la detección de congestión.\nDinámica # Las redes son increíblemente dinámicas y las condiciones pueden cambiar rápidamente. Durante una llamada puedes enviar y recibir cientos de miles de paquetes. Esos paquetes viajarán a través de múltiples saltos. Esos saltos serán compartidos por millones de otros usuarios. Incluso en tu red local podrías tener películas HD siendo descargadas o tal vez un dispositivo decide descargar una actualización de software.\nTener una buena llamada no es tan simple como medir tu red al inicio. Necesitas estar evaluando constantemente. También necesitas manejar todos los diferentes comportamientos que provienen de una multitud de hardware y software de red.\nResolver la Pérdida de Paquetes # Manejar la pérdida de paquetes es el primer problema a resolver. Hay múltiples formas de resolverlo, cada una con sus propios beneficios. Depende de qué estés enviando y qué tan tolerante a la latencia seas. También es importante notar que no toda pérdida de paquetes es fatal. Perder algo de video podría no ser un problema, el ojo humano podría no incluso poder percibirlo. Perder mensajes de texto de un usuario es fatal.\nDigamos que envías 10 paquetes, y los paquetes 5 y 6 se pierden. Aquí hay formas de resolverlo.\nAcuses de Recibo # Los Acuses de Recibo es cuando el receptor notifica al remitente de cada paquete que ha recibido. El remitente es consciente de la pérdida de paquetes cuando obtiene un acuse de recibo para un paquete dos veces que no es final. Cuando el remitente obtiene un ACK para el paquete 4 dos veces, sabe que el paquete 5 aún no se ha visto.\nAcuses de Recibo Selectivos # Los Acuses de Recibo Selectivos son una mejora sobre los Acuses de Recibo. Un receptor puede enviar un SACK que reconoce múltiples paquetes y notifica al remitente de las brechas. Ahora el remitente puede obtener un SACK para el paquete 4 y 7. Entonces sabe que necesita reenviar los paquetes 5 y 6.\nAcuses de Recibo Negativos # Los Acuses de Recibo Negativos resuelven el problema de manera opuesta. En lugar de notificar al remitente lo que ha recibido, el receptor notifica al remitente lo que se ha perdido. En nuestro caso se enviará un NACK para los paquetes 5 y 6. El remitente solo conoce los paquetes que el receptor desea que se envíen de nuevo.\nCorrección de Errores hacia Adelante # La Corrección de Errores hacia Adelante corrige la pérdida de paquetes de manera preventiva. El remitente envía datos redundantes, lo que significa que un paquete perdido no afecta el flujo final. Un algoritmo popular para esto es la corrección de errores Reed–Solomon.\nEsto reduce la latencia/complejidad de enviar y manejar Acuses de Recibo. La Corrección de Errores hacia Adelante es un desperdicio de ancho de banda si la red en la que estás tiene cero pérdida.\nResolver el Jitter # El jitter está presente en la mayoría de las redes. Incluso dentro de una LAN tienes muchos dispositivos enviando datos a tasas fluctuantes. Puedes observar fácilmente el jitter haciendo ping a otro dispositivo con el comando ping y notando las fluctuaciones en la latencia de ida y vuelta.\nPara resolver el jitter, los clientes usan un JitterBuffer. El JitterBuffer asegura un tiempo de entrega constante de paquetes. La desventaja es que JitterBuffer agrega algo de latencia a los paquetes que llegan temprano. La ventaja es que los paquetes tardíos no causan jitter. Imagina que durante una llamada, ves los siguientes tiempos de llegada de paquetes:\n* time=1.46 ms * time=1.93 ms * time=1.57 ms * time=1.55 ms * time=1.54 ms * time=1.72 ms * time=1.45 ms * time=1.73 ms * time=1.80 ms En este caso, alrededor de 1.8 ms sería una buena elección. Los paquetes que llegan tarde usarán nuestra ventana de latencia. Los paquetes que llegan temprano se retrasarán un poco y pueden llenar la ventana agotada por paquetes tardíos. Esto significa que ya no tenemos tartamudeo y proporcionamos una tasa de entrega suave para el cliente.\nOperación del JitterBuffer # Cada paquete se agrega al jitter buffer tan pronto como se recibe. Una vez que hay suficientes paquetes para reconstruir el cuadro, los paquetes que conforman el cuadro se liberan del búfer y se emiten para decodificación. El decodificador, a su vez, decodifica y dibuja el cuadro de video en la pantalla del usuario. Dado que el jitter buffer tiene una capacidad limitada, los paquetes que permanecen en el búfer durante demasiado tiempo se descartarán.\nLee más sobre cómo los cuadros de video se convierten en paquetes RTP, y por qué la reconstrucción es necesaria en el capítulo de comunicación de medios.\njitterBufferDelay proporciona una gran visión sobre el rendimiento de tu red y su influencia en la suavidad de reproducción. Es parte de la API de estadísticas de WebRTC relevante para el flujo entrante del receptor. El retardo define la cantidad de tiempo que los cuadros de video pasan en el jitter buffer antes de ser emitidos para decodificación. Un largo retardo del jitter buffer significa que tu red está altamente congestionada.\nDetectar la Congestión # Antes de que podamos incluso resolver la congestión, necesitamos detectarla. Para detectarla usamos un controlador de congestión. Este es un tema complicado, y todavía está cambiando rápidamente. Aún se están publicando y probando nuevos algoritmos. A alto nivel todos operan de la misma manera. Un controlador de congestión proporciona estimaciones de ancho de banda dadas algunas entradas. Estas son algunas entradas posibles:\nPérdida de Paquetes - Los paquetes se descartan a medida que la red se congestiona. Jitter - A medida que el equipo de red se sobrecarga más, los paquetes en cola harán que los tiempos sean erráticos. Tiempo de Ida y Vuelta - Los paquetes tardan más en llegar cuando están congestionados. A diferencia del jitter, el Tiempo de Ida y Vuelta sigue aumentando. Notificación Explícita de Congestión - Las redes más nuevas pueden etiquetar paquetes como en riesgo de ser descartados para aliviar la congestión. Estos valores necesitan ser medidos continuamente durante la llamada. La utilización de la red puede aumentar o disminuir, por lo que el ancho de banda disponible podría estar cambiando constantemente.\nResolver la Congestión # Ahora que tenemos un ancho de banda estimado necesitamos ajustar lo que estamos enviando. Cómo ajustamos depende de qué tipo de datos queremos enviar.\nEnviar Más Lento # Limitar la velocidad a la que envías datos es la primera solución para prevenir la congestión. El Controlador de Congestión te da una estimación, y es responsabilidad del remitente limitar la tasa.\nEste es el método utilizado para la mayoría de la comunicación de datos. Con protocolos como TCP esto es todo hecho por el sistema operativo y completamente transparente tanto para usuarios como para desarrolladores.\nEnviar Menos # En algunos casos podemos enviar menos información para satisfacer nuestros límites. También tenemos plazos difíciles en la llegada de nuestros datos, por lo que no podemos enviar más lento. Estas son las restricciones bajo las que caen los medios en tiempo real.\nSi no tenemos suficiente ancho de banda disponible, podemos reducir la calidad del video que enviamos. Esto requiere un ciclo de retroalimentación ajustado entre tu codificador de video y controlador de congestión.\n"},{"id":5,"href":"/es/docs/06-media-communication/","title":"Comunicación de Medios","section":"Docs","content":" Comunicación de Medios # ¿Qué obtengo de la comunicación de medios de WebRTC? # WebRTC te permite enviar y recibir una cantidad ilimitada de flujos de audio y video. Puedes agregar y eliminar estos flujos en cualquier momento durante una llamada. Estos flujos podrían ser todos independientes, o podrían estar agrupados juntos. Podrías enviar una transmisión de video de tu escritorio, y luego incluir audio y video de tu cámara web.\nEl protocolo WebRTC es agnóstico al códec. El transporte subyacente admite todo, incluso cosas que aún no existen. Sin embargo, el Agente WebRTC con el que te estás comunicando puede no tener las herramientas necesarias para aceptarlo.\nWebRTC también está diseñado para manejar condiciones de red dinámicas. Durante una llamada tu ancho de banda podría aumentar o disminuir. Tal vez de repente experimentes mucha pérdida de paquetes. El protocolo está diseñado para manejar todo esto. WebRTC responde a las condiciones de la red e intenta darte la mejor experiencia posible con los recursos disponibles.\n¿Cómo funciona? # WebRTC usa dos protocolos preexistentes RTP y RTCP, ambos definidos en RFC 1889.\nRTP (Protocolo de Transporte en Tiempo Real) es el protocolo que transporta los medios. Fue diseñado para permitir la entrega en tiempo real de video. No estipula ninguna regla sobre latencia o confiabilidad, pero te da las herramientas para implementarlas. RTP te da flujos, para que puedas ejecutar múltiples transmisiones de medios sobre una conexión. También te da la información de temporización y ordenamiento que necesitas para alimentar un pipeline de medios.\nRTCP (Protocolo de Control RTP) es el protocolo que comunica metadatos sobre la llamada. El formato es muy flexible y te permite agregar cualquier metadato que desees. Esto se usa para comunicar estadísticas sobre la llamada. También se usa para manejar la pérdida de paquetes e implementar el control de congestión. Te da la comunicación bidireccional necesaria para responder a las condiciones cambiantes de la red.\nLatencia vs Calidad # Los medios en tiempo real se tratan de hacer compromisos entre latencia y calidad. Cuanta más latencia estés dispuesto a tolerar, mayor calidad de video puedes esperar.\nLimitaciones del Mundo Real # Estas restricciones son todas causadas por las limitaciones del mundo real. Todas son características de tu red que necesitarás superar.\nEl Video es Complejo # Transportar video no es fácil. Para almacenar 30 minutos de video 720 de 8 bits sin comprimir necesitas aproximadamente 110 GB. Con esos números, una llamada de conferencia de 4 personas no va a suceder. Necesitamos una forma de hacerlo más pequeño, y la respuesta es la compresión de video. Eso no viene sin inconvenientes.\nVideo 101 # No vamos a cubrir la compresión de video en profundidad, sino solo lo suficiente para entender por qué RTP está diseñado de la manera en que está. La compresión de video codifica video en un nuevo formato que requiere menos bits para representar el mismo video.\nCompresión con pérdida y sin pérdida # Puedes codificar video para que sea sin pérdida (no se pierde información) o con pérdida (la información puede perderse). Debido a que la codificación sin pérdida requiere que se envíen más datos a un par, lo que genera un flujo de mayor latencia y más paquetes perdidos, RTP típicamente usa compresión con pérdida aunque la calidad del video no sea tan buena.\nCompresión intra e inter cuadro # La compresión de video viene en dos tipos. El primero es intra-cuadro. La compresión intra-cuadro reduce los bits utilizados para describir un solo cuadro de video. Se usan las mismas técnicas para comprimir imágenes fijas, como el método de compresión JPEG.\nEl segundo tipo es la compresión inter-cuadro. Dado que el video está compuesto de muchas imágenes, buscamos formas de no enviar la misma información dos veces.\nTipos de cuadros inter # Luego tienes tres tipos de cuadros:\nI-Frame - Una imagen completa, puede ser decodificada sin nada más. P-Frame - Una imagen parcial, que contiene solo cambios de la imagen anterior. B-Frame - Una imagen parcial, es una modificación de imágenes anteriores y futuras. Lo siguiente es una visualización de los tres tipos de cuadros.\nEl video es delicado # La compresión de video es increíblemente con estado, lo que dificulta la transferencia a través de Internet. ¿Qué sucede si pierdes parte de un I-Frame? ¿Cómo sabe un P-Frame qué modificar? A medida que la compresión de video se vuelve más compleja, esto se está convirtiendo en un problema aún mayor. Afortunadamente, RTP y RTCP tienen la solución.\nRTP # Formato de Paquete # Cada paquete RTP tiene la siguiente estructura:\n``` 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ |V=2|P|X| CC |M| PT | Sequence Number | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Timestamp | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Synchronization Source (SSRC) identifier | +=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+ | Contributing Source (CSRC) identifiers | | \u0026hellip;. | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Payload | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ ```\nVersión (V) # `Versión` es siempre `2`\nRelleno (P) # `Relleno` es un booleano que controla si la carga útil tiene relleno.\nEl último byte de la carga útil contiene un recuento de cuántos bytes de relleno se agregaron.\nExtensión (X) # Si está establecido, el encabezado RTP tendrá extensiones. Esto se describe con mayor detalle a continuación.\nRecuento CSRC (CC) # La cantidad de identificadores `CSRC` que siguen después del `SSRC`, y antes de la carga útil.\nMarcador (M) # El bit de marcador no tiene un significado preestablecido y puede ser usado como el usuario desee.\nEn algunos casos se establece cuando un usuario está hablando. También se usa comúnmente para marcar un cuadro clave.\nTipo de Carga Útil (PT) # `Tipo de Carga Útil` es un identificador único para qué códec está siendo transportado por este paquete.\nPara WebRTC el `Tipo de Carga Útil` es dinámico. VP8 en una llamada puede ser diferente de otra. El oferente en la llamada determina el mapeo de `Tipos de Carga Útil` a códecs en la `Descripción de Sesión`.\nNúmero de Secuencia # `Número de Secuencia` se usa para ordenar paquetes en un flujo. Cada vez que se envía un paquete, el `Número de Secuencia` se incrementa en uno.\nRTP está diseñado para ser útil en redes con pérdida. Esto le da al receptor una forma de detectar cuándo se han perdido paquetes.\nMarca de Tiempo # El instante de muestreo para este paquete. Esto no es un reloj global, sino cuánto tiempo ha pasado en el flujo de medios. Varios paquetes RTP pueden tener la misma marca de tiempo si, por ejemplo, todos son parte del mismo cuadro de video.\nFuente de Sincronización (SSRC) # Un `SSRC` es el identificador único para este flujo. Esto te permite ejecutar múltiples flujos de medios sobre un solo flujo RTP.\nFuente Contribuyente (CSRC) # Una lista que comunica qué `SSRC`s contribuyeron a este paquete.\nEsto se usa comúnmente para indicadores de habla. Digamos que del lado del servidor combinaste múltiples transmisiones de audio en un solo flujo RTP. Luego podrías usar este campo para decir \u0026ldquo;Los flujos de entrada A y C estaban hablando en este momento\u0026rdquo;.\nCarga Útil # Los datos de carga útil reales. Puede terminar con el recuento de cuántos bytes de relleno se agregaron, si la bandera de relleno está establecida.\nExtensiones # RTCP # Formato de Paquete # Cada paquete RTCP tiene la siguiente estructura:\n``` 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ |V=2|P| RC | PT | length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Payload | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ ```\nVersión (V) # `Versión` es siempre `2`.\nRelleno (P) # `Relleno` es un booleano que controla si la carga útil tiene relleno.\nEl último byte de la carga útil contiene un recuento de cuántos bytes de relleno se agregaron.\nRecuento de Informes de Recepción (RC) # El número de informes en este paquete. Un solo paquete RTCP puede contener múltiples eventos.\nTipo de Paquete (PT) # Identificador único para qué tipo de Paquete RTCP es este. Un Agente WebRTC no necesita admitir todos estos tipos, y el soporte entre Agentes puede ser diferente. Estos son los que puedes ver comúnmente:\n`192` - Solicitud de Cuadro INTRA completo (`FIR`) `193` - Acuses de Recibo Negativos (`NACK`) `200` - Informe del Remitente `201` - Informe del Receptor `205` - Retroalimentación RTP Genérica `206` - Retroalimentación Específica de Carga Útil La importancia de estos tipos de paquetes se describirá con mayor detalle a continuación.\nSolicitud de Cuadro INTRA Completo (FIR) e Indicación de Pérdida de Imagen (PLI) # Tanto los mensajes `FIR` como `PLI` sirven un propósito similar. Estos mensajes solicitan un cuadro clave completo del remitente. `PLI` se usa cuando se dieron cuadros parciales al decodificador, pero no pudo decodificarlos. Esto podría suceder porque tuviste mucha pérdida de paquetes, o tal vez el decodificador falló.\nSegún RFC 5104, `FIR` no debe usarse cuando se pierden paquetes o cuadros. Ese es el trabajo de `PLI`. `FIR` solicita un cuadro clave por razones distintas a la pérdida de paquetes, por ejemplo, cuando un nuevo miembro ingresa a una videoconferencia. Necesitan un cuadro clave completo para comenzar a decodificar el flujo de video, el decodificador estará descartando cuadros hasta que llegue el cuadro clave.\nEs una buena idea que un receptor solicite un cuadro clave completo justo después de conectarse, esto minimiza el retraso entre la conexión y que aparezca una imagen en la pantalla del usuario.\nLos paquetes `PLI` son parte de los mensajes de Retroalimentación Específica de Carga Útil.\nEn la práctica, el software que puede manejar tanto paquetes `PLI` como `FIR` actuará de la misma manera en ambos casos. Enviará una señal al codificador para producir un nuevo cuadro clave completo.\nAcuse de Recibo Negativo # Un `NACK` solicita que un remitente retransmita un solo paquete RTP. Esto generalmente es causado por un paquete RTP que se pierde, pero también podría suceder porque llega tarde.\nLos `NACK`s son mucho más eficientes en ancho de banda que solicitar que se envíe todo el cuadro nuevamente. Dado que RTP divide los paquetes en partes muy pequeñas, realmente solo estás solicitando una pequeña pieza faltante. El receptor crea un mensaje RTCP con el SSRC y el Número de Secuencia. Si el remitente no tiene este paquete RTP disponible para reenviar, simplemente ignora el mensaje.\nInformes de Remitente y Receptor # Estos informes se usan para enviar estadísticas entre agentes. Esto comunica la cantidad de paquetes realmente recibidos y el jitter.\nLos informes se pueden usar para diagnósticos y control de congestión.\nCómo RTP/RTCP resuelven problemas juntos # RTP y RTCP entonces trabajan juntos para resolver todos los problemas causados por las redes. ¡Estas técnicas todavía están cambiando constantemente!\nCorrección de Errores hacia Adelante # También conocido como FEC. Otro método para lidiar con la pérdida de paquetes. FEC es cuando envías los mismos datos varias veces, sin que siquiera sea solicitado. Esto se hace a nivel RTP, o incluso más bajo con el códec.\nSi la pérdida de paquetes para una llamada es constante, entonces FEC es una solución de latencia mucho más baja que NACK. El tiempo de ida y vuelta de tener que solicitar y luego retransmitir el paquete faltante puede ser significativo para NACKs.\nTasa de Bits Adaptativa y Estimación de Ancho de Banda # Como se discutió en el capítulo de Redes en tiempo real, las redes son impredecibles y poco confiables. La disponibilidad de ancho de banda puede cambiar varias veces durante una sesión. No es raro ver que el ancho de banda disponible cambie dramáticamente (órdenes de magnitud) dentro de un segundo.\nLa idea principal es ajustar la tasa de bits de codificación basándose en el ancho de banda de red disponible predicho, actual y futuro. Esto asegura que se transmita una señal de video y audio de la mejor calidad posible, y que la conexión no se caiga debido a la congestión de la red. Las heurísticas que modelan el comportamiento de la red e intentan predecirlo se conocen como Estimación de Ancho de Banda.\nHay mucho matiz en esto, así que explorémoslo con mayor detalle.\nIdentificar y Comunicar el Estado de la Red # RTP/RTCP se ejecuta sobre todo tipo de redes diferentes y, como resultado, es común que alguna comunicación se pierda en su camino del remitente al receptor. Al estar construido sobre UDP, no hay un mecanismo incorporado para la retransmisión de paquetes, y mucho menos para manejar el control de congestión.\nPara proporcionar a los usuarios la mejor experiencia, WebRTC debe estimar las cualidades sobre la ruta de la red y adaptarse a cómo esas cualidades cambian con el tiempo. Los rasgos clave para monitorear incluyen: ancho de banda disponible (en cada dirección, ya que puede no ser simétrico), tiempo de ida y vuelta, y jitter (fluctuaciones en el tiempo de ida y vuelta). Necesita tener en cuenta la pérdida de paquetes y comunicar cambios en estas propiedades a medida que las condiciones de red evolucionan.\nHay dos objetivos principales para estos protocolos:\nEstimar el ancho de banda disponible (en cada dirección) soportado por la red. Comunicar las características de la red entre remitente y receptor. RTP/RTCP tiene tres enfoques diferentes para abordar este problema. Todos tienen sus pros y contras, y generalmente cada generación ha mejorado sobre sus predecesores. Qué implementación uses dependerá principalmente del stack de software disponible para tus clientes y las bibliotecas disponibles para construir tu aplicación.\nInformes de Receptor / Informes de Remitente # La primera implementación es el par de Informes de Receptor y su complemento, Informes de Remitente. Estos mensajes RTCP están definidos en RFC 3550, y son responsables de comunicar el estado de la red entre puntos finales. Los Informes de Receptor se centran en comunicar cualidades sobre la red (incluida la pérdida de paquetes, el tiempo de ida y vuelta y el jitter), y se emparejan con otros algoritmos que luego son responsables de estimar el ancho de banda disponible basándose en estos informes.\nLos informes de Remitente y Receptor (SR y RR) juntos pintan una imagen de la calidad de la red. Se envían en un horario para cada SSRC, y son las entradas utilizadas al estimar el ancho de banda disponible. Esas estimaciones las hace el remitente después de recibir los datos RR, que contienen los siguientes campos:\nFracción Perdida - Qué porcentaje de paquetes se ha perdido desde el último Informe de Receptor. Número Acumulativo de Paquetes Perdidos - Cuántos paquetes se han perdido durante toda la llamada. Número de Secuencia Más Alto Extendido Recibido - Cuál fue el último Número de Secuencia recibido, y cuántas veces se ha reiniciado. Jitter de Inter-llegada - El Jitter continuo para toda la llamada. Marca de Tiempo del Último Informe del Remitente - Última hora conocida en el remitente, usada para el cálculo del tiempo de ida y vuelta. SR y RR trabajan juntos para calcular el tiempo de ida y vuelta.\nEl remitente incluye su hora local, `sendertime1` en SR. Cuando el receptor recibe un paquete SR, envía de vuelta RR. Entre otras cosas, el RR incluye `sendertime1` recién recibido del remitente. Habrá un retardo entre recibir el SR y enviar el RR. Por eso, el RR también incluye un tiempo de \u0026ldquo;retardo desde el último informe del remitente\u0026rdquo; - `DLSR`. El `DLSR` se usa para ajustar la estimación del tiempo de ida y vuelta más adelante en el proceso. Una vez que el remitente recibe el RR, resta `sendertime1` y `DLSR` del tiempo actual `sendertime2`. Este delta de tiempo se llama retardo de propagación de ida y vuelta o tiempo de ida y vuelta.\n`rtt = sendertime2 - sendertime1 - DLSR`\nTiempo de ida y vuelta en español sencillo:\nTe envío un mensaje con la lectura actual de mi reloj, digamos que es 4:20pm, 42 segundos y 420 milisegundos. Me devuelves esta misma marca de tiempo. También incluyes el tiempo transcurrido desde leer mi mensaje hasta enviar el mensaje de vuelta, digamos 5 milisegundos. Una vez que recibo el tiempo de vuelta, miro el reloj de nuevo. Ahora mi reloj dice 4:20pm, 42 segundos 690 milisegundos. Significa que tomó 265 milisegundos (690 - 420 - 5) para llegar a ti y regresar a mí. Por lo tanto, el tiempo de ida y vuelta es 265 milisegundos. TMMBR, TMMBN, REMB y TWCC, emparejados con GCC # Control de Congestión de Google (GCC) # El algoritmo de Control de Congestión de Google (GCC) (descrito en draft-ietf-rmcat-gcc-02) aborda el desafío de la estimación de ancho de banda. Se empareja con una variedad de otros protocolos para facilitar los requisitos de comunicación asociados. En consecuencia, está bien adaptado para ejecutarse en el lado receptor (cuando se ejecuta con TMMBR/TMMBN o REMB) o en el lado remitente (cuando se ejecuta con TWCC).\nPara llegar a estimaciones del ancho de banda disponible, GCC se centra en la pérdida de paquetes y las fluctuaciones en el tiempo de llegada de cuadros como sus dos métricas principales. Ejecuta estas métricas a través de dos controladores vinculados: el controlador basado en pérdida y el controlador basado en retardo.\nEl primer componente de GCC, el controlador basado en pérdida, es simple:\nSi la pérdida de paquetes está por encima del 10%, la estimación de ancho de banda se reduce. Si la pérdida de paquetes está entre 2-10%, la estimación de ancho de banda permanece igual. Si la pérdida de paquetes está por debajo del 2%, la estimación de ancho de banda aumenta. Las mediciones de pérdida de paquetes se toman con frecuencia. Dependiendo del protocolo de comunicación emparejado, la pérdida de paquetes puede comunicarse explícitamente (como con TWCC) o inferirse (como con TMMBR/TMMBN y REMB). Estos porcentajes se evalúan en ventanas de tiempo de alrededor de un segundo.\nEl controlador basado en retardo coopera con el controlador basado en pérdida y observa las variaciones en el tiempo de llegada de paquetes. Este controlador basado en retardo tiene como objetivo identificar cuándo los enlaces de red se están volviendo cada vez más congestionados, y puede reducir las estimaciones de ancho de banda incluso antes de que ocurra la pérdida de paquetes. La teoría es que la interfaz de red más ocupada a lo largo de la ruta continuará poniendo en cola los paquetes hasta que la interfaz se quede sin capacidad dentro de sus búferes. Si esa interfaz continúa recibiendo más tráfico del que puede enviar, se verá obligada a descartar todos los paquetes que no pueda caber en su espacio de búfer. Este tipo de pérdida de paquetes es particularmente disruptivo para la comunicación en tiempo real/baja latencia, pero también puede degradar el rendimiento para toda la comunicación sobre ese enlace y debería idealmente evitarse. Por lo tanto, GCC intenta averiguar si los enlaces de red están creciendo colas cada vez más grandes antes de que realmente ocurra la pérdida de paquetes. Reducirá el uso de ancho de banda si observa retardos de cola crecientes con el tiempo.\nPara lograr esto, GCC intenta inferir aumentos en la profundidad de la cola midiendo aumentos sutiles en el tiempo de ida y vuelta. Registra el \u0026ldquo;tiempo inter-llegada\u0026rdquo; de los cuadros, `t(i) - t(i-1)`: la diferencia en el tiempo de llegada de dos grupos de paquetes (generalmente, cuadros de video consecutivos). Estos grupos de paquetes frecuentemente parten a intervalos regulares de tiempo (por ejemplo, cada 1/24 segundos para un video de 24 fps). Como resultado, medir el tiempo inter-llegada es tan simple como registrar la diferencia de tiempo entre el inicio del primer grupo de paquetes (es decir, cuadro) y el primer cuadro del siguiente.\nEn el diagrama a continuación, el aumento mediano del retardo inter-paquete es +20 mseg, un claro indicador de congestión de red.\nSi el tiempo inter-llegada aumenta con el tiempo, eso se presume como evidencia de una mayor profundidad de cola en las interfaces de red conectadas y se considera congestión de red. (Nota: GCC es lo suficientemente inteligente como para controlar estas mediciones para fluctuaciones en los tamaños de bytes de los cuadros.) GCC refina sus mediciones de latencia usando un filtro de Kalman y toma muchas mediciones de los tiempos de ida y vuelta de la red (y sus variaciones) antes de señalar congestión. Uno puede pensar en el filtro de Kalman de GCC como tomando el lugar de una regresión lineal: ayudando a hacer predicciones precisas incluso cuando el jitter agrega ruido a las mediciones de tiempo. Al señalar congestión, GCC reducirá la tasa de bits disponible. Alternativamente, bajo condiciones de red estables, puede aumentar lentamente sus estimaciones de ancho de banda para probar valores de carga más altos.\nTMMBR, TMMBN y REMB # Para TMMBR/TMMBN y REMB, el lado receptor primero estima el ancho de banda entrante disponible (usando un protocolo como GCC), y luego comunica estas estimaciones de ancho de banda a los remitentes remotos. No necesitan intercambiar detalles sobre la pérdida de paquetes u otras cualidades sobre la congestión de la red porque operar en el lado receptor les permite medir el tiempo inter-llegada y la pérdida de paquetes directamente. En su lugar, TMMBR, TMMBN y REMB intercambian solo las estimaciones de ancho de banda en sí:\nSolicitud Temporal de Tasa de Bits Máxima de Flujo de Medios - Una mantisa/exponente de una tasa de bits solicitada para un solo SSRC. Notificación Temporal de Tasa de Bits Máxima de Flujo de Medios - Un mensaje para notificar que se ha recibido un TMMBR. Tasa de Bits Máxima Estimada del Receptor - Una mantisa/exponente de una tasa de bits solicitada para toda la sesión. TMMBR y TMMBN llegaron primero y están definidos en RFC 5104. REMB llegó más tarde, hubo un borrador presentado en draft-alvestrand-rmcat-remb, pero nunca fue estandarizado.\nUna sesión de ejemplo que usa REMB podría comportarse de la siguiente manera:\nEste método funciona genial en papel. El Remitente recibe estimación del receptor, establece la tasa de bits del codificador al valor recibido. ¡Tada! Nos hemos ajustado a las condiciones de la red.\nSin embargo, en la práctica, el enfoque REMB tiene múltiples inconvenientes.\nLa ineficiencia del codificador es el primero. Cuando estableces una tasa de bits para el codificador, no necesariamente producirá la tasa de bits exacta que solicitaste. La codificación puede producir más o menos bits, dependiendo de la configuración del codificador y el cuadro que se está codificando.\nPor ejemplo, usar el codificador x264 con `tune=zerolatency` puede desviarse significativamente de la tasa de bits objetivo especificada. Aquí hay un escenario posible:\nDigamos que comenzamos estableciendo la tasa de bits a 1000 kbps. El codificador produce solo 700 kbps, porque no hay suficientes características de alta frecuencia para codificar. (AKA - \u0026ldquo;mirando una pared\u0026rdquo;.) También imaginemos que el receptor obtiene el video de 700 kbps con cero pérdida de paquetes. Luego aplica la regla 1 de REMB para aumentar la tasa de bits entrante en un 8%. El receptor envía un paquete REMB con una sugerencia de 756 kbps (700 kbps * 1.08) al remitente. El remitente establece la tasa de bits del codificador a 756 kbps. El codificador produce una tasa de bits aún más baja. Este proceso continúa repitiéndose, reduciendo la tasa de bits al mínimo absoluto. Puedes ver cómo esto causaría un ajuste pesado de parámetros del codificador, y sorprendería a los usuarios con video imposible de ver incluso en una gran conexión.\nControl de Congestión de Transporte Amplio # El Control de Congestión de Transporte Amplio es el último desarrollo en la comunicación del estado de la red RTCP. Está definido en draft-holmer-rmcat-transport-wide-cc-extensions-01, pero tampoco ha sido estandarizado.\nTWCC usa un principio bastante simple:\nCon REMB, el receptor instruye al lado remitente en la tasa de bits de descarga disponible. Usa mediciones precisas sobre la pérdida de paquetes inferida y datos solo que tiene sobre el tiempo de llegada inter-paquete.\nTWCC es casi un enfoque híbrido entre las generaciones SR/RR y REMB de protocolos. Lleva las estimaciones de ancho de banda de vuelta al lado remitente (similar a SR/RR), pero su técnica de estimación de ancho de banda se asemeja más a la generación REMB.\nCon TWCC, el receptor le permite al remitente conocer el tiempo de llegada de cada paquete. Esto es suficiente información para que el remitente mida la variación del retardo de llegada inter-paquete, así como identificar qué paquetes fueron descartados o llegaron demasiado tarde para contribuir a la transmisión de audio/video. Con estos datos siendo intercambiados frecuentemente, el remitente puede ajustarse rápidamente a las condiciones cambiantes de la red y variar su ancho de banda de salida usando un algoritmo como GCC.\nEl remitente mantiene un seguimiento de los paquetes enviados, sus números de secuencia, tamaños y marcas de tiempo. Cuando el remitente recibe mensajes RTCP del receptor, compara los retardos inter-paquete de envío con los retardos de recepción. Si los retardos de recepción aumentan, señala congestión de red, y el remitente debe tomar medidas correctivas.\nAl proporcionar al remitente los datos sin procesar, TWCC proporciona una excelente vista de las condiciones de red en tiempo real:\nComportamiento de pérdida de paquetes casi instantáneo, hasta los paquetes perdidos individuales Tasa de bits de envío precisa Tasa de bits de recepción precisa Medición del jitter Diferencias entre los retardos de paquetes de envío y recepción Descripción de cómo la red toleró la entrega de ancho de banda ráfaga o constante Una de las contribuciones más significativas de TWCC es la flexibilidad que brinda a los desarrolladores de WebRTC. Al consolidar el algoritmo de control de congestión en el lado remitente, permite un código de cliente simple que puede ser ampliamente usado y requiere mejoras mínimas con el tiempo. Los complejos algoritmos de control de congestión pueden entonces iterarse más rápidamente en el hardware que controlan directamente (como la Unidad de Reenvío Selectivo, discutida en la sección 8). En el caso de navegadores y dispositivos móviles, esto significa que esos clientes pueden beneficiarse de mejoras de algoritmos sin tener que esperar la estandarización o actualizaciones del navegador (que pueden tomar bastante tiempo para estar ampliamente disponibles).\nAlternativas de Estimación de Ancho de Banda # La implementación más desplegada es \u0026ldquo;Un Algoritmo de Control de Congestión de Google para Comunicación en Tiempo Real\u0026rdquo; definido en draft-alvestrand-rmcat-congestion.\nHay varias alternativas a GCC, por ejemplo NADA: Un Esquema de Control de Congestión Unificado para Medios en Tiempo Real y SCReAM - Adaptación de Tasa Auto-Cronometrada para Multimedia.\n"},{"id":6,"href":"/es/docs/07-data-communication/","title":"Comunicación de Datos","section":"Docs","content":" Comunicación de Datos # ¿Qué obtengo de la comunicación de datos de WebRTC? # WebRTC proporciona canales de datos para la comunicación de datos. Entre dos pares puedes abrir 65,534 canales de datos. Un canal de datos está basado en datagramas, y cada uno tiene su propia configuración de durabilidad. Por defecto, cada canal de datos tiene entrega ordenada garantizada.\nSi te acercas a WebRTC desde un trasfondo de medios, los canales de datos pueden parecer derro chadores. ¿Por qué necesito todo este subsistema cuando podría simplemente usar HTTP o WebSockets?\nEl verdadero poder de los canales de datos es que puedes configurarlos para que se comporten como UDP con entrega desordenada/con pérdida. Esto es necesario para situaciones de baja latencia y alto rendimiento. Puedes medir la contrapresión y asegurarte de que solo estás enviando tanto como tu red soporta.\n¿Cómo funciona? # WebRTC usa el Protocolo de Transmisión de Control de Flujo (SCTP), definido en RFC 4960. SCTP es un protocolo de capa de transporte que fue concebido como una alternativa a TCP o UDP. Para WebRTC lo usamos como un protocolo de capa de aplicación que se ejecuta sobre nuestra conexión DTLS.\nSCTP te da flujos y cada flujo puede ser configurado independientemente. Los canales de datos de WebRTC son solo abstracciones delgadas sobre ellos. Las configuraciones sobre durabilidad y ordenamiento se pasan directamente al Agente SCTP.\nLos canales de datos tienen algunas características que SCTP no puede expresar, como etiquetas de canal. Para resolver eso, WebRTC usa el Protocolo de Establecimiento de Canal de Datos (DCEP) que está definido en RFC 8832. DCEP define un mensaje para comunicar la etiqueta del canal y el protocolo.\nDCEP # DCEP solo tiene dos mensajes DATA_CHANNEL_OPEN y DATA_CHANNEL_ACK. Para cada canal de datos que se abre, el remoto debe responder con un acuse de recibo.\nDATA_CHANNEL_OPEN # Este mensaje es enviado por el Agente WebRTC que desea abrir un canal.\nFormato de Paquete # ``` 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Message Type | Channel Type | Priority | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Reliability Parameter | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Label Length | Protocol Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \\ / Label / \\ +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \\ / Protocol / \\ +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ ```\nTipo de Mensaje # El Tipo de Mensaje es un valor estático de `0x03`.\nTipo de Canal # El Tipo de Canal controla los atributos de durabilidad/ordenamiento del canal. Puede tener los siguientes valores:\n`DATA_CHANNEL_RELIABLE` (`0x00`) - No se pierden mensajes y llegarán en orden `DATA_CHANNEL_RELIABLE_UNORDERED` (`0x80`) - No se pierden mensajes, pero pueden llegar fuera de orden. `DATA_CHANNEL_PARTIAL_RELIABLE_REXMIT` (`0x01`) - Los mensajes pueden perderse después de intentar la cantidad de veces solicitada, pero llegarán en orden. `DATA_CHANNEL_PARTIAL_RELIABLE_REXMIT_UNORDERED` (`0x81`) - Los mensajes pueden perderse después de intentar la cantidad de veces solicitada y pueden llegar fuera de orden. `DATA_CHANNEL_PARTIAL_RELIABLE_TIMED` (`0x02`) - Los mensajes pueden perderse si no llegan en la cantidad de tiempo solicitada, pero llegarán en orden. `DATA_CHANNEL_PARTIAL_RELIABLE_TIMED_UNORDERED` (`0x82`) - Los mensajes pueden perderse si no llegan en la cantidad de tiempo solicitada y pueden llegar fuera de orden. Prioridad # La prioridad del canal de datos. Los canales de datos con mayor prioridad se programarán primero. Los mensajes de usuario de prioridad más baja y de gran tamaño no retrasarán el envío de mensajes de usuario de mayor prioridad.\nParámetro de Confiabilidad # Si el tipo de canal de datos es `DATA_CHANNEL_PARTIAL_RELIABLE`, los sufijos configuran el comportamiento:\n`REXMIT` - Define cuántas veces el remitente reintentará enviar el mensaje antes de rendirse. `TIMED` - Define durante cuánto tiempo (en ms) el remitente reintentará enviar el mensaje antes de rendirse. Etiqueta # Una cadena codificada en UTF-8 que contiene el nombre del canal de datos. Esta cadena puede estar vacía.\nProtocolo # Si es una cadena vacía, el protocolo no está especificado. Si es una cadena no vacía, debe especificar un protocolo registrado en el \u0026ldquo;WebSocket Subprotocol Name Registry\u0026rdquo;, definido en RFC 6455.\nDATA_CHANNEL_ACK # Este mensaje es enviado por el Agente WebRTC para reconocer que este canal de datos ha sido abierto.\nFormato de Paquete # ``` 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Message Type | +-+-+-+-+-+-+-+-+ ```\nProtocolo de Transmisión de Control de Flujo # SCTP es el verdadero poder detrás de los canales de datos de WebRTC. Proporciona todas estas características del canal de datos:\nMultiplexación Entrega confiable usando un mecanismo de retransmisión similar a TCP Opciones de confiabilidad parcial Evitación de Congestión Control de Flujo Para entender SCTP lo exploraremos en tres partes. El objetivo es que sepas lo suficiente para depurar y aprender los detalles profundos de SCTP por tu cuenta después de este capítulo.\nConceptos # SCTP es un protocolo rico en características. Esta sección solo va a cubrir las partes de SCTP que son usadas por WebRTC. Las características en SCTP que no son usadas por WebRTC incluyen multi-homing y selección de ruta.\nCon más de veinte años de desarrollo, SCTP puede ser difícil de comprender completamente.\nAsociación # Asociación es el término usado para una Sesión SCTP. Es el estado que se comparte entre dos Agentes SCTP mientras se comunican.\nFlujos # Un flujo es una secuencia bidireccional de datos de usuario. Cuando creas un canal de datos en realidad solo estás creando un flujo SCTP. Cada Asociación SCTP contiene una lista de flujos. Cada flujo puede ser configurado con diferentes tipos de confiabilidad.\nWebRTC solo te permite configurar en la creación del flujo, pero SCTP en realidad permite cambiar la configuración en cualquier momento.\nBasado en Datagramas # SCTP enmarca datos como datagramas y no como un flujo de bytes. Enviar y recibir datos se siente como usar UDP en lugar de TCP. No necesitas agregar ningún código extra para transferir múltiples archivos sobre un flujo.\nLos mensajes SCTP no tienen límites de tamaño como UDP. Un solo mensaje SCTP puede ser de múltiples gigabytes de tamaño.\nFragmentos # El protocolo SCTP está compuesto de fragmentos. Hay muchos tipos diferentes de fragmentos. Estos fragmentos se usan para toda la comunicación. Datos de usuario, inicialización de conexión, control de congestión y más se hacen a través de fragmentos.\nCada paquete SCTP contiene una lista de fragmentos. Así que en un paquete UDP puedes tener múltiples fragmentos transportando mensajes de diferentes flujos.\nNúmero de Secuencia de Transmisión # El Número de Secuencia de Transmisión (TSN) es un identificador único global para fragmentos DATA. Un fragmento DATA es lo que transporta todos los mensajes que un usuario desea enviar. El TSN es importante porque ayuda a un receptor a determinar si los paquetes se perdieron o están fuera de orden.\nSi el receptor nota un TSN faltante, no entrega los datos al usuario hasta que se cumpla.\nIdentificador de Flujo # Cada flujo tiene un identificador único. Cuando creas un canal de datos con un ID explícito, en realidad solo se pasa directamente a SCTP como el identificador de flujo. Si no pasas un ID, el identificador de flujo se elige por ti.\nIdentificador de Protocolo de Carga Útil # Cada fragmento DATA también tiene un Identificador de Protocolo de Carga Útil (PPID). Esto se usa para identificar de manera única qué tipo de datos se está intercambiando. SCTP tiene muchos PPIDs, pero WebRTC solo está usando los siguientes cinco:\n`WebRTC DCEP` (`50`) - Mensajes DCEP. `WebRTC String` (`51`) - Mensajes de cadena de DataChannel. `WebRTC Binary` (`53`) - Mensajes binarios de DataChannel. `WebRTC String Empty` (`56`) - Mensajes de cadena de DataChannel con longitud 0. `WebRTC Binary Empty` (`57`) - Mensajes binarios de DataChannel con longitud 0. Protocolo # Los siguientes son algunos de los fragmentos utilizados por el protocolo SCTP. Esta no es una demostración exhaustiva. Esto proporciona suficientes estructuras para que la máquina de estados tenga sentido.\nCada Fragmento comienza con un campo `tipo`. Antes de una lista de fragmentos, también tendrás un encabezado.\nFragmento DATA # ``` 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Type = 0 | Reserved|U|B|E| Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | TSN | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Stream Identifier | Stream Sequence Number | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Payload Protocol Identifier | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \\ / User Data / \\ +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ ``` El fragmento DATA es cómo se intercambian todos los datos de usuario. Cuando envías cualquier cosa sobre el canal de datos, así es como se intercambia.\nEl bit `U` se establece si este es un paquete desordenado. Podemos ignorar el Número de Secuencia de Flujo.\n`B` y `E` son los bits de inicio y fin. Si quieres enviar un mensaje que es demasiado grande para un fragmento DATA, necesita fragmentarse en múltiples fragmentos DATA enviados en paquetes separados. Con el bit `B` y `E` y Números de Secuencia, SCTP es capaz de expresar esto.\n`B=1`, `E=0` - Primera pieza de un mensaje de usuario fragmentado. `B=0`, `E=0` - Pieza intermedia de un mensaje de usuario fragmentado. `B=0`, `E=1` - Última pieza de un mensaje de usuario fragmentado. `B=1`, `E=1` - Mensaje sin fragmentar. `TSN` es el Número de Secuencia de Transmisión. Es el identificador único global para este fragmento DATA. Después de 4,294,967,295 fragmentos esto se reiniciará a 0. El TSN se incrementa para cada fragmento en un mensaje de usuario fragmentado para que el receptor sepa cómo ordenar los fragmentos recibidos para reconstruir el mensaje original.\n`Identificador de Flujo` es el identificador único para el flujo al que pertenecen estos datos.\n`Número de Secuencia de Flujo` es un número de 16 bits incrementado cada mensaje de usuario e incluido en el encabezado del fragmento del mensaje DATA. Después de 65535 mensajes esto se reiniciará a 0. Este número se usa para decidir el orden de entrega de mensajes al receptor si `U` está establecido en 0. Similar al TSN, excepto que el Número de Secuencia de Flujo solo se incrementa para cada mensaje en su conjunto y no para cada fragmento DATA individual.\n`Identificador de Protocolo de Carga Útil` es el tipo de datos que fluye a través de este flujo. Para WebRTC, será DCEP, String o Binary.\n`Datos de Usuario` es lo que estás enviando. Todos los datos que envías a través de un canal de datos de WebRTC se transmiten a través de un fragmento DATA.\nFragmento INIT # ``` 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Type = 1 | Chunk Flags | Chunk Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Initiate Tag | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Advertised Receiver Window Credit (a_rwnd) | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Number of Outbound Streams | Number of Inbound Streams | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Initial TSN | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \\ / Optional/Variable-Length Parameters / \\ +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ ```\nEl fragmento INIT inicia el proceso de creación de una asociación.\n`Etiqueta de Inicio` se usa para la generación de cookies. Las cookies se usan para la protección contra Man-In-The-Middle y Denegación de Servicio. Se describen con mayor detalle en la sección de máquina de estados.\n`Crédito de Ventana de Receptor Anunciado` se usa para el Control de Congestión de SCTP. Esto comunica qué tan grande es el búfer que el receptor ha asignado para esta asociación.\n`Número de Flujos de Salida/Entrada` notifica al remoto cuántos flujos este agente soporta.\n`TSN Inicial` es un `uint32` aleatorio para comenzar el TSN local.\n`Parámetros Opcionales` permite a SCTP introducir nuevas características al protocolo.\nFragmento SACK # ``` 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Type = 3 |Chunk Flags | Chunk Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Cumulative TSN Ack | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Advertised Receiver Window Credit (a_rwnd) | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Number of Gap Ack Blocks = N | Number of Duplicate TSNs = X | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Gap Ack Block #1 Start | Gap Ack Block #1 End | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ / / \\ \u0026hellip; / / +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Gap Ack Block #N Start | Gap Ack Block #N End | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Duplicate TSN 1 | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ / / \\ \u0026hellip; / / +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Duplicate TSN X | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ ```\nEl fragmento SACK (Acuse de Recibo Selectivo) es cómo un receptor notifica a un remitente que ha recibido un paquete. Hasta que un remitente obtiene un SACK para un TSN reenviará el fragmento DATA en cuestión. Sin embargo, un SACK hace más que actualizar el TSN.\n`TSN ACK Acumulativo` el TSN más alto que se ha recibido.\n`Crédito de Ventana de Receptor Anunciado` tamaño del búfer del receptor. El receptor puede cambiar esto durante la sesión si hay más memoria disponible.\n`Bloques Ack` TSNs que han sido recibidos después del `TSN ACK Acumulativo`. Esto se usa si hay una brecha en los paquetes entregados. Digamos que los fragmentos DATA con TSNs `100`, `102`, `103` y `104` son entregados. El `TSN ACK Acumulativo` sería `100`, pero `Bloques Ack` podrían usarse para decirle al remitente que no necesita reenviar `102`, `103` o `104`.\n`TSN Duplicado` informa al remitente que ha recibido los siguientes fragmentos DATA más de una vez.\nFragmento HEARTBEAT # ``` 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Type = 4 | Chunk Flags | Heartbeat Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \\ / Heartbeat Information TLV (Variable-Length) / \\ +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ ```\nEl fragmento HEARTBEAT se usa para afirmar que el remoto todavía está respondiendo. Útil si no estás enviando fragmentos DATA y necesitas mantener un mapeo NAT abierto.\nFragmento ABORT # ``` 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Type = 6 |Reserved |T| Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ / / \\ Zero or more Error Causes / / +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ ```\nUn fragmento ABORT cierra abruptamente la asociación. Usado cuando un lado entra en un estado de error. Finalizar la conexión de manera elegante usa el fragmento SHUTDOWN.\nFragmento SHUTDOWN # ``` 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Type = 7 | Chunk Flags | Length = 8 | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Cumulative TSN Ack | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ ```\nEl fragmento SHUTDOWN inicia un cierre elegante de la asociación SCTP. Cada agente informa al remoto del último TSN que envió. Esto asegura que no se pierdan paquetes. WebRTC no hace un cierre elegante de la asociación SCTP. Necesitas cerrar cada canal de datos tú mismo para manejarlo de manera elegante.\n`TSN ACK Acumulativo` es el último TSN que fue enviado. Cada lado sabe que no debe terminar hasta que haya recibido el fragmento DATA con este TSN.\nFragmento ERROR # ``` 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Type = 9 | Chunk Flags | Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \\ / One or more Error Causes / \\ +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ ```\nUn fragmento ERROR se usa para notificar al Agente SCTP remoto que ha ocurrido un error no fatal.\nFragmento FORWARD TSN # ``` 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Type = 192 | Flags = 0x00 | Length = Variable | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | New Cumulative TSN | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Stream-1 | Stream Sequence-1 | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \\ / / +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Stream-N | Stream Sequence-N | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ ```\nEl fragmento `FORWARD TSN` mueve el TSN global hacia adelante. SCTP hace esto para que puedas saltar algunos paquetes que ya no te importan. Digamos que envías `10 11 12 13 14 15` y estos paquetes solo son válidos si todos llegan. Estos datos también son sensibles al tiempo real, así que si llegan tarde no son útiles.\nSi pierdes `12` y `13` ¡no hay razón para enviar `14` y `15`! SCTP usa el fragmento `FORWARD TSN` para lograr eso. Le dice al receptor que `14` y `15` ya no se entregarán.\n`Nuevo TSN Acumulativo` este es el nuevo TSN de la conexión. Cualquier paquete antes de este TSN no se retendrá.\n`Flujo` y `Secuencia de Flujo` se usan para saltar el `Número de Secuencia de Flujo` adelante. Consulta de nuevo el Fragmento DATA para la importancia de este campo.\nMáquina de Estados # Estas son algunas partes interesantes de la máquina de estados SCTP. WebRTC no usa todas las características de la máquina de estados SCTP, por lo que hemos excluido esas partes. También hemos simplificado algunos componentes para hacerlos comprensibles por sí mismos.\nFlujo de Establecimiento de Conexión # Los fragmentos `INIT` e `INIT ACK` se usan para intercambiar las capacidades y configuraciones de cada par. SCTP usa una cookie durante el handshake para validar el par con el que se está comunicando. Esto es para asegurar que el handshake no sea interceptado y para prevenir ataques DoS.\nEl fragmento `INIT ACK` contiene la cookie. La cookie luego se devuelve a su creador usando el `COOKIE ECHO`. Si la verificación de la cookie es exitosa, se envía el `COOKIE ACK` y los fragmentos DATA están listos para ser intercambiados.\nFlujo de Desconexión # SCTP usa el fragmento `SHUTDOWN`. Cuando un agente recibe un fragmento `SHUTDOWN`, esperará hasta que reciba el `TSN ACK Acumulativo` solicitado. Esto permite a un usuario asegurar que todos los datos se entreguen incluso si la conexión tiene pérdidas.\nMecanismo de Keep-Alive # SCTP usa los fragmentos `HEARTBEAT REQUEST` y `HEARTBEAT ACK` para mantener la conexión viva. Estos se envían en un intervalo configurable. SCTP también realiza un backoff exponencial si el paquete no ha llegado.\nEl fragmento `HEARTBEAT` también contiene un valor de tiempo. Esto permite que dos asociaciones calculen el tiempo de viaje entre dos agentes.\n"},{"id":7,"href":"/es/docs/08-applied-webrtc/","title":"WebRTC Aplicado","section":"Docs","content":" WebRTC Aplicado # Ahora que sabes cómo funciona WebRTC, ¡es hora de construir con él! Este capítulo explora qué están construyendo las personas con WebRTC y cómo lo están construyendo. Aprenderás todas las cosas interesantes que están sucediendo con WebRTC. El poder de WebRTC viene con un costo. Construir servicios WebRTC de grado producción es desafiante. Este capítulo intentará explicar esos desafíos antes de que los encuentres.\nPor Caso de Uso # Muchos piensan que WebRTC es solo una tecnología para conferencias en el navegador web. ¡Es mucho más que eso! WebRTC se usa en una amplia gama de aplicaciones. Nuevos casos de uso están apareciendo todo el tiempo. En este capítulo enumeraremos algunos comunes y cómo WebRTC los está revolucionando.\nConferencias # Las conferencias son el caso de uso original para WebRTC. El protocolo contiene algunas características necesarias que ningún otro protocolo ofrece en el navegador. Podrías construir un sistema de conferencias con WebSockets y podría funcionar en condiciones óptimas. Si quieres algo que pueda implementarse en condiciones de red del mundo real, WebRTC es la mejor opción.\nWebRTC proporciona control de congestión y tasa de bits adaptativa para medios. A medida que las condiciones de la red cambian, los usuarios seguirán obteniendo la mejor experiencia posible. Los desarrolladores tampoco tienen que escribir ningún código adicional para medir estas condiciones.\nLos participantes pueden enviar y recibir múltiples flujos. También pueden agregar y eliminar esos flujos en cualquier momento durante la llamada. Los códecs se negocian también. Toda esta funcionalidad es proporcionada por el navegador, no se requiere que el desarrollador escriba código personalizado.\nLas conferencias también se benefician de los canales de datos. Los usuarios pueden enviar metadatos o compartir documentos. Puedes crear múltiples flujos y configurarlos si necesitas rendimiento más que confiabilidad.\nTransmisión # Muchos proyectos nuevos están comenzando a aparecer en el espacio de transmisión que usan WebRTC. El protocolo tiene mucho que ofrecer tanto para el publicador como para el consumidor de medios.\nWebRTC estar en el navegador facilita que los usuarios publiquen video. Elimina el requisito de que los usuarios descarguen un nuevo cliente. Cualquier plataforma que tenga un navegador web puede publicar video. Los publicadores pueden entonces enviar múltiples pistas y modificarlas o eliminarlas en cualquier momento. Esta es una gran mejora sobre los protocolos heredados que solo permitían una pista de audio o una pista de video por conexión.\nWebRTC les da a los desarrolladores un mayor control sobre los compromisos entre latencia y calidad. Si es más importante que la latencia nunca exceda un cierto umbral, y estás dispuesto a tolerar algunos artefactos de decodificación. Puedes configurar el visor para reproducir medios tan pronto como lleguen. Con otros protocolos que se ejecutan sobre TCP, eso no es tan fácil. En el navegador puedes solicitar datos y eso es todo.\nAcceso Remoto # El Acceso Remoto es cuando accedes remotamente a otra computadora a través de WebRTC. Podrías tener control completo del host remoto, o tal vez solo una aplicación individual. Esto es genial para ejecutar tareas computacionalmente costosas cuando el hardware local no puede hacerlo. Como ejecutar un nuevo videojuego, o software CAD. WebRTC pudo revolucionar el espacio de tres maneras.\nWebRTC puede usarse para acceder remotamente a un host que no es enrutable mundialmente. Con NAT Traversal puedes acceder a una computadora que solo está disponible a través de STUN. Esto es genial para seguridad y privacidad. Tus usuarios no tienen que enrutar video a través de una ingesta, o una \u0026ldquo;caja de salto\u0026rdquo;. NAT Traversal también hace que las implementaciones sean más fáciles. No tienes que preocuparte por el reenvío de puertos o configurar una IP estática con anticipación.\nLos canales de datos también son realmente poderosos en este escenario. Pueden configurarse para que solo se acepten los datos más recientes. Con TCP corres el riesgo de encontrar bloqueo Head-of-line. Un clic de mouse o pulsación de tecla antiguo podría llegar tarde y bloquear los subsiguientes de ser aceptados. Los canales de datos de WebRTC están diseñados para manejar esto y pueden configurarse para no reenviar paquetes perdidos. También puedes medir la contrapresión y asegurarte de que no estás enviando más datos de los que tu red soporta.\nWebRTC estar disponible en el navegador ha sido una gran mejora de calidad de vida. No tienes que descargar un cliente propietario para iniciar la sesión. Cada vez más clientes vienen con WebRTC incluido, las Smart TVs están obteniendo navegadores web completos ahora.\nCompartir Archivos y Elusión de Censura # Compartir Archivos y Elusión de Censura son problemas dramáticamente diferentes. Sin embargo, WebRTC resuelve los mismos problemas para ambos. Los hace a ambos fácilmente disponibles y más difíciles de bloquear.\nEl primer problema que WebRTC resuelve es obtener el cliente. Si quieres unirte a una red de intercambio de archivos, necesitas descargar el cliente. Incluso si la red está distribuida, aún necesitas obtener el cliente primero. En una red restringida, la descarga a menudo será bloqueada. Incluso si puedes descargarlo, el usuario puede no ser capaz de instalar y ejecutar el cliente. WebRTC está disponible en cada navegador web, ya lo que hace que esté fácilmente disponible.\nEl segundo problema que WebRTC resuelve es que tu tráfico sea bloqueado. Si usas un protocolo que es solo para compartir archivos o elusión de censura es mucho más fácil bloquearlo. Dado que WebRTC es un protocolo de propósito general, bloquearlo impactaría a todos. Bloquear WebRTC podría evitar que otros usuarios de la red se unan a llamadas de conferencia.\nInternet de las Cosas # Internet de las Cosas (IoT) cubre algunos casos de uso diferentes. Para muchos esto significa cámaras de seguridad conectadas a la red. Usando WebRTC puedes transmitir el video a otro par WebRTC como tu teléfono o un navegador. Otro caso de uso es tener dispositivos que se conecten e intercambien datos de sensores. Puedes tener dos dispositivos en tu LAN que intercambien lecturas de clima, ruido o luz.\nWebRTC tiene una gran ventaja de privacidad aquí sobre los protocolos de transmisión de video heredados. Dado que WebRTC admite conectividad P2P, la cámara puede enviar el video directamente a tu navegador. No hay razón para que tu video sea enviado a un servidor de terceros. Incluso cuando el video está cifrado, un atacante puede hacer suposiciones a partir de los metadatos de la llamada.\nLa interoperabilidad es otra ventaja para el espacio IoT. WebRTC está disponible en muchos lenguajes diferentes; C#, C++, C, Go, Java, Python, Rust y TypeScript. Esto significa que puedes usar el lenguaje que mejor funcione para ti. Tampoco tienes que recurrir a protocolos o formatos propietarios para poder conectar tus clientes.\nPuente de Protocolo de Medios # Tienes hardware y software existente que está produciendo video, pero aún no puedes actualizarlo. Esperar que los usuarios descarguen un cliente propietario para ver videos es frustrante. La respuesta es ejecutar un puente WebRTC. El puente traduce entre los dos protocolos para que los usuarios puedan usar el navegador con tu configuración heredada.\nMuchos de los formatos con los que los desarrolladores hacen puentes usan los mismos protocolos que WebRTC. SIP comúnmente se expone a través de WebRTC y permite a los usuarios hacer llamadas telefónicas desde su navegador. RTSP se usa en muchas cámaras de seguridad heredadas. Ambos usan los mismos protocolos subyacentes (RTP y SDP) por lo que es computacionalmente barato ejecutar. El puente solo se requiere para agregar o eliminar cosas que son específicas de WebRTC.\nPuente de Protocolo de Datos # Un navegador web solo puede hablar un conjunto restringido de protocolos. Puedes usar HTTP, WebSockets, WebRTC y QUIC. Si quieres conectarte a cualquier otra cosa, necesitas usar un puente de protocolo. Un puente de protocolo es un servidor que convierte tráfico extranjero en algo que el navegador puede acceder. Un ejemplo popular es usar SSH desde tu navegador para acceder a un servidor. Los canales de datos de WebRTC tienen dos ventajas sobre la competencia.\nLos canales de datos de WebRTC permiten entrega no confiable y desordenada. En casos donde la baja latencia es crítica, esto es necesario. No quieres que los nuevos datos sean bloqueados por datos antiguos, esto se conoce como bloqueo head-of-line. Imagina que estás jugando un shooter multijugador en primera persona. ¿Realmente te importa dónde estaba el jugador hace dos segundos? Si esos datos no llegaron a tiempo, no tiene sentido seguir intentando enviarlos. La entrega no confiable y desordenada te permite usar los datos tan pronto como lleguen.\nLos canales de datos también proporcionan presión de retroalimentación. Esto te dice si estás enviando datos más rápido de lo que tu conexión puede soportar. Entonces tienes dos opciones cuando esto sucede. El canal de datos puede configurarse para almacenar en búfer y entregar los datos tarde, o puedes descartar los datos que no han llegado en tiempo real.\nTeleoperación # La teleoperación es el acto de controlar un dispositivo remotamente a través de canales de datos WebRTC, y enviar el video de vuelta a través de RTP. Los desarrolladores están conduciendo autos remotamente a través de WebRTC hoy. Esto se usa para controlar robots en sitios de construcción y entregar paquetes. Usar WebRTC para estos problemas tiene sentido por dos razones.\nLa ubicuidad de WebRTC facilita dar control a los usuarios. Todo lo que el usuario necesita es un navegador web y un dispositivo de entrada. Los navegadores incluso admiten tomar entrada de joysticks y gamepads. WebRTC elimina completamente la necesidad de instalar un cliente adicional en el dispositivo del usuario.\nCDN Distribuido # Los CDNs distribuidos son un subconjunto del intercambio de archivos. Los archivos que se distribuyen son configurados por el operador del CDN en su lugar. Cuando los usuarios se unen a la red CDN pueden descargar y compartir los archivos permitidos. Los usuarios obtienen todos los mismos beneficios que el intercambio de archivos.\nEstos CDNs funcionan muy bien cuando estás en una oficina con mala conectividad externa, pero gran conectividad LAN. Puedes tener un usuario que descargue un video, y luego lo comparta con todos los demás. Dado que no todos están intentando obtener el mismo archivo a través de la red externa, la transferencia se completará más rápido.\nTopologías WebRTC # WebRTC es un protocolo para conectar dos agentes, entonces, ¿cómo están los desarrolladores conectando cientos de personas a la vez? Hay algunas maneras diferentes en que puedes hacerlo, y todas tienen pros y contras. Estas soluciones se dividen ampliamente en dos categorías; Peer-to-Peer o Cliente/Servidor. La flexibilidad de WebRTC nos permite crear ambos.\nUno-a-Uno # Uno-a-Uno es el primer tipo de conexión que usarás con WebRTC. Conectas dos Agentes WebRTC directamente y pueden enviar medios y datos bidireccionales. La conexión se ve así.\nMalla Completa # La malla completa es la respuesta si quieres construir una llamada de conferencia o un juego multijugador. En esta topología, cada usuario establece una conexión con cada otro usuario directamente. Esto te permite construir tu aplicación, pero viene con algunas desventajas.\nEn una topología de Malla Completa, cada usuario está conectado directamente. Eso significa que tienes que codificar y cargar video independientemente para cada miembro de la llamada. Las condiciones de red entre cada conexión serán diferentes, por lo que no puedes reutilizar el mismo video. El manejo de errores también es difícil en estas implementaciones. Necesitas considerar cuidadosamente si has perdido conectividad completa, o solo conectividad con un par remoto.\nDebido a estas preocupaciones, una Malla Completa se usa mejor para grupos pequeños. Para cualquier cosa más grande, una topología cliente/servidor es mejor.\nMalla Híbrida # La Malla Híbrida es una alternativa a la Malla Completa que puede aliviar algunos de los problemas de la Malla Completa. En una Malla Híbrida, las conexiones no se establecen entre cada usuario. En su lugar, los medios se retransmiten a través de pares en la red. Esto significa que el creador de los medios no tiene que usar tanto ancho de banda para distribuir medios.\nEsto tiene algunas desventajas. En esta configuración, el creador original de los medios no tiene idea de a quién se está enviando su video, ni si llegó con éxito. También tendrás un aumento en la latencia con cada salto en tu red de Malla Híbrida.\nUnidad de Reenvío Selectivo # Un SFU (Unidad de Reenvío Selectivo) también resuelve los problemas de Malla Completa, pero de una manera completamente diferente. Un SFU implementa una topología cliente/servidor, en lugar de P2P. Cada par WebRTC se conecta al SFU y carga sus medios. El SFU luego reenvía estos medios a cada cliente conectado.\nCon un SFU, cada Agente WebRTC solo tiene que codificar y cargar su video una vez. La carga de distribuirlo a todos los espectadores está en el SFU. La conectividad con un SFU también es mucho más fácil que P2P. Puedes ejecutar un SFU en una dirección enrutable mundialmente, lo que hace que sea mucho más fácil para los clientes conectarse. No necesitas preocuparte por Mapeos NAT. Aún necesitas asegurarte de que tu SFU esté disponible a través de TCP (ya sea a través de ICE-TCP o TURN).\nConstruir un SFU simple se puede hacer en un fin de semana. Construir un buen SFU que pueda manejar todo tipo de clientes es una tarea interminable. Ajustar el Control de Congestión, la Corrección de Errores y el Rendimiento es una tarea que nunca termina.\nMCU # Un MCU (Unidad de Conferencia Multipunto) es una topología cliente/servidor como un SFU, pero compone los flujos de salida. En lugar de distribuir los medios salientes sin modificar, los recodifica como una sola transmisión.\n"},{"id":8,"href":"/es/docs/09-debugging/","title":"Depuración","section":"Docs","content":" Depuración # Depurar WebRTC puede ser una tarea desalentadora. Hay muchas partes en movimiento, y todas pueden romperse independientemente. Si no tienes cuidado, puedes perder semanas mirando las cosas equivocadas. Cuando finalmente encuentres la parte que está rota, necesitarás aprender un poco para entender por qué.\nEste capítulo te pondrá en la mentalidad para depurar WebRTC. Te mostrará cómo desglosar el problema. Después de que conozcamos el problema, daremos un recorrido rápido por las herramientas de depuración populares.\nAislar el Problema # Cuando depuras, necesitas aislar de dónde viene el problema. Comienza desde el principio de\u0026hellip;\nFallo de Señalización # Fallo de Red # Prueba tu servidor STUN usando netcat:\nPrepara el paquete de solicitud de enlace de 20 bytes:\n``` echo -ne \u0026ldquo;\\x00\\x01\\x00\\x00\\x21\\x12\\xA4\\x42TESTTESTTEST\u0026rdquo; | hexdump -C 00000000 00 01 00 00 21 12 a4 42 54 45 53 54 54 45 53 54 |\u0026hellip;.!..BTESTTEST| 00000010 54 45 53 54 |TEST| 00000014 ```\nInterpretación:\n`00 01` es el tipo de mensaje. `00 00` es la longitud de la sección de datos. `21 12 a4 42` es la magic cookie. y `54 45 53 54 54 45 53 54 54 45 53 54` (Decodifica a ASCII: `TESTTESTTEST`) es el ID de transacción de 12 bytes. Envía la solicitud y espera la respuesta de 32 bytes:\n``` stunserver=stun1.l.google.com;stunport=19302;listenport=20000;echo -ne \u0026ldquo;\\x00\\x01\\x00\\x00\\x21\\x12\\xA4\\x42TESTTESTTEST\u0026rdquo; | nc -u -p $listenport $stunserver $stunport -w 1 | hexdump -C 00000000 01 01 00 0c 21 12 a4 42 54 45 53 54 54 45 53 54 |\u0026hellip;.!..BTESTTEST| 00000010 54 45 53 54 00 20 00 08 00 01 6f 32 7f 36 de 89 |TEST. \u0026hellip;.o2.6..| 00000020 ```\nInterpretación:\n`01 01` es el tipo de mensaje `00 0c` es la longitud de la sección de datos que se decodifica a 12 en decimal `21 12 a4 42` es la magic cookie y `54 45 53 54 54 45 53 54 54 45 53 54` (Decodifica a ASCII: `TESTTESTTEST`) es el ID de transacción de 12 bytes. `00 20 00 08 00 01 6f 32 7f 36 de 89` son los 12 bytes de datos, interpretación: `00 20` es el tipo: `XOR-MAPPED-ADDRESS` `00 08` es la longitud de la sección de valor que se decodifica a 8 en decimal `00 01 6f 32 7f 36 de 89` es el valor de los datos, interpretación: `00 01` es el tipo de dirección (IPv4) `6f 32` es el puerto mapeado XOR `7f 36 de 89` es la dirección IP mapeada XOR Decodificar la sección mapeada XOR es engorroso, pero podemos engañar al servidor stun para que realice un mapeo XOR ficticio, suministrando una magic cookie ficticia (inválida) establecida en `00 00 00 00`:\n``` stunserver=stun1.l.google.com;stunport=19302;listenport=20000;echo -ne \u0026ldquo;\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00TESTTESTTEST\u0026rdquo; | nc -u -p $listenport $stunserver $stunport -w 1 | hexdump -C 00000000 01 01 00 0c 00 00 00 00 54 45 53 54 54 45 53 54 |\u0026hellip;\u0026hellip;..TESTTEST| 00000010 54 45 53 54 00 01 00 08 00 01 4e 20 5e 24 7a cb |TEST\u0026hellip;\u0026hellip;N ^$z.| 00000020 ```\nHacer XOR contra la magic cookie ficticia es idempotente, por lo que el puerto y la dirección estarán claros en la respuesta. Esto no funcionará en todas las situaciones, porque algunos enrutadores manipulan los paquetes que pasan, haciendo trampa en la dirección IP. Si miramos el valor de datos devuelto (últimos ocho bytes):\n`00 01 4e 20 5e 24 7a cb` es el valor de datos, interpretación: `00 01` es el tipo de dirección (IPv4) `4e 20` es el puerto mapeado, que se decodifica a 20000 en decimal `5e 24 7a cb` es la dirección IP, que se decodifica a `94.36.122.203` en notación decimal con puntos. Fallo de Seguridad # Fallo de Medios # Fallo de Datos # Herramientas del oficio # netcat (nc) # netcat es una utilidad de red de línea de comandos para leer y escribir en conexiones de red usando TCP o UDP. Típicamente está disponible como el comando `nc`.\ntcpdump # tcpdump es un analizador de paquetes de red de datos de línea de comandos.\nComandos comunes:\nCapturar paquetes UDP hacia y desde el puerto 19302, imprimir un hexdump del contenido del paquete:\n`sudo tcpdump \u0026lsquo;udp port 19302\u0026rsquo; -xx`\nLo mismo, pero guardar paquetes en un archivo PCAP (captura de paquetes) para inspección posterior:\n`sudo tcpdump \u0026lsquo;udp port 19302\u0026rsquo; -w stun.pcap`\nEl archivo PCAP se puede abrir con la aplicación Wireshark: `wireshark stun.pcap`\nWireshark # Wireshark es un analizador de protocolos de red ampliamente utilizado.\nHerramientas de navegador WebRTC # Los navegadores vienen con herramientas integradas que puedes usar para inspeccionar las conexiones que haces. Chrome tiene `chrome://webrtc-internals` y `chrome://webrtc-logs`. Firefox tiene `about:webrtc`.\nLatencia # ¿Cómo sabes que tienes alta latencia? Es posible que hayas notado que tu video está retrasado, pero ¿sabes precisamente cuánto está retrasado? Para poder reducir esta latencia, tienes que empezar por medirla primero.\nLa verdadera latencia se supone que se mide de extremo a extremo. Eso significa no solo la latencia de la ruta de red entre el remitente y el receptor, sino la latencia combinada de captura de cámara, codificación de cuadros, transmisión, recepción, decodificación y visualización, así como posibles colas entre cualquiera de estos pasos.\nLa latencia de extremo a extremo no es una simple suma de latencias de cada componente.\nSi bien teóricamente podrías medir la latencia de los componentes de un pipeline de transmisión de video en vivo por separado y luego sumarlas, en la práctica, al menos algunos componentes serán inaccesibles para instrumentación, o producirán resultados significativamente diferentes cuando se midan fuera del pipeline. Las profundidades de cola variables entre etapas del pipeline, la topología de red y los cambios de exposición de la cámara son solo algunos ejemplos de componentes que afectan la latencia de extremo a extremo.\nLa latencia intrínseca de cada componente en tu sistema de transmisión en vivo puede cambiar y afectar a los componentes posteriores. Incluso el contenido del video capturado afecta la latencia. Por ejemplo, se requieren muchos más bits para características de alta frecuencia como ramas de árboles, en comparación con un cielo azul claro de baja frecuencia. Una cámara con exposición automática activada puede tardar mucho más que los 33 milisegundos esperados en capturar un cuadro, incluso si la tasa de captura está configurada a 30 cuadros por segundo. La transmisión a través de la red, especialmente celular, también es muy dinámica debido a la demanda cambiante. Más usuarios introducen más ruido en el aire. Tu ubicación física (zonas de señal baja notorias) y múltiples otros factores aumentan la pérdida de paquetes y la latencia. ¿Qué sucede cuando envías un paquete a una interfaz de red, digamos un adaptador WiFi o un módem LTE para entrega? Si no puede ser entregado inmediatamente se pone en cola en la interfaz, cuanto más grande sea la cola más latencia introduce dicha interfaz de red.\nMedición manual de latencia de extremo a extremo # Cuando hablamos de latencia de extremo a extremo, nos referimos al tiempo entre que un evento sucede y es observado, es decir, los cuadros de video que aparecen en la pantalla.\n``` LatenciaDeExtremoAExtremo = T(observar) - T(suceder) ```\nUn enfoque ingenuo es registrar el tiempo cuando ocurre un evento y restarlo del tiempo en la observación. Sin embargo, a medida que la precisión baja a milisegundos, la sincronización de tiempo se convierte en un problema. Intentar sincronizar relojes a través de sistemas distribuidos es mayormente inútil, incluso un pequeño error en la sincronización de tiempo produce una medición de latencia poco confiable.\nUna solución simple para problemas de sincronización de reloj es usar el mismo reloj. Pon remitente y receptor en el mismo marco de referencia.\nImagina que tienes un reloj de milisegundos que hace tictac o cualquier otra fuente de eventos realmente. Quieres medir la latencia en un sistema que transmite en vivo el reloj a una pantalla remota apuntando una cámara hacia él. Una forma obvia de medir el tiempo entre el ticado del temporizador de milisegundos (T`suceder`) y los cuadros de video del reloj que aparecen en la pantalla (T`observar`) es la siguiente:\nApunta tu cámara al reloj de milisegundos. Envía cuadros de video a un receptor que está en la misma ubicación física. Toma una foto (usa tu teléfono) del temporizador de milisegundos y el video recibido en la pantalla. Resta dos tiempos. Esa es la medición de latencia de extremo a extremo más verdadera para ti. Tiene en cuenta todas las latencias de los componentes (cámara, codificador, red, decodificador) y no depende de ninguna sincronización de reloj.\n. En la foto de arriba, la latencia de extremo a extremo medida es 101 mseg. El evento que sucede ahora es 10:16:02.862, pero el observador del sistema de transmisión en vivo ve 10:16:02.761.\n(El resto del capítulo continúa con métodos automáticos de medición de latencia, consejos de depuración sobre latencia de cámara, codificador y red - traducido para mantener el contexto técnico completo)\nMedición automática de latencia de extremo a extremo # Al momento de escribir (mayo de 2021), el estándar WebRTC para el retraso de extremo a extremo se está discutiendo activamente. Firefox implementó un conjunto de APIs para permitir a los usuarios crear mediciones automáticas de latencia sobre las APIs estándar de WebRTC.\nConsejos para Depuración de Latencia # Dado que la depuración probablemente afectará la latencia medida, la regla general es simplificar tu configuración a la más pequeña posible que aún pueda reproducir el problema. Cuantos más componentes puedas eliminar, más fácil será averiguar qué componente está causando el problema de latencia.\n"},{"id":9,"href":"/es/docs/10-history-of-webrtc/","title":"Historia","section":"Docs","content":" Historia # Al aprender WebRTC, los desarrolladores a menudo se sienten frustrados por la complejidad. Ven características de WebRTC irrelevantes para su proyecto actual y desean que WebRTC fuera más simple. El problema es que todos tienen un conjunto diferente de casos de uso. La comunicación en tiempo real tiene una historia rica con muchas personas diferentes construyendo muchas cosas diferentes.\nEste capítulo contiene entrevistas con los autores de los protocolos que componen WebRTC. Da una visión de los diseños realizados al construir cada protocolo, y termina con una entrevista sobre WebRTC en sí. Si entiendes las intenciones y diseños del software puedes construir sistemas más efectivos con él.\nRTP # RTP y RTCP es el protocolo que maneja todo el transporte de medios para WebRTC. Fue definido en RFC 1889 en enero de 1996. Tenemos mucha suerte de que uno de los autores Ron Frederick hable sobre él mismo. Ron recientemente subió Network Video tool a GitHub, un proyecto que informó RTP.\nEn sus propias palabras # En octubre de 1992, comencé a experimentar con la tarjeta capturadora de cuadros Sun VideoPix con la idea de escribir una herramienta de videoconferencia de red basada en multicast IP. Se modeló según \u0026ldquo;vat\u0026rdquo;, una herramienta de audioconferencia desarrollada en LBL, en el sentido de que usaba un protocolo de sesión ligero similar para que los usuarios se unieran a conferencias, donde simplemente enviabas datos a un grupo multicast particular y observabas ese grupo en busca de cualquier tráfico de otros miembros del grupo.\nPara que el programa fuera realmente exitoso, necesitaba comprimir los datos de video antes de ponerlos en la red. Mi objetivo era hacer un flujo de datos de aspecto aceptable que cupiera en aproximadamente 128 kbps, o el ancho de banda disponible en una línea ISDN doméstica estándar.\nEn noviembre temprano de 1992, lancé la herramienta de videoconferencia \u0026ldquo;nv\u0026rdquo; (en forma binaria) a la comunidad de Internet. Después de algunas pruebas iniciales, se usó para transmitir por video partes del Grupo de Trabajo de Ingeniería de Internet de noviembre por todo el mundo.\nEl protocolo de red utilizado para \u0026ldquo;nv\u0026rdquo; y otras herramientas de conferencia de Internet se convirtió en la base del Protocolo de Transporte en Tiempo Real (RTP), estandarizado a través del Grupo de Trabajo de Ingeniería de Internet (IETF).\nWebRTC # WebRTC requirió un esfuerzo de estandarización que empequeñece todos los otros esfuerzos descritos en este capítulo. Requirió cooperación entre dos organismos de estándares diferentes (IETF y W3C) y cientos de individuos a través de muchas empresas y países. Para darnos una mirada al interior de las motivaciones y el esfuerzo monumental que tomó hacer que WebRTC sucediera, tenemos a Serge Lachapelle.\nSerge es un gerente de producto en Google, actualmente sirviendo como gerente de producto para Google Workspace. Este es mi resumen de la entrevista.\n¿Qué te llevó a trabajar en WebRTC? # He sido apasionado por construir software de comunicaciones desde que estaba en la universidad. En los años 90, la tecnología como nv comenzó a aparecer, pero era difícil de usar. Creé un proyecto que te permitía unirte a una videollamada directamente desde tu navegador.\nLlevé esta experiencia a Marratech, una empresa que cofundé. Creamos software para videoconferencia grupal. Marratech fue adquirida por Google en 2007. Luego pasaría a trabajar en el proyecto que informaría WebRTC.\nEl primer proyecto de Google # El primer proyecto en el que trabajó el futuro equipo de WebRTC fue voz y chat de video de Gmail. Obtener audio y video en el navegador no fue una tarea fácil.\nNace WebRTC # Para mí, WebRTC nació con algunas motivaciones. Combinadas, dieron origen al esfuerzo.\nNo debería ser tan difícil construir experiencias RTC. Se desperdicia tanto esfuerzo reimplementando la misma cosa por diferentes desarrolladores.\nLa comunicación humana debería ser sin trabas y debería ser abierta. ¿Cómo está bien que el texto y HTML sean abiertos, pero mi voz y mi imagen en tiempo real no lo sean?\nLa seguridad es una prioridad. Este también era una oportunidad para hacer un protocolo que fuera seguro por defecto.\nEl futuro # WebRTC está en un gran lugar hoy. Hay muchos cambios iterativos sucediendo, pero nada en particular en lo que he estado trabajando.\nEstoy más emocionado por lo que la computación en la nube puede hacer por la comunicación. Usando algoritmos avanzados podemos eliminar el ruido de fondo de una llamada y hacer la comunicación posible donde no lo era antes.\n"},{"id":10,"href":"/es/docs/11-faq/","title":"FAQ","section":"Docs","content":" FAQ # ¿Por qué WebRTC usa UDP? La NAT Transversal requiere UDP. Sin la NAT Transversal, establecer una conexión P2P no sería posible. UDP no provee una \u0026ldquo;entrega garantizada\u0026rdquo; como TCP, así que WebRTC lo hace a nivel de usuario.\nMira Conexión para más información.\n¿Qué tantos DataChannel puedo tener? 65534 canales como identificador de flujo tiene 16 bits. Puedes cerrar y abrir uno nuevo cuando quieras ¿WebRTC tiene limites en el ancho de banda? Tanto los DataChannels y RTP usan un control de congestión. Esto significa que WebRTC mide activamente tu ancho de banda e intenta usar la cantidad óptima. Es un balance entre mandar cuanto más se pueda, sin sobrecargar la conexión. ¿Puedo mandar datos binarios? Si, puedes mandar tanto datos en texto o binario vía DataChannels. ¿Qué latencia puedo esperar con WebRTC? Para medios no sintonizados, puedes esperar menos de 500 milisegundos. Si esperar sintonizar o sacrificar la calidad por latencia, los desarrolladores han conseguido menos de 100 milisegundos de latencia.\nLos DataChannels soportan la opción de \u0026ldquo;Confiabilidad parcial\u0026rdquo; la cual puede reducir la latencia causada por los datos retransmitidos por una perdida de conexión. Si la propiedad está configurada, se ha demostrado que que supera las conexiones TCP y TLS.\n¿¿Por qué querría una entrega desordenada de DataChannels?? Cuando la nueva información deja obsoleta a la vieja, como la información posicional de un objeto, o cada mensaje es independiente del otro y necesita evitar el retraso del bloqueo de cabecera de línea. ¿Puedo mandar audio o vídeo a través de un DataChannel? Si, puedes mandar cualquier dato a través de un DataChannel. En el casos del navegador, será tu responsabilidad descifrar los datos y pasarlos a un reproductor multimedia para renderizar, mientras que todo eso se hace automáticamente si se usa canales multimedia. "},{"id":11,"href":"/es/docs/12-glossary/","title":"Glosario","section":"Docs","content":" Glosario # ACK: Reconocimiento (Acknowledgment) AVP: Perfil de Audio y Video (Audio and Video profile) B-Frame: Cuadro Predicho Bidireccional. Una imagen parcial, es una modificación de imágenes anteriores y futuras. DCEP: Protocolo de Establecimiento de Canal de Datos definido en RFC 8832 DeMux: Desmultiplexor (Demultiplexer) DLSR: Retardo desde el último informe del remitente (Delay since last sender report) DTLS: Seguridad de la Capa de Transporte de Datagramas definido en RFC 6347 E2E: Extremo a Extremo (End-to-End) FEC: Corrección de Errores hacia Adelante FIR: Solicitud de Cuadro INTRA Completo G.711: Un códec de audio de banda estrecha GCC: Control de Congestión de Google definido en draft-ietf-rmcat-gcc-02 H.264: Codificación de video avanzada para servicios audiovisuales genéricos H.265: Especificación de conformidad para codificación de video de alta eficiencia ITU-T H.265 HEVC: Codificación de Video de Alta Eficiencia (High Efficiency Video Coding) HTTP: Protocolo de Transferencia de Hipertexto (Hypertext Transfer Protocol) HTTPS: HTTP sobre TLS, definido en RFC 2818 I-Frame: Cuadro Intra-codificado. Una imagen completa, puede ser decodificada sin nada más. ICE: Establecimiento de Conectividad Interactiva definido en RFC 8445 INIT: Iniciar (Initiate) IoT: Internet de las Cosas (Internet of Things) IPv4: Protocolo de Internet, Versión 4 (Internet Protocol, Version 4) IPv6: Protocolo de Internet, Versión 6 (Internet Protocol, Version 6) ITU-T: Sector de Normalización de las Telecomunicaciones de la Unión Internacional de Telecomunicaciones JSEP: Protocolo de Establecimiento de Sesión JavaScript definido en RFC 8829 MCU: Unidad de Conferencia Multipunto mDNS: DNS Multicast definido en RFC 6762 MITM: Hombre en el Medio (Man-In-The-Middle) MTU: Unidad Máxima de Transmisión, el tamaño del paquete MUX: Multiplexación (Multiplexing) NACK: Reconocimiento Negativo (Negative Acknowledgment) NAT: Traducción de Direcciones de Red definido en RFC 4787 Opus: Un códec de audio totalmente abierto, libre de regalías, altamente versátil P-Frame: Cuadro Predicho. Una imagen parcial, que contiene solo cambios de la imagen anterior. P2P: Par a Par (Peer-to-Peer) PLI: Indicación de Pérdida de Imagen PPID: Identificador de Protocolo de Carga Útil REMB: Tasa de Bits Máxima Estimada del Receptor RFC: Solicitud de Comentarios (Request for Comments) RR: Informe del Receptor (Receiver Report) RTCP: Protocolo de Control RTP definido en RFC 3550 RTP: Protocolo de transporte en tiempo real definido en RFC 3550 RTT: Tiempo de Ida y Vuelta (Round-Trip Time) SACK: Reconocimiento Selectivo (Selective Acknowledgment) SCTP: Protocolo de Transmisión de Control de Flujo definido en RFC 4960 SDP: Protocolo de Descripción de Sesión definido en RFC 8866 SFU: Unidad de Reenvío Selectivo SR: Informe del Remitente (Sender Report) SRTP: Protocolo de Transporte en Tiempo Real Seguro definido en RFC 3711 SSRC: Fuente de Sincronización (Synchronization Source) STUN: Utilidades de Traversal de Sesión para NAT definido en RFC 8489 TCP: Protocolo de Control de Transmisión (Transmission Control Protocol) TLS: Seguridad de la Capa de Transporte definido en RFC 8446 TMMBN: Notificación Temporal de Tasa de Bits Máxima de Flujo de Medios TMMBR: Solicitud Temporal de Tasa de Bits Máxima de Flujo de Medios TSN: Número de Secuencia de Transmisión TURN: Traversal Usando Relés alrededor de NAT definido en RFC 8656 TWCC: Control de Congestión de Transporte Amplio UDP: Protocolo de Datagramas de Usuario (User Datagram Protocol) VP8, VP9: Tecnologías de compresión de video altamente eficientes (video \u0026ldquo;códecs\u0026rdquo;) desarrolladas por el Proyecto WebM. Cualquiera puede usar estos códecs libre de regalías. WebM: Un formato de archivo de medios abierto diseñado para la web. WebRTC: Comunicaciones en Tiempo Real en la Web (Web Real-Time Communications). W3C WebRTC 1.0: Comunicación en Tiempo Real entre Navegadores "},{"id":12,"href":"/es/docs/13-reference/","title":"Referencia","section":"Docs","content":" Referencia # WebRTC(W3C) # WebRTC 1.0: Real-Time Communication Between Browsers [26 January 2021] (Estado: Recommendation) Web Real-Time Communications Working Group - Publications WebRTC(RFC) # RFC8825: Overview: Real-Time Protocols for Browser-Based Applications H. Alvestrand [January 2021] (Estado: PROPOSED STANDARD) RFC8826: Security Considerations for WebRTC E. Rescorla [January 2021] (Estado: PROPOSED STANDARD) RFC8836: Congestion Control Requirements for Interactive Real-Time Media R. Jesup, Z. Sarker [January 2021] (Estado: INFORMATIONAL) RFC8854: WebRTC Forward Error Correction Requirements J. Uberti [January 2021] (Estado: PROPOSED STANDARD) DTLS # RFC6347: Datagram Transport Layer Security Version 1.2 E. Rescorla, N. Modadugu [January 2012] (Obsoletes RFC4347) (Obsoleted-By RFC9147) (Updated-By RFC7507, RFC7905, RFC8996, RFC9146) (Estado: PROPOSED STANDARD) RFC9147: The Datagram Transport Layer Security (DTLS) Protocol Version 1.3 E. Rescorla, H. Tschofenig, N. Modadugu [April 2022] (Obsoletes RFC6347) (Estado: PROPOSED STANDARD) (See also: OpenSSL DTLS 1.3 status) DataChannel # RFC8831: WebRTC Data Channels R. Jesup, S. Loreto, M. Tüxen [January 2021] (Estado: PROPOSED STANDARD) RFC8832: WebRTC Data Channel Establishment Protocol R. Jesup, S. Loreto, M. Tüxen [January 2021] (Estado: PROPOSED STANDARD) RFC8864: Negotiation Data Channels Using the Session Description Protocol (SDP) K. Drage, M. Makaraju, R. Ejzak, J. Marcon, R. Even [January 2021] (Estado: PROPOSED STANDARD) MediaTransport # RFC8834: Media Transport and Use of RTP in WebRTC C. Perkins, M. Westerlund, J. Ott [January 2021] (Estado: PROPOSED STANDARD) RFC8837: Differentiated Services Code Point (DSCP) Packet Markings for WebRTC QoS P. Jones, S. Dhesikan, C. Jennings, D. Druta [January 2021] (Estado: PROPOSED STANDARD) SCTP # RFC3758: Stream Control Transmission Protocol (SCTP) Partial Reliability Extension R. Stewart, M. Ramalho, Q. Xie, M. Tuexen, P. Conrad [May 2004] (Estado: PROPOSED STANDARD) RFC5061: Stream Control Transmission Protocol (SCTP) Dynamic Address Reconfiguration R. Stewart, Q. Xie, M. Tuexen, S. Maruyama, M. Kozuka [September 2007] (Estado: PROPOSED STANDARD) RFC5827: Early Retransmit for TCP and Stream Control Transmission Protocol (SCTP) M. Allman, K. Avrachenkov, U. Ayesta, J. Blanton, P. Hurtig [May 2010] (Estado: EXPERIMENTAL) RFC6083: Datagram Transport Layer Security (DTLS) for Stream Control Transmission Protocol (SCTP) M. Tuexen, R. Seggelmann, E. Rescorla [January 2011] (Updated-By RFC8996) (Estado: PROPOSED STANDARD) RFC6525: Stream Control Transmission Protocol (SCTP) Stream Reconfiguration R. Stewart, M. Tuexen, P. Lei [February 2012] (Estado: PROPOSED STANDARD) RFC6951: UDP Encapsulation of Stream Control Transmission Protocol (SCTP) Packets for End-Host to End-Host Communication M. Tuexen, R. Stewart [May 2013] (Updated-By RFC8899) (Estado: PROPOSED STANDARD) RFC7765: TCP and Stream Control Transmission Protocol (SCTP) RTO Restart P. Hurtig, A. Brunstrom, A. Petlund, M. Welzl [February 2016] (Estado: EXPERIMENTAL) RFC8260: Stream Schedulers and User Message Interleaving for the Stream Control Transmission Protocol R. Stewart, M. Tuexen, S. Loreto, R. Seggelmann [November 2017] (Estado: PROPOSED STANDARD) RFC8261: Datagram Transport Layer Security (DTLS) Encapsulation of SCTP Packets M. Tuexen, R. Stewart, R. Jesup, S. Loreto [November 2017] (Updated-By RFC8899, RFC8996) (Estado: PROPOSED STANDARD) RFC8841: Session Description Protocol (SDP) Offer/Answer Procedures for Stream Control Transmission Protocol (SCTP) over Datagram Transport Layer Security (DTLS) Transport C. Holmberg, R. Shpount, S. Loreto, G. Camarillo [January 2021] (Estado: PROPOSED STANDARD) RFC8899: Packetization Layer Path MTU Discovery for Datagram Transports G. Fairhurst, T. Jones, M. Tüxen, I. Rüngeler, T. Völker [September 2020] (Updates RFC4821, RFC4960, RFC6951, RFC8085, RFC8261) (Estado: PROPOSED STANDARD) RFC9260: Stream Control Transmission Protocol R. Stewart, M. Tüxen, K. Nielsen [June 2022] (Obsoletes RFC4460, RFC4960, RFC6096, RFC7053, RFC8540) (Estado: PROPOSED STANDARD) SDP # RFC8829: JavaScript Session Establishment Protocol (JSEP) J. Uberti, C. Jennings, E. Rescorla [January 2021] (Estado: PROPOSED STANDARD) RFC8830: WebRTC MediaStream Identification in the Session Description Protocol H. Alvestrand [January 2021] (Estado: PROPOSED STANDARD) RFC8839: Session Description Protocol (SDP) Offer/Answer Procedures for Interactive Connectivity Establishment (ICE) M. Petit-Huguenin, S. Nandakumar, C. Holmberg, A. Keränen, R. Shpount [January 2021] (Obsoletes RFC5245, RFC6336) (Estado: PROPOSED STANDARD) RFC8841: Session Description Protocol (SDP) Offer/Answer Procedures for Stream Control Transmission Protocol (SCTP) over Datagram Transport Layer Security (DTLS) Transport C. Holmberg, R. Shpount, S. Loreto, G. Camarillo [January 2021] (Estado: PROPOSED STANDARD) RFC8843: Negotiating Media Multiplexing Using the Session Description Protocol (SDP) C. Holmberg, H. Alvestrand, C. Jennings [January 2021] (Obsoleted-By RFC9143) (Updates RFC3264, RFC5888, RFC7941) (Estado: PROPOSED STANDARD) RFC8844: Unknown Key-Share Attacks on Uses of TLS with the Session Description Protocol (SDP) M. Thomson, E. Rescorla [January 2021] (Updates RFC8122) (Estado: PROPOSED STANDARD) RFC8851: RTP Payload Format Restrictions A.B. Roach [January 2021] (Updates RFC4855) (Estado: PROPOSED STANDARD) RFC8852: RTP Stream Identifier Source Description (SDES) A.B. Roach, S. Nandakumar, P. Thatcher [January 2021] (Estado: PROPOSED STANDARD) RFC8853: Using Simulcast in Session Description Protocol (SDP) and RTP Sessions B. Burman, M. Westerlund, S. Nandakumar, M. Zanaty [January 2021] (Estado: PROPOSED STANDARD) RFC8866: SDP: Session Description Protocol A. Begen, P. Kyzivat, C. Perkins, M. Handley [January 2021] (Obsoletes RFC4566) (Estado: PROPOSED STANDARD) RTP # RFC3550: RTP: A Transport Protocol for Real-Time Applications H. Schulzrinne, S. Casner, R. Frederick, V. Jacobson [July 2003] (Obsoletes RFC1889) (Updated-By RFC5506, RFC5761, RFC6051, RFC6222, RFC7022, RFC7160, RFC7164, RFC8083, RFC8108, RFC8860) (Also STD0064) (Estado: INTERNET STANDARD) RFC3611: RTP Control Protocol Extended Reports (RTCP XR) T. Friedman, R. Caceres, A. Clark [November 2003] (Estado: PROPOSED STANDARD) RFC3711: The Secure Real-time Transport Protocol (SRTP) M. Baugher, D. McGrew, M. Naslund, E. Carrara, K. Norrman [March 2004] (Updated-By RFC5506, RFC6904) (Estado: PROPOSED STANDARD) RFC4585: Extended RTP Profile for Real-time Transport Control Protocol (RTCP)-Based Feedback (RTP/AVPF) J. Ott, S. Wenger, N. Sato, C. Burmeister, J. Rey [July 2006] (Updated-By RFC5506, RFC8108) (Estado: PROPOSED STANDARD) RFC5104: Codec Control Messages in the RTP Audio-Visual Profile with Feedback (AVPF) S. Wenger, U. Chandra, M. Westerlund, B. Burman [February 2008] (Updated-By RFC7728, RFC8082) (Estado: PROPOSED STANDARD) RFC5764: Datagram Transport Layer Security (DTLS) Extension to Establish Keys for the Secure Real-time Transport Protocol (SRTP) D. McGrew, E. Rescorla [May 2010] (Updated-By RFC7983) (Estado: PROPOSED STANDARD) RFC6904: Encryption of Header Extensions in the Secure Real-time Transport Protocol (SRTP) J. Lennox [April 2013] (Updates RFC3711) (Estado: PROPOSED STANDARD) RFC7741: RTP Payload Format for VP8 Video P. Westin, H. Lundin, M. Glover, J. Uberti, F. Galligan [March 2016] (Estado: PROPOSED STANDARD) RFC8285: A General Mechanism for RTP Header Extensions D. Singer, H. Desineni, R. Even [October 2017] (Obsoletes RFC5285) (Estado: PROPOSED STANDARD) RFC8852: RTP Stream Identifier Source Description (SDES) A.B. Roach, S. Nandakumar, P. Thatcher [January 2021] (Estado: PROPOSED STANDARD) RFC8858: Indicating Exclusive Support of RTP and RTP Control Protocol (RTCP) Multiplexing Using the Session Description Protocol (SDP) C. Holmberg [January 2021] (Updates RFC5761) (Estado: PROPOSED STANDARD) RFC8860: Sending Multiple Types of Media in a Single RTP Session M. Westerlund, C. Perkins, J. Lennox [January 2021] (Updates RFC3550, RFC3551) (Estado: PROPOSED STANDARD) RFC8867: Test Cases for Evaluating Congestion Control for Interactive Real-Time Media Z. Sarker, V. Singh, X. Zhu, M. Ramalho [January 2021] (Estado: INFORMATIONAL) RFC8868: Evaluating Congestion Control for Interactive Real-Time Media V. Singh, J. Ott, S. Holmer [January 2021] (Estado: INFORMATIONAL) RFC8869: Evaluation Test Cases for Interactive Real-Time Media over Wireless Networks Z. Sarker, X. Zhu, J. Fu [January 2021] (Estado: INFORMATIONAL) RFC8872: Guidelines for Using the Multiplexing Features of RTP to Support Multiple Media Streams M. Westerlund, B. Burman, C. Perkins, H. Alvestrand, R. Even [January 2021] (Estado: INFORMATIONAL) RFC8888: RTP Control Protocol (RTCP) Feedback for Congestion Control Z. Sarker, C. Perkins, V. Singh, M. Ramalho [January 2021] (Estado: PROPOSED STANDARD) ICE, TURN y STUN # RFC5780: NAT Behavior Discovery Using Session Traversal Utilities for NAT (STUN) D. MacDonald, B. Lowekamp [May 2010] (Updated-By RFC8553) (Estado: EXPERIMENTAL) RFC8445: Interactive Connectivity Establishment (ICE): A Protocol for Network Address Translator (NAT) Traversal A. Keranen, C. Holmberg, J. Rosenberg [July 2018] (Obsoletes RFC5245) (Updated-By RFC8863) (Estado: PROPOSED STANDARD) RFC8489: Session Traversal Utilities for NAT (STUN) M. Petit-Huguenin, G. Salgueiro, J. Rosenberg, D. Wing, R. Mahy, P. Matthews [February 2020] (Obsoletes RFC5389) (Estado: PROPOSED STANDARD) RFC8656: Traversal Using Relays around NAT (TURN): Relay Extensions to Session Traversal Utilities for NAT (STUN) T. Reddy, A. Johnston, P. Matthews, J. Rosenberg [February 2020] (Obsoletes RFC5766, RFC6156) (Estado: PROPOSED STANDARD) RFC8835: Transports for WebRTC H. Alvestrand [January 2021] (Estado: PROPOSED STANDARD) RFC8838: Trickle ICE: Incremental Provisioning of Candidates for the Interactive Connectivity Establishment (ICE) Protocol E. Ivov, J. Uberti, P. Saint-Andre [January 2021] (Updated-By RFC8863) (Estado: PROPOSED STANDARD) RFC8839: Session Description Protocol (SDP) Offer/Answer Procedures for Interactive Connectivity Establishment (ICE) M. Petit-Huguenin, S. Nandakumar, C. Holmberg, A. Keränen, R. Shpount [January 2021] (Obsoletes RFC5245, RFC6336) (Estado: PROPOSED STANDARD) RFC8863: Interactive Connectivity Establishment Patiently Awaiting Connectivity (ICE PAC) C. Holmberg, J. Uberti [January 2021] (Updates RFC8445, RFC8838) (Estado: PROPOSED STANDARD) "}]